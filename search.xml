<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Papers Reading about LLM</title>
      <link href="/2024/08/16/Papers-Reading-about-LLM/"/>
      <url>/2024/08/16/Papers-Reading-about-LLM/</url>
      
        <content type="html"><![CDATA[<p><strong>阅读大纲</strong></p><table>    <tr>        <th>Filed</th>        <th>Paper</th>        <th>Date</th>      </tr >    <tr >        <td rowspan="1"><b>Dataset</b></td>        <td>Img-Diff</td>        <td>24-08-16</td>    </tr>    <tr >        <td rowspan="1"><b>Agent</b></td>        <td>The AI Scientist</td>        <td>24-09-03</td>    </tr></table><h1 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h1><h3>Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models</h3><ul><li><a href="https://arxiv.org/abs/2408.04594">ArXiv</a> <a href="https://github.com/modelscope/data-juicer/tree/ImgDiff">Code</a></li><li>简介：MLLMs的两个关键研究点：模型结构和数据质量。本文提出Img-Diff数据集，利用新数据集对MLLMs微调后效果更好。</li><li>关键技术：<ol><li>Prompt-to-Prompt的方式使用图像对和Stable-Diffusion-XL生成object replacement相似图像对，采用多个过滤模块提高数据质量</li><li>Difference Area Generator提取包含不同目标的bounding box</li><li>Difference Captions Generator生成不同区域的文字描述</li></ol></li></ul><div align="center">  <img src="24-08-16Img-Diff1.png"></div><div align="center">  <img src="24-08-16Img-Diff2.png"></div><div align="center">  <img src="24-08-16Img-Diff3.png"></div><p><br></p><hr><h1 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h1><h3>The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</h3><ul><li>Sakana AI <a href="https://web3.arxiv.org/abs/2408.06292">ArXiv</a> <a href="https://github.com/SakanaAI/AI-Scientist">Code</a></li><li>简介：使用LLM提出第一个全自动科学发现：The AI Scientist，可以端到端生成研究ideas、写代码、开展实验、可视化结果、写论文、模拟评估。在三个研究方向diffusion modeling、transformer-based language modeling和learning dynamics上展开，生成的论文可以达到顶会WR水平。</li><li>关键技术：<ol><li>Idea生成：使用LLM和多轮COT+self-reflection提升idea生成和实验计划，使用Semantic Scholar API过滤相似ideas。</li><li>实验迭代：使用代码助手Aider开展实验收集结果</li><li>写Paper：提示会议模版、论文结构框架，不包括引用。然后用Semantic Scholar API找相关工作并提示给Aider生成参考文献，最后修正生成最终latex</li><li>论文review：利用NeurIPS review guidelines设计一个基于GPT-4o的agent</li></ol></li></ul><div align="center">  <img src="24-09-03The-AI-Scientist.png"></div><p><br></p><hr><p>自回归学习：自回归 (AR) 模型是统计和时间序列模型，用于根据数据点的先前值进行分析和预测。<br>自回归模型假设给定时间变量的值与其过去的值线性相关，这使得它们可用于建模和预测时间相关数据。<br>自回归模型假设变量在任何给定时间的值都线性依赖于其先前的值。换句话说，自回归模型旨在捕获和量化变量的过去对其现在和未来的影响。</p><p>我们提出了视觉自回归建模（VAR），这是一种新一代范式，它将图像上的自回归学习重新定义为从粗到精的“下一尺度”<br>“预测”或“下一分辨率预测”，与标准的光栅扫描“下一个令牌预测”不同。</p>]]></content>
      
      
      <categories>
          
          <category> Reading Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
            <tag> CV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Daily Leetcode</title>
      <link href="/2024/07/09/Daily-Leetcode/"/>
      <url>/2024/07/09/Daily-Leetcode/</url>
      
        <content type="html"><![CDATA[<h1 id="每日一题"><a href="#每日一题" class="headerlink" title="每日一题"></a>每日一题</h1><h2 id="DP"><a href="#DP" class="headerlink" title="DP"></a>DP</h2><ul><li>24.7.21 <a href="https://leetcode.cn/problems/maximum-subarray-sum-with-one-deletion/">1186删除一次得到子数组最大和</a> 枚举数组右端点讨论</li><li>24.7.23 <a href="https://leetcode.cn/problems/find-the-sum-of-subsequence-powers/">3098求出所有子序列的能量和</a> 子序列枚举，很难想到dfs的定义</li><li>24.8.11 <a href="https://leetcode.cn/problems/uncrossed-lines/">1035不相交的线</a> 类似最长公共子序列</li><li>24.8.15 <a href="https://leetcode.cn/problems/maximum-difference-score-in-a-grid/">3148矩阵中的最大得分</a> 寻找最大最小值，记录到当前位置的最小值</li><li>24.8.19 <a href="https://leetcode.cn/problems/student-attendance-record-ii/">552学生出勤记录II</a> 把 dfs写在外面，多个测试用例可共享记忆化搜索结果，效率更高。</li><li>24.8.20 <a href="https://leetcode.cn/problems/find-number-of-ways-to-reach-the-k-th-stair/">3154到达第K级台阶的方案数</a> 灵神的组合数学秀麻了</li><li>24.8.28 <a href="https://leetcode.cn/problems/minimum-substring-partition-of-equal-character-frequency/">3144分割字符频率相等的最少子字符串</a> 满足条件：字符串长度=最大频率*字典长度</li></ul><h3 id="技巧类DP"><a href="#技巧类DP" class="headerlink" title="技巧类DP"></a>技巧类DP</h3><ul><li>24.7.9 <a href="https://leetcode.cn/problems/find-the-maximum-length-of-valid-subsequence-ii/">3202找出有效子序列的最大长度II</a> <a href="https://leetcode.cn/circle/discuss/mDfnkW/">灵神模运算整理</a></li></ul><h3 id="数位DP"><a href="#数位DP" class="headerlink" title="数位DP"></a>数位DP</h3><ul><li>24.8.21 <a href="https://leetcode.cn/problems/maximum-number-that-sum-of-the-prices-is-less-than-or-equal-to-k/">3007价值和小于等于K的最大数字</a> 好难啊</li></ul><h2 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h2><ul><li>24.7.15 <a href="https://leetcode.cn/problems/accounts-merge/">721账户合并</a> 计算联通块，将相同value的key索引存入列表</li><li>24.7.22 <a href="https://leetcode.cn/problems/detonate-the-maximum-bombs">2101引爆最多的炸弹</a> 建有向图+枚举起点</li><li>24.8.12 <a href="https://leetcode.cn/problems/implement-magic-dictionary/">676实现一个魔法字典</a> 字典树，child设为dict()</li></ul><h2 id="图"><a href="#图" class="headerlink" title="图"></a>图</h2><ul><li>24.7.17 <a href="https://leetcode.cn/problems/number-of-possible-sets-of-closing-branches/">2959关闭分部的可行集合数目</a> Floyd算法，二进制枚举，两点之间有多个边用二维矩阵建图</li><li>24.7.18 <a href="https://leetcode.cn/problems/minimum-time-to-visit-disappearing-nodes/">3112访问消失节点的最少时间</a> Dijkstra算法</li></ul><h2 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a>贪心</h2><ul><li>24.7.26 <a href="https://leetcode.cn/problems/find-the-value-of-the-partition/">2740找出分值区</a></li><li>24.7.27 <a href="https://leetcode.cn/problems/lexicographically-smallest-string-after-operations-with-constraint">3106满足距离约束且字典序最小的字符串</a></li><li>24.9.3 <a href="https://leetcode.cn/problems/maximum-strength-of-a-group/">2708一个小组的最大实力值</a> 记录最大最小值</li></ul><h2 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h2><ul><li>24.8.22 <a href="https://leetcode.cn/problems/minimum-array-end/">3133数组最后一个元素的最小值</a></li></ul><h2 id="二分"><a href="#二分" class="headerlink" title="二分"></a>二分</h2><ul><li>24.8.3 <a href="https://leetcode.cn/problems/maximum-points-inside-the-square/">3143正方形中的最多点数</a> 答案有单调性，可二分</li></ul><h2 id="前缀和"><a href="#前缀和" class="headerlink" title="前缀和"></a>前缀和</h2><ul><li>24.8.14 <a href="https://leetcode.cn/problems/special-array-ii/">3152特殊数组II</a> 二分不如前缀和优雅</li></ul><h2 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h2><ul><li>24.7.10/11 <a href="https://leetcode.cn/problems/count-the-number-of-incremovable-subarrays-ii/">2972统计移除递增子数组的数目I/II</a> 枚举后缀，分类讨论</li><li>24.8.9 <a href="https://leetcode.cn/problems/find-the-integer-added-to-array-ii/">3132找出与数组相加的整数II</a> 灵神的双指针太优雅了，我写的是💩</li><li>24.9.2 <a href="https://leetcode.cn/problems/maximize-the-confusion-of-an-exam/">2024. 考试的最大困扰度</a> 用defaultdict记录</li><li>24.9.8 <a href="https://leetcode.cn/problems/squares-of-a-sorted-array/">977有序数组的平方</a></li><li>24.9.12 <a href="https://leetcode.cn/problems/find-the-maximum-number-of-marked-indices/">2576求出最多标记下标</a></li><li>24.9.18 <a href="https://leetcode.cn/problems/the-latest-time-to-catch-a-bus/">2332坐上公交的最晚时间</a> 分别模拟上车和插队</li></ul><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><ul><li>24.7.13 <a href="https://leetcode.cn/problems/find-if-array-can-be-sorted/">3011判断一个数组是否可以变为有序</a> 数组，分组循环</li><li>24.7.14 <a href="https://leetcode.cn/problems/max-increase-to-keep-city-skyline/">807保持城市天际线</a> 数组，求行列最大值</li><li>24.7.19 <a href="https://leetcode.cn/problems/minimum-levels-to-gain-more-points/description/">3096得到更多分数的最少关卡数目</a></li><li>24.7.24 <a href="https://leetcode.cn/problems/relocate-marbles/">2766重新放置石块</a> 哈希集合模拟</li><li>24.7.25 <a href="https://leetcode.cn/problems/minimum-operations-to-make-a-special-number/">2844生成特殊数字的最少操作</a> 字符串</li><li>24.7.29 <a href="https://leetcode.cn/problems/baseball-game/">682棒球比赛</a> 用数组模拟</li><li>24.9.5 <a href="https://leetcode.cn/problems/clear-digits/">3174清除数字</a> stack</li><li>24.9.9 <a href="https://leetcode.cn/problems/merge-nodes-in-between-zeros/">2181合并零之间的节点</a> 链表</li><li>24.9.14 <a href="https://leetcode.cn/problems/removing-stars-from-a-string/">2390从字符串移除星号</a> stack</li><li>24.9.22 <a href="https://leetcode.cn/problems/find-the-town-judge/">997找到小镇的法官</a> 记录出入度</li></ul><h2 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h2><ul><li>24.7.9 <a href="https://leetcode.cn/problems/minimize-manhattan-distances/">3102最小化曼哈顿距离</a><br>曼哈顿距离与切比雪夫距离(max(|x2-x1|,|y2-y1|))转换：<ul><li>将一个点 (x,y) 的坐标变为 (x+y,x−y)后，原坐标系中的曼哈顿距离等于新坐标系中的切比雪夫距离。</li><li>将一个点 (x,y) 的坐标变为 ((x+y)/2,(x−y)/2)后，原坐标系中的切比雪夫距离等于新坐标系中的曼哈顿距离。</li></ul></li><li>24.7.20 <a href="https://leetcode.cn/problems/minimum-moves-to-spread-stones-over-grid/">2850将石头分散到网格图的最少移动次数</a> 全排列，调包</li><li>24.7.28 <a href="https://leetcode.cn/problems/falling-squares/">699掉落的方块</a> 暴力枚举，线段树不会！</li><li>24.7.30 <a href="https://leetcode.cn/problems/double-modular-exponentiation/">2961双模幂运算</a> 快速幂</li></ul><h2 id="一眼题"><a href="#一眼题" class="headerlink" title="一眼题"></a>一眼题</h2><ul><li>24.7.12 <a href="https://leetcode.cn/problems/minimum-number-game/">2974最小数字游戏</a></li><li>24.7.16 <a href="https://leetcode.cn/problems/find-common-elements-between-two-arrays/">2956找到两个数组中的公共元素</a></li><li>24.7.31 <a href="https://leetcode.cn/problems/minimum-rectangles-to-cover-points/">3111覆盖所有点的最小矩形数目</a></li><li>24.8.13 <a href="https://leetcode.cn/problems/special-array-i/">3151特殊数组I</a></li><li>24.8.18 <a href="https://leetcode.cn/problems/student-attendance-record-i/">551学生出勤记录I</a></li><li>24.8.29 <a href="https://leetcode.cn/problems/check-if-grid-satisfies-conditions/">3142判断矩阵是否满足条件</a></li><li>24.9.1 <a href="https://leetcode.cn/problems/number-of-students-doing-homework-at-a-given-time/">1450在既定时间做作业的人数</a></li><li>24.9.4 <a href="https://leetcode.cn/problems/happy-students/">2860让所有学生保持开心的分组方法数</a></li><li>24.9.19 <a href="https://leetcode.cn/problems/length-of-the-longest-alphabetical-continuous-substring/">2414最长的字母序连续子字符串的长度</a></li><li>24.9.23 <a href="https://leetcode.cn/problems/best-sightseeing-pair/">1014最佳观光组合</a> 枚举右，维护左</li></ul><h1 id="刷题技巧"><a href="#刷题技巧" class="headerlink" title="刷题技巧"></a>刷题技巧</h1><h2 id="巧用内置库"><a href="#巧用内置库" class="headerlink" title="巧用内置库"></a>巧用内置库</h2><ul><li>计算前缀和：<code>list(itertools.accumulate(l, initial=0))</code></li><li>获取连续重叠对 <code>for a, b in itertools.pairwise(nums):</code> </li><li>从nums中选2个元素组合/排列 <code>for i in itertools.combinations/permutations(nums, 2):</code> </li><li>check函数二分：<code>bisect_left(range(1_000_000_001), True, key=check)</code></li></ul><h2 id="巧用数据结构"><a href="#巧用数据结构" class="headerlink" title="巧用数据结构"></a>巧用数据结构</h2><ul><li>有序数组 <code>from sortedcontainers import SortedList</code></li></ul><h3 id="其他技巧"><a href="#其他技巧" class="headerlink" title="其他技巧"></a>其他技巧</h3><ul><li>死循环，同时记录当前轮数 <code>for i in count(1):</code></li><li>数组每行最大值：<code>mx_row = list(map(max, nums))</code></li><li>数组每列最大值：<code>mx_col = list(map(max, zip(*nums)))</code></li><li>1_000_000_001表示10**9+1</li><li>设置dict的value默认值为ind：<code>defaultdict(lambda: inf)</code></li><li><code>enumerate(nums, start=1)</code></li></ul>]]></content>
      
      
      <categories>
          
          <category> Daily </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Work &amp; Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Technical Summary —— Pytorch &amp; Numpy</title>
      <link href="/2024/07/09/Technical-Summary-Deep-Learning/"/>
      <url>/2024/07/09/Technical-Summary-Deep-Learning/</url>
      
        <content type="html"><![CDATA[<p>近期致力于总结科研或者工作中用到的主要技术栈，从技术原理到常用语法，这次查缺补漏当作我的小百科。主要技术包括：</p><ul><li>✅<a href="https://xfliu1998.github.io/2024/04/07/Technical-Summary-Database/">数据库常用：MySQL, Hive SQL, Spark SQL</a></li><li>✅<a href="https://xfliu1998.github.io/2024/04/15/Technical-Summary-BigData/">大数据处理常用：Pyspark, Pandas</a></li><li>⚪ 图像处理常用：OpenCV, Matplotlib </li><li>⚪ 机器学习常用：SciPy, Sklearn</li><li>✅ <a href="https://xfliu1998.github.io/2024/07/09/Technical-Summary-Deep-Learning/">深度学习常用：Pytorch, Numpy</a></li><li>✅ <a href="https://xfliu1998.github.io/2024/07/02/Technical-Summary-Necessary/">常用命令: Shell, Git, Vim</a></li></ul><p>以下整理错误或者缺少的部分欢迎指正！！！</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Torch的tensor可以在GPU上加速运算，Numpy的ndarray只能在CPU上加速运算。</p><ul><li><a href="https://pytorch.org/docs/2.4/">torch2.4 API</a></li><li><a href="https://numpy.org/doc/stable/reference/index.html">numpy API</a></li></ul><p>导包与相互转化<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> f</span><br><span class="line"></span><br><span class="line">np_data = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">torch_data = torch.from_numpy(np_data).cuda()</span><br><span class="line">tensor2array = torch_data.cpu().detach().numpy()</span><br></pre></td></tr></table></figure></p><h2 id="相同语法"><a href="#相同语法" class="headerlink" title="相同语法"></a>相同语法</h2><div class="table-container"><table><thead><tr><th>功能</th><th>函数</th></tr></thead><tbody><tr><td>查看矩阵行数</td><td><code>len(x)</code></td></tr><tr><td>取出矩阵x的k对角元素</td><td><code>np/torch.diag(x, k)</code></td></tr><tr><td>取出矩阵x的下三k角矩阵</td><td><code>np/torch.tril(x, k)</code></td></tr><tr><td>取出矩阵x的上三k角矩阵</td><td><code>np/torch.triu(x, k)</code></td></tr><tr><td>指定范围，指定步长，生成等差数列</td><td><code>np/torch.arange(start, end, step)</code></td></tr><tr><td>指定范围，指定生成个数，生成等差数列</td><td><code>np/torch.linspace(strat, end, num)</code></td></tr><tr><td>指定范围，指定生成个数，对数均分</td><td><code>np/torch.logspace(strat, end, num)</code></td></tr><tr><td></td><td>``</td></tr><tr><td>矩阵加法</td><td><code>np/torch.add(x1, x2)</code></td></tr><tr><td>矩阵减法</td><td><code>np/torch.substact(x1, x2)</code></td></tr><tr><td>矩阵除法</td><td><code>np/torch.divide(x1, x2)</code></td></tr><tr><td>取指数/对数</td><td><code>np/torch.exp/log(x)</code></td></tr><tr><td>取平方</td><td><code>np/torch.sqrt(x)</code></td></tr><tr><td>转置</td><td><code>x.T</code></td></tr><tr><td>矩阵伪逆</td><td><code>np/torch.linalg.pinv(x)</code></td></tr><tr><td></td><td>``</td></tr><tr><td>求累加和</td><td><code>np/torch.cumsum(x)</code></td></tr><tr><td>求最值及其索引</td><td><code>np/torch.max/min/argmax/argmin/abs(x, axis/dim)</code></td></tr><tr><td>统计函数</td><td><code>np/torch.mean/median/sum(x, axis/dim)</code></td></tr><tr><td>沿着某一维度计算相邻元素的差</td><td><code>np/torch.diff(x, axis/dim)</code></td></tr><tr><td>判断是否为inf/有穷</td><td><code>np/torch.isinf/isfinite(x)</code></td></tr><tr><td>指定维度上布尔值有/全真</td><td><code>np/torch.any(x, axis/dim)</code></td></tr><tr><td>条件函数</td><td><code>np/torch.where(condition, true_value, false_value)</code></td></tr><tr><td>返回满足条件的索引</td><td><code>np/torch.where(condition)[0]</code></td></tr><tr><td>x1是否在x2中</td><td><code>np/torch.isin(x1, x2)</code></td></tr><tr><td>元素去重</td><td><code>np/torch.unique(x, axis/dim)</code> 获得去重后的一维矩阵</td></tr><tr><td></td><td>``</td></tr><tr><td>*修改维度(增大补0，变小删除)</td><td><code>np/torch.resize(x, size/shape)</code></td></tr><tr><td>*修改维度(前后元素数相同，不改变原数组及元素顺序)</td><td><code>np/torch.reshape(x, size/shape)</code></td></tr><tr><td>*去除某一为1的维度</td><td><code>np/torch.squeeze(x, axis/dim)</code></td></tr><tr><td>*指定增加某一维度</td><td><code>np.unsqueeze(x, axis/dim)</code></td></tr><tr><td>移动维度</td><td><code>np/torch.moveaxis(x, source, destination)</code></td></tr><tr><td>指定维度直接拼接</td><td><code>np.concatenate((x1, x2, ...), axis/dim)</code> torch可以写为cat</td></tr><tr><td>指定维度新建一维拼接</td><td><code>np/torch.stack((x1, x2, ...), axis/dim)</code></td></tr><tr><td>指定维度拼接</td><td><code>np/torch.hstack/vstack/dstack((x1, x2, ...))</code></td></tr><tr><td>矩阵分割</td><td><code>np/torch.split(x, indices_or_sections/split_size_or_sections)</code></td></tr><tr><td>指定维度分割</td><td><code>np/torch.hsplit/vsplit/dsplit(x)</code></td></tr></tbody></table></div><p>以上标*的也可以使用<code>ndarray/tensor.resize()</code>等。</p><h2 id="专属语法"><a href="#专属语法" class="headerlink" title="专属语法"></a>专属语法</h2><div class="table-container"><table><thead><tr><th>功能</th><th>函数</th></tr></thead><tbody><tr><td>原地打乱顺序</td><td><code>np.random.shuffle(x)</code></td></tr><tr><td>非原地打乱顺序</td><td><code>np.random.permutation(x)</code></td></tr><tr><td>对x保留d位小数，后面的四舍五入</td><td><code>np.round(x, d)</code></td></tr><tr><td>求协方差矩阵</td><td><code>np.corrcoef(x)</code></td></tr><tr><td>布尔操作</td><td><code>np.logical_and/or(x1, x2)</code></td></tr><tr><td>删除指定位置/布尔索引的元素</td><td><code>np.delete(x, index/bool_index)</code></td></tr><tr><td>指定增加某一维度</td><td><code>np.expand_dims(x, axis=None)</code></td></tr><tr><td>指定维度逐元素重复</td><td><code>x.repeat(axis, repeats)</code></td></tr><tr><td></td><td>``</td></tr><tr><td>求平方根倒数</td><td><code>torch.rsqrt()</code></td></tr><tr><td>获得最大的k个元素</td><td><code>x.topk(k, dim)</code></td></tr><tr><td>某一维度上最小的第k个</td><td><code>x.kthvalue(k, dim)</code></td></tr><tr><td>组合计算</td><td><code>f.log_softmax(x)</code> 先sf再log</td></tr><tr><td>组合计算</td><td><code>torch.logsumexp(x)</code> 先e再sum再log</td></tr><tr><td>对x在维度0上逆序</td><td><code>torch.flip(x, dims=[0])</code></td></tr><tr><td>维度变换</td><td><code>x.view(shape)</code> 类似reshape，与原tensor共享内存</td></tr><tr><td>维度扩大</td><td><code>x.expand(shape)</code> 维度变为shape的维度</td></tr><tr><td>张量切割</td><td><code>torch.chunk(x, chunks, dim)</code> 切割为指定chunks数量的张量块</td></tr><tr><td>获取mask</td><td><code>x.ge(0.5)</code> ge&gt;，le&lt;，gt&gt;=，lt&lt;=，eq=</td></tr><tr><td>根据mask筛选</td><td><code>torch.masked_select(x, x.le(20))</code></td></tr></tbody></table></div><h2 id="不同语法对比"><a href="#不同语法对比" class="headerlink" title="不同语法对比"></a>不同语法对比</h2><h3 id="矩阵创建"><a href="#矩阵创建" class="headerlink" title="矩阵创建"></a>矩阵创建</h3><div class="table-container"><table><thead><tr><th></th><th>numpy</th><th>torch</th></tr></thead><tbody><tr><td>基础变量</td><td><code>np.array(data, dtype=None)</code></td><td><code>torch.tenosr(data, dtype=None, device=None, requires_grad=False)</code></td></tr><tr><td>全0/1矩阵</td><td><code>np.zeros/ones((3, 4))</code></td><td><code>torch.zeros/ones(3, 4)</code></td></tr><tr><td>全值矩阵</td><td><code>np.full(size, value)</code></td><td><code>torch.full(shape, value)</code></td></tr><tr><td>未初始化矩阵</td><td><code>np.empty(size)</code></td><td><code>torch.empty(shape)</code></td></tr><tr><td>N维单位矩阵</td><td><code>np.identity/eye(N)</code></td><td><code>torch.eye(N)</code></td></tr><tr><td>随机整数</td><td><code>np.random.randint(low, high, size)</code></td><td><code>torch.empty(shape).random_(low, high)</code></td></tr><tr><td>[0, 1)均匀分布</td><td><code>np.random.rand(3, 4)</code></td><td><code>torch.rand(3, 4)</code></td></tr><tr><td>任意均匀分布</td><td><code>np.random.uniform(low, high, size)</code></td><td><code>torch.empty(shape).uniform_(low, high)</code></td></tr><tr><td>标准正态分布</td><td><code>np.random.randn(3, 4)</code></td><td><code>torch.randn(3, 4)</code></td></tr><tr><td>指定期望和方差的标准正态分布</td><td><code>np.random.normal(loc, scale, size)</code></td><td><code>torch.normal(mean, std, size)</code></td></tr></tbody></table></div><p>numpy和torch均可使用<code>zeros_like, ones_like, full_like, empty_like(tensor/array)</code>创建矩阵。</p><h3 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h3><div class="table-container"><table><thead><tr><th></th><th>numpy</th><th>torch</th></tr></thead><tbody><tr><td>对应位置相乘</td><td><code>x1 * x2</code>或<code>np.multiply(x1, x2)</code></td><td><code>x1 * x2</code>或<code>torch.mul(x1, x2)</code></td></tr><tr><td>向量乘法</td><td><code>x1.dot(x2)</code>或<code>np.dot(x1, x2)</code> 2d时同矩阵乘法</td><td><code>x1.dot(x2)</code>或<code>torch.dot(x1, x2)</code>最多1d</td></tr><tr><td>矩阵乘向量</td><td>``</td><td><code>torch.mv(x, w0)</code></td></tr><tr><td>矩阵乘法</td><td><code>x1 @ x2</code>或<code>np.matmul(x1, x2)</code></td><td><code>x1 @ x2</code>或<code>torch.mm(x1, x2)</code> 最多2d，bmm最多3d</td></tr><tr><td>近似值</td><td><code>np.floor/ceil/round(x)</code></td><td><code>x.floor/ceil/round()</code></td></tr><tr><td>取整数部分</td><td><code>np.trunc(x)</code></td><td><code>x.trunc()</code>, <code>x.frac()</code>取小数部分</td></tr><tr><td>数值截断</td><td><code>np.clip(a, a_min, a_max, out=None)</code></td><td><code>torch.clamp(input, min, max, out=None)</code></td></tr><tr><td>求幂</td><td><code>np.power(x1, x2)</code> x2数字矩阵均可</td><td><code>torch.pow(input: Tensor, exponent: Number)</code></td></tr><tr><td>求逆</td><td><code>np.linalg.inv(x)</code></td><td><code>torch.inverse(x)</code></td></tr><tr><td>求伪逆</td><td><code>torch.linalg.pinv</code></td><td><code>np.linalg.inv(a)</code></td></tr><tr><td>求范数</td><td><code>np.linalg.norm(x)</code></td><td><code>x.norm(p, dim)</code>或<code>torch.norm(x)</code></td></tr></tbody></table></div><h3 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h3><div class="table-container"><table><thead><tr><th></th><th>numpy</th><th>torch</th></tr></thead><tbody><tr><td>查看维度</td><td><code>x.shape</code> x.size为元素数量</td><td><code>x.shape=x.size()</code></td></tr><tr><td>展平为一维，返回视图</td><td><code>x.ravel()</code></td><td><code>torch.ravel(x)</code></td></tr><tr><td>展平为一维，返回拷贝</td><td><code>x.flatten()</code></td><td><code>x.flatten()=x.flatten(start_dim=0, end_dim=-1)=torch.flatten(x, start_dim=0, end_dim=-1)</code></td></tr><tr><td>*交换维度</td><td><code>np.swapaxes(x, axis1, axis2)</code></td><td><code>torch.transpose(x, dim0, dim1)</code></td></tr><tr><td>*维度重排</td><td><code>np.transpose(x, new_axis)</code> 默认为转置</td><td><code>torch.permute(x, new_dim)</code></td></tr><tr><td>对应维度按数组重复size/shape倍</td><td><code>np.tile(x, size)</code></td><td><code>x.repeat(shape)</code></td></tr></tbody></table></div><p>以上标*的也可以使用<code>ndarray/tensor.resize()</code>等。</p><h3 id="其他操作"><a href="#其他操作" class="headerlink" title="其他操作"></a>其他操作</h3><div class="table-container"><table><thead><tr><th></th><th>numpy</th><th>torch</th></tr></thead><tbody><tr><td>修改数据类型</td><td><code>x.astype(np.int32)</code></td><td><code>x.type(torch.int32)</code></td></tr><tr><td>返回为真的索引</td><td><code>np.argwhere(x==k)</code></td><td><code>torch.nonzero(x==k)</code></td></tr><tr><td>复制矩阵</td><td><code>x2 = x1.copy()</code></td><td><code>x2 = x1.clone()</code></td></tr><tr><td>指定维度滚动shift步，补齐到前边</td><td><code>np.roll(x, shift, axis=None)</code></td><td><code>torch.roll(x, shift, dims=None)</code></td></tr><tr><td>在指定维度反转数据</td><td><code>np.flip(x, axis)</code></td><td><code>torch.flip(x, dims)</code></td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> Machine Learning and Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Technical Summary —— Common Command</title>
      <link href="/2024/07/02/Technical-Summary-Necessary/"/>
      <url>/2024/07/02/Technical-Summary-Necessary/</url>
      
        <content type="html"><![CDATA[<p>近期致力于总结科研或者工作中用到的主要技术栈，从技术原理到常用语法，这次查缺补漏当作我的小百科。主要技术包括：</p><ul><li>✅<a href="https://xfliu1998.github.io/2024/04/07/Technical-Summary-Database/">数据库常用：MySQL, Hive SQL, Spark SQL</a></li><li>✅<a href="https://xfliu1998.github.io/2024/04/15/Technical-Summary-BigData/">大数据处理常用：Pyspark, Pandas</a></li><li>⚪ 图像处理常用：OpenCV, Matplotlib </li><li>⚪ 机器学习常用：SciPy, Sklearn</li><li>✅ <a href="https://xfliu1998.github.io/2024/07/09/Technical-Summary-Deep-Learning/">深度学习常用：Pytorch, Numpy</a></li><li>✅ <a href="https://xfliu1998.github.io/2024/07/02/Technical-Summary-Necessary/">常用命令: Shell, Git, Vim</a></li></ul><p>以下整理错误或者缺少的部分欢迎指正！！！</p><h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><p>Linux 的目录中有且只有一个根目录 / 。Linux 是以文件的形式管理我们的设备，因此 linux 系统一切皆为文件。Linux命令严格区分大小写。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ifconfig  # 查询当前网卡信息</span><br><span class="line">ifconfig eth0  # 配置网卡 </span><br><span class="line">df    # 查看系统分区</span><br><span class="line">ls /bin/   # 里面存放的为Linux命令文件  </span><br></pre></td></tr></table></figure><h3 id="文件处理命令"><a href="#文件处理命令" class="headerlink" title="文件处理命令"></a>文件处理命令</h3><ul><li>显示目录文件 <code>ls  选项[-ald]  [文件或目录]</code><br><code>-a</code> 显示所有文件，包括隐藏文件<br><code>-l</code>  详细信息显示（可简略为<code>ll</code>）<br><code>-d</code>  查看目录属性<br><code>-h</code> 人性化显示<ul><li>创建新目录 <code>mkdir -p  [目录名]</code><br><code>-p</code> 递归创建</li></ul></li><li>切换目录 <code>cd [目录]</code><br><code>cd ..</code> 返回上一级目录</li><li>显示当前目录 <code>pwd</code></li><li>删除空目录 <code>rmdir [目录名]</code> </li><li>复制 <code>cp  -rp  [原文件或目录] [目标目录]</code><br><code>-r</code>  复制目录<br><code>-p</code>  保留文件属性</li><li>删除文件 <code>rm  -rf   [文件或目录]</code><br><code>-f</code>  强制执行<ul><li>创建空文件 <code>touch  [文件名]</code></li></ul></li><li>显示文件内容 <code>cat [文件名]</code><br><code>-n</code>  显示行号</li><li>分页显示文件内容 <code>more  [文件名]</code><br><code>(空格)或f</code> 翻页<br><code>(Enter)</code> 换行<br><code>q或Q</code>  退出<br><code>/</code> 搜索</li><li>分页显示文件内容（可向上翻页）<code>less  [文件名]</code> </li><li>显示文件前面几行 <code>head -n [文件名]</code></li><li>显示文件后面几行 <code>tail -n [文件名]</code><br><code>-f</code>  动态显示文件末尾内容 </li><li>生成链接文件 <code>ln  -s  [原文件]  [目标文件]</code><br><code>-s</code> 创建软连接</li></ul><blockquote><p><strong>软链接</strong>的作用和Windows中的快捷方式差不多，是指向源文件安装路径的符号链接，大小很小，真正拥有的权限是源文件所决定的权限 。<br><strong>硬链接</strong>就是把源文件拷贝到目标位置，与 <code>cp -p</code> 最大区别是可以同步更新，源文件有变化硬链接文件会同时变化，如果源文件丢失或被删除，硬链接并不会消失。可以通过i节点来区分，源文件和硬链接文件的i节点是一样的，所以他们会同步更新，但是不能跨分区放置硬链接，且不能对目录使用。</p></blockquote><h3 id="权限管理命令"><a href="#权限管理命令" class="headerlink" title="权限管理命令"></a>权限管理命令</h3><p>用户有三类：u所有者（只有一个）、g所属组、o其他人、a所有人<br>权限有三类：r、w、x</p><div class="table-container"><table><thead><tr><th>代表字符</th><th>对文件的含义</th><th>对目录的含义</th></tr></thead><tbody><tr><td>r:read</td><td>可以查看文件内容 可以cat/more/head/tail/less</td><td>可以列出目录中的内容 可以ls</td></tr><tr><td>w:write</td><td>可以修改文件内容 可以vim</td><td>可以在目录中创建、删除文件 可以touch/mkdir/rmdir/rm</td></tr><tr><td>x:execute</td><td>可以执行文件 可以script(脚本) command(命令)</td><td>可以进入目录 可以cd</td></tr></tbody></table></div><ul><li>改变文件或目录权限 <code>chmod  [&#123;ugoa&#125;&#123;+-=&#125;&#123;rwx&#125;] [文件或目录]</code><br><code>-R</code> 递归修改，即修改包括文件下目录的权限</li><li>改变文件或目录的所有者 <code>chown  [用户] [文件或目录]</code> </li><li>改变文件或目录的所属组 <code>chgrp  [用户组]  [文件或目录]</code> </li><li>显示、设置文件的缺省权限 <code>umask [-S]</code><br><code>-S</code>  以rwx形式显示新建文件缺省权限<br>新建文件默认没有 x 权限</li></ul><p><code>umask</code> 指令直接输入之后会显示 <code>0022</code>，其中 0 代表特殊权限，022代表 777 与 022 之间异或逻辑关系</p><h3 id="文件搜索命令"><a href="#文件搜索命令" class="headerlink" title="文件搜索命令"></a>文件搜索命令</h3><ul><li>文件搜索 <code>find  [搜索范围]  [匹配条件]</code><br> <code>-name</code> 文件名匹配，<code>*</code>匹配任意字符， <code>？</code>匹配任意一个字符<br> <code>-iname</code> 不区分大小写文件名匹配<br> <code>-size</code> 指定文件大小，size后接的数据只能为数据块<br> <code>+n</code> 大于， <code>-n</code> 小于，<code>n</code> 等于 1个数据块=512字节=0.5K<br> <code>-user</code> 根据所有者查找<br> <code>-group</code> 根据所属组查找<br> <code>-type</code> 根据文件类型查找，<code>f</code>文件，<code>d</code>目录，<code>l</code>软链接<br> <code>-a</code> 同时满足， <code>-o</code> 满足任意一个</li><li>在文件资料库中查找文件 <code>locate [文件名]</code><br><code>updatedb</code> 更新资料库</li><li>搜索命令所在目录及别名信息 <code>which [命令名]</code></li><li>搜索命令所在目录及帮助文档路径 <code>whereis [命令名]</code></li><li>在文件中搜寻字串匹配的行并输出 <code>grep  -iv [指定字串] [文件]</code><br><code>-i</code> 不区分大小写<br><code>-v</code> 排除指定字串 </li></ul><h3 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a>帮助命令</h3><ul><li>获得帮助信息 <code>man  [命令或配置文件]</code></li><li>获得命令的简单介绍信息 <code>whatis 命令名</code></li><li>查询简短的配置文件的作用 <code>apropos [配置文件名称]</code> </li><li>获得Shell内置命令的帮助信息 <code>help 命令名</code></li></ul><h3 id="用户管理命令"><a href="#用户管理命令" class="headerlink" title="用户管理命令"></a>用户管理命令</h3><ul><li>添加新用户 <code>useradd 用户名</code></li><li>设置用户密码 <code>passwd 用户名</code></li><li>查看登录用户信息 <code>who</code></li><li>查看登录用户详细信息 <code>w</code></li></ul><h3 id="压缩解压命令"><a href="#压缩解压命令" class="headerlink" title="压缩解压命令"></a>压缩解压命令</h3><ul><li><strong>.gz</strong>格式压缩 <code>gzip [文件]</code><br>解压缩 <code>gunzip [压缩文件]</code><br> 只能压缩文件不能压缩目录</li><li>打包解包目录，压缩后文件格式为.tar.gz <code>tar 选项[-zxcf] [压缩后文件名] [目录]</code><br><code>-c</code> 打包<br><code>-x</code> 解包<br><code>-v</code> 显示详细信息<br><code>-f</code> 指定文件名<br><code>-z</code> 打包同时压缩/解压缩</li><li><strong>.zip</strong>格式压缩 <code>zip 选项[-r]  [压缩后文件名]  [文件或目录]</code><br>解压缩 <code>unzip [压缩文件]</code><br>压缩文件后保留原文件<br><code>-r</code> 压缩目录</li><li><strong>.bz2</strong>格式压缩  <code>bzip2  选项 [-k] [文件]</code><br>解压缩 <code>bunzip2  选项 [-k] [压缩文件]</code><br><code>-k</code> 产生压缩文件后保留原文件<br>可与<code>tar</code>结合使用</li></ul><h3 id="网络命令"><a href="#网络命令" class="headerlink" title="网络命令"></a>网络命令</h3><ul><li>给用户发信息，以Ctrl+D保存结束 <code>write  &lt;用户名&gt;</code></li><li>发广播信息 <code>wall [message]</code></li><li>测试网络连通性 <code>ping 选项 IP地址</code></li><li>查看和设置网卡信息 <code>ifconfig 网卡名称 IP地址</code></li><li>查看发送电子邮件 <code>mail [用户名]</code></li><li>列出目前与过去登入系统的用户信息 <code>last</code></li><li>检查某特定用户上次登录时间 <code>lastlog</code></li><li>显示数据包到主机间的路径 <code>traceroute</code></li><li>显示网络相关信息 <code>netstat [选项]</code><br><code>-t</code> TCP协议<br><code>-u</code> UDP协议<br><code>-l</code> 监听<br><code>-r</code> 路由<br><code>-n</code> 显示IP地址和端口号<br>查看本机监听的端口 <code>netstat -tlun</code><br>查看本机的所有网络连接 <code>netstat -an</code><br>查看本机路由表（网关） <code>netstat -rn</code></li><li>配置网络（Red Hat专有）<code>setup</code></li><li>设备挂载 <code>mount [-t文件系统] 设备文件名 挂载点</code></li></ul><h3 id="关机重启命令"><a href="#关机重启命令" class="headerlink" title="关机重启命令"></a>关机重启命令</h3><p>在服务器上重启需要先停掉服务，否则物理内存会坏。且远程服务器只能重启，关机后需要管理员手动开机</p><ul><li>关机重启 <code>shutdown [选项] 时间</code><br><code>-c</code> 取消前一个关机命令<br><code>-h</code> 关机<br><code>-r</code> 重启<br>其他关机命令 <code>halt</code> <code>poweroff</code> <code>init 0</code><br>其他重启命令 <code>reboot</code> <code>init6</code></li><li>系统运行级别<br>0 关机<br>1 单用户，进入选项菜单 只有root用户登陆进去 相当于Windows安全模式F8，只不过没有图形界面<br>2 不完全多用户，不含NFS服务，无图形界面、NFS网络文件系统，Linux之间文件传输共享方式，除了NFS服务，和3一样。<br>3 完全多用户<br>4 未分配<br>5 图形界面<br>6 重启</li><li>查询系统运行级别 <code>runlevel</code></li><li>退出登录 <code>logout</code></li></ul><h2 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h2><p>Xshell是连接远程服务器工具的一种，常用命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ssh 服务器ip# 连接服务器</span><br><span class="line"></span><br><span class="line">rz -be# 上传文件至服务器(-b表示以二进制方式，默认为文本方式；-e对所有控制字符转义)</span><br><span class="line">sz filename# 从服务器下载文件至本地</span><br><span class="line"></span><br><span class="line">scp -r host@ip:服务器端文件 本地位置 # 从服务器下载文件至本地（位置互换为上传） -r表示文件夹 -v显示详情</span><br><span class="line"></span><br><span class="line">python test.py# 执行代码</span><br><span class="line"></span><br><span class="line">ps aux# 查看所有服务进程</span><br><span class="line">top# 查看系统健康状态</span><br><span class="line">pstree# 查看进程树</span><br><span class="line"></span><br><span class="line">netstat -nlp# 查看服务对应端口</span><br></pre></td></tr></table></figure><p>Shell脚本的执行方式</p><ol><li>echo输出命令 <code>echo [选项] [输出内容]</code><br><code>-e</code> 支持反斜线控制的字符转换</li><li>执行脚本的三种方式：<br><code>./xxx.sh</code> 需要先赋予执行权限 <code>chmod 755 xxx.sh</code><br><code>. xxx.sh</code><br><code>bash xxx.sh</code></li><li>注意事项<ul><li>脚本第一行的 <code>#!/bin/Bash</code> 不是注释，是标识下面的语句为Shell脚本 </li><li>ctrl+c终止当前命令；ctrl+d退出当前终端</li></ul></li></ol><h3 id="Bash的基本功能"><a href="#Bash的基本功能" class="headerlink" title="Bash的基本功能"></a>Bash的基本功能</h3><ul><li>历史命令 <code>history [选项] [历史命令保存文件]</code><br><code>-c</code> 清空历史命令<br><code>-w</code> 把缓存中的历史命令写入历史命令保存文件~/.bash_history<br>默认保存1000条，可在环境变量配置文件/etc/profile中进行修改</li><li>命令别名 <code>alias 别名=&#39;原命令&#39;</code><br>查询命令别名 <code>alias</code><br>删除别名 <code>unalias 别名</code><br>系统别名文件/root/.bashrc ，修改后永久生效</li></ul><h3 id="输入输出重定向"><a href="#输入输出重定向" class="headerlink" title="输入输出重定向"></a>输入输出重定向</h3><ol><li><p>标准输入输出<br>| 设备 | 设备文件名 | 文件描述符 | 类型 |<br>|—|—|—|—|<br>| 键盘 | /dev/stdin | 0 | 标准输入 |<br>| 显示器 | /dev/sdtout | 1 | 标准输出 |<br>| 显示器 | /dev/sdterr | 2 | 标准错误输出 |</p></li><li><p>输出重定向<br>| 类型| 符号| 作用|<br>|—|—|—|<br>| 标准输出重定向    | 命令 &gt; 文件    | 以覆盖的方式，把命令的正确输出输 出到指定的文件或设备当中<br>| 标准输出重定向 |  命令 &gt;&gt; 文件 | 以追加的方式，把命令的 正确输出输出到指定的文 件或设备当中<br>| 标准错误输出重定向    | 错误命令 2&gt;文件| 以覆盖的方式，把命令的 错误输出输出到指定的文 件或设备当中<br>| 标准错误输出重定向 |  错误命令 2&gt;&gt;文件    | 以追加的方式，把命令的错误输出输出到指定的文件或设备当中<br>| 正确输出和错误输出同时保存    | 命令 &gt; 文件 2&gt;&amp;1    | 以覆盖的方式，把正确输 出和错误输出都保存到同 一个文件当中<br>| 正确输出和错误输出同时保存    | 命令 &gt;&gt; 文件 2&gt;&amp;1|     以追加的方式，把正确输 出和错误输出都保存到同 一个文件当中<br>| 正确输出和错误输出同时保存    | 命令 &amp;&gt;文件    | 以覆盖的方式，把正确输出和错误输出都保存到同一个文件当中<br>| 正确输出和错误输出同时保存    | 命令 &amp;&gt;&gt;文件|     以追加的方式，把正确输出和错误输出都保存到同一个文件当中<br>| 正确输出和错误输出同时保存    | 命令 &gt;&gt; 文件1 2&gt;&gt;文件2|     把正确的输出追加到文件1中，把错误的输出追加到文件2中</p></li></ol><h3 id="Bash的变量"><a href="#Bash的变量" class="headerlink" title="Bash的变量"></a>Bash的变量</h3><ol><li><p>本地变量<br>变量调用 <code>echo $name</code><br>查看当前系统全部变量 <code>set</code><br>变量删除 <code>unset nam e</code></p></li><li><p>环境变量<br>声明变量 <code>export 变量名=变量值</code><br>查询变量 <code>env</code><br>删除变量 <code>unset 变量名</code> </p></li></ol><h3 id="Shell编程"><a href="#Shell编程" class="headerlink" title="Shell编程"></a>Shell编程</h3><ul><li>cut命令 <code>cut [选项] 文件名</code><br><code>-f</code> 列号，提取第几列<br><code>-d</code> 分隔符，按照指定分隔符分割列<br>eg：<code>cut -d &quot;:&quot; -f 1,3 /etc/passwd</code> 以：为分隔符提取第一第三列<br>当文件以空格分隔而不是\t分隔时cut会提取出错</li><li>printf命令 <code>printf   ’输出类型输出格式’    输出内容</code><br>  <strong>输出类型：</strong><br>  <code>%ns</code>  输出字符串。n是数字指代输出几个字符<br>  <code>%ni</code> 输出整数。n是数字指代输出几个数字<br>  <code>%m.nf</code> 输出浮点数。m和n是数字，指代输出的整数   位数和小数位数。如%8.2f代表共输出8位数，   其中2位是小数，6位是整数<br>  <strong>输出格式：</strong><br>  <code>\a</code> 输出警告声音<br>  <code>\b</code> 输出退格键，也就是Backspace键<br>  <code>\f</code>  清除屏幕<br>  <code>\n</code> 换行<br>  <code>\r</code> 回车，也就是Enter键<br>  <code>\t</code>  平输出退格键，也就是Tab键<br>  <code>\v</code> 垂直输出退格键，也就是Tab键</li><li>awk命令 <code>awk ‘条件1&#123;动作1&#125; 条件2&#123;动作2&#125;…’ 文件名</code><br>  <strong>条件（Pattern）：</strong><br>  一般使用关系表达式作为条件，x &gt;= 10 判断变量 x是否大于等于10<br>  <strong>动作（Action）：</strong><br>  格式化输出 ，流程控制语句<br>  BEGIN<br>  END<br>  FS内置变量<br>  关系运算符</li><li>sed命令 <code>sed [选项] ‘[动作]’ 文件名</code><br>  sed 是一种几乎包括在所有 UNIX 平台（包括 Linux）的轻量级流编辑器。sed主要是用来将数据进行选取、替换、删除、新增的命令<br>  <code>-n</code> 一般sed命令会把所有数据都输出到屏幕 ，  如果加入此选择，则只会把经过sed命令处理的行输出到屏幕。<br>  <code>-e</code> 允许对输入数据应用多条sed命令编辑<br>  <code>-i</code>  用sed的修改结果直接修改读取数据的文件，  而不是由屏幕输出<br>  <strong>动作：</strong><br>  <code>a \</code> 追加，在当前行后添加一行或多行。添加多行时，除最后 一行 外，每行末尾需要用“\”代表数据未完结<br>  <code>c \</code> 行替换，用c后面的字符串替换原数据行，替换多行时，除最  后一行外，每行末尾需“\”代表数据未完结<br>  <code>i \</code> 插入，在当期行前插入一行或多行。插入多行时，除最后 一行外，每行末尾需要“\”代表数据未完结<br>  <code>d</code> 删除，删除指定的行<br>  <code>p</code> 打印，输出指定的行。<br>  <code>s</code> 字串替换，用一个字符串替换另外一个字符串。格式为“行范  围s/旧字串/新字串/g”（和vim中的替换格式类似）</li></ul><h3 id="流程控制"><a href="#流程控制" class="headerlink" title="流程控制"></a>流程控制</h3><p><strong>if语句</strong><br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.单分支if条件语句</span></span><br><span class="line"><span class="keyword">if</span>  [ 条件判断式 ] ; then</span><br><span class="line">程序 </span><br><span class="line">fi  </span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line"><span class="keyword">if</span>  [ 条件判断式 ]  </span><br><span class="line">    then</span><br><span class="line">        程序 </span><br><span class="line">fi </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.双分支if条件语句</span></span><br><span class="line"><span class="keyword">if</span> [ 条件判断式 ] </span><br><span class="line">    then   </span><br><span class="line">        条件成立时，执行的程序  </span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        条件不成立时，执行的另一个程序 </span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.多分支if条件语句</span></span><br><span class="line"><span class="keyword">if</span> [ 条件判断式<span class="number">1</span> ]</span><br><span class="line">    then</span><br><span class="line">        当条件判断式<span class="number">1</span>成立时，执行程序<span class="number">1</span></span><br><span class="line">elif [ 条件判断式<span class="number">2</span> ]</span><br><span class="line">    then</span><br><span class="line">        当条件判断式<span class="number">2</span>成立时，执行程序<span class="number">2</span></span><br><span class="line">„省略更多条件…</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    当所有条件都不成立时，最后执行此程序</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></p><p><strong>case语句</strong><br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">case <span class="variable">$</span> 变量名 <span class="keyword">in</span>  </span><br><span class="line">    <span class="string">&quot; 值1&quot;</span>）   </span><br><span class="line">         如果变量的值等于值<span class="number">1</span>，则执行程序<span class="number">1</span>   </span><br><span class="line">        ; ;</span><br><span class="line">     <span class="string">&quot; 值2&quot;</span>）   </span><br><span class="line">         如果变量的值等于值<span class="number">2</span>，则执行程序<span class="number">2</span>  </span><br><span class="line">          ; ;  </span><br><span class="line">      …省略其他分支…  </span><br><span class="line">      * ）   </span><br><span class="line">      如果变量的值都不是以上的值，则执行此程序 </span><br><span class="line">      ; ;</span><br><span class="line">esac </span><br></pre></td></tr></table></figure></p><p><strong>for循环</strong><br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> 变量 <span class="keyword">in</span> 值<span class="number">1</span> 值<span class="number">2</span> 值<span class="number">3</span></span><br><span class="line">    <span class="keyword">do</span> </span><br><span class="line">        程序</span><br><span class="line">    done</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>((初始值;循环控制条件;变量变化))</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        程序</span><br><span class="line">    done</span><br></pre></td></tr></table></figure></p><p><strong>while循环与until循环</strong><br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 条件成立时进入循环</span></span><br><span class="line"><span class="keyword">while</span> [ 条件判断式 ]</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        程序</span><br><span class="line">    done</span><br><span class="line"></span><br><span class="line"><span class="comment"># 条件不成立时进入循环</span></span><br><span class="line"><span class="keyword">until</span> [ 条件判断式 ]</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        程序</span><br><span class="line">    done</span><br></pre></td></tr></table></figure></p><p><strong>函数</strong><br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[ <span class="type">function</span> ] funname [()]&#123;</span><br><span class="line">    action;</span><br><span class="line">    [<span class="type">return</span> <span class="built_in">int</span>;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 项目提交</span></span><br><span class="line">git init</span><br><span class="line">git add 想要提交的文件</span><br><span class="line">git commit -m &quot;提交说明&quot;</span><br><span class="line">git remote add origin 仓库地址</span><br><span class="line">git push -u origin master</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 更新仓库</span></span><br><span class="line">git status   # 检查是否在该分支下，若不在，切换分支git checkout 分支名。</span><br><span class="line">git add 更新的文件名</span><br><span class="line">git commit -m &quot;更新说明&quot;</span><br><span class="line">git pull# 拉取当前分支最新代码</span><br><span class="line">git push origin master # 上传</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 输入github账户用户名和密码</span></span><br><span class="line">git config --global user.name &quot;你的GitHub登陆名&quot;</span><br><span class="line">git config --global user.email &quot;你的GitHub注册邮箱&quot; </span><br></pre></td></tr></table></figure><p>公司开发分支为develop，员工个人开发分支为personal_develop。员工每次开发需要将develop分支merge到自己分支，在此基础上开发。开发后再提交merge develop request</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 切换到主分支develop</span></span><br><span class="line">git checkout develop</span><br><span class="line"><span class="meta">#</span><span class="bash"> 检查当前分支</span></span><br><span class="line">git branch</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将develop分支代码拉到本地</span></span><br><span class="line">git pull</span><br><span class="line"><span class="meta">#</span><span class="bash"> 切换到个人分支</span></span><br><span class="line">git checkout personal_develop</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将develop分支合并到personal_develop</span></span><br><span class="line">git merge develop</span><br><span class="line"></span><br><span class="line">git clone url# 克隆项目代码</span><br></pre></td></tr></table></figure><h2 id="Vim"><a href="#Vim" class="headerlink" title="Vim"></a>Vim</h2><div align="center">  <img src="Vim.png" height=60% width=60%></div><p>进入文件，如果没有则新建文件<code>vim file_name</code></p><p><strong>写入模式</strong></p><ul><li><code>i</code> 进入写入模式并插入之前<br><code>I</code> 行首插入</li><li><code>a</code> 插入之后<br> <code>A</code> 行尾插入</li><li><code>o</code> 下行插入<br><code>O</code> 上行插入</li><li><code>w</code> 光标向下移动一个词<br><code>b</code> 光标向上移动一个词</li></ul><p><strong>命令模式</strong>（normal模式）</p><ul><li><code>:w</code> 保存<br><code>:w new_filename</code> 另存为指定文件</li><li><code>:q</code> 退出<br><code>:q!</code> 不保存修改退出</li><li><code>:wq</code> 保存并退出 <code>ZZ</code><br><code>:wq!</code> 保存修改并退出（文件所有者及root可使用）</li></ul><p><strong>visual模式</strong></p><ul><li><code>v</code> 进入viual模式从当前位置开始选中</li><li>:normal A.jpg 选中的行尾全部加上.jpg后缀</li><li>ctrl+v 选中块</li></ul><p><strong>\<operation> \<motion></strong><br><code>d ←→</code> 删除光标 （<code>d+6→</code>删除右边6个字符）<br><code>y ←→</code> 复制光标 （<code>y+3←</code>复制左边3个字符）</p><p><strong>复制粘贴剪切</strong></p><ul><li><code>yy</code> 复制当前行<br><code>nyy</code> 复制当前行一下n行 </li><li><code>p</code> 粘贴在当前行上<br><code>P</code> 粘贴在当前行下</li><li><code>dd</code> 删除一行（其实是剪切）<br><code>ndd</code> 删除当前行一下n行<br><code>D</code> 删除光标所在行到文件末尾的内容<br><code>x</code> 删除光标后一个字符<br><code>c</code> 删除并进入写入模式</li><li><code>ciw</code> 词中删除一个词并进入写入模式 （change in word）<br><code>yi&quot;</code> 复制双引号中的内容并进入写入模式（yank in “”）</li></ul><p><strong>替换和取消</strong></p><ul><li><code>r</code> 取代光标所在处字符</li><li><code>R</code> 从光标所在处开始替换字符，按Esc结束</li><li><code>u</code> 撤销</li></ul><p><strong>查找及替换</strong></p><ul><li><code>f</code> 查找<br><code>/</code> 搜索</li><li><code>n</code>下一条结果<br><code>N</code>上一条结果</li><li><code>:%s/old/new/g</code>    全文替换指定字符串<br><code>:n1,n2s/old/new/g</code> 在一定范围内替换指定字符串</li></ul><p><strong>移动</strong></p><ul><li><code>0</code> 回到行首<br><code>$</code> 移到行尾</li><li><code>:1</code> 或 <code>gg</code> 跳到第一行<br><code>:$</code> 或 <code>G</code> 跳到最后一行<br><code>25gg</code> 或 <code>25G</code> 跳到第25行</li><li><code>jkhl</code>上下左右</li></ul><p><strong>刷新分屏</strong></p><ul><li><code>:source $MYVIMRC</code> 刷新vim</li><li><code>:split</code> 上下分屏<br><code>:vsplit</code> 左右分屏</li></ul><p><strong>使用技巧</strong></p><ul><li>导入命令执行结果 <code>r  !命令</code> </li><li>连续行注释<br><code>:n1,n2s/^/#/g</code><br><code>:n1,n2s/^#//g</code><br><code>:n1,n2s/^/\/\//g</code> </li></ul><h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">查看python版本</span></span><br><span class="line">python(3) --version</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看所有的虚拟环境，带有星号*的为当前虚拟环境</span></span><br><span class="line">conda info -e</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建虚拟环境</span></span><br><span class="line">conda create -n your_venv_name python=x.x</span><br><span class="line">virtualenv your_venv_name</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入指定虚拟环境</span></span><br><span class="line">activate your_venv_name(Windows)</span><br><span class="line">source your_venv_name(Linux)</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 退出当前虚拟环境</span></span><br><span class="line">deactivate</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除虚拟环境</span></span><br><span class="line">conda remove -n your_venv_name --all</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看已安装模块</span></span><br><span class="line">pip list</span><br><span class="line">pip freeze</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 批量安装</span></span><br><span class="line">pip freeze &gt; requirements.txt</span><br><span class="line">pip install -r requirements.txt</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 普通下载</span></span><br><span class="line">pip install virtualenv# 安装虚拟环境</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><ul><li><a href="https://blog.csdn.net/keiven_/article/details/118916251">Linux笔记目录</a></li><li><a href="https://blog.csdn.net/keiven_/article/details/112112292">Git相关命令</a></li><li><a href="https://blog.csdn.net/keiven_/article/details/116841540">部署开发环境相关命令</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Analysis and Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Get Target Mask for Zero-shot Learning</title>
      <link href="/2024/07/01/Get-Mask/"/>
      <url>/2024/07/01/Get-Mask/</url>
      
        <content type="html"><![CDATA[<h2 id="目标描述"><a href="#目标描述" class="headerlink" title="目标描述"></a>目标描述</h2><p>给定RGB视频或图片，目标是分割出图像中的指定目标掩码。我们需要复现两个Zero-shot的开源项目，分别为IDEA研究院的GroundingDINO和Facebook的SAM。首先使用目标检测方法GroundingDINO，输入想检测目标的文字提示，可以获得目标的anchor box。将上一步获得的box信息作为SAM的提示，分割出目标mask。具体效果如下（测试数据来自VolumeDeform数据集）：</p><div align="center">  <img src="Grounding_SAM.png" height=80% width=80%></div><p>其中GroundingDINO根据<code>white shirt</code>的文字输入计算的box信息为：<code>&quot;shirt_000500&quot;: &quot;[194.23726, 2.378189, 524.09503, 441.5135]&quot;</code>。项目实测下来单张图片的预测速度GroundingDINO要慢于SAM。GroundingDINO和SAM均会给出多个预测结果，当选择置信度最高的结果时两个模型也会存在预测不准确的情况。</p><h2 id="论文简介"><a href="#论文简介" class="headerlink" title="论文简介"></a>论文简介</h2><h3 id="GroundingDINO"><a href="#GroundingDINO" class="headerlink" title="GroundingDINO"></a>GroundingDINO</h3><p>GroundingDINO extends a closedset detector DINO by performing vision-language modality fusion at multiple phases, including a feature enhancer, a language-guided query selection module, and a cross-modality decoder. Such a deep fusion strategy effectively improves open-set object detection.</p><div align="center">  <img src="GroundingDino.png"></div><h3 id="SAM"><a href="#SAM" class="headerlink" title="SAM"></a>SAM</h3><ul><li>简介：使用三个组件建立图像分割的<strong>foundation model</strong>，解决一系列下游分割问题，可zero-shot生成</li><li>关键技术：<ol><li>promptable分割任务：使用prompt engineering，prompt不确定时输出多目标mask</li><li>分割模型：image encoder + prompt encoder -&gt; mask decoder</li><li>数据驱动：SA-1B（1B masks from 11M imgs）手工标注-&gt;半自动-&gt;全自动</li></ol></li><li>Limitation：存在不连贯不精细的mask结果；交互式实时mask生成但是img encoder耗时；text-to-mask任务效果不鲁棒</li></ul><div align="center">  <img src="23-11-17SAM_foundation.png"></div><div align="center">  <img src="23-11-17SAM.png"></div><h2 id="项目实战"><a href="#项目实战" class="headerlink" title="项目实战"></a>项目实战</h2><p>两个项目的复现很简单，按照github的readme配置相关环境并运行程序。当然也可以直接使用一站式项目Grounded Segment Anything等。当需要分割的图片较多时，可以修改GroundingDINO的<code>demo.sh</code>和<code>demo/inference_on_a_image.py</code>文件将检测结果保存至json文件。</p><p><strong>demo/inference_on_a_image.py文件</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改plot_boxes_to_image函数输出box信息</span></span><br><span class="line">image_with_box, mask, box_coor = plot_boxes_to_image(image_pil, pred_dict)</span><br><span class="line"><span class="comment"># obj为目标名称，i为当前图片的索引</span></span><br><span class="line">obj = <span class="string">&#x27;shirt&#x27;</span></span><br><span class="line">data = &#123;<span class="string">f&#x27;<span class="subst">&#123;obj&#125;</span>_<span class="subst">&#123;<span class="built_in">str</span>(i).zfill(<span class="number">6</span>)&#125;</span>&#x27;</span>: <span class="built_in">str</span>(<span class="built_in">list</span>(box_coor.cpu().detach().numpy()))&#125;</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;box.json&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    old_data = json.load(f)</span><br><span class="line">    old_data.update(data)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;box.json&quot;</span>, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(old_data, f, indent=<span class="number">4</span>)</span><br><span class="line">    <span class="comment"># f.write(json.dumps(old_data, indent=4, ensure_ascii=False))</span></span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure></p><p>然后SAM再读取json文件获取box信息，将SAM的输入提示改为box。</p><p><strong>测试代码</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">coords = []</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_mask</span>(<span class="params">mask, ax, random_color=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> random_color:</span><br><span class="line">        color = np.concatenate([np.random.random(<span class="number">3</span>), np.array([<span class="number">0.6</span>])], axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        color = np.array([<span class="number">30</span> / <span class="number">255</span>, <span class="number">144</span> / <span class="number">255</span>, <span class="number">255</span> / <span class="number">255</span>, <span class="number">0.6</span>])</span><br><span class="line">    h, w = mask.shape[-<span class="number">2</span>:]</span><br><span class="line">    mask_image = mask.reshape(h, w, <span class="number">1</span>) * color.reshape(<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">    ax.imshow(mask_image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_points</span>(<span class="params">coords, labels, ax, marker_size=<span class="number">375</span></span>):</span></span><br><span class="line">    pos_points = coords[labels == <span class="number">1</span>]</span><br><span class="line">    neg_points = coords[labels == <span class="number">0</span>]</span><br><span class="line">    ax.scatter(pos_points[:, <span class="number">0</span>], pos_points[:, <span class="number">1</span>], color=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;*&#x27;</span>, s=marker_size, edgecolor=<span class="string">&#x27;white&#x27;</span>,</span><br><span class="line">               linewidth=<span class="number">1.25</span>)</span><br><span class="line">    ax.scatter(neg_points[:, <span class="number">0</span>], neg_points[:, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;*&#x27;</span>, s=marker_size, edgecolor=<span class="string">&#x27;white&#x27;</span>,</span><br><span class="line">               linewidth=<span class="number">1.25</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_box</span>(<span class="params">box, ax</span>):</span></span><br><span class="line">    x0, y0 = box[<span class="number">0</span>], box[<span class="number">1</span>]</span><br><span class="line">    w, h = box[<span class="number">2</span>] - box[<span class="number">0</span>], box[<span class="number">3</span>] - box[<span class="number">1</span>]</span><br><span class="line">    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor=<span class="string">&#x27;green&#x27;</span>, facecolor=(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), lw=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">on_click</span>(<span class="params">event</span>):</span></span><br><span class="line">    <span class="keyword">global</span> coords</span><br><span class="line">    <span class="keyword">if</span> event.button == <span class="number">1</span>:</span><br><span class="line">        x, y = event.xdata, event.ydata</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;鼠标左键点击：x=<span class="subst">&#123;x:<span class="number">.2</span>f&#125;</span>, y=<span class="subst">&#123;y:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        coords.append([x, y])</span><br><span class="line">        <span class="comment"># if len(coords) == 2:</span></span><br><span class="line">        <span class="comment">#     fig.canvas.mpl_disconnect(cid)</span></span><br><span class="line">    <span class="keyword">elif</span> event.button == <span class="number">3</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;鼠标右键点击&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mask</span>(<span class="params">image, mask_id=<span class="number">1</span>, click_coords=<span class="literal">False</span>, choose_mask=<span class="literal">False</span>, box=<span class="literal">None</span></span>):</span></span><br><span class="line">    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)</span><br><span class="line">    <span class="comment"># plt.figure(figsize=(10, 10))</span></span><br><span class="line">    <span class="comment"># plt.imshow(image)</span></span><br><span class="line">    <span class="comment"># plt.axis(&#x27;on&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> click_coords:</span><br><span class="line">        <span class="keyword">global</span> coords</span><br><span class="line">        fig, ax = plt.subplots()  <span class="comment"># 创建画布和子图对象</span></span><br><span class="line">        fig.set_size_inches(<span class="number">30</span>, <span class="number">20</span>)  <span class="comment"># 设置宽度和高度，单位为英寸（inch）</span></span><br><span class="line">        ax.imshow(image)</span><br><span class="line">        cid = fig.canvas.mpl_connect(<span class="string">&#x27;button_press_event&#x27;</span>, on_click)</span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># 如果使用 必须全局</span></span><br><span class="line">        coords = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> segment_anything <span class="keyword">import</span> SamPredictor, sam_model_registry</span><br><span class="line">    sam_checkpoint = <span class="string">&quot;sam_vit_h_4b8939.pth&quot;</span></span><br><span class="line">    model_type = <span class="string">&quot;vit_h&quot;</span></span><br><span class="line">    device = <span class="string">&quot;cuda&quot;</span></span><br><span class="line">    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)</span><br><span class="line">    sam.to(device=device)</span><br><span class="line">    predictor = SamPredictor(sam)</span><br><span class="line">    predictor.set_image(image)</span><br><span class="line"></span><br><span class="line">    input_point = np.array(coords)</span><br><span class="line">    input_label = np.array([<span class="number">1</span>] * <span class="built_in">len</span>(coords))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plt.figure(figsize=(10, 10))</span></span><br><span class="line">    <span class="comment"># plt.imshow(image)</span></span><br><span class="line">    <span class="comment"># show_points(input_point, input_label, plt.gca())</span></span><br><span class="line">    <span class="comment"># plt.axis(&#x27;on&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line">    input_box = box</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(coords) == <span class="number">0</span>:</span><br><span class="line">        input_point = <span class="literal">None</span></span><br><span class="line">        input_label = <span class="literal">None</span></span><br><span class="line">    masks, scores, logits = predictor.predict(</span><br><span class="line">        point_coords=input_point,</span><br><span class="line">        point_labels=input_label,</span><br><span class="line">        box=input_box[<span class="literal">None</span>, :],</span><br><span class="line">        multimask_output=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> choose_mask:</span><br><span class="line">        plt.figure(figsize=(<span class="number">60</span>, <span class="number">20</span>))</span><br><span class="line">        plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        plt.imshow(image)</span><br><span class="line">        show_mask(masks[<span class="number">0</span>], plt.gca())</span><br><span class="line">        <span class="comment"># show_points(input_point, input_label, plt.gca())</span></span><br><span class="line">        plt.title(<span class="string">f&quot;Mask 0, Score: <span class="subst">&#123;scores[<span class="number">0</span>]:<span class="number">.3</span>f&#125;</span>&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">        plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        plt.imshow(image)</span><br><span class="line">        show_mask(masks[<span class="number">1</span>], plt.gca())</span><br><span class="line">        <span class="comment"># show_points(input_point, input_label, plt.gca())</span></span><br><span class="line">        plt.title(<span class="string">f&quot;Mask 1, Score: <span class="subst">&#123;scores[<span class="number">1</span>]:<span class="number">.3</span>f&#125;</span>&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">        plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">        plt.imshow(image)</span><br><span class="line">        show_mask(masks[<span class="number">2</span>], plt.gca())</span><br><span class="line">        <span class="comment"># show_points(input_point, input_label, plt.gca())</span></span><br><span class="line">        plt.title(<span class="string">f&quot;Mask 2, Score: <span class="subst">&#123;scores[<span class="number">1</span>]:<span class="number">.3</span>f&#125;</span>&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">        mask_id = <span class="built_in">int</span>(<span class="built_in">input</span>())  <span class="comment"># 通过输入idx或者设置特定的idx输出</span></span><br><span class="line"></span><br><span class="line">    mask = masks[mask_id]</span><br><span class="line">    mask = np.tile(np.expand_dims(mask, axis=-<span class="number">1</span>), <span class="number">3</span>)</span><br><span class="line">    mask_data = np.where(mask, <span class="number">255</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># mask_image = np.where(mask, image/255, 0.)</span></span><br><span class="line">    <span class="comment"># plt.figure(figsize=(10, 10))</span></span><br><span class="line">    <span class="comment"># plt.imshow(mask_image)</span></span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">    <span class="keyword">if</span> click_coords: coords.clear()</span><br><span class="line">    <span class="keyword">return</span> mask_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    obj = <span class="string">&#x27;shirt&#x27;</span></span><br><span class="line">    color_path = <span class="string">f&#x27;/Data/VolumeDeformData/<span class="subst">&#123;obj&#125;</span>/data/&#x27;</span></span><br><span class="line">    mask_path = <span class="string">f&#x27;/Data/VolumeDeformData/<span class="subst">&#123;obj&#125;</span>/mask/&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(mask_path):</span><br><span class="line">        os.makedirs(mask_path)</span><br><span class="line"></span><br><span class="line">    img_paths = []</span><br><span class="line">    <span class="keyword">for</span> extension <span class="keyword">in</span> [<span class="string">&quot;jpg&quot;</span>, <span class="string">&quot;png&quot;</span>, <span class="string">&quot;jpeg&quot;</span>]:</span><br><span class="line">        img_paths += glob.glob(os.path.join(color_path, <span class="string">&quot;*.&#123;&#125;&quot;</span>.<span class="built_in">format</span>(extension)))</span><br><span class="line"></span><br><span class="line">    json_path = <span class="string">&#x27;GroundingDINO-main/box.json&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        data = json.load(f)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img_paths) // <span class="number">2</span>):</span><br><span class="line">            img_name = <span class="string">f&#x27;frame-<span class="subst">&#123;<span class="built_in">str</span>(i).zfill(<span class="number">6</span>)&#125;</span>.color.png&#x27;</span></span><br><span class="line">            img = cv2.imread(color_path + img_name)</span><br><span class="line">            <span class="built_in">id</span> = <span class="string">f&#x27;<span class="subst">&#123;obj&#125;</span>_<span class="subst">&#123;<span class="built_in">str</span>(i).zfill(<span class="number">6</span>)&#125;</span>&#x27;</span></span><br><span class="line">            box = np.array(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>, data[<span class="built_in">id</span>][<span class="number">1</span>:-<span class="number">1</span>].split(<span class="string">&#x27;,&#x27;</span>))))</span><br><span class="line">            mask = get_mask(img, mask_id=<span class="number">2</span>, click_coords=<span class="literal">False</span>, choose_mask=<span class="literal">False</span>, box=box)</span><br><span class="line">            cv2.imwrite(mask_path + <span class="built_in">str</span>(i).zfill(<span class="number">6</span>) + <span class="string">&#x27;.png&#x27;</span>, mask)</span><br><span class="line">            <span class="built_in">print</span>(img_name)</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure></p><h2 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h2><ul><li><strong>GroundingDINO</strong> <a href="https://github.com/IDEA-Research/GroundingDINO">github</a> <a href="https://arxiv.org/abs/2303.05499">arXiv</a></li><li><strong>SAM</strong> <a href="https://segment-anything.com">Demo</a> <a href="https://github.com/facebookresearch/segment-anything">github</a> <a href="https://arxiv.org/abs/2304.02643">arXiv</a></li><li><strong>Grounded Segment Anything</strong> <a href="https://github.com/IDEA-Research/Grounded-Segment-Anything">github</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Reading Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Computer Vision </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Technical Summary —— Big Data Processing</title>
      <link href="/2024/04/15/Technical-Summary-BigData/"/>
      <url>/2024/04/15/Technical-Summary-BigData/</url>
      
        <content type="html"><![CDATA[<p>近期致力于总结科研或者工作中用到的主要技术栈，从技术原理到常用语法，这次查缺补漏当作我的小百科。主要技术包括：</p><ul><li>✅<a href="https://xfliu1998.github.io/2024/04/07/Technical-Summary-Database/">数据库常用：MySQL, Hive SQL, Spark SQL</a></li><li>✅<a href="https://xfliu1998.github.io/2024/04/15/Technical-Summary-BigData/">大数据处理常用：Pyspark, Pandas</a></li><li>⚪ 图像处理常用：OpenCV, Matplotlib </li><li>⚪ 机器学习常用：SciPy, Sklearn</li><li>✅ <a href="https://xfliu1998.github.io/2024/07/09/Technical-Summary-Deep-Learning/">深度学习常用：Pytorch, Numpy</a></li><li>✅ <a href="https://xfliu1998.github.io/2024/07/02/Technical-Summary-Necessary/">常用命令: Shell, Git, Vim</a></li></ul><p>以下整理错误或者缺少的部分欢迎指正！！！</p><h1 id="大数据处理常用：Pyspark-Pandas"><a href="#大数据处理常用：Pyspark-Pandas" class="headerlink" title="大数据处理常用：Pyspark, Pandas"></a>大数据处理常用：Pyspark, Pandas</h1><h2 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h2><div class="table-container"><table><thead><tr><th></th><th>Pyspark</th><th>Pandas</th></tr></thead><tbody><tr><td>运行环境</td><td>分布式计算集群（Hadoop/Apache Spark集群）</td><td>单个计算机</td></tr><tr><td>数据规模</td><td>亿级大规模</td><td>百万级小规模</td></tr><tr><td>优势</td><td>分布式计算-&gt;并行处理，处理速度快</td><td>API简单-&gt;数据处理简单</td></tr><tr><td>延迟机制</td><td>lazy execution, 执行动作之前不执行任务</td><td>eager execution, 任务立即被执行</td></tr><tr><td>内存缓存</td><td>persist()/cache()将转换的RDDs保存在内存</td><td>单机缓存</td></tr><tr><td>DataFrame可变性</td><td>不可变，修改则返回一个新的DataFrame</td><td>可变</td></tr><tr><td>可扩展性</td><td>好</td><td>差</td></tr><tr><td>列名允许重复</td><td>✓</td><td>×</td></tr></tbody></table></div><h2 id="常用语法对比"><a href="#常用语法对比" class="headerlink" title="常用语法对比"></a>常用语法对比</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 头文件</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, LongType, StringType, ArrayType  <span class="comment"># 或者直接导入*</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建SparkSession对象</span></span><br><span class="line">spark = SparkSession.builder \</span><br><span class="line">    .appName(<span class="string">&quot;username&quot;</span>) \</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建空表</span></span><br><span class="line">schema = StructType([</span><br><span class="line">                StructField(<span class="string">&#x27;id&#x27;</span>, LongType()),</span><br><span class="line">                StructField(<span class="string">&#x27;type&#x27;</span>, StringType()),</span><br><span class="line">            ])  <span class="comment"># spark需要指定列名和类型</span></span><br><span class="line">spark_df = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema=schema)</span><br><span class="line">pandas_df = pd.DataFrame(columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;type&#x27;</span>], index=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据现有数据创建</span></span><br><span class="line">data = [(<span class="number">1</span>, <span class="string">&quot;Alice&quot;</span>, <span class="number">2000</span>), (<span class="number">2</span>, <span class="string">&quot;Bob&quot;</span>, <span class="number">2001</span>), (<span class="number">3</span>, <span class="string">&quot;Charlie&quot;</span>, <span class="number">2002</span>)]</span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;id&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;name&quot;</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;birth_year&quot;</span>, IntegerType(), <span class="literal">True</span>)</span><br><span class="line">])</span><br><span class="line">spark_df = spark.createDataFrame(data, [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;birth_year&quot;</span>])</span><br><span class="line">spark_df = spark.createDataFrame(data, schema)</span><br><span class="line">pandas_df = pd.DataFrame(data=data, columns=[<span class="string">&quot;id&quot;</span>, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;birth_year&quot;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取csv文件</span></span><br><span class="line">spark_df = spark.read.csv(<span class="string">&quot;data.csv&quot;</span>, header=<span class="literal">True</span>, inferSchema=<span class="literal">True</span>)</span><br><span class="line">pandas_df = pd.read_csv(<span class="string">&quot;data.csv&quot;</span>, sep=<span class="string">&quot;\t&quot;</span>)  <span class="comment"># read_excel</span></span><br><span class="line"><span class="comment"># 保存数据到csv</span></span><br><span class="line">spark_df.write.csv(<span class="string">&#x27;data.csv&#x27;</span>, header=<span class="literal">True</span>)</span><br><span class="line">pandas_df.to_csv(<span class="string">&quot;data.csv&quot;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取hive表数据</span></span><br><span class="line">spark_df = spark.sql(<span class="string">&#x27;select * from tab&#x27;</span>)</span><br><span class="line"><span class="comment"># 保存数据到hive表</span></span><br><span class="line">spark_df.write.mode(<span class="string">&#x27;overwrite&#x27;</span>).saveAsTable(<span class="string">&#x27;db_name.tab_name&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 相互转换</span></span><br><span class="line">spark_df = SQLContext.createDataFrame(pandas_df)</span><br><span class="line">pandas_df = spark_df.toPandas()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换数据类型</span></span><br><span class="line">spark_df = spark_df.withColumn(<span class="string">&quot;A&quot;</span>, col(<span class="string">&quot;age&quot;</span>).cast(StringType))</span><br><span class="line">pandas_df[<span class="string">&quot;A&quot;</span>] = pandas_df[<span class="string">&#x27;A&#x27;</span>].astype(<span class="string">&quot;int&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重置索引</span></span><br><span class="line">spark_df = spark_df.withColumn(<span class="string">&quot;id&quot;</span>, monotonically_increasing_id())  <span class="comment"># 生成一个增长的id列</span></span><br><span class="line">pandas_df.reset_index()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 切片</span></span><br><span class="line">pandas_df[<span class="string">&#x27;a&#x27;</span>:<span class="string">&#x27;c&#x27;</span>]  <span class="comment"># a-c三行</span></span><br><span class="line">pandas_df.iloc[<span class="number">1</span>:<span class="number">3</span>, <span class="number">0</span>:<span class="number">2</span>]  <span class="comment"># 1-2行，0-1列。左闭右开</span></span><br><span class="line">pandas_df.iloc[[<span class="number">0</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>]] <span class="comment"># 第0，2行第0，2列</span></span><br><span class="line">pandas_df.loc[<span class="string">&#x27;a&#x27;</span>:<span class="string">&#x27;c&#x27;</span>, [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>]] <span class="comment"># 第a-c行A，B列</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择列</span></span><br><span class="line">spark_df.select(<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>)</span><br><span class="line">pandas_df[[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除列</span></span><br><span class="line">spark_df.drop(<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>)</span><br><span class="line">pandas_df.drop([<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)  <span class="comment"># inplace表示是否创建新对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 新增列，设置列值</span></span><br><span class="line">spark_df = spark_df.withColumn(<span class="string">&#x27;name&#x27;</span>, F.lit(<span class="number">0</span>))</span><br><span class="line">pandas_df[<span class="string">&#x27;name&#x27;</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改列值</span></span><br><span class="line">spark_df.withColumn(<span class="string">&#x27;name&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">pandas_df[<span class="string">&#x27;name&#x27;</span>] = <span class="number">1</span></span><br><span class="line"><span class="comment"># 使用函数修改列值</span></span><br><span class="line">spark_df = spark_df.withColumn(<span class="string">&#x27;code&#x27;</span>, F.when(F.isnull(spark_df.code), <span class="number">0</span>).otherwise(spark_df.code))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改列名</span></span><br><span class="line">spark_df.withColumnRenamed(<span class="string">&#x27;old_name&#x27;</span>, <span class="string">&#x27;new_name&#x27;</span>)</span><br><span class="line">pandas_df.rename(columns=&#123;<span class="string">&#x27;old_name1&#x27;</span>: <span class="string">&#x27;new_name1&#x27;</span>, <span class="string">&#x27;old_name1&#x27;</span>: <span class="string">&#x27;new_name2&#x27;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示数据</span></span><br><span class="line">spark_df.limit(<span class="number">10</span>) <span class="comment"># 前10行</span></span><br><span class="line">spark_df.show/take(<span class="number">10</span>)  <span class="comment"># collect()返回全部数据</span></span><br><span class="line">spark_df/pandas_df.first/head/tail(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 表格遍历</span></span><br><span class="line">saprk_df.collect()[:<span class="number">10</span>]</span><br><span class="line">spark_df.foreach(<span class="keyword">lambda</span> row: <span class="built_in">print</span>(row[<span class="string">&#x27;c1&#x27;</span>], row[<span class="string">&#x27;c2&#x27;</span>]))</span><br><span class="line"><span class="keyword">for</span> i, row <span class="keyword">in</span> pandas_df.iterrows():</span><br><span class="line">    <span class="built_in">print</span>(row[<span class="string">&quot;c1&quot;</span>], row[<span class="string">&quot;c2&quot;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 排序</span></span><br><span class="line">spark/pandas_df.sort()  <span class="comment"># 按列值排序</span></span><br><span class="line">pandas_df.sort_index()  <span class="comment"># 按轴排序</span></span><br><span class="line">pandas_df.sort_values(by=[<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>], axis=<span class="number">0</span>, ascending=[<span class="literal">True</span>, <span class="literal">False</span>], inplace=<span class="literal">True</span>)  <span class="comment"># 指定列升序/降序排序</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 过滤</span></span><br><span class="line">spark_df.<span class="built_in">filter</span>(df[<span class="string">&#x27;col_name&#x27;</span>] &gt; <span class="number">1</span>)     <span class="comment"># spark_df.where(df[&#x27;col_name&#x27;] &gt; 1)</span></span><br><span class="line">pandas_df[pandas_df[<span class="string">&#x27;col_name&#x27;</span>] &gt; <span class="number">1</span>]</span><br><span class="line">pandas_df_new = pandas_df[pandas_df[<span class="string">&quot;code&quot;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">len</span>(x) == <span class="number">11</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 去重</span></span><br><span class="line">spark_df.select(<span class="string">&#x27;col_name&#x27;</span>).distinct()</span><br><span class="line">spark_df_filter = spark_df.drop_duplicates([<span class="string">&quot;col_name&quot;</span>])</span><br><span class="line">pandas_df.drop_duplicates([<span class="string">&quot;col_name&quot;</span>], keep=<span class="string">&#x27;first&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 缺失数据处理</span></span><br><span class="line">spark_df.na.fill()</span><br><span class="line">spark_df.na.drop(subset=[<span class="string">&#x27;A&#x27;</span>, <span class="string">&quot;B&quot;</span>])  <span class="comment"># 同dropna</span></span><br><span class="line">pandas_df.fillna()</span><br><span class="line">pandas_df.dropna(subset=[<span class="string">&#x27;A&#x27;</span>, <span class="string">&quot;B&quot;</span>], how=<span class="string">&quot;any&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 空值过滤 filter=choose</span></span><br><span class="line">spark_df.<span class="built_in">filter</span>(~(F.isnull(spark_df.d)))</span><br><span class="line">spark_df.<span class="built_in">filter</span>(~(spark_df[<span class="string">&#x27;A&#x27;</span>].isNull() | spark_df[<span class="string">&#x27;B&#x27;</span>].isNull()))   <span class="comment"># 选出列值不为空的行  isnan()=isNull()&lt;-&gt;isNOtnan()</span></span><br><span class="line">pandas_df[pandas_df[<span class="string">&#x27;A&#x27;</span>].isna()]  <span class="comment"># 选出列值为空的行</span></span><br><span class="line">pandas_df[pandas_df[<span class="string">&#x27;A&#x27;</span>].notna()] <span class="comment"># 选出列值不为空的行</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计</span></span><br><span class="line">spark/pandas_df.count()  <span class="comment"># spark返回总行数，pandas返回列非空总数</span></span><br><span class="line">spark/pandas_df.describe() <span class="comment"># 描述列的count, mean, min, max...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算某一列均值</span></span><br><span class="line">average_value = spark_df.select(<span class="string">&quot;col_name&quot;</span>).agg(&#123;<span class="string">&quot;col_name&quot;</span>: <span class="string">&quot;avg&quot;</span>&#125;).collect()[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">average_value = pandas_df[<span class="string">&quot;col_name&quot;</span>].mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 表合并</span></span><br><span class="line"><span class="comment"># 按行合并，相当于追加</span></span><br><span class="line">spark_df = spark_df.unionAll(spark_df1)</span><br><span class="line">pandas_df = pd.concat([df_up, df_down], axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 按列合并</span></span><br><span class="line">spark_df = spark_df.join(df1, df1.<span class="built_in">id</span>==spark_df.<span class="built_in">id</span>, <span class="string">&#x27;inner&#x27;</span>).drop(df1.<span class="built_in">id</span>)  <span class="comment"># df1.id==spark_df.id也可写成[&#x27;id]（当且仅当列名相同）</span></span><br><span class="line">pd.merge(df_left, df_right, left_on=<span class="string">&quot;a&quot;</span>, right_on=<span class="string">&quot;b&quot;</span>, how=<span class="string">&quot;left|right|inner|outer&quot;</span>)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚合函数</span></span><br><span class="line">spark_df_collect = spark_df.groupBy(<span class="string">&#x27;number&#x27;</span>).agg(</span><br><span class="line">    F.collect_set(<span class="string">&#x27;province&#x27;</span>).alias(<span class="string">&#x27;set_province&#x27;</span>),</span><br><span class="line">    F.first(<span class="string">&#x27;city&#x27;</span>).alias(<span class="string">&#x27;set_city&#x27;</span>),</span><br><span class="line">    F.collect_list(<span class="string">&#x27;district&#x27;</span>).alias(<span class="string">&#x27;set_district&#x27;</span>),</span><br><span class="line">    F.<span class="built_in">max</span>(<span class="string">&#x27;report_user&#x27;</span>).alias(<span class="string">&#x27;set_report_user&#x27;</span>),</span><br><span class="line">    F.<span class="built_in">min</span>(<span class="string">&#x27;first_type&#x27;</span>).alias(<span class="string">&#x27;set_first_type&#x27;</span>))</span><br><span class="line"><span class="comment"># 分组聚合</span></span><br><span class="line">spark_df.groupBy(<span class="string">&#x27;A&#x27;</span>).agg(F.avg(<span class="string">&#x27;B&#x27;</span>), F.<span class="built_in">min</span>(<span class="string">&#x27;B&#x27;</span>))</span><br><span class="line">spark/pandas_df.groupby(<span class="string">&#x27;A&#x27;</span>).avg(<span class="string">&#x27;B&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据函数分组聚合</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> pd.DataFrame(&#123;</span><br><span class="line">        <span class="string">&quot;A&quot;</span>: x[<span class="string">&quot;A&quot;</span>].tolist()[<span class="number">0</span>],</span><br><span class="line">        <span class="string">&quot;B&quot;</span>: <span class="built_in">sum</span>(x[<span class="string">&quot;B&quot;</span>])&#125;, index=[<span class="number">0</span>])</span><br><span class="line">pandas_df_result = pandas_df.groupby([<span class="string">&quot;A&quot;</span>]).apply(func)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># spark udf函数和pandas apply函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func1</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line">spark_df.withColumn(<span class="string">&quot;col_name&quot;</span>, F.udf(func1, IntegerType())(spark_df.a, spark_df.b))  <span class="comment"># spark_df[&#x27;a&#x27;]或F.col(&quot;a&quot;)))</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func2</span>(<span class="params">x,y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> x &gt; np.mean(y) <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">pandas_df[<span class="string">&#x27;A&#x27;</span>].apply(func2, args=(pandas_df[<span class="string">&#x27;B&#x27;</span>],))</span><br><span class="line">pandas_df[<span class="string">&#x27;C&#x27;</span>] = pandas_df.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x[<span class="string">&#x27;A&#x27;</span>] &gt; (x[<span class="string">&#x27;B&#x27;</span>]*<span class="number">0.5</span>) <span class="keyword">else</span> <span class="number">0</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># spark创建临时表</span></span><br><span class="line">spark_df.createOrReplaceTempView(<span class="string">&#x27;tmp_table&#x27;</span>)  <span class="comment"># 用sql API</span></span><br><span class="line">res1 = spark.sql(<span class="string">&#x27;select * from tmp_table&#x27;</span>)</span><br><span class="line">spark_df.registerTempTable(<span class="string">&#x27;tmp_table&#x27;</span>) <span class="comment"># 用dataframe API</span></span><br><span class="line">res2 = spark.table(<span class="string">&#x27;tmp_table&#x27;</span>) </span><br></pre></td></tr></table></figure><p><strong>其他常用设置</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparkUtils</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.spark = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_spark</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.spark <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.spark = SparkSession.builder.appName(<span class="string">&quot;username&quot;</span>) \</span><br><span class="line">                .enableHiveSupport().config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="string">&quot;500&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.sql.broadcastTimeout&quot;</span>, <span class="string">&quot;3600&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.driver.memory&quot;</span>, <span class="string">&quot;200g&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.executor.memory&quot;</span>, <span class="string">&quot;40g&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.yarn.appMasterEnv.yarn.nodemanager.container-executor.class&quot;</span>, <span class="string">&quot;DockerLinuxContainer&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.executorEnv.yarn.nodemanager.container-executor.class&quot;</span>, <span class="string">&quot;DockerLinuxContainer&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.yarn.appMasterEnv.yarn.nodemanager.docker-container-executor.image-name&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;bdp-docker.jd.com:5000/wise_mart_bag:latest&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.executorEnv.yarn.nodemanager.docker-container-executor.image-name&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;bdp-docker.jd.com:5000/wise_mart_bag:latest&quot;</span>) \</span><br><span class="line">                .getOrCreate()</span><br><span class="line">        self.spark.sql(<span class="string">&#x27;SET hive.exec.dynamic.partition=true&#x27;</span>)</span><br><span class="line">        self.spark.sql(<span class="string">&#x27;SET hive.exec.dynamic.partition.mode=nonstrict&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> self.spark</span><br><span class="line"></span><br><span class="line">spark = SparkUtils()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成dataframe</span></span><br><span class="line">spark_data = spark.sql(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    select </span></span><br><span class="line"><span class="string">      id, </span></span><br><span class="line"><span class="string">      username</span></span><br><span class="line"><span class="string">    from </span></span><br><span class="line"><span class="string">      tab1</span></span><br><span class="line"><span class="string">    where </span></span><br><span class="line"><span class="string">      status in (1, 2, 3)</span></span><br><span class="line"><span class="string">      and dt = &#x27;&#123;&#125;&#x27;</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span>.<span class="built_in">format</span>(date))</span><br><span class="line"></span><br><span class="line"><span class="comment"># pandas常用显示设置</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_rows&#x27;</span>, <span class="number">100</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.width&#x27;</span>,<span class="number">1000</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_colwidth&#x27;</span>,<span class="number">1000</span>)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> Data Analysis and Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Technical Summary —— Database Usage</title>
      <link href="/2024/04/07/Technical-Summary-Database/"/>
      <url>/2024/04/07/Technical-Summary-Database/</url>
      
        <content type="html"><![CDATA[<p>近期致力于总结科研或者工作中用到的主要技术栈，从技术原理到常用语法，这次查缺补漏当作我的小百科。主要技术包括：</p><ul><li>✅<a href="https://xfliu1998.github.io/2024/04/07/Technical-Summary-Database/">数据库常用：MySQL, Hive SQL, Spark SQL</a></li><li>✅<a href="https://xfliu1998.github.io/2024/04/15/Technical-Summary-BigData/">大数据处理常用：Pyspark, Pandas</a></li><li>⚪ 图像处理常用：OpenCV, Matplotlib </li><li>⚪ 机器学习常用：SciPy, Sklearn</li><li>✅ <a href="https://xfliu1998.github.io/2024/07/09/Technical-Summary-Deep-Learning/">深度学习常用：Pytorch, Numpy</a></li><li>✅ <a href="https://xfliu1998.github.io/2024/07/02/Technical-Summary-Necessary/">常用命令: Shell, Git, Vim</a></li></ul><p>以下整理错误或者缺少的部分欢迎指正！！！</p><h1 id="数据库常用：MySQL-HQL-Spark-SQL"><a href="#数据库常用：MySQL-HQL-Spark-SQL" class="headerlink" title="数据库常用：MySQL, HQL, Spark SQL"></a>数据库常用：MySQL, HQL, Spark SQL</h1><blockquote><p>数据库（Database）是按照数据结构来组织、存储和管理数据的仓库。</p></blockquote><h2 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h2><div class="table-container"><table><thead><tr><th></th><th>MySQL</th><th>Hive SQL</th><th>Spark SQL</th></tr></thead><tbody><tr><td>数据存储系统</td><td>关系型数据库</td><td>基于Hadoop的数据仓库系统</td><td>在Spark上构建的分布式计算引擎</td></tr><tr><td>数据处理能力</td><td>小规模结构化数据</td><td>大规模非结构化和半结构化数据</td><td>大规模非结构化和半结构化数据</td></tr><tr><td>执行引擎</td><td>传统查询优化器和Executor</td><td>将查询转换为MapReduce</td><td>Spark引擎</td></tr><tr><td>分布式存储和处理</td><td>否</td><td>是</td><td>是</td></tr><tr><td>实时查询</td><td>是</td><td>否（只能离线分析）</td><td>是</td></tr><tr><td>可扩展性</td><td>低</td><td>高</td><td>高</td></tr><tr><td>优势</td><td>管理索引、表分区</td><td>表分区、分桶、UDF/UDAF</td><td>提供DF接口</td></tr></tbody></table></div><p>更详细的介绍：</p><ul><li><a href="https://xfliu1998.github.io/2022/01/18/5.4-Hive/">Hive &amp; Hbase</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.6-Spark-SQL/">Spark SQL &amp; Spark streaming</a></li><li><a href="https://blog.csdn.net/keiven_/article/details/117883655">数据库分类及数据库笔记目录</a></li></ul><h2 id="常用语法"><a href="#常用语法" class="headerlink" title="常用语法"></a>常用语法</h2><div class="table-container"><table><thead><tr><th></th><th>MySQL</th><th>Hive SQL</th><th>Spark SQL</th></tr></thead><tbody><tr><td>关系</td><td></td><td>适用大部分MySQL语法</td><td>兼容hive</td></tr><tr><td>DDL（定义）</td><td>CREATE DROP ALTER</td><td>✓</td><td>✓</td></tr><tr><td>DML（操作）</td><td>INSERT DELETE UPDATE</td><td>✓</td><td>✓</td></tr><tr><td>DQL（查询）</td><td>SELECT WHERE</td><td>✓</td><td>✓</td></tr><tr><td>DCL（控制）</td><td>GRANT REVOKE</td><td>✓</td><td>✓</td></tr><tr><td>函数</td><td><code>nvl(expr1, expr2)</code></td><td><code>ifnull(ex pr1, expr2)</code></td><td>同hive</td></tr><tr><td>merge into</td><td>只能使用update/delete/insert代替</td><td>✓</td><td>✓</td></tr><tr><td>join on关联条件支持不等值连接</td><td>×</td><td>×</td><td>✓</td></tr></tbody></table></div><p><strong>MYSQL 常用</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span><span class="operator">/</span><span class="keyword">DROP</span> DATABASE<span class="operator">/</span><span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> db<span class="operator">/</span>tab; <span class="comment">-- 创建/删除数据库/表</span></span><br><span class="line">USE db; <span class="comment">-- 使用指定数据库</span></span><br><span class="line"><span class="keyword">SET</span> SQL_SAFE_UPDATES <span class="operator">=</span> <span class="number">0</span>; <span class="comment">-- 关闭安全模式</span></span><br><span class="line"><span class="keyword">SHOW</span> DATABASES<span class="operator">/</span>TABLES; <span class="comment">-- 查询所有数据库/表名;</span></span><br><span class="line"><span class="keyword">desc</span> 表名; <span class="comment">-- 查询表结构</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student(  <span class="comment">-- 列名 数据类型（包括int、double、varchar、date、datetime、timestamp）</span></span><br><span class="line">id <span class="type">INT</span> <span class="keyword">primary</span> key auto_increment,        </span><br><span class="line">    NAME <span class="type">VARCHAR</span>(<span class="number">20</span>) <span class="keyword">unique</span>,  </span><br><span class="line">    age <span class="type">INT</span> <span class="keyword">not</span> <span class="keyword">NULL</span>,</span><br><span class="line">    adress <span class="type">VARCHAR</span>(<span class="number">10</span>) <span class="keyword">constraint</span> 外键名 <span class="keyword">foreign</span> key (外键列名) reference 主表名(主表列名),</span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> student <span class="keyword">VALUES</span>(<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;马云&#x27;</span>,<span class="string">&#x27;55&#x27;</span>,<span class="string">&#x27;男&#x27;</span>, <span class="string">&#x27;杭州&#x27;</span>, <span class="string">&#x27;66&#x27;</span>, <span class="string">&#x27;78&#x27;</span>),</span><br><span class="line">  (<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;柳青&#x27;</span>, <span class="string">&#x27;20&#x27;</span>, <span class="string">&#x27;女&#x27;</span>, <span class="string">&#x27;湖南&#x27;</span>, <span class="string">&#x27;86&#x27;</span>, <span class="keyword">NULL</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> 表名 rename 新表名；</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> 表名 <span class="keyword">ADD</span><span class="operator">/</span>MODIFY 列名 数据类型； <span class="comment">-- 新增/修改列名、类型</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> 表名 CHANGE 列名 新列别 新数据类型；</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> 表名 <span class="keyword">DROP</span> 列名;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> 表名 <span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> 外键名 <span class="keyword">FOREIGN</span> KEY (外键列名) <span class="keyword">REFERENCES</span> department 主表名(主表列名); <span class="comment">-- 创建完表添加外键约束</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> 表名 <span class="keyword">DROP</span> <span class="keyword">FOREIGN</span> KEY 外键名; <span class="comment">-- 删除外键</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> student <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">9</span>;</span><br><span class="line">UPDATE student <span class="keyword">SET</span> age <span class="operator">=</span> <span class="number">99</span> <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">9</span>;</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> 表名；</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    (<span class="keyword">DISTINCT</span>) 字段列表 (<span class="keyword">as</span> 别名)</span><br><span class="line"><span class="keyword">FROM</span> </span><br><span class="line">    表名列表</span><br><span class="line"><span class="keyword">WHERE</span> </span><br><span class="line">    条件列表       <span class="comment">-- where在分组前限定，后不可跟聚合函数</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> </span><br><span class="line">    分组字段</span><br><span class="line"><span class="keyword">having</span></span><br><span class="line">    分组之后的条件  <span class="comment">-- having在分组后限定，后可进行聚合函数的判断</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> </span><br><span class="line">    排序字段 <span class="keyword">ASC</span><span class="operator">/</span><span class="keyword">DESC</span> <span class="comment">-- (ASC默认升序，DESC降序)</span></span><br><span class="line">limit</span><br><span class="line">    分页限制       <span class="comment">-- 开始索引，每页查询条数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- as起别名; 计算math和english分数之和</span></span><br><span class="line"><span class="keyword">SELECT</span> math, english, math <span class="operator">+</span> IFNULL(english, <span class="number">0</span>) [<span class="keyword">AS</span>] 总分 <span class="keyword">FROM</span> student; <span class="comment">-- 如果有null参与运算，计算结果都为null</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询姓名第二个字是化的；通配符：%任意多个字符，_单个字符</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> student <span class="keyword">WHERE</span> NAME <span class="keyword">LIKE</span> <span class="string">&#x27;_化%&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 聚合函数；按性别分组分别查询男女生的平均分、人数，要求数学分数高于70分，分组后人数要大于两个 </span></span><br><span class="line"><span class="keyword">SELECT</span> sex, <span class="built_in">AVG</span>(math), <span class="built_in">COUNT</span>(id) <span class="keyword">FROM</span> student <span class="keyword">WHERE</span> math <span class="operator">&gt;</span> <span class="number">70</span> <span class="keyword">GROUP</span> <span class="keyword">BY</span> sex <span class="keyword">HAVING</span> <span class="built_in">COUNT</span>(id) <span class="operator">&gt;</span> <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 笛卡尔积</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> dept, emp;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 内连接</span></span><br><span class="line"><span class="keyword">SELECT</span> emp.`name`,emp.`gender`,dept.`name` <span class="keyword">FROM</span> emp,dept <span class="keyword">WHERE</span> emp.`dept_id` <span class="operator">=</span> dept.`id`;  <span class="comment">-- 隐式内连接</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp [<span class="keyword">INNER</span>] <span class="keyword">JOIN</span> dept <span class="keyword">ON</span> emp.`dept_id` <span class="operator">=</span> dept.`id`;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 外连接</span></span><br><span class="line"><span class="keyword">SELECT</span> t1.<span class="operator">*</span>,t2.name <span class="keyword">FROM</span> emp t1 <span class="keyword">LEFT</span> [<span class="keyword">outer</span>] <span class="keyword">JOIN</span> dept t2 <span class="keyword">ON</span> t1.`dept_id` <span class="operator">=</span> t2.`id`; <span class="comment">-- 左外连接：左表所有数据及交集部分</span></span><br><span class="line"><span class="keyword">SELECT</span> t1.<span class="operator">*</span>,t2.name <span class="keyword">FROM</span> dept t2 <span class="keyword">RIGHT</span> [<span class="keyword">outer</span>] <span class="keyword">JOIN</span> emp t1 <span class="keyword">ON</span> t1.`dept_id` <span class="operator">=</span> t2.`id`; <span class="comment">-- 右外连接：右表所有数据及交集部分</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 子查询 */</span></span><br><span class="line"><span class="comment">-- 子查询的结果是单行单列的，子查询可作为条件，使用运算符判断</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">WHERE</span> emp.`salary` <span class="operator">&lt;</span> (<span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) <span class="keyword">FROM</span> emp);</span><br><span class="line"><span class="comment">-- 子查询的结果是多行单列的，子查询可作为条件，使用运算符in判断</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">WHERE</span> dept_id <span class="keyword">IN</span> (<span class="keyword">SELECT</span> id <span class="keyword">FROM</span> dept <span class="keyword">WHERE</span> NAME <span class="operator">=</span> <span class="string">&#x27;市场部&#x27;</span> <span class="keyword">OR</span> NAME <span class="operator">=</span> <span class="string">&#x27;财务部&#x27;</span>);</span><br><span class="line"><span class="comment">-- 子查询的结果是多行多列的，子查询可作为一张虚拟表参与查询</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> dept t1,(<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">WHERE</span> emp.`join_date` <span class="operator">&gt;</span> <span class="string">&#x27;2011-11-11&#x27;</span>) t2 <span class="keyword">WHERE</span> t1.`id` <span class="operator">=</span> t2.dept_id;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 常用函数 </span></span><br><span class="line"><span class="keyword">select</span> if(<span class="type">boolean</span> testCondition, T valueTrue, T valueFalseOrNull) <span class="keyword">from</span> <span class="keyword">user</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> 条件 <span class="keyword">then</span> 值</span><br><span class="line">...</span><br><span class="line"><span class="keyword">when</span> 条件 <span class="keyword">then</span> 值 <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span> 字段名; </span><br><span class="line">CONCAT(str1,str2,…)  <span class="comment">-- 连接字符串</span></span><br><span class="line">CONCAT_WS(separator,str1,str2,...) <span class="comment">-- 以分隔符连接字符串</span></span><br><span class="line">GROUP_CONCAT( [<span class="keyword">distinct</span>] 要连接的字段 [<span class="keyword">group</span> <span class="keyword">by</span> 字段] [separator <span class="string">&#x27;分隔符&#x27;</span>]) <span class="comment">-- 分组连接字段</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- with as；相当于创建e、d临时表</span></span><br><span class="line"><span class="keyword">with</span></span><br><span class="line">    e <span class="keyword">as</span> (<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> scott.emp),</span><br><span class="line">    d <span class="keyword">as</span> (<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> scott.dept)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> e, d <span class="keyword">where</span> e.deptno <span class="operator">=</span> d.deptno;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- union all多个select不去重不排序；union [distinct] 去重且排序</span></span><br><span class="line"><span class="keyword">select</span> id,score <span class="keyword">from</span> union_test1 <span class="keyword">union</span> [<span class="keyword">distinct</span>] <span class="keyword">select</span> id, score <span class="keyword">from</span> union_test2;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- json data</span></span><br><span class="line">jsonData <span class="operator">=</span> <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">&quot;message&quot;:&#123;</span></span><br><span class="line"><span class="string">&quot;location&quot;:[&#123;&quot;county&quot;:&quot;浦东&quot;,&quot;city&quot;:&quot;上海&quot;&#125;,</span></span><br><span class="line"><span class="string">&#123;&quot;county&quot;:&quot;西直门&quot;,&quot;city&quot;:&quot;北京&quot;&#125;]</span></span><br><span class="line"><span class="string">&#125;   &#125;&#x27;</span> <span class="comment">--jsonData列数据为字符串格式，外面是单引号，里面是双引号</span></span><br><span class="line"><span class="keyword">select</span> get_json_object(jsonData,<span class="string">&#x27;$.message.location[0].city&#x27;</span>) <span class="keyword">from</span> test <span class="comment">--输出：上海</span></span><br></pre></td></tr></table></figure></p><p><strong>hive常用命令</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hive # hive启动！</span><br><span class="line">hive -e &quot;sql语句&quot;# 不进入hive交互窗口执行sql语句</span><br><span class="line">hive -f xxx.sql# 不进入hive交互窗口执行脚本中的sql语句</span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"><span class="built_in">exit</span>/quit; <span class="comment"># 退出hive窗口</span></span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash">dfs -ls /; <span class="comment"># 查看hdfs文件系统</span></span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash">! ls /opt/module/datas; <span class="comment"># 查看本地文件系统</span></span></span><br><span class="line">cat .hivehistory         # 查看在hive中输入的所有历史命令</span><br><span class="line">desc formatted table_name;   # 查询某个表的HDFS地址</span><br><span class="line">dfs -ls address_url;     # 进入该地址中可以看到相应分区的最后更新时间</span><br></pre></td></tr></table></figure></p><p><strong>分区表常用</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建分区表常见写法</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> student2(</span><br><span class="line">    id <span class="type">int</span>, name string</span><br><span class="line">)</span><br><span class="line">[COMMENT table_comment] </span><br><span class="line">partitioned <span class="keyword">by</span> (<span class="keyword">month</span> string) <span class="comment">-- [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]  -- 分区表</span></span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...)  <span class="comment">-- 分桶表</span></span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS] </span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span> <span class="comment">--[ROW FORMAT row_format] </span></span><br><span class="line">stored <span class="keyword">as</span> textfile  <span class="comment">-- [STORED AS file_format] </span></span><br><span class="line">location <span class="string">&#x27;/user/hive/warehouse/student2&#x27;</span>; <span class="comment">-- [LOCATION hdfs_path]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 同时创建/删除多个分区</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> dept_partition <span class="keyword">add</span><span class="operator">/</span><span class="keyword">drop</span> <span class="keyword">partition</span>(<span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201705&#x27;</span>), <span class="keyword">partition</span>(<span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201704&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看分区表有多少分区</span></span><br><span class="line"><span class="keyword">show</span> partitions dept_partition;</span><br><span class="line"><span class="comment">-- 查看分区表结构</span></span><br><span class="line"><span class="keyword">desc</span> formatted dept_partition;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 从本地文件覆盖/追加表数据</span></span><br><span class="line">load data [<span class="keyword">local</span>] inpath <span class="string">&#x27;/opt/module/datas/student.txt&#x27;</span> [overwrite] <span class="keyword">into</span> <span class="keyword">table</span> 表名 [<span class="keyword">partition</span> (partcol1<span class="operator">=</span>val1,…)];</span><br></pre></td></tr></table></figure></p><p><strong>高级操作merge into</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">MERGE</span> <span class="keyword">INTO</span> table_name alias1 </span><br><span class="line"><span class="keyword">USING</span> (<span class="keyword">table</span><span class="operator">|</span><span class="keyword">view</span><span class="operator">|</span>sub_query) alias2</span><br><span class="line"><span class="keyword">ON</span> (<span class="keyword">join</span> <span class="keyword">condition</span>) </span><br><span class="line"><span class="keyword">WHEN</span> MATCHED <span class="keyword">THEN</span> </span><br><span class="line">    UPDATE   <span class="comment">-- DELETE</span></span><br><span class="line">    <span class="keyword">SET</span> col1 <span class="operator">=</span> col1_val1, </span><br><span class="line">        col2 <span class="operator">=</span> col2_val2</span><br><span class="line"><span class="keyword">WHEN</span> <span class="keyword">NOT</span> MATCHED <span class="keyword">THEN</span> </span><br><span class="line">    <span class="keyword">INSERT</span> (column_list) <span class="keyword">VALUES</span> (column_values); </span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> Data Analysis and Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Causal Inference</title>
      <link href="/2024/03/31/Causal-Inference/"/>
      <url>/2024/03/31/Causal-Inference/</url>
      
        <content type="html"><![CDATA[<h1 id="因果推断和增益模型"><a href="#因果推断和增益模型" class="headerlink" title="因果推断和增益模型"></a>因果推断和增益模型</h1><h2 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h2><p>在日常生活和数据分析中可以得到大量相关性的结论，我们通过各种统计模型、机器学习、深度学习模型，通过分析得到种种结论，但是这里面存在一个巨大的疑问就是，“相关性一定等于因果性吗？”图1.1为缅因州黄油消费量和离婚率的关系图，从图上可以看出这两个变量呈高度相关的关系，但是如果我们从因果的角度来阐释，说黄油消费导致了离婚，或者离婚导致了黄油出售，显然都非常荒谬。事实上，相关性通常是对称的，因果性通常是不对称的（单向箭头）。相关性不一定说明了因果性，但因果性一般都会在统计层面导致相关性。也即相关性$\neq$因果性。</p><div align='center'><img src='非因果关系.png' width=800></img><p>图1.1 缅因州黄油消费量和离婚率的关系图</p></div><p>另外一个例子，在智能营销的发放优惠券场景下用户可分为如图1.2所示四类。建模时主要针对persuadables营销敏感人群，即给这部分人群发券可以增加人群购买欲望从而增加收益。要避免sleeping dogs人群，这类人群发放优惠券会产生发作用，即会降低人群的购买欲望。人群的区分需要明确是否因为发放优惠券才导致了购买行为，这是一个因果推断问题。预测发放优惠券带来的收益是一个增益模型。由此引出两个概念：</p><ul><li><strong>因果推断（causal inference）</strong>：即研究如何更加科学地识别变量间的因果关系，估算同一个体在干预和不干预（互斥情况下）不同输出的差异。</li><li><strong>增益模型（uplift model）</strong>：需要预测某种干预增量（uplift）的模型，即干预动作（treatment）对用户响应行为（outcome）产生的效果。为了克服估算同一个体同时受到干预和不干预这一反事实的现状，增益模型强依赖于随机实验（将用户随机分配到实验组&amp;对照组）的结果数据。<div align='center'><img src='营销人群分类.png' width=500></img><p>图1.2 营销人群分类</p></div></li></ul><h2 id="因果推断基础"><a href="#因果推断基础" class="headerlink" title="因果推断基础"></a>因果推断基础</h2><p>以发放优惠券问题为例，建立以下因果推断模型：</p><ul><li>输入变量$context \space x$：包含用户的多维度特征信息</li><li>权益干预$treatment \space t$：一般考虑二值干预$t_i\in 0,1$，如是否给用户发优惠券，发优惠券定义为treatment组，不发优惠券定义为control组。</li><li>输出变量$y$：包括潜在结果protential outcome $y$和观察结果oberved outcome $y_{obs}$<ul><li>潜在结果$y_1(x), y_0(x)$分别为用户有没有给treatment</li><li>用户受到干预时 $y<em>{obs}=y</em>{1}(x)$，用户未受到干预时$y_{obs}=y_0(x)$</li></ul></li></ul><p>以上三个变量之间的关系如图2.1所示。</p><div align='center'><img src='因果推断模型变量关系图.png' width=300></img><p>图2.1 因果推断模型变量关系图</p> </div><ul><li>对于单个用户，希望得到individual treatment effect(ite)，$ite=y_1(x)-y_0(x)$</li><li>对于整体的效果，希望得到the average treatment effect(ate)，$ate=e(y_1(x)-y_0(x))$</li></ul><p>ite和ate即因果效应$\tau$（增益），增益模型目标是最大化增益。一般取所有用户的因果效应期望的估计值来衡量整个用户群的效果，称为条件平均因果效应（conditional average treatment effect, cate）。实际中对用户$i$不可能同时观察到使用策略（treatment）和未使用策略（control）的输出结果，用下式表示用户可以观察到的输出结果，如果使用干预，$w_i$为1否则为0：</p><script type="math/tex; mode=display">y_i^{obs}=w_iy_i(1)+(1-w_i)y_i(0)</script><p>当假设CIA(conditional independence assumption)成立时，即给定特征下用户被随机分配到实验组/对照组（与用户的干预敏感度无关）。可以通过计算下式来估算每个个体的增益：</p><script type="math/tex; mode=display">\tau_i=E[y_i^{obs}|x_i=x, w_i=1]-E[y_i^{obs}|x_i=x, w_i=0]</script><p>由于增益无法观测，造成不能得到监督学习的label，如果得到了监督学习的label，就可以对数据集进行训练集测试集的划分，定义目标函数和损失函数进行神经网络训练，达到优化目标的目的。所以需要使用增益模型对评估增益的方法描述。通过ab实验可以获得使用干预策略和不使用干预策略两组人群，如果两组人群的特征分布一致，可以通过模拟两组人群的$\tau(x_i)$得到个体用户的$\tau(x_i)$。因此增益模型依赖ab实验的数据。ab实验也可以称为随机化实验（randomized controlled trials），在ab实验中，数据的treatment和control组理论上同质，即除treatment外其余特征相同。这就导致ab实验往往耗费的成本较高，是最“贵”的因果推断方式，有时候无法控制“treatment”，只能拨一小波人进行实验，需要通过子人群（obs数据）的增益效果来推断个体（rct数据）的增益效果。</p><p>基础的增益模型主要有以下三种：</p><ol><li>Meta Learning</li><li>Tree-based Method（增量直接建模）</li><li>Representation Learning</li></ol><h2 id="主要增益模型"><a href="#主要增益模型" class="headerlink" title="主要增益模型"></a>主要增益模型</h2><h3 id="Meta-Learning"><a href="#Meta-Learning" class="headerlink" title="Meta Learning"></a>Meta Learning</h3><p>这个方向使用基础的机器学习方法去首先估计条件平均输出$E<a href="cate">y|x = x</a>$，然后基于不同的结果获得cate estimator ，以下介绍几种经典的meta learning：</p><h4 id="S-Learner（One-Model）"><a href="#S-Learner（One-Model）" class="headerlink" title="S-Learner（One Model）"></a>S-Learner（One Model）</h4><p>通过现有模型（LR，GBDT，NN等）对treatment / control的数据进行训练，在预测的时候分别对该用户被干预和不被干预时的p进行预测计算，相减后便是增益。其计算步骤如下：</p><ol><li>ATE:<ul><li>step1: 模型条件期望$\mu(t, w)=E(y|t,w)$</li><li>step2: 每个样本的平均增益$\hat \tau =\frac{1}{n}\sum_i(\hat \mu(1, w_i)-\hat \mu(0, w_i))$</li></ul></li><li>CATE<ul><li>step1: $\mu(t, w, x)=E(y|t=t,w=w,x=x)$</li><li>step2: 每个样本的平均增益$\hat \tau =\frac{1}{n}\sum_i(\hat \mu(1, w_i, x)-\hat \mu(0, w_i, x))$</li></ul></li></ol><ul><li>优点：S-learner简单直观、直接使用既有预测算法；预测仅依赖一个模型，避免了多模型的误差累积；更多的数据和特征工程对预测准确率有利。</li><li>缺点：该方法不直接建模uplift；且需要额外进行特征工程工作(由于模型拟合的是y，所以若t直接作为一个特征放进去，可能由于对y的预测能力不足而未充分利用)。</li><li>应用：在因果推断未受关注之前，诸如优惠券发放的问题常用该方法，直接建模“对什么人，发放什么面额券，是否会下单”，预测阶段则对user和coupon交叉组合后进行预测，得到(user,coupon)组合的下单率，然后再依据预算、roi或其他约束进行mckp求解。</li></ul><h4 id="T-Learner（Two-Model）"><a href="#T-Learner（Two-Model）" class="headerlink" title="T-Learner（Two Model）"></a>T-Learner（Two Model）</h4><p>又称差分响应模型，通常作为baseline模型，模型分别在干预组和非干预组训练，即对 $\mu_1(w)=E[y_i(1)|x_i]$和$\mu_0(w)=E[y_i(0)|x_i]$分别建模，一个用户通过两个模型进行预测并对结果取差则得到预估的uplift值，模型图如3.1所示。</p><div align='center'>  <img src='差分响应模型.png', width=200></img>  <p>图3.1 差分响应模型</p> </div><ul><li>优点：较好区分干预组和非干预组</li><li>缺点：容易出现两个模型的bias方向不一致，形成误差累积，当干预组和对照组之间的数据量差异较大，即不平衡时，对结果影响较大。使用时需要针对两个模型进行打分分布校准。</li></ul><p><strong>说明：</strong> 通常使用倾向性评分匹配法（propensity score matching， psm）计算个体对实验组和对照组的倾向性，倾向性评分匹配法可以利用倾向性评分值综合所有观测变量信息从而达到均衡变量、减少偏倚的目的。使用treatment变量的预测概率作为ps score，即给定$x_i$用户被干预的概率，定义为$p(x_i)=p(w_i=1|x_i)$，将倾向性评分相近的样本互相匹配（匹配方法：直接匹配、将倾向性评分取对数、选择阈值等）。</p><h4 id="R-Learner"><a href="#R-Learner" class="headerlink" title="R-Learner"></a>R-Learner</h4><p>通过将问题转化为定义损失函数(r-loss)的形式进行学习训练，更关注“残差”。其实现步骤如下：</p><ol><li>通过交叉验证的方式，每次预测一组，得到整个数据集的预测结果$\hat m$和倾向得分$\hat e$：<script type="math/tex; mode=display">e(x)=e[w=1|x=x]</script><script type="math/tex; mode=display">m(x)=e[y=1|x=x]</script></li><li>最小化损失函数，估计增量，其中$q(i)$表示样本$i$在第几组<script type="math/tex; mode=display">\hat l_n\{\tau(·)\}=\frac{1}{n}\sum^n_{i=1}[\{y_i-\hat m^{-q(i)}(x_i)\}-\{w_i-\hat e^{-q(i)}(x_i)\}\tau (x_i)]^2</script></li><li><p>注：具体实现时，参考causalml的实现方式，将损失函数改为：</p><script type="math/tex; mode=display">\hat l_n\{\tau(·)\}=\frac{1}{n}\sum^n_{i=1}[\frac{y_i-\hat m^{-q(i)}(x_i)}{w_i-\hat e^{-q(i)}(x_i)}-\tau(x_i)]^2·\{w_i-\hat e^{-q(i)}(x_i)\}^2</script><p>即为一个mse损失的预测任务，注意除了预测目标变换外，对每个样本要施加相应的权重。</p></li></ol><p>R-learner相对灵活，但模型效果依赖于$\hat m$和$\hat e$的估计精度，实现起来复杂度较高，不是特别实用。</p><h4 id="X-Learner"><a href="#X-Learner" class="headerlink" title="X-Learner"></a>X-Learner</h4><p>通过交叉训练的方式，解决T-Learner中数据量差异问题。X-Learner充分利用数据估计每个group的estimator，对于数据倾斜很严重的估计有很好的弥补作用。X-Learner估计步骤如下：</p><ol><li>和t-learner一样先用treatment和control数据训练两个模型分别得到数据估计条件期望$\hat \mu_1=E[y_1∣x=x]$和$\hat \mu_0=E[y_0∣x=x]$ </li><li>针对treatment组，$\hat \tau<em>{1, i}=y_i(1)-\hat \mu_0(x_i)$;针对control组，$\hat \tau</em>{0, i}=\hat \mu<em>1(x_i)-y_i(0)$。分别学习2个模型的$\hat \tau_1(x)$和$\hat \tau_0(x)$，其中$\hat \tau_1(x)$使用treatment组数据预测$\hat \tau</em>{1,i}$，$\hat \tau<em>0(x)$使用control组数据预测$\hat \tau</em>{0,i}$</li><li>利用权重函数$g(x)\in [0,1]$组合2个模型的$\hat \tau_1(x)$和$\hat \tau_0(x)$进行预测:$\hat \tau(x)=g(x)\hat \tau_0(x)+(1-g(x))\hat \tau_1(x)$</li></ol><p>X-Learner在T-learner基础上，利用了全量的数据进行预测，主要解决treatment组间数据量差异较大的情况。但流程相对复杂、计算成本较高，有时还会由于多模型误差累积等问题效果不佳。另外，不论是分类问题还是回归问题，在 计算最终效应步骤时，都需要使用回归模型来拟合。</p><h4 id="类别转换法（Calss-Transformation-Approch）"><a href="#类别转换法（Calss-Transformation-Approch）" class="headerlink" title="类别转换法（Calss Transformation Approch）"></a>类别转换法（Calss Transformation Approch）</h4><p>类别转换方法是一种特殊Meta Learning，是针对二分（$y_i^{obs}={0, 1}$）的情境提出，在个体被分到实验组和对照组概率一样的假设下，定义目标变量：</p><script type="math/tex; mode=display">z_i=y_i^{obs}w_i+(1-y_i^{obs})(1-w_i)</script><p>$z_i$在两种情况下等于1（其他时候为0）：</p><ul><li>对象在实验组中且$y_i^{obs}=1$</li><li>对象在对照组中且$y_i^{obs}=0$</li></ul><p>因此可以直接将实验组和对照组用户合并，使用一个模型建模，实现了数据层面和模型层面的打通。当满足条件$p(x_i)=p(w_i=1|x_i)=0.5$（个体被分到实验组和对照组的概率相同）的情况下，可以证明uplift的训练相当于训练$p(z_i=1|x_i)$：</p><script type="math/tex; mode=display">\tau(x)=p^t(y=1|x)-p^c(y=1|x)=2p(z=1|x)-1</script><p>此时只需要对$p(z_i=1|x_i)$建模即可。预测时，模型预测的结果就是uplift score，这点与差分响应模型不同。</p><ul><li>优点：较为简单，效果比two-model好</li><li>缺点：需要基于2个假设<ul><li>二分类情景</li><li>个体对实验组和对照组的倾向性须一致    <div align='center'><img src='类别转换方法.png' width=400></img><p>图3.2 类别转换方法</p></div></li></ul></li></ul><p>拓展到分布不均衡样本：不均衡样本的情况下，倾向分不为1/2。通过对转换后的输出，应用机器学习模型预测增益：</p><script type="math/tex; mode=display">y_i^*=y_i(1)\frac{w_i}{\hat p(x_i)}-y_i(0)\frac{1-w_i}{1-\hat p(x_i)}</script><p>其中$\hat p$是对$p(x_i)=p(w_i=1|x_i)$的一致估计，在满足cia的条件下，类别转换后变量在给定$x_i$下的期望等于增益，即：</p><script type="math/tex; mode=display">e[y_i^*|x_i]=\tau(x_i)</script><h3 id="Tree-based-Method（增量直接建模）"><a href="#Tree-based-Method（增量直接建模）" class="headerlink" title="Tree-based Method（增量直接建模）"></a>Tree-based Method（增量直接建模）</h3><p>通过对现有机器学习算法（树、RF、SVM）的改造直接对增益效果建模，最流行的是树模型。传统机器学习模型中，树模型主要的思路就是通过对特征点进行分裂，将x划分到一个又一个子空间中，这与补贴场景下，希望找到某一小部分增量很高的用户的想法几乎是完美重合。因此，与Meta-Learner不同的是，uplift model下的树模型希望通过这样的分裂方式达到对增量直接建模的目的。决策树算法的分裂规则：</p><script type="math/tex; mode=display">\delta_{gain}=i_{after}(d)-i_{before}(d)</script><p>增益决策树算法的分裂规则：</p><script type="math/tex; mode=display">\delta_{gian}=d_{after}(p^t,p^c)-d_{before}(p^t,p^c)</script><p>传统分类树模型是希望通过信息理论(information theory)中的信息熵等思想，用计算信息增益的方法去解决分类问题。而在uplift tree model中，其本质也还是想要通过衡量分裂前后的变量差值去决策是否分裂节点，不过这里的这个决策差值的计算方法不再是信息增益(information gain)，而是不同的直接对增量uplift建模的计算方法，其中包括了</p><ul><li>利用分布散度对uplift建模</li><li>直接对uplift建模的CTS</li><li>Causal Forest</li></ul><h4 id="分布散度下的uplift-tree"><a href="#分布散度下的uplift-tree" class="headerlink" title="分布散度下的uplift-tree"></a>分布散度下的uplift-tree</h4><p>分布散度是用来度量两个概率分布之间差异性的值，当两个分布相同时，两个离散分布的散度为非负且等于零。可以把实验组和对照组理解为两个概率分布，利用分布散度作为非叶节点分裂标准，最大化实验组和对照组的样本类别分布之间的差异，减少样本不确定度。在uplift model中，常见的分布散度及计算方法如下：</p><ul><li>kl散度 (kullback-leibler divergence)：<script type="math/tex; mode=display">kl(p^t(y):p^c(y))=\sum_y p^t(y)log\frac{p^t(y)}{p^c(y)}</script></li><li>欧式距离 (squared euclidean distance) :<script type="math/tex; mode=display">e(p^t(y):p^c(y))=\sum_y(p^t(y)-p^c(y))^2</script></li><li>卡方散度(chi-squared divergence):<script type="math/tex; mode=display">\chi^2(p^t(y):p^c(y))=\sum_y\frac{(p^t(y)-p^c(y))^2}{p^c(y)}</script></li></ul><p>其中$p^t(y)$表示实验组数据样本类别$y$的概率分布，$p^t(y)$表示$y=y$时的概率，$p^c(y)$和$p^c(y)$同理；kl散度、欧式距离和卡方散度有以下共同点：当两个概率分布相同时值为0；当两个概率分布差异越大时值越大。欧式距离有以下优点：对称性；值更稳定，当$p^c(y)$趋向于0时，$p^t(y)$非0时，kl散度和卡方散度趋于无穷。</p><p>除此以外，分布散度还有个特点：通过公式可以推导，当结点中对照组数据为空时，kl散度会退化为决策树分裂准则中的信息增益；欧式距离和卡方散度将会退化为基尼指数。而当结点中实验组数据为空时，欧式距离将会化为基尼指数。这也是该类分裂准则的优点之一。</p><h4 id="对uplift直接建模的CST-Tree"><a href="#对uplift直接建模的CST-Tree" class="headerlink" title="对uplift直接建模的CST Tree"></a>对uplift直接建模的CST Tree</h4><p>mit的zhao yan 等人在2017年提出了一种新的名为cts的分裂准则去构建uplift tree。cts algorithm是contextual treatment selection的缩写。不同于分布散度，在该标准下，会直接最大化每个节点上实验组和对照组之间label期望的差值（可以理解为该节点上样本的uplift值），并以此来分裂节点。<br>cts树具体构造流程为：</p><ol><li>计算分裂前实验组和对照组转化率最大值，记为指标：<script type="math/tex; mode=display">\mu_{before}=max_{t=0,...,k}e[y|x\in \phi, t=t]</script>其中$t=0$表示对照组，$t=1,…,k$表示实验组。</li><li>根据某特征值将数据分为左右分支，计算分裂后左分支实验组和对照组转化率最大值，右分支实验组和对照组转化率最大值，对左右分支最大值求和记为：<script type="math/tex; mode=display">\mu_{after}=p(x\in \phi _t|x\in \phi)max_{t_t=0,...,k}e[y|x\in \phi_t,t=t_t]+p(x\in \phi _c|x\in \phi)max_{t_c=0,...,k}e[y|x\in \phi_c,t=t_c]</script></li><li>利用树分裂前后的节点做差得到增益：<script type="math/tex; mode=display">\delta \mu=\mu_{after}-\mu_{before}</script></li><li>遍历所有特征值，重复2、3步骤，计算所有特征值对应的增益，取最大增益对应的特征值作为分裂节点。</li><li>对左右分支数据重复以上步骤，构建增益决策树。</li></ol><p>CTS tree与uplift tree的主要区别在于分裂准则：CTS tree仍是分裂后与分裂前得分之差，区别在于uplift tree的得分用的是分布散度，而这里的目标是分裂能够最大化结点内各个treatment中最大的y值期望。</p><h4 id="Causal-Forest"><a href="#Causal-Forest" class="headerlink" title="Causal Forest"></a>Causal Forest</h4><p>Causal Forest实际上是一类算法，这类算法的核心是把一个个建立好的causal tree (uplift tree)做集成，把每棵causal tree (uplift tree)计算出来的treatment effect取一个平均。而对于causalforest，可以是任意单tree-based方法。这类方法需要满足unconfoundedness(CIA)假设，即在叶子结点上控制住所有的confounder x后，treatment和outcome要独立。</p><p>这类方法很简单，难点在于怎么建立causal tree才能满足。要建一棵”诚实树”（honest tree），即对于任意样本 $i$，他的 $y_i$ 一部分用于生成树结果，另一部分估算叶子节点的uplift值，只能二选一。</p><ul><li>对于标准的cart树，用叶子节点的 y 的均值表示其中样本的结果，这个策略的依据是认为叶子节点 l(x) 足够小，使得结果中 $y_i$ 近似同分布。</li><li>对于因果树，类比认为叶子节点足够小，使得叶子节点 l(x) 内的 $(y_i,w_i)$ 对近似取自随机试验，则指定叶子节点的增益为：<script type="math/tex; mode=display">\hat \tau(x)=\frac{1} {|\{i:w_i=1,x_i\in l\}|} \sum^{y_i}_{ \{i:w_i=1, x_i\in l\} }- \frac{1}{|\{i:w_i=0,x_i\in l\}|} \sum^{y_i}_{ \{i:w_i=0, x_i\in l\} }</script></li></ul><p>基于不同的样本子集训练多个因果树，用均值作为最终的结果：</p><script type="math/tex; mode=display">\hat \tau(x)=b^{-1}\sum^b_{b=1}\hat \tau_b(x)</script><p>该方法可以直接对uplift建模，理论上精度会很高，但实际应用上除了修改分裂规则外，还需修改loss函数、剪枝算法等，成本较高。</p><h3 id="Representation-Learning"><a href="#Representation-Learning" class="headerlink" title="Representation Learning"></a>Representation Learning</h3><p>本身由于选择偏差的存在，导致treament组和control组的人群自带偏差，而类似S-Learner的方法又会使得treat的作用丢失。利用表示学习的方式可以将人群embedding中并尽可能消除bias和保存treat。</p><h4 id="BNN-amp-BLR"><a href="#BNN-amp-BLR" class="headerlink" title="BNN &amp; BLR"></a>BNN &amp; BLR</h4><p>BNN是经常用作baseline的经典方法，模型通过优化损失函数来获得最终的增益，其损失函数包括了3个部分：</p><ol><li>事实数据的误差</li><li>与i最近的j的反事实数据的误差</li><li>事实数据+反事实数据的分布差异</li></ol><p>有两种学习增益$φ$的方式：</p><ol><li>对于特征进行选择BLR，在embedding层只有一层，进行特征筛选，只保留在treatment组和control组差距较小的特征，如果差别很大，则设置较小的权重。</li><li>深度方法bnn，embedding后整体的loss加入分布的差异，如图3.3所示。<div align='center'><img src='bnn结构.png' width=400></img><p>图3.3 bnn结构</p></div></li></ol><h4 id="Tarnet"><a href="#Tarnet" class="headerlink" title="Tarnet"></a>Tarnet</h4><p>BLR存在两个缺点：需要一个两步的优化（优化$φ$和优化$y$）<br>如果$φ$的维度很高的话，$t$的重要性会被忽略掉，tarnet通过增加$ω$的加权，解决了一下treat和control组的sample数量不均衡的问题，实际上效果比较好。</p><h4 id="DragonNet-目标正则化"><a href="#DragonNet-目标正则化" class="headerlink" title="DragonNet + 目标正则化"></a>DragonNet + 目标正则化</h4><p>DragonNet 利用倾向评分的充分性进行评估调整。论文中将x中与预测结果y相关、与t无关的部分看作噪声，只从x中和t相关的变量中预测y，对特征的条件作用等效于对倾向评分本身的作用。dragonnet 模型图如下：</p><div align='center'><img src='dragonnet模型图.png' width=350></img><p>图3.4 dragonnet模型图</p></div><p>网络结构为一个三头的端到端架构，通过变量x和t预测倾向性评分和y。</p><ul><li>使用一个深度网络得到一个表示层z，通过z预测treatment和输出</li><li>使用2个隐藏层的神经网络分别预测t=1和t=0时的增益</li><li>倾向性评分的输出使用了线性（sigmoid）映射</li></ul><p>dragonnet相当于tarnet+倾向性评分预测头，当数据量较大时，两个模型的效果一致。dragonnet在训练时使用了momentum优化器进行梯度下降<br>加入目标正则化类似于tmle（targeted  minimum loss estimation），可以减小具有非参数的最优渐近特性的模型偏差，即减轻有限样本的不稳定性。目标正则化基于两个条件：</p><ul><li>对条件输出和倾向性评分是连续估计</li><li>模型简化为非参数的情况</li></ul><h4 id="DRnet-、VCnet-函数目标正则化"><a href="#DRnet-、VCnet-函数目标正则化" class="headerlink" title="DRnet 、VCnet + 函数目标正则化"></a>DRnet 、VCnet + 函数目标正则化</h4><p>DRnet和变系数神经网络（VCnet）均可以将二分的treatment转换为连续treatment，二者的模型结构如下：</p><div align='center'><img src='drnet、vcnet模型图.png' width=700></img><p>图3.5 DRnet、VCnet模型图</p></div><ul><li>DRnet相当于x经过一个深层神经网络后得到z，z是输入由条件密度估计器提取的特征，即为t的倾向性预测，然后将连续的t转换为多个块，即使用分散的多头预测输出变量，实际上t仍然不是连续的。为了进一步加强t的影响，可以在每一个隐藏层上添加了一个t，这种结构的一个问题是，通过对每个t块使用不同的预测头，破坏了μ的连续性。结果上表示drnet确实产生了不连续曲线。</li><li>vcnet则在预测得到z之后，将μ的预测头重新定义：$\mu^{nn}(t, x)=f<em>{\theta (t)}(z)$，$f</em>{θ(t)}$是一个具有参数$θ(t)$而不是固定$θ$的（深度）神经网络。t的影响通过神经网络的参数$θ(t)$直接输入结果，这将t与其他协变量x区分开来，避免了t信息的丢失。在典型的样条基选择下，如b样条，一旦激活函数是连续的，vcnet将自动产生连续的adrf估计量。</li></ul><p>VCnet保持估计自抗扰函数连续性的同时提高了模型的表达能力，其优势主要表现在两点：</p><ul><li>保持平均剂量-反应曲线（adrf）连续性</li><li>强调了t的影响，t在高维中不会丢失</li></ul><p>为了提高有限样本的性能，使用有针对性的正则化，以获得整个adrf曲线的双重鲁棒估计。论文中表示VCnet和函数目标正则化的表现是独立的，当二者同时使用时模型效果最佳。</p><h4 id="ACE"><a href="#ACE" class="headerlink" title="ACE"></a>ACE</h4><p>ACE主要的思想希望在representation之后能够尽可能地保留局部相似性，如图3.6所示，样本在原始空间转换到表示空间后应该尽量可能保留局部相似性。整体希望表示之前用x计算出倾向性得分相近的个体，表示之后这些个体之间的距离还是相近。</p><div align='center'><img src='局部相似性举例.png' width=700></img><p>图3.6 局部相似性举例</p></div><h4 id="SITE"><a href="#SITE" class="headerlink" title="SITE"></a>SITE</h4><p>普通的表示学习方法考虑了全局的分布信息，但是没有考虑用户间的局部相似性，knn的方法考虑了局部相似性，但是忽略了全局信息，SITE里使用了三元triplet pairs的方法根据倾向性得分选择三个对，倾向性得分在中间的一对，倾向性得分接近1的treat unit，倾向性得分接近0的control group。</p><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><p>模型评估的难点在于不存在ground truth——因为无法同时对一个样本干预和不干预。所以大部分衡量指标需要通过聚合指标（衡量群体）实现，例如uplift bins和uplift curves。</p><h3 id="uplift-bins"><a href="#uplift-bins" class="headerlink" title="uplift bins"></a>uplift bins</h3><p>对所有的样本包括treatment和control数据同时预测uplift值，然后按照uplift值进行排序，分别计算每个十分位里treatment和control组的输出平均值，每个十分位两组平均值的差即为增益。图4.1为同一数据集下分别利用差分响应模型和类别转换方法得到的uplift bins图。</p><div align='center'><img src='uplift bins.png'></img><p>图4.1 uplift bins图</p></div>上图的评估方式无法比较不同模型的好坏，为了能跨模型比较，引入累计增益图，如图4.2所示。第一个bar代表前10%的uplift，第二个bar代表前20%的uplift。一个表现好的模型在前半段会有比较大的值，后半段下降。累计增益图对运营很有帮助：如果希望圈选一部分人进行干预，可以通过图找到增益效果的最大值，从而达到利益最大化（例：圈选前40%的用户可以达到最大值）。<div align='center'><img src='累计增益图.png'></img><p>图4.2 累计增益图</p></div><h3 id="uplift曲线"><a href="#uplift曲线" class="headerlink" title="uplift曲线"></a>uplift曲线</h3><p>以上都是通过可视化的形式展示模型好坏，引入数值指标可以用于直接比较。uplift曲线通过分别计算treatment和control的预测值按值排序计算分位值差异，不能保证相同高分位人群是相似的，但是这种方法在随机试验和实践中效果最好。可以通过以下公式计算数据集中每一个$t$的增益效果：</p><script type="math/tex; mode=display">f(t)=(\frac{y_t^t}{n_t^t}-\frac{y^c_t}{n^c_t})(n_t^t+n_t^c)</script><p>其中$t$表示按照预测uplift值进行排序的前$t$个观察值。图4.3为不同模型的uplift曲线，横坐标表示按照增益排序后的人群数量，纵坐标表示增益。从图中可以看出，two-model的效果最好。</p><div align='center'><img src='不同模型的uplift曲线.png' width=500></img><p>图4.3 不同模型的uplift曲线</p></div><h3 id="qini曲线"><a href="#qini曲线" class="headerlink" title="qini曲线"></a>qini曲线</h3><p>也可以通过qini曲线来衡量模型好坏，如图4.4所示。和uplift曲线的定义类似，二者可以相互转换。其表示如下：</p><script type="math/tex; mode=display">g(t)=y^t_t-\frac{y^c_tn^t_t}{n^c_t}</script><p>定义qini系数，即qini曲线下的面积auuc（area under uplift curve）可以衡量模型好坏，qini系数越大模型越好。</p><div align='center'><img src='不同模型的qini曲线.png' width=500></img><p>图4.4 不同模型的qini曲线</p></div><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文首先从一个实例出发阐述了因果性不等于相关性，进而引出因果推断和增益模型。然后简单介绍了因果推断的基础内容，并介绍了主要的三类增益模型：元学习、增益直接建模、表示学习，每一类模型都简要介绍了其经典模型。之后介绍了增益模型的评价指标，包括uplift bins、uplift curve和qini曲线。</p><p>增益模型实际上是一大类模型框架，本质上可以用传统响应模型或其他机器学习模型嵌入增益模型的框架，但是预测结果并不是一个概率，模型评价方式也有变化。目前增益模型在以下两个方面仍然存在不足：</p><ol><li><strong>训练样本收集</strong><br> 增益模型建模强依赖于ab实验，数据要求很高。建模时要求实验组和对照组样本数量一样（实践中不一定有这个严格要求）。而且实验组和对照组的样本特征分布要一致，例如，训练数据不能是实验组预测后的结果、对照组随机选择的结果这样的组合，因为这样不满足干预策略与用户特征相互独立的假设$p(g∣x)=p(g)$。故实验组中还需要预留一部分随机选择的用户，与对照组中的用户作为模型迭代的数据，或者实验组与对照组都先经过某个策略或模型的筛选。</li><li><strong>多维度建模</strong><br> 上述所有模型都是针对干预策略只有一种且为二分类的情况，而treatment可以用多种维度和连续变量表示。而treatment可以用多种维度，如不同渠道发放不同折扣的优惠券，不同场景推送不同内容的push。传统的响应模型以转化为多分类问题解决，但uplift modeling难以简单转化为多分类问题。此外，个性化广告推送也依赖长期和短期的用户行为特征构建。不同营销场景下的用户特征可以共用，可以构建统一的线上线下特征平台。</li></ol><h2 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h2><p>针对进行课程汇报时老师提出的问题我在进行了相关的资料查阅后整理如下：</p><p><strong>Q1: 如何确定变量之间的是否存在因果性？</strong></p><p>事物之间的因果关系目前仍是计量经济学中研究的问题之一。经济分析中的因果关系识别就是指在分析中把影响某个经济结果的最重要决定因素提取出来，作为研究的关注焦点。从理论角度讲，我们需要在理论模型中解释为什么被忽略的其他因素不会系统性地改变理论所关注的主体规律；从实证角度看，需要尽可能全面收集这些其他因素对应的衡量指标，并在实证分析中考虑这些因素的影响。通过在实证分析中“控制”或者“剔除”这些其他因素的作用，我们便可以识别出理论模型中所关注的主体规律。<br>科学研究中识别因果可以说是非常困难的事情，尤其是对于社会科学而言。自然科学中可以通过实验控制的方法来识别因果。若想知道某个实验设计能否获得两个变量之间的因果关系，首先需要了解确定因果关系的条件有哪些。目前，普遍采用的是英国哲学家穆勒提出的三个条件：</p><ol><li>共变性，两个事件必须是共变或一起变化的；</li><li>时间顺序：一个事件必须在另一个事件之前发生；</li><li>排除其他可能的解释。<br>这三个条件必须同时满足才能确定因果关系。然而社会科学中这样的问题往往会变得很复杂，原因是一方面而言许多影响结果的变量无法被完美控制，另一方面许多变量也无法人为改变。</li></ol><p><strong>Q2: 目前因果森林面临的挑战？</strong></p><p>在经济学中有个名词为“共时性”，即指两个变量的值可能是由其他一些变量同时决定的，因此不能推导这两个变量之间具有因果关系。“共时性”是“内生性”的一种，“内生性”的意思是说我们视为原因的变量本身也是被其他因素决定的结果，所以是模型中“内生”的，而不是单纯“外生”的原因。内生性有两种表现形式，一种是上面讨论的“共时性”，另一种表现形式则是反向因果，也即解释变量反而可能是结果，而被解释变量则是原因。涉及混杂因素时，需要解决的内生性问题是“共时性”。如何在不能直接观察到混杂变量取值的情况下，将它们的影响纳入实证分析中，进而恰当地排除它们的影响，从而正确地进行因果推断呢？去年诺贝尔经济学奖的几位学者，正是在这个研究领域做出了卓越的贡献。在去年诺贝尔奖中提到一类变量，这类变量是在理论模型中会对被解释变量起到关键影响作用，但却无法在实证研究中直接控制的变量，因为在现实中无法直接观察到它们对应的衡量指标，它们被称为“混杂因素”，也是因果关系识别中的核心挑战。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li>[1] Yao L ,  Chu Z ,  Li S , et al. A Survey on Causal Inference[J].  2020.</li><li>[2] Gutierrez P , Jean-Yves Gérardy. Causal Inference and Uplift Modelling: A Review of the Literature[C]// International Conference on Predictive Applications and APIs. PMLR, 2017.</li><li>[3] Athey S ,  Wager S . Estimating Treatment Effects with Causal Forests: An Application[J].  2019.</li><li>[4] Wager S ,  Athey S . Estimation and Inference of Heterogeneous Treatment Effects using Random Forests[J]. Research Papers, 2017, 8(6):1831-45.</li><li>[5] Athey S ,  Tibshirani J ,  Wager S . Generalized Random Forests[J]. Research Papers, 2018.</li><li>[6] Johansson F D ,  Shalit U ,  Sontag D . Learning Representations for Counterfactual Inference[J].  2016.</li><li>[7] Shalit U ,  Johansson F ,  Sontag D . Estimating individual treatment effect: generalization bounds and algorithms[C]// 2016.</li><li>[8] Shi C ,  Blei D M ,  Veitch V . Adapting Neural Networks for the Estimation of Treatment Effects[C]// 2019.</li><li>[9] Nie L ,  Ye M ,  Liu Q , et al. VCNet and Functional Targeted Regularization For Learning Causal Effects of Continuous Treatments[C]// 2021.</li><li>[10] Hassanpour N ,  Greiner R . CounterFactual Regression with Importance Sampling Weights[C]// Twenty-Eighth International Joint Conference on Artificial Intelligence IJCAI-19. 2019.</li><li>[11] Yao L ,  Li S ,  Li Y , et al. ACE: Adaptively Similarity-Preserved Representation Learning for Individual Treatment Effect Estimation[C]// 2019 IEEE International Conference on Data Mining (ICDM). IEEE, 2019.</li><li>[12] Yao L ,  Li S ,  Li Y , et al. Representation Learning for Treatment Effect Estimation from Observational Data[C]// Neural Information Processing Systems. 2018.</li><li>[13] Zhao Z ,  Zhang Y ,  Harinen T , et al. Feature Selection Methods for Uplift Modeling[J].  2020.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Search / Advertisement / Recommendation / Causal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3D Construction Based KinectV2</title>
      <link href="/2024/03/24/Construction-Based-KinectV2/"/>
      <url>/2024/03/24/Construction-Based-KinectV2/</url>
      
        <content type="html"><![CDATA[<p>完整项目链接：<a href="https://github.com/xfliu1998/kinectProject/tree/main">GitHub - xfliu1998/kinectProject</a></p><h1 id="Kinect-V2相机标定及图像处理（Python）"><a href="#Kinect-V2相机标定及图像处理（Python）" class="headerlink" title="Kinect V2相机标定及图像处理（Python）"></a>Kinect V2相机标定及图像处理（Python）</h1><h2 id="Kinect-V2相机标定"><a href="#Kinect-V2相机标定" class="headerlink" title="Kinect V2相机标定"></a>Kinect V2相机标定</h2><p>使用<strong>张正友标定法</strong>对Kinect V2相机标定。原理及参考代码见以下链接：</p><blockquote><p>单目相机标定实现—张正友标定法：<a href="https://blog.csdn.net/weixin_43763292/article/details/128546103?spm=1001.2014.3001.5506">https://blog.csdn.net/weixin_43763292/article/details/128546103?spm=1001.2014.3001.5506</a><br>python利用opencv进行相机标定(完全版)：<a href="https://blog.csdn.net/dgut_guangdian/article/details/107467070?spm=1001.2014.3001.5506">https://blog.csdn.net/dgut_guangdian/article/details/107467070?spm=1001.2014.3001.5506</a><br>Kinect2.0-Python调用-PyKinect2：<a href="https://blog.csdn.net/zcz0101/article/details/115718427?spm=1001.2014.3001.5506">https://blog.csdn.net/zcz0101/article/details/115718427?spm=1001.2014.3001.5506</a></p></blockquote><ol><li><strong>导入需要的包</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> glob <span class="keyword">as</span> gb</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> keyboard</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> utils.calibration <span class="keyword">import</span> Calibrator</span><br><span class="line"><span class="keyword">from</span> utils.kinect <span class="keyword">import</span> Kinect</span><br></pre></td></tr></table></figure><ol><li><strong>拍摄不同角度的标定图。</strong>取照要求：不同角度不同位置拍摄（10-20）张标定图，棋盘格的视野在整张图的1/4~2/3左右。以下函数默认拍摄20张图，按空格键拍摄照片，按q键结束拍摄，拍的标定图会保存到指定路径。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_chess_image</span>(<span class="params">image_num=<span class="number">20</span></span>):</span></span><br><span class="line">    out_path = <span class="string">&#x27;./data/chess/&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(out_path):</span><br><span class="line">        os.makedirs(out_path)</span><br><span class="line">    camera = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        (grabbed, img) = camera.read()</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; keyboard.is_pressed(<span class="string">&#x27;space&#x27;</span>):  <span class="comment"># press space to save an image</span></span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            firename = <span class="built_in">str</span>(<span class="string">f&#x27;<span class="subst">&#123;out_path&#125;</span>img<span class="subst">&#123;<span class="built_in">str</span>(i)&#125;</span>.jpg&#x27;</span>)</span><br><span class="line">            cv2.imwrite(firename, img)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;write: &#x27;</span>, firename)</span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>) <span class="keyword">or</span> i == image_num:  <span class="comment"># press q to finish</span></span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><ol><li><strong>对相机标定。</strong>函数将相机的内参和畸变系数输出至指定路径，同时可以获得每张标定图的外参矩阵。函数需要用到标定类，代码在utils包中。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">camera_calibrator</span>(<span class="params">shape_inner_corner=(<span class="params"><span class="number">11</span>, <span class="number">8</span></span>), size_grid=<span class="number">0.025</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    :param shape_inner_corner: checkerboard size = 12*9</span></span><br><span class="line"><span class="string">    :param size_grid: the length of the sides of the checkerboard = 25mm</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    chess_dir = <span class="string">&quot;./data/chess&quot;</span></span><br><span class="line">    out_path = <span class="string">&quot;./data/dedistortion/chess&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(out_path):</span><br><span class="line">        os.makedirs(out_path)</span><br><span class="line">    <span class="comment"># create calibrator</span></span><br><span class="line">    calibrator = Calibrator(chess_dir, shape_inner_corner, size_grid)</span><br><span class="line">    <span class="comment"># calibrate the camera</span></span><br><span class="line">    mat_intri, coff_dis = calibrator.calibrate_camera()</span><br><span class="line">    np.save(<span class="string">&#x27;./data/intrinsic_matrix.npy&#x27;</span>, mat_intri)</span><br><span class="line">    np.save(<span class="string">&#x27;./data/distortion_cofficients.npy&#x27;</span>, coff_dis)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;intrinsic matrix: \n &#123;&#125;&quot;</span>.<span class="built_in">format</span>(mat_intri))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;distortion cofficients: \n &#123;&#125;&quot;</span>.<span class="built_in">format</span>(coff_dis))  <span class="comment"># (k_1, k_2, p_1, p_2, k_3)</span></span><br><span class="line">    <span class="comment"># dedistortion</span></span><br><span class="line">    calibrator.dedistortion(chess_dir, out_path)</span><br><span class="line">    <span class="keyword">return</span> mat_intri, coff_dis</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Calibrator</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, img_dir, shape_inner_corner, size_grid, visualization=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        --parameters--</span></span><br><span class="line"><span class="string">        img_dir: the directory that save images for calibration, str</span></span><br><span class="line"><span class="string">        shape_inner_corner: the shape of inner corner, Array of int, (h, w)</span></span><br><span class="line"><span class="string">        size_grid: the real size of a grid in calibrator, float</span></span><br><span class="line"><span class="string">        visualization: whether visualization, bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.img_dir = img_dir</span><br><span class="line">        self.shape_inner_corner = shape_inner_corner</span><br><span class="line">        self.size_grid = size_grid</span><br><span class="line">        self.visualization = visualization</span><br><span class="line">        self.mat_intri = <span class="literal">None</span>   <span class="comment"># intrinsic matrix</span></span><br><span class="line">        self.coff_dis = <span class="literal">None</span>    <span class="comment"># cofficients of distortion</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># create the conner in world space</span></span><br><span class="line">        w, h = shape_inner_corner</span><br><span class="line">        <span class="comment"># cp_int: save the coordinate of corner points in world space in &#x27;int&#x27; form. like (0,0,0), ...., (10,7,0)</span></span><br><span class="line">        cp_int = np.zeros((w * h, <span class="number">3</span>), np.float32)</span><br><span class="line">        cp_int[:, :<span class="number">2</span>] = np.mgrid[<span class="number">0</span>:w, <span class="number">0</span>:h].T.reshape(-<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="comment"># cp_world: corner point in world space, save the coordinate of corner points in world space</span></span><br><span class="line">        self.cp_world = cp_int * size_grid</span><br><span class="line"></span><br><span class="line">        <span class="comment"># images</span></span><br><span class="line">        self.img_paths = []</span><br><span class="line">        <span class="keyword">for</span> extension <span class="keyword">in</span> [<span class="string">&quot;jpg&quot;</span>, <span class="string">&quot;png&quot;</span>, <span class="string">&quot;jpeg&quot;</span>]:</span><br><span class="line">            self.img_paths += glob.glob(os.path.join(img_dir, <span class="string">&quot;*.&#123;&#125;&quot;</span>.<span class="built_in">format</span>(extension)))</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(self.img_paths), <span class="string">&quot;No images for calibration found!&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calibrate_camera</span>(<span class="params">self</span>):</span></span><br><span class="line">        w, h = self.shape_inner_corner</span><br><span class="line">        <span class="comment"># criteria: only for subpix calibration, which is not used here</span></span><br><span class="line">        <span class="comment"># criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)</span></span><br><span class="line">        points_world = []   <span class="comment"># the points in world space</span></span><br><span class="line">        points_pixel = []   <span class="comment"># the points in pixel space (relevant to points_world)</span></span><br><span class="line">        <span class="keyword">for</span> img_path <span class="keyword">in</span> self.img_paths:</span><br><span class="line">            img = cv2.imread(img_path)</span><br><span class="line">            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">            <span class="comment"># find the corners, cp_img: corner points in pixel space</span></span><br><span class="line">            ret, cp_img = cv2.findChessboardCorners(gray_img, (w, h), <span class="literal">None</span>)</span><br><span class="line">            <span class="comment"># if ret is True, save</span></span><br><span class="line">            <span class="keyword">if</span> ret:</span><br><span class="line">                <span class="comment"># cv2.cornerSubPix(gray_img, cp_img, (11,11), (-1,-1), criteria)</span></span><br><span class="line">                points_world.append(self.cp_world)</span><br><span class="line">                points_pixel.append(cp_img)</span><br><span class="line">                <span class="comment"># view the corners</span></span><br><span class="line">                <span class="keyword">if</span> self.visualization:</span><br><span class="line">                    cv2.drawChessboardCorners(img, (w, h), cp_img, ret)</span><br><span class="line">                    _, img_name = os.path.split(img_path)</span><br><span class="line">                    cv2.imwrite(os.path.join(self.img_dir, <span class="string">f&quot;dedistortion/coner_detect/<span class="subst">&#123;img_name&#125;</span>&quot;</span>), img)</span><br><span class="line">                    cv2.imshow(<span class="string">&#x27;FoundCorners&#x27;</span>, img)</span><br><span class="line">                    cv2.waitKey(<span class="number">500</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calibrate the camera</span></span><br><span class="line">        ret, mat_intri, coff_dis, v_rot, v_trans = cv2.calibrateCamera(points_world, points_pixel, gray_img.shape[::-<span class="number">1</span>], <span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line">        <span class="comment"># print(&quot;ret: &#123;&#125;&quot;.format(ret))</span></span><br><span class="line">        <span class="comment"># print(&quot;intrinsic matrix: \n &#123;&#125;&quot;.format(mat_intri))</span></span><br><span class="line">        <span class="comment"># # in the form of (k_1, k_2, p_1, p_2, k_3)</span></span><br><span class="line">        <span class="comment"># print(&quot;distortion cofficients: \n &#123;&#125;&quot;.format(coff_dis))</span></span><br><span class="line">        <span class="comment"># print(&quot;rotation vectors: \n &#123;&#125;&quot;.format(v_rot))</span></span><br><span class="line">        <span class="comment"># print(&quot;translation vectors: \n &#123;&#125;&quot;.format(v_trans))</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate the error of reproject</span></span><br><span class="line">        total_error = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(points_world)):</span><br><span class="line">            points_pixel_repro, _ = cv2.projectPoints(points_world[i], v_rot[i], v_trans[i], mat_intri, coff_dis)</span><br><span class="line">            error = cv2.norm(points_pixel[i], points_pixel_repro, cv2.NORM_L2) / <span class="built_in">len</span>(points_pixel_repro)</span><br><span class="line">            total_error += error</span><br><span class="line">        <span class="comment"># print(&quot;Average error of reproject: &#123;&#125;&quot;.format(total_error / len(points_world)))</span></span><br><span class="line"></span><br><span class="line">        self.mat_intri = mat_intri</span><br><span class="line">        self.coff_dis = coff_dis</span><br><span class="line">        <span class="keyword">return</span> mat_intri, coff_dis</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dedistortion</span>(<span class="params">self, img_dir, save_dir</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(save_dir):</span><br><span class="line">            os.makedirs(save_dir)</span><br><span class="line">        <span class="comment"># if not calibrated, calibrate first</span></span><br><span class="line">        <span class="keyword">if</span> self.mat_intri <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">assert</span> self.coff_dis <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line">            self.calibrate_camera()</span><br><span class="line"></span><br><span class="line">        img_paths = []</span><br><span class="line">        <span class="keyword">for</span> extension <span class="keyword">in</span> [<span class="string">&quot;jpg&quot;</span>, <span class="string">&quot;png&quot;</span>, <span class="string">&quot;jpeg&quot;</span>]:</span><br><span class="line">            img_paths += glob.glob(os.path.join(img_dir, <span class="string">&quot;*.&#123;&#125;&quot;</span>.<span class="built_in">format</span>(extension)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> img_path <span class="keyword">in</span> img_paths:</span><br><span class="line">            _, img_name = os.path.split(img_path)</span><br><span class="line">            img = cv2.imread(img_path)</span><br><span class="line">            h, w = img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>]</span><br><span class="line">            newcameramtx, roi = cv2.getOptimalNewCameraMatrix(self.mat_intri, self.coff_dis, (w, h), <span class="number">1</span>, (w, h))</span><br><span class="line">            dst = cv2.undistort(img, self.mat_intri, self.coff_dis, <span class="literal">None</span>, newcameramtx)</span><br><span class="line">            <span class="comment"># clip the data</span></span><br><span class="line">            <span class="comment"># x, y, w, h = roi</span></span><br><span class="line">            <span class="comment"># dst = dst[y:y+h, x:x+w]</span></span><br><span class="line">            cv2.imwrite(os.path.join(save_dir, img_name), dst)</span><br><span class="line">        <span class="comment"># print(&quot;Dedistorted images have been saved to: &#123;&#125;&quot;.format(save_dir))</span></span><br></pre></td></tr></table></figure><h2 id="Kinect-V2相机获取图像及图像预处理"><a href="#Kinect-V2相机获取图像及图像预处理" class="headerlink" title="Kinect V2相机获取图像及图像预处理"></a>Kinect V2相机获取图像及图像预处理</h2><ol><li><strong>使用Kinect V2相机拍摄RGB-D数据流。</strong>设定拍摄目标的名字<code>name</code>，运行函数后延时1s开始拍摄，按<code>ESC</code>键结束拍摄。拍摄的RGB-D数据首先保存到指定路径下的h5文件中，同时输出拍摄的时间。拍摄Kinect图像需要用到Kinect类，代码在utils包中。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">capture_image</span>(<span class="params">name</span>):</span></span><br><span class="line">    file_name = <span class="string">&#x27;./data/h5/&#x27;</span> + name + <span class="string">&#x27;.h5&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(file_name):</span><br><span class="line">        os.remove(file_name)</span><br><span class="line">    <span class="built_in">open</span>(file_name, <span class="string">&quot;x&quot;</span>)</span><br><span class="line">    f = h5py.File(file_name, <span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    kinect = Kinect()</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    s = time.time()</span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        data = kinect.get_the_data_of_color_depth_infrared_image()</span><br><span class="line">        <span class="comment"># save data</span></span><br><span class="line">        f.create_dataset(<span class="built_in">str</span>(i), data=data[<span class="number">0</span>])</span><br><span class="line">        f.create_dataset(<span class="built_in">str</span>(i+<span class="number">1</span>), data=data[<span class="number">1</span>])</span><br><span class="line">        i += <span class="number">2</span></span><br><span class="line">        cv2.imshow(<span class="string">&#x27;kinect&#x27;</span>, data[<span class="number">0</span>])</span><br><span class="line">        cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> keyboard.is_pressed(<span class="string">&#x27;esc&#x27;</span>):  <span class="comment"># press ESC to exit</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;record time: %f s&#x27;</span> % (time.time() - s))</span><br><span class="line">    <span class="keyword">return</span> file_name</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pykinect2 <span class="keyword">import</span> PyKinectV2</span><br><span class="line"><span class="keyword">from</span> pykinect2.PyKinectV2 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pykinect2 <span class="keyword">import</span> PyKinectRuntime</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> ctypes</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> keyboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Kinect</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._kinect = PyKinectRuntime.PyKinectRuntime(PyKinectV2.FrameSourceTypes_Color | PyKinectV2.FrameSourceTypes_Depth | PyKinectV2.FrameSourceTypes_Infrared)</span><br><span class="line">        self.color_frame = <span class="literal">None</span></span><br><span class="line">        self.depth_frame = <span class="literal">None</span></span><br><span class="line">        self.infrared_frame = <span class="literal">None</span></span><br><span class="line">        self.w_color = <span class="number">1920</span></span><br><span class="line">        self.h_color = <span class="number">1080</span></span><br><span class="line">        self.w_depth = <span class="number">512</span></span><br><span class="line">        self.h_depth = <span class="number">424</span></span><br><span class="line">        self.csp_type = _ColorSpacePoint * np.<span class="built_in">int</span>(self.w_color * self.h_color)</span><br><span class="line">        self.csp = ctypes.cast(self.csp_type(), ctypes.POINTER(_DepthSpacePoint))</span><br><span class="line">        self.color = <span class="literal">None</span></span><br><span class="line">        self.depth = <span class="literal">None</span></span><br><span class="line">        self.infrared = <span class="literal">None</span></span><br><span class="line">        self.first_time = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Copying this image directly in python is not as efficient as getting another frame directly from C++</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get the latest color data&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_the_last_color</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self._kinect.has_new_color_frame():</span><br><span class="line">            <span class="comment"># the obtained image data is 2d and needs to be converted to the desired format</span></span><br><span class="line">            frame = self._kinect.get_last_color_frame()</span><br><span class="line">            <span class="comment"># return 4 channels, and one channel is not registered</span></span><br><span class="line">            gbra = frame.reshape([self._kinect.color_frame_desc.Height, self._kinect.color_frame_desc.Width, <span class="number">4</span>])</span><br><span class="line">            <span class="comment"># remove color image data, the default is that the mirror image needs to be flipped</span></span><br><span class="line">            color_frame = gbra[..., :<span class="number">3</span>][:, ::-<span class="number">1</span>, :]</span><br><span class="line">            <span class="keyword">return</span> color_frame</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get the latest depth data&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_the_last_depth</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self._kinect.has_new_depth_frame():</span><br><span class="line">            frame = self._kinect.get_last_depth_frame()</span><br><span class="line">            depth_frame_all = frame.reshape([self._kinect.depth_frame_desc.Height, self._kinect.depth_frame_desc.Width])</span><br><span class="line">            self.depth_frame = depth_frame_all[:, ::-<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">return</span> self.depth_frame</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get the latest infrared data&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_the_last_infrared</span>(<span class="params">self, Infrared_threshold = <span class="number">16000</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> self._kinect.has_new_infrared_frame():</span><br><span class="line">            frame = self._kinect.get_last_infrared_frame()</span><br><span class="line">            image_infrared_all = frame.reshape([self._kinect.infrared_frame_desc.Height, self._kinect.infrared_frame_desc.Width])</span><br><span class="line">            <span class="comment"># image_infrared_all[image_infrared_all &gt; Infrared_threshold] = 0</span></span><br><span class="line">            <span class="comment"># image_infrared_all = image_infrared_all / Infrared_threshold * 255</span></span><br><span class="line">            self.infrared_frame = image_infrared_all[:, ::-<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">return</span> self.infrared_frame</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Match the depth pixels into the color image&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">map_depth_points_to_color_points</span>(<span class="params">self, depth_points</span>):</span></span><br><span class="line">        depth_points = [self.map_depth_point_to_color_point(x) <span class="keyword">for</span> x <span class="keyword">in</span> depth_points]</span><br><span class="line">        <span class="keyword">return</span> depth_points</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">map_depth_point_to_color_point</span>(<span class="params">self, depth_point</span>):</span></span><br><span class="line">        <span class="keyword">global</span> valid</span><br><span class="line">        depth_point_to_color = copy.deepcopy(depth_point)</span><br><span class="line">        n = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">            self.get_the_last_depth()</span><br><span class="line">            self.get_the_last_color()</span><br><span class="line">            color_point = self._kinect._mapper.MapDepthPointToColorSpace(_DepthSpacePoint(<span class="number">511</span> - depth_point_to_color[<span class="number">1</span>], depth_point_to_color[<span class="number">0</span>]), self.depth_frame[depth_point_to_color[<span class="number">0</span>], <span class="number">511</span> - depth_point_to_color[<span class="number">1</span>]])</span><br><span class="line">            <span class="keyword">if</span> math.isinf(<span class="built_in">float</span>(color_point.y)):</span><br><span class="line">                n += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> n &gt;= <span class="number">10000</span>:</span><br><span class="line">                    color_point = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                color_point = [np.int0(color_point.y), <span class="number">1920</span> - np.int0(color_point.x)]  <span class="comment"># image coordinates, human eye Angle</span></span><br><span class="line">                valid += <span class="number">1</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;valid number：&#x27;</span>, valid)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> color_point</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Map an array of color pixels into a depth image&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">map_color_points_to_depth_points</span>(<span class="params">self, color_points</span>):</span></span><br><span class="line">        self.get_the_last_depth()</span><br><span class="line">        self.get_the_last_color()</span><br><span class="line">        self._kinect._mapper.MapColorFrameToDepthSpace(ctypes.c_uint(<span class="number">512</span> * <span class="number">424</span>), self._kinect._depth_frame_data, ctypes.c_uint(<span class="number">1920</span> * <span class="number">1080</span>), self.csp)</span><br><span class="line">        depth_points = [self.map_color_point_to_depth_point(x, <span class="literal">True</span>) <span class="keyword">for</span> x <span class="keyword">in</span> color_points]</span><br><span class="line">        <span class="keyword">return</span> depth_points</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">map_color_point_to_depth_point</span>(<span class="params">self, color_point, if_call_flg=<span class="literal">False</span></span>):</span></span><br><span class="line">        n = <span class="number">0</span></span><br><span class="line">        color_point_to_depth = copy.deepcopy(color_point)</span><br><span class="line">        color_point_to_depth[<span class="number">1</span>] = <span class="number">1920</span> - color_point_to_depth[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">            self.get_the_last_depth()</span><br><span class="line">            self.get_the_last_color()</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> if_call_flg:</span><br><span class="line">                self._kinect._mapper.MapColorFrameToDepthSpace(ctypes.c_uint(<span class="number">512</span> * <span class="number">424</span>), self._kinect._depth_frame_data, ctypes.c_uint(<span class="number">1920</span> * <span class="number">1080</span>), self.csp)</span><br><span class="line">            <span class="keyword">if</span> math.isinf(<span class="built_in">float</span>(self.csp[color_point_to_depth[<span class="number">0</span>] * <span class="number">1920</span> + color_point_to_depth[<span class="number">1</span>] - <span class="number">1</span>].y)) \</span><br><span class="line">                    <span class="keyword">or</span> np.isnan(self.csp[color_point_to_depth[<span class="number">0</span>] * <span class="number">1920</span> + color_point_to_depth[<span class="number">1</span>] - <span class="number">1</span>].y):</span><br><span class="line">                n += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> n &gt;= <span class="number">10000</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;Color mapping depth, invalid points&#x27;</span>)</span><br><span class="line">                    depth_point = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    depth_point = [np.int0(self.csp[color_point_to_depth[<span class="number">0</span>] * <span class="number">1920</span> + color_point_to_depth[<span class="number">1</span>] - <span class="number">1</span>].y),</span><br><span class="line">                                   np.int0(self.csp[color_point_to_depth[<span class="number">0</span>] * <span class="number">1920</span> + color_point_to_depth[<span class="number">1</span>] - <span class="number">1</span>].x)]</span><br><span class="line">                <span class="keyword">except</span> OverflowError <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;Color mapping depth, invalid points&#x27;</span>)</span><br><span class="line">                    depth_point = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        depth_point[<span class="number">1</span>] = <span class="number">512</span> - depth_point[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> depth_point</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get the latest color and depth images as well as infrared images&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_the_data_of_color_depth_infrared_image</span>(<span class="params">self</span>):</span></span><br><span class="line">        time_s = time.time()</span><br><span class="line">        <span class="keyword">if</span> self.first_time:</span><br><span class="line">            <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">                n = <span class="number">0</span></span><br><span class="line">                self.color = self.get_the_last_color()</span><br><span class="line">                n += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                self.depth = self.get_the_last_depth()</span><br><span class="line">                n += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> self._kinect.has_new_infrared_frame():</span><br><span class="line">                    frame = self._kinect.get_last_infrared_frame()</span><br><span class="line">                    image_infrared_all = frame.reshape([self._kinect.depth_frame_desc.Height, self._kinect.depth_frame_desc.Width])</span><br><span class="line">                    self.infrared = image_infrared_all[:, ::-<span class="number">1</span>]</span><br><span class="line">                    n += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                t = time.time() - time_s</span><br><span class="line">                <span class="keyword">if</span> n == <span class="number">3</span>:</span><br><span class="line">                    self.first_time = <span class="literal">False</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">elif</span> t &gt; <span class="number">5</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;No image data is obtained, please check that the Kinect2 connection is normal&#x27;</span>)</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> self._kinect.has_new_color_frame():</span><br><span class="line">                frame = self._kinect.get_last_color_frame()</span><br><span class="line">                gbra = frame.reshape([self._kinect.color_frame_desc.Height, self._kinect.color_frame_desc.Width, <span class="number">4</span>])</span><br><span class="line">                gbr = gbra[:, :, :<span class="number">3</span>][:, ::-<span class="number">1</span>, :]</span><br><span class="line">                self.color = gbr</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self._kinect.has_new_depth_frame():</span><br><span class="line">                frame = self._kinect.get_last_depth_frame()</span><br><span class="line">                image_depth_all = frame.reshape([self._kinect.depth_frame_desc.Height, self._kinect.depth_frame_desc.Width])</span><br><span class="line">                depth = image_depth_all[:, ::-<span class="number">1</span>]</span><br><span class="line">                self.depth = depth</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self._kinect.has_new_infrared_frame():</span><br><span class="line">                frame = self._kinect.get_last_infrared_frame()</span><br><span class="line">                image_infrared_all = frame.reshape([self._kinect.depth_frame_desc.Height, self._kinect.depth_frame_desc.Width])</span><br><span class="line">                self.infrared = image_infrared_all[:, ::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.color, self.depth, self.infrared</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    kinect = Kinect()</span><br><span class="line">    s = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        data = kinect.get_the_data_of_color_depth_infrared_image()</span><br><span class="line">        img = data[<span class="number">0</span>]</span><br><span class="line">        mat_intri = np.load(<span class="string">&#x27;./data/intrinsic_matrix.npy&#x27;</span>)</span><br><span class="line">        coff_dis = np.load(<span class="string">&#x27;./data/distortion_cofficients.npy&#x27;</span>)</span><br><span class="line">        h, w = img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>]</span><br><span class="line">        newcameramtx, roi = cv.getOptimalNewCameraMatrix(mat_intri, coff_dis, (w, h), <span class="number">1</span>, (w, h))</span><br><span class="line">        dst = cv.undistort(img, mat_intri, coff_dis, <span class="literal">None</span>, newcameramtx)</span><br><span class="line">        dst = cv.cvtColor(dst, cv.COLOR_BGR2RGB)</span><br><span class="line">        plt.imshow(dst/<span class="number">255</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        # store the mapping matrix in an npy file</span></span><br><span class="line"><span class="string">        color_points = np.zeros((512 * 424, 2), dtype=np.int)  # valid number: 207662</span></span><br><span class="line"><span class="string">        k = 0</span></span><br><span class="line"><span class="string">        for i in range(424):</span></span><br><span class="line"><span class="string">            for j in range(512):</span></span><br><span class="line"><span class="string">                color_points[k] = [i, j]</span></span><br><span class="line"><span class="string">                k += 1</span></span><br><span class="line"><span class="string">        depth_map_color = kinect.map_depth_points_to_color_points(color_points)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        # turn to 0 that is not in the mapping range</span></span><br><span class="line"><span class="string">        depth_map_color[..., 0] = np.where(depth_map_color[..., 0] &gt;= 1080, 0, depth_map_color[..., 0])</span></span><br><span class="line"><span class="string">        depth_map_color[..., 0] = np.where(depth_map_color[..., 0] &lt; 0, 0, depth_map_color[..., 0])</span></span><br><span class="line"><span class="string">        depth_map_color[..., 1] = np.where(depth_map_color[..., 1] &gt;= 1920, 0, depth_map_color[..., 1])</span></span><br><span class="line"><span class="string">        depth_map_color[..., 1] = np.where(depth_map_color[..., 1] &lt; 0, 0, depth_map_color[..., 1])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        # interpolated fill 0 values</span></span><br><span class="line"><span class="string">        zeros = np.array(list(set(np.where(depth_map_color == 0)[0])))</span></span><br><span class="line"><span class="string">        for zero in zeros:</span></span><br><span class="line"><span class="string">            if zero &lt; 40 * 512 or zero &gt; 360 * 512:</span></span><br><span class="line"><span class="string">                continue</span></span><br><span class="line"><span class="string">            j = 1</span></span><br><span class="line"><span class="string">            while depth_map_color[zero - j].any() == 0 or depth_map_color[zero + j].any() == 0:</span></span><br><span class="line"><span class="string">                j += 1</span></span><br><span class="line"><span class="string">            depth_map_color[zero][0] = (depth_map_color[zero - j][0] + depth_map_color[zero + j][0]) // 2</span></span><br><span class="line"><span class="string">            depth_map_color[zero][1] = (depth_map_color[zero - j][1] + depth_map_color[zero + j][1]) // 2</span></span><br><span class="line"><span class="string">        np.save(&#x27;full_depth_map_color.npy&#x27;, full_depth_map_color)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        depth_map_color = np.load(<span class="string">&#x27;./data/full_depth_map_color.npy&#x27;</span>)   <span class="comment"># (424*512, 2)</span></span><br><span class="line">        full_depth_map_color = depth_map_color</span><br><span class="line">        map_color = dst[full_depth_map_color[..., <span class="number">0</span>], full_depth_map_color[..., <span class="number">1</span>]]  <span class="comment"># (424*512, 2)</span></span><br><span class="line">        map_color = map_color.reshape((<span class="number">424</span>, <span class="number">512</span>, <span class="number">3</span>))</span><br><span class="line">        plt.imshow(map_color/<span class="number">255</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> keyboard.is_pressed(<span class="string">&#x27;esc&#x27;</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><ol><li><strong>彩色图去畸变。</strong>利用上文计算的相机参数对每一张彩色图去除畸变，同时保存去畸变后的彩色图。需要用到以下两个函数：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dedistortion</span>(<span class="params">mat_intri, coff_dis, img</span>):</span></span><br><span class="line">    h, w = img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>]</span><br><span class="line">    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mat_intri, coff_dis, (w, h), <span class="number">1</span>, (w, h))</span><br><span class="line">    dst = cv2.undistort(img, mat_intri, coff_dis, <span class="literal">None</span>, newcameramtx)</span><br><span class="line">    <span class="keyword">return</span> dst</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_image</span>(<span class="params">data, name, <span class="built_in">type</span>, <span class="built_in">dir</span>=<span class="string">&#x27;test&#x27;</span></span>):</span></span><br><span class="line">    <span class="keyword">global</span> num</span><br><span class="line">    idx = <span class="built_in">str</span>(num).zfill(<span class="number">6</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">dir</span> == <span class="string">&#x27;raw&#x27;</span>:</span><br><span class="line">        color_path = <span class="string">&#x27;./data/&#x27;</span> + name + <span class="string">&#x27;/color&#x27;</span></span><br><span class="line">        depth_path = <span class="string">&#x27;./data/&#x27;</span> + name + <span class="string">&#x27;/depth&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        color_path = <span class="string">&quot;./test_data/&quot;</span> + name + <span class="string">&#x27;/color&#x27;</span></span><br><span class="line">        depth_path = <span class="string">&quot;./test_data/&quot;</span> + name + <span class="string">&#x27;/depth&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(color_path):</span><br><span class="line">        os.makedirs(color_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(depth_path):</span><br><span class="line">        os.makedirs(depth_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">&#x27;color&#x27;</span>:</span><br><span class="line">        cv2.imwrite(color_path + <span class="string">&#x27;/color-&#x27;</span> + idx + <span class="string">&#x27;.png&#x27;</span>, data)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        cv2.imwrite(depth_path + <span class="string">&#x27;/depth-&#x27;</span> + idx + <span class="string">&#x27;.png&#x27;</span>, data)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">dir</span> == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            num += <span class="number">1</span></span><br></pre></td></tr></table></figure><ol><li><strong>深度图彩色图对齐。</strong>kinect相机的颜色相机和深度传感器之间存在距离，导致深度图和颜色图像素不是一一对应，需要对齐，使用以下函数对齐color和depth，对齐后将图像中心裁剪为尺寸<code>(480, 360)</code>。但是对齐后的颜色图可以会出现对齐错误（对齐npy文件存储在data包中，获取方式见<code>kinect.py</code>的main函数）。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">center_crop</span>(<span class="params">img,  crop_size</span>):</span></span><br><span class="line">    tw, th = crop_size</span><br><span class="line">    h, w = img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(img.shape) == <span class="number">2</span>:</span><br><span class="line">        crop_img = img[(h - th) // <span class="number">2</span>:(h + th) // <span class="number">2</span>, (w - tw) // <span class="number">2</span>:(w + tw) // <span class="number">2</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        crop_img = img[(h - th) // <span class="number">2</span>:(h + th) // <span class="number">2</span>, (w - tw) // <span class="number">2</span>:(w + tw) // <span class="number">2</span>, :]</span><br><span class="line">    <span class="keyword">return</span> crop_img</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">match_color_depth</span>(<span class="params">color, depth</span>):</span></span><br><span class="line">    <span class="comment"># crop+resize is worse</span></span><br><span class="line">    full_depth_map_color = np.load(<span class="string">&#x27;data/full_depth_map_color.npy&#x27;</span>)</span><br><span class="line">    map_color = color[full_depth_map_color[..., <span class="number">0</span>], full_depth_map_color[..., <span class="number">1</span>]]  <span class="comment"># (424*512, 2)</span></span><br><span class="line">    map_color = map_color.reshape((<span class="number">424</span>, <span class="number">512</span>, <span class="number">3</span>))</span><br><span class="line">    <span class="comment"># 512 * 424</span></span><br><span class="line">    color = center_crop(map_color, (<span class="number">480</span>, <span class="number">360</span>))</span><br><span class="line">    depth = center_crop(depth, (<span class="number">480</span>, <span class="number">360</span>))</span><br><span class="line">    <span class="comment"># plt.subplot(1, 2, 1)</span></span><br><span class="line">    <span class="comment"># plt.imshow(color)</span></span><br><span class="line">    <span class="comment"># plt.subplot(1, 2, 2)</span></span><br><span class="line">    <span class="comment"># plt.imshow(depth)</span></span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">    <span class="keyword">return</span> color, depth</span><br></pre></td></tr></table></figure><ol><li><strong>输出color视频。</strong>将校正后的color图像流输出为指定路径下的视频。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trans_video</span>(<span class="params">image_path, video_name, fps, res, <span class="built_in">type</span></span>):</span></span><br><span class="line">    img_path = gb.glob(image_path + <span class="string">&quot;/*.png&quot;</span>)</span><br><span class="line">    videoWriter = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*<span class="string">&#x27;DIVX&#x27;</span>), fps, res)</span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> img_path:</span><br><span class="line">        img = cv2.imread(path)</span><br><span class="line">        img = cv2.resize(img, res)</span><br><span class="line">        videoWriter.write(img)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;transform &#x27;</span> + <span class="built_in">type</span> + <span class="string">&#x27; video done!&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_video</span>(<span class="params">name</span>):</span></span><br><span class="line">    currentdate = datetime.datetime.now()</span><br><span class="line">    file_name = <span class="built_in">str</span>(currentdate.day) + <span class="string">&quot;.&quot;</span> + <span class="built_in">str</span>(currentdate.month) + <span class="string">&quot;.&quot;</span> + <span class="built_in">str</span>(currentdate.hour) + <span class="string">&quot;.&quot;</span> + <span class="built_in">str</span>(currentdate.minute)</span><br><span class="line">    color_path = <span class="string">&#x27;./data/&#x27;</span> + name + <span class="string">&#x27;/color&#x27;</span></span><br><span class="line">    <span class="comment"># depth_path = &#x27;./data/&#x27; + name + &#x27;/depth&#x27;</span></span><br><span class="line">    video_path = <span class="string">&#x27;./data/&#x27;</span> + name + <span class="string">&#x27;/video&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(video_path):</span><br><span class="line">        os.makedirs(video_path)</span><br><span class="line">    trans_video(color_path, video_path + <span class="string">&#x27;/color-&#x27;</span> + file_name + <span class="string">&#x27;.avi&#x27;</span>, <span class="number">30</span>, (<span class="number">1920</span>, <span class="number">1080</span>), <span class="string">&#x27;color&#x27;</span>)</span><br><span class="line">    <span class="comment"># trans_video(depth_path, depth_path + &#x27;/depth-&#x27; + file_name + &#x27;.avi&#x27;, 30, (512, 424), &#x27;depth&#x27;)</span></span><br></pre></td></tr></table></figure><ol><li><strong>完整调用。</strong>调用以上程序的主程序如下：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 1. shooting calibration images</span></span><br><span class="line">    get_chess_image()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. camera calibration</span></span><br><span class="line">    mat_intri, coff_dis = camera_calibrator()</span><br><span class="line">    <span class="comment"># mat_intri = np.load(&#x27;./data/intrinsic_matrix.npy&#x27;)</span></span><br><span class="line">    <span class="comment"># coff_dis = np.load(&#x27;./data/distortion_cofficients.npy&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. capture object images to save h5 file</span></span><br><span class="line">    name = <span class="string">&#x27;object&#x27;</span></span><br><span class="line">    file_name = capture_image(name)</span><br><span class="line"></span><br><span class="line">    f = h5py.File(file_name, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(f.keys()), <span class="number">2</span>):</span><br><span class="line">        color = f[<span class="built_in">str</span>(i)][:]</span><br><span class="line">        depth = f[<span class="built_in">str</span>(i + <span class="number">1</span>)][:]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. data process: dedistortion; match color and depth images; save color/depth images</span></span><br><span class="line">        dedistortion_color = dedistortion(mat_intri, coff_dis, color)</span><br><span class="line">        save_image(dedistortion_color, name, <span class="string">&#x27;color&#x27;</span>, <span class="string">&#x27;raw&#x27;</span>)</span><br><span class="line">        save_image(depth, name, <span class="string">&#x27;depth&#x27;</span>, <span class="string">&#x27;raw&#x27;</span>)</span><br><span class="line">        new_color, new_depth = match_color_depth(dedistortion_color, depth)</span><br><span class="line">        save_image(new_color, name, <span class="string">&#x27;color&#x27;</span>, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">        save_image(new_depth, name, <span class="string">&#x27;depth&#x27;</span>, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">    f.close()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;image save done!&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. convert to video</span></span><br><span class="line">    save_video(name)</span><br></pre></td></tr></table></figure><h1 id="基于RGB-D数据和掩码的实时三维重建"><a href="#基于RGB-D数据和掩码的实时三维重建" class="headerlink" title="基于RGB-D数据和掩码的实时三维重建"></a>基于RGB-D数据和掩码的实时三维重建</h1><p>输入指定数量的RGB-D图像及图像掩码（mask可以使用SAM模型获取）的路径，代码可以实现掩码内空洞点云的填充、任意倍率上采样，然后进行结果的open3d非阻塞可视化，重建图保存在指定路径。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, MinMaxScaler</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> open3d <span class="keyword">as</span> o3d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_neighbors</span>():</span></span><br><span class="line">    <span class="comment"># preprocessing neighborhood point coordinates</span></span><br><span class="line">    neighbors_list = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">9</span>):</span><br><span class="line">        neighbors = []</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(-r, r + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(-r, r + <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> math.sqrt(x ** <span class="number">2</span> + y ** <span class="number">2</span>) &lt;= r:</span><br><span class="line">                    neighbors.append([x, y])</span><br><span class="line">        neighbors.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>] ** <span class="number">2</span> + x[<span class="number">1</span>] ** <span class="number">2</span>)</span><br><span class="line">        neighbors_list[r] = neighbors[<span class="number">1</span>:]</span><br><span class="line">    <span class="built_in">print</span>(neighbors_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">neighbors_list = &#123;<span class="number">1</span>: [[-<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>]],</span><br><span class="line">                  <span class="number">2</span>: [[-<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">2</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">2</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">0</span>]],</span><br><span class="line">                  <span class="number">3</span>: [[-<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">2</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">2</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">0</span>], [-<span class="number">2</span>, -<span class="number">1</span>], [-<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">2</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, -<span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">1</span>], [<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">2</span>, -<span class="number">2</span>], [-<span class="number">2</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>], [-<span class="number">3</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">3</span>], [<span class="number">0</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">0</span>]],</span><br><span class="line">                  <span class="number">4</span>: [[-<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">2</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">2</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">0</span>], [-<span class="number">2</span>, -<span class="number">1</span>], [-<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">2</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, -<span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">1</span>], [<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">2</span>, -<span class="number">2</span>], [-<span class="number">2</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>], [-<span class="number">3</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">3</span>], [<span class="number">0</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">0</span>], [-<span class="number">3</span>, -<span class="number">1</span>], [-<span class="number">3</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">3</span>], [-<span class="number">1</span>, <span class="number">3</span>], [<span class="number">1</span>, -<span class="number">3</span>], [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">1</span>], [<span class="number">3</span>, <span class="number">1</span>], [-<span class="number">3</span>, -<span class="number">2</span>], [-<span class="number">3</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">3</span>], [-<span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, -<span class="number">3</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">2</span>], [<span class="number">3</span>, <span class="number">2</span>], [-<span class="number">4</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">4</span>], [<span class="number">0</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">0</span>]],</span><br><span class="line">                  <span class="number">5</span>: [[-<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">2</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">2</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">0</span>], [-<span class="number">2</span>, -<span class="number">1</span>], [-<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">2</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, -<span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">1</span>], [<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">2</span>, -<span class="number">2</span>], [-<span class="number">2</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>], [-<span class="number">3</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">3</span>], [<span class="number">0</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">0</span>], [-<span class="number">3</span>, -<span class="number">1</span>], [-<span class="number">3</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">3</span>], [-<span class="number">1</span>, <span class="number">3</span>], [<span class="number">1</span>, -<span class="number">3</span>], [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">1</span>], [<span class="number">3</span>, <span class="number">1</span>], [-<span class="number">3</span>, -<span class="number">2</span>], [-<span class="number">3</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">3</span>], [-<span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, -<span class="number">3</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">2</span>], [<span class="number">3</span>, <span class="number">2</span>], [-<span class="number">4</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">4</span>], [<span class="number">0</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">0</span>], [-<span class="number">4</span>, -<span class="number">1</span>], [-<span class="number">4</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">4</span>], [-<span class="number">1</span>, <span class="number">4</span>], [<span class="number">1</span>, -<span class="number">4</span>], [<span class="number">1</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">1</span>], [<span class="number">4</span>, <span class="number">1</span>], [-<span class="number">3</span>, -<span class="number">3</span>], [-<span class="number">3</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">3</span>], [<span class="number">3</span>, <span class="number">3</span>], [-<span class="number">4</span>, -<span class="number">2</span>], [-<span class="number">4</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">4</span>], [-<span class="number">2</span>, <span class="number">4</span>], [<span class="number">2</span>, -<span class="number">4</span>], [<span class="number">2</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">2</span>], [<span class="number">4</span>, <span class="number">2</span>], [-<span class="number">5</span>, <span class="number">0</span>], [-<span class="number">4</span>, -<span class="number">3</span>], [-<span class="number">4</span>, <span class="number">3</span>], [-<span class="number">3</span>, -<span class="number">4</span>], [-<span class="number">3</span>, <span class="number">4</span>], [<span class="number">0</span>, -<span class="number">5</span>], [<span class="number">0</span>, <span class="number">5</span>], [<span class="number">3</span>, -<span class="number">4</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">3</span>], [<span class="number">4</span>, <span class="number">3</span>], [<span class="number">5</span>, <span class="number">0</span>]],</span><br><span class="line">                  <span class="number">6</span>: [[-<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">2</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">2</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">0</span>], [-<span class="number">2</span>, -<span class="number">1</span>], [-<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">2</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, -<span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">1</span>], [<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">2</span>, -<span class="number">2</span>], [-<span class="number">2</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>], [-<span class="number">3</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">3</span>], [<span class="number">0</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">0</span>], [-<span class="number">3</span>, -<span class="number">1</span>], [-<span class="number">3</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">3</span>], [-<span class="number">1</span>, <span class="number">3</span>], [<span class="number">1</span>, -<span class="number">3</span>], [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">1</span>], [<span class="number">3</span>, <span class="number">1</span>], [-<span class="number">3</span>, -<span class="number">2</span>], [-<span class="number">3</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">3</span>], [-<span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, -<span class="number">3</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">2</span>], [<span class="number">3</span>, <span class="number">2</span>], [-<span class="number">4</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">4</span>], [<span class="number">0</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">0</span>], [-<span class="number">4</span>, -<span class="number">1</span>], [-<span class="number">4</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">4</span>], [-<span class="number">1</span>, <span class="number">4</span>], [<span class="number">1</span>, -<span class="number">4</span>], [<span class="number">1</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">1</span>], [<span class="number">4</span>, <span class="number">1</span>], [-<span class="number">3</span>, -<span class="number">3</span>], [-<span class="number">3</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">3</span>], [<span class="number">3</span>, <span class="number">3</span>], [-<span class="number">4</span>, -<span class="number">2</span>], [-<span class="number">4</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">4</span>], [-<span class="number">2</span>, <span class="number">4</span>], [<span class="number">2</span>, -<span class="number">4</span>], [<span class="number">2</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">2</span>], [<span class="number">4</span>, <span class="number">2</span>], [-<span class="number">5</span>, <span class="number">0</span>], [-<span class="number">4</span>, -<span class="number">3</span>], [-<span class="number">4</span>, <span class="number">3</span>], [-<span class="number">3</span>, -<span class="number">4</span>], [-<span class="number">3</span>, <span class="number">4</span>], [<span class="number">0</span>, -<span class="number">5</span>], [<span class="number">0</span>, <span class="number">5</span>], [<span class="number">3</span>, -<span class="number">4</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">3</span>], [<span class="number">4</span>, <span class="number">3</span>], [<span class="number">5</span>, <span class="number">0</span>], [-<span class="number">5</span>, -<span class="number">1</span>], [-<span class="number">5</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">5</span>], [-<span class="number">1</span>, <span class="number">5</span>], [<span class="number">1</span>, -<span class="number">5</span>], [<span class="number">1</span>, <span class="number">5</span>], [<span class="number">5</span>, -<span class="number">1</span>], [<span class="number">5</span>, <span class="number">1</span>], [-<span class="number">5</span>, -<span class="number">2</span>], [-<span class="number">5</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">5</span>], [-<span class="number">2</span>, <span class="number">5</span>], [<span class="number">2</span>, -<span class="number">5</span>], [<span class="number">2</span>, <span class="number">5</span>], [<span class="number">5</span>, -<span class="number">2</span>], [<span class="number">5</span>, <span class="number">2</span>], [-<span class="number">4</span>, -<span class="number">4</span>], [-<span class="number">4</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">4</span>], [<span class="number">4</span>, <span class="number">4</span>], [-<span class="number">5</span>, -<span class="number">3</span>], [-<span class="number">5</span>, <span class="number">3</span>], [-<span class="number">3</span>, -<span class="number">5</span>], [-<span class="number">3</span>, <span class="number">5</span>], [<span class="number">3</span>, -<span class="number">5</span>], [<span class="number">3</span>, <span class="number">5</span>], [<span class="number">5</span>, -<span class="number">3</span>], [<span class="number">5</span>, <span class="number">3</span>], [-<span class="number">6</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">6</span>], [<span class="number">0</span>, <span class="number">6</span>], [<span class="number">6</span>, <span class="number">0</span>]],</span><br><span class="line">                  <span class="number">7</span>: [[-<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">2</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">2</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">0</span>], [-<span class="number">2</span>, -<span class="number">1</span>], [-<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">2</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, -<span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">1</span>], [<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">2</span>, -<span class="number">2</span>], [-<span class="number">2</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>], [-<span class="number">3</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">3</span>], [<span class="number">0</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">0</span>], [-<span class="number">3</span>, -<span class="number">1</span>], [-<span class="number">3</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">3</span>], [-<span class="number">1</span>, <span class="number">3</span>], [<span class="number">1</span>, -<span class="number">3</span>], [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">1</span>], [<span class="number">3</span>, <span class="number">1</span>], [-<span class="number">3</span>, -<span class="number">2</span>], [-<span class="number">3</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">3</span>], [-<span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, -<span class="number">3</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">2</span>], [<span class="number">3</span>, <span class="number">2</span>], [-<span class="number">4</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">4</span>], [<span class="number">0</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">0</span>], [-<span class="number">4</span>, -<span class="number">1</span>], [-<span class="number">4</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">4</span>], [-<span class="number">1</span>, <span class="number">4</span>], [<span class="number">1</span>, -<span class="number">4</span>], [<span class="number">1</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">1</span>], [<span class="number">4</span>, <span class="number">1</span>], [-<span class="number">3</span>, -<span class="number">3</span>], [-<span class="number">3</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">3</span>], [<span class="number">3</span>, <span class="number">3</span>], [-<span class="number">4</span>, -<span class="number">2</span>], [-<span class="number">4</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">4</span>], [-<span class="number">2</span>, <span class="number">4</span>], [<span class="number">2</span>, -<span class="number">4</span>], [<span class="number">2</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">2</span>], [<span class="number">4</span>, <span class="number">2</span>], [-<span class="number">5</span>, <span class="number">0</span>], [-<span class="number">4</span>, -<span class="number">3</span>], [-<span class="number">4</span>, <span class="number">3</span>], [-<span class="number">3</span>, -<span class="number">4</span>], [-<span class="number">3</span>, <span class="number">4</span>], [<span class="number">0</span>, -<span class="number">5</span>], [<span class="number">0</span>, <span class="number">5</span>], [<span class="number">3</span>, -<span class="number">4</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">3</span>], [<span class="number">4</span>, <span class="number">3</span>], [<span class="number">5</span>, <span class="number">0</span>], [-<span class="number">5</span>, -<span class="number">1</span>], [-<span class="number">5</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">5</span>], [-<span class="number">1</span>, <span class="number">5</span>], [<span class="number">1</span>, -<span class="number">5</span>], [<span class="number">1</span>, <span class="number">5</span>], [<span class="number">5</span>, -<span class="number">1</span>], [<span class="number">5</span>, <span class="number">1</span>], [-<span class="number">5</span>, -<span class="number">2</span>], [-<span class="number">5</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">5</span>], [-<span class="number">2</span>, <span class="number">5</span>], [<span class="number">2</span>, -<span class="number">5</span>], [<span class="number">2</span>, <span class="number">5</span>], [<span class="number">5</span>, -<span class="number">2</span>], [<span class="number">5</span>, <span class="number">2</span>], [-<span class="number">4</span>, -<span class="number">4</span>], [-<span class="number">4</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">4</span>], [<span class="number">4</span>, <span class="number">4</span>], [-<span class="number">5</span>, -<span class="number">3</span>], [-<span class="number">5</span>, <span class="number">3</span>], [-<span class="number">3</span>, -<span class="number">5</span>], [-<span class="number">3</span>, <span class="number">5</span>], [<span class="number">3</span>, -<span class="number">5</span>], [<span class="number">3</span>, <span class="number">5</span>], [<span class="number">5</span>, -<span class="number">3</span>], [<span class="number">5</span>, <span class="number">3</span>], [-<span class="number">6</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">6</span>], [<span class="number">0</span>, <span class="number">6</span>], [<span class="number">6</span>, <span class="number">0</span>], [-<span class="number">6</span>, -<span class="number">1</span>], [-<span class="number">6</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">6</span>], [-<span class="number">1</span>, <span class="number">6</span>], [<span class="number">1</span>, -<span class="number">6</span>], [<span class="number">1</span>, <span class="number">6</span>], [<span class="number">6</span>, -<span class="number">1</span>], [<span class="number">6</span>, <span class="number">1</span>], [-<span class="number">6</span>, -<span class="number">2</span>], [-<span class="number">6</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">6</span>], [-<span class="number">2</span>, <span class="number">6</span>], [<span class="number">2</span>, -<span class="number">6</span>], [<span class="number">2</span>, <span class="number">6</span>], [<span class="number">6</span>, -<span class="number">2</span>], [<span class="number">6</span>, <span class="number">2</span>], [-<span class="number">5</span>, -<span class="number">4</span>], [-<span class="number">5</span>, <span class="number">4</span>], [-<span class="number">4</span>, -<span class="number">5</span>], [-<span class="number">4</span>, <span class="number">5</span>], [<span class="number">4</span>, -<span class="number">5</span>], [<span class="number">4</span>, <span class="number">5</span>], [<span class="number">5</span>, -<span class="number">4</span>], [<span class="number">5</span>, <span class="number">4</span>], [-<span class="number">6</span>, -<span class="number">3</span>], [-<span class="number">6</span>, <span class="number">3</span>], [-<span class="number">3</span>, -<span class="number">6</span>], [-<span class="number">3</span>, <span class="number">6</span>], [<span class="number">3</span>, -<span class="number">6</span>], [<span class="number">3</span>, <span class="number">6</span>], [<span class="number">6</span>, -<span class="number">3</span>], [<span class="number">6</span>, <span class="number">3</span>], [-<span class="number">7</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">7</span>], [<span class="number">0</span>, <span class="number">7</span>], [<span class="number">7</span>, <span class="number">0</span>]],</span><br><span class="line">                  <span class="number">8</span>: [[-<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">2</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">2</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">0</span>], [-<span class="number">2</span>, -<span class="number">1</span>], [-<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">2</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, -<span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">1</span>], [<span class="number">2</span>, <span class="number">1</span>], [-<span class="number">2</span>, -<span class="number">2</span>], [-<span class="number">2</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>], [-<span class="number">3</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">3</span>], [<span class="number">0</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">0</span>], [-<span class="number">3</span>, -<span class="number">1</span>], [-<span class="number">3</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">3</span>], [-<span class="number">1</span>, <span class="number">3</span>], [<span class="number">1</span>, -<span class="number">3</span>], [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">1</span>], [<span class="number">3</span>, <span class="number">1</span>], [-<span class="number">3</span>, -<span class="number">2</span>], [-<span class="number">3</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">3</span>], [-<span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, -<span class="number">3</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">2</span>], [<span class="number">3</span>, <span class="number">2</span>], [-<span class="number">4</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">4</span>], [<span class="number">0</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">0</span>], [-<span class="number">4</span>, -<span class="number">1</span>], [-<span class="number">4</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">4</span>], [-<span class="number">1</span>, <span class="number">4</span>], [<span class="number">1</span>, -<span class="number">4</span>], [<span class="number">1</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">1</span>], [<span class="number">4</span>, <span class="number">1</span>], [-<span class="number">3</span>, -<span class="number">3</span>], [-<span class="number">3</span>, <span class="number">3</span>], [<span class="number">3</span>, -<span class="number">3</span>], [<span class="number">3</span>, <span class="number">3</span>], [-<span class="number">4</span>, -<span class="number">2</span>], [-<span class="number">4</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">4</span>], [-<span class="number">2</span>, <span class="number">4</span>], [<span class="number">2</span>, -<span class="number">4</span>], [<span class="number">2</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">2</span>], [<span class="number">4</span>, <span class="number">2</span>], [-<span class="number">5</span>, <span class="number">0</span>], [-<span class="number">4</span>, -<span class="number">3</span>], [-<span class="number">4</span>, <span class="number">3</span>], [-<span class="number">3</span>, -<span class="number">4</span>], [-<span class="number">3</span>, <span class="number">4</span>], [<span class="number">0</span>, -<span class="number">5</span>], [<span class="number">0</span>, <span class="number">5</span>], [<span class="number">3</span>, -<span class="number">4</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">3</span>], [<span class="number">4</span>, <span class="number">3</span>], [<span class="number">5</span>, <span class="number">0</span>], [-<span class="number">5</span>, -<span class="number">1</span>], [-<span class="number">5</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">5</span>], [-<span class="number">1</span>, <span class="number">5</span>], [<span class="number">1</span>, -<span class="number">5</span>], [<span class="number">1</span>, <span class="number">5</span>], [<span class="number">5</span>, -<span class="number">1</span>], [<span class="number">5</span>, <span class="number">1</span>], [-<span class="number">5</span>, -<span class="number">2</span>], [-<span class="number">5</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">5</span>], [-<span class="number">2</span>, <span class="number">5</span>], [<span class="number">2</span>, -<span class="number">5</span>], [<span class="number">2</span>, <span class="number">5</span>], [<span class="number">5</span>, -<span class="number">2</span>], [<span class="number">5</span>, <span class="number">2</span>], [-<span class="number">4</span>, -<span class="number">4</span>], [-<span class="number">4</span>, <span class="number">4</span>], [<span class="number">4</span>, -<span class="number">4</span>], [<span class="number">4</span>, <span class="number">4</span>], [-<span class="number">5</span>, -<span class="number">3</span>], [-<span class="number">5</span>, <span class="number">3</span>], [-<span class="number">3</span>, -<span class="number">5</span>], [-<span class="number">3</span>, <span class="number">5</span>], [<span class="number">3</span>, -<span class="number">5</span>], [<span class="number">3</span>, <span class="number">5</span>], [<span class="number">5</span>, -<span class="number">3</span>], [<span class="number">5</span>, <span class="number">3</span>], [-<span class="number">6</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">6</span>], [<span class="number">0</span>, <span class="number">6</span>], [<span class="number">6</span>, <span class="number">0</span>], [-<span class="number">6</span>, -<span class="number">1</span>], [-<span class="number">6</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">6</span>], [-<span class="number">1</span>, <span class="number">6</span>], [<span class="number">1</span>, -<span class="number">6</span>], [<span class="number">1</span>, <span class="number">6</span>], [<span class="number">6</span>, -<span class="number">1</span>], [<span class="number">6</span>, <span class="number">1</span>], [-<span class="number">6</span>, -<span class="number">2</span>], [-<span class="number">6</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">6</span>], [-<span class="number">2</span>, <span class="number">6</span>], [<span class="number">2</span>, -<span class="number">6</span>], [<span class="number">2</span>, <span class="number">6</span>], [<span class="number">6</span>, -<span class="number">2</span>], [<span class="number">6</span>, <span class="number">2</span>], [-<span class="number">5</span>, -<span class="number">4</span>], [-<span class="number">5</span>, <span class="number">4</span>], [-<span class="number">4</span>, -<span class="number">5</span>], [-<span class="number">4</span>, <span class="number">5</span>], [<span class="number">4</span>, -<span class="number">5</span>], [<span class="number">4</span>, <span class="number">5</span>], [<span class="number">5</span>, -<span class="number">4</span>], [<span class="number">5</span>, <span class="number">4</span>], [-<span class="number">6</span>, -<span class="number">3</span>], [-<span class="number">6</span>, <span class="number">3</span>], [-<span class="number">3</span>, -<span class="number">6</span>], [-<span class="number">3</span>, <span class="number">6</span>], [<span class="number">3</span>, -<span class="number">6</span>], [<span class="number">3</span>, <span class="number">6</span>], [<span class="number">6</span>, -<span class="number">3</span>], [<span class="number">6</span>, <span class="number">3</span>], [-<span class="number">7</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">7</span>], [<span class="number">0</span>, <span class="number">7</span>], [<span class="number">7</span>, <span class="number">0</span>], [-<span class="number">7</span>, -<span class="number">1</span>], [-<span class="number">7</span>, <span class="number">1</span>], [-<span class="number">5</span>, -<span class="number">5</span>], [-<span class="number">5</span>, <span class="number">5</span>], [-<span class="number">1</span>, -<span class="number">7</span>], [-<span class="number">1</span>, <span class="number">7</span>], [<span class="number">1</span>, -<span class="number">7</span>], [<span class="number">1</span>, <span class="number">7</span>], [<span class="number">5</span>, -<span class="number">5</span>], [<span class="number">5</span>, <span class="number">5</span>], [<span class="number">7</span>, -<span class="number">1</span>], [<span class="number">7</span>, <span class="number">1</span>], [-<span class="number">6</span>, -<span class="number">4</span>], [-<span class="number">6</span>, <span class="number">4</span>], [-<span class="number">4</span>, -<span class="number">6</span>], [-<span class="number">4</span>, <span class="number">6</span>], [<span class="number">4</span>, -<span class="number">6</span>], [<span class="number">4</span>, <span class="number">6</span>], [<span class="number">6</span>, -<span class="number">4</span>], [<span class="number">6</span>, <span class="number">4</span>], [-<span class="number">7</span>, -<span class="number">2</span>], [-<span class="number">7</span>, <span class="number">2</span>], [-<span class="number">2</span>, -<span class="number">7</span>], [-<span class="number">2</span>, <span class="number">7</span>], [<span class="number">2</span>, -<span class="number">7</span>], [<span class="number">2</span>, <span class="number">7</span>], [<span class="number">7</span>, -<span class="number">2</span>], [<span class="number">7</span>, <span class="number">2</span>], [-<span class="number">7</span>, -<span class="number">3</span>], [-<span class="number">7</span>, <span class="number">3</span>], [-<span class="number">3</span>, -<span class="number">7</span>], [-<span class="number">3</span>, <span class="number">7</span>], [<span class="number">3</span>, -<span class="number">7</span>], [<span class="number">3</span>, <span class="number">7</span>], [<span class="number">7</span>, -<span class="number">3</span>], [<span class="number">7</span>, <span class="number">3</span>], [-<span class="number">6</span>, -<span class="number">5</span>], [-<span class="number">6</span>, <span class="number">5</span>], [-<span class="number">5</span>, -<span class="number">6</span>], [-<span class="number">5</span>, <span class="number">6</span>], [<span class="number">5</span>, -<span class="number">6</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">6</span>, -<span class="number">5</span>], [<span class="number">6</span>, <span class="number">5</span>], [-<span class="number">8</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">8</span>], [<span class="number">0</span>, <span class="number">8</span>], [<span class="number">8</span>, <span class="number">0</span>]]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mask_from_dist</span>(<span class="params">image, d=<span class="number">1</span></span>):</span></span><br><span class="line">    mask = np.where(image[..., -<span class="number">1</span>] &lt;= d, image[..., -<span class="number">1</span>], <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># mask1 = load_mask(data_path + &#x27;/mask/0.png&#x27;)[..., 0]  # (h, w)</span></span><br><span class="line">    <span class="comment"># mask2 = load_mask(data_path + &#x27;/mask/1.png&#x27;)[..., 0]  # (h, w)</span></span><br><span class="line">    <span class="comment"># mask += mask1</span></span><br><span class="line">    <span class="comment"># mask += mask2</span></span><br><span class="line">    mask = np.tile(np.expand_dims(mask, axis=-<span class="number">1</span>), <span class="number">3</span>)</span><br><span class="line">    mask_data = np.where(mask, <span class="number">255</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> mask_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crop</span>(<span class="params">img,  crop_size, crop_type</span>):</span></span><br><span class="line">    tw, th = crop_size</span><br><span class="line">    h, w = img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> crop_type == <span class="string">&#x27;center&#x27;</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(img.shape) == <span class="number">2</span>:</span><br><span class="line">            crop_img = img[(h - th) // <span class="number">2</span>:(h + th) // <span class="number">2</span>, (w - tw) // <span class="number">2</span>:(w + tw) // <span class="number">2</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            crop_img = img[(h - th) // <span class="number">2</span>:(h + th) // <span class="number">2</span>, (w - tw) // <span class="number">2</span>:(w + tw) // <span class="number">2</span>, :]</span><br><span class="line">    <span class="comment"># down sample: INTER_NEAREST INTER_AREA</span></span><br><span class="line">    <span class="keyword">elif</span> crop_type == <span class="string">&#x27;cv2resize&#x27;</span>:</span><br><span class="line">        crop_img = cv2.resize(img, crop_size, interpolation=cv2.INTER_NEAREST)</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># INTER_LINEAR</span></span><br><span class="line">        crop_img = cv2.resize(img, crop_size)</span><br><span class="line">    <span class="keyword">return</span> crop_img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span>(<span class="params">img, normal_type</span>):</span></span><br><span class="line">    h, w = img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>]</span><br><span class="line">    source_color_img = img[:, :, :<span class="number">3</span>]</span><br><span class="line">    source_depth_img = img[:, :, <span class="number">3</span>:]</span><br><span class="line">    <span class="keyword">if</span> normal_type == <span class="string">&#x27;standard_scaler&#x27;</span>:</span><br><span class="line">        color_img = source_color_img.reshape(h * w, <span class="number">3</span>)</span><br><span class="line">        depth_img = source_depth_img.reshape(h * w, <span class="number">3</span>)</span><br><span class="line">        std_sca1 = StandardScaler()</span><br><span class="line">        std_sca2 = StandardScaler()</span><br><span class="line">        color_img_sca = std_sca1.fit_transform(color_img)</span><br><span class="line">        depth_img_sca = std_sca2.fit_transform(depth_img)</span><br><span class="line">        color_img_sca = color_img_sca.reshape(h, w, <span class="number">3</span>)</span><br><span class="line">        depth_img_sca = depth_img_sca.reshape(h, w, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">elif</span> normal_type == <span class="string">&#x27;minMax_scalar&#x27;</span>:</span><br><span class="line">        color_img = source_color_img.reshape(h * w, <span class="number">3</span>)</span><br><span class="line">        depth_img = source_depth_img.reshape(h * w, <span class="number">3</span>)</span><br><span class="line">        mm_sca1 = MinMaxScaler()</span><br><span class="line">        mm_sca2 = MinMaxScaler()</span><br><span class="line">        color_img_sca = mm_sca1.fit_transform(color_img)</span><br><span class="line">        depth_img_sca = mm_sca2.fit_transform(depth_img)</span><br><span class="line">        color_img_sca = color_img_sca.reshape(h, w, <span class="number">3</span>)</span><br><span class="line">        depth_img_sca = depth_img_sca.reshape(h, w, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        color_img_sca = source_color_img / <span class="number">255</span></span><br><span class="line">        depth_img_sca = source_depth_img</span><br><span class="line">    img_sca = np.concatenate((color_img_sca, depth_img_sca, source_color_img, source_depth_img), axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> img_sca</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backproject_depth</span>(<span class="params">depth_image, intrinsics</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(depth_image.shape) == <span class="number">2</span></span><br><span class="line">    intrinsics[-<span class="number">1</span>][-<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    height, width = depth_image.shape</span><br><span class="line">    <span class="keyword">if</span> depth_image.dtype != np.float32:</span><br><span class="line">        depth_image = depth_image.astype(np.float32)</span><br><span class="line"></span><br><span class="line">    depth_image /= <span class="number">1000</span>  <span class="comment"># unit: m</span></span><br><span class="line">    img = np.ones((width, height, <span class="number">3</span>))</span><br><span class="line">    img[..., <span class="number">0</span>] = np.array([[i] * height <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(width)]).reshape(width, height)</span><br><span class="line">    img[..., <span class="number">1</span>] = np.array(<span class="built_in">list</span>(<span class="built_in">range</span>(height)) * width).reshape(width, height)</span><br><span class="line">    Z = np.repeat(np.transpose(depth_image).reshape(width, height, <span class="number">1</span>), <span class="number">3</span>, axis=<span class="number">2</span>)</span><br><span class="line">    img2d = img * Z  <span class="comment"># (h, w, 3)</span></span><br><span class="line">    point_image = np.matmul(img2d, np.linalg.inv(np.transpose(intrinsics)))  <span class="comment"># 3, hxw  xyz</span></span><br><span class="line">    point_image = point_image.swapaxes(<span class="number">0</span>, <span class="number">1</span>).astype(np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    point_image = np.zeros((height, width, 3), dtype=np.float32)</span></span><br><span class="line"><span class="string">    k_x, k_y, u_0, v_0 = intrinsics[0, 0], intrinsics[1, 1], intrinsics[0, 2], intrinsics[1, 2]</span></span><br><span class="line"><span class="string">    for v in range(height):  # row -&gt; y</span></span><br><span class="line"><span class="string">        for u in range(width):  # col -&gt; x</span></span><br><span class="line"><span class="string">            if depth_image[v, u] == 0:</span></span><br><span class="line"><span class="string">                continue</span></span><br><span class="line"><span class="string">            depth = depth_image[v, u]</span></span><br><span class="line"><span class="string">            z_c = depth / 1000   # unit: m</span></span><br><span class="line"><span class="string">            x_c = (u - u_0) * z_c / k_x</span></span><br><span class="line"><span class="string">            y_c = (v - v_0) * z_c / k_y</span></span><br><span class="line"><span class="string">            point_image[v, u] = np.array([x_c, y_c, z_c], dtype=np.float32)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> point_image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_image</span>(<span class="params">color_image_path, depth_image_path, intrinsics</span>):</span></span><br><span class="line">    color_image = io.imread(color_image_path)  <span class="comment"># (h, w, 3)  RGB</span></span><br><span class="line">    depth_image = io.imread(depth_image_path)  <span class="comment"># (h, w)</span></span><br><span class="line">    <span class="comment"># depth_image = cv2.GaussianBlur(depth_image, (3, 3), 1)</span></span><br><span class="line">    depth_image = backproject_depth(depth_image, intrinsics)  <span class="comment"># (h, w, 3)  xyz</span></span><br><span class="line">    image = np.concatenate((color_image, depth_image), axis=-<span class="number">1</span>)  <span class="comment"># (h, w, 6)</span></span><br><span class="line">    <span class="keyword">return</span> image  <span class="comment"># (h, w, 6)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_mask</span>(<span class="params">mask_image_path</span>):</span></span><br><span class="line">    mask_image = cv2.imread(mask_image_path)</span><br><span class="line">    <span class="keyword">return</span> mask_image / <span class="number">255.</span>  <span class="comment"># (h, w, 3)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">display_inlier_outlier</span>(<span class="params">cloud, ind</span>):</span></span><br><span class="line">    inlier_cloud = cloud.select_by_index(ind)</span><br><span class="line">    outlier_cloud = cloud.select_by_index(ind, invert=<span class="literal">True</span>)</span><br><span class="line">    outlier_cloud.paint_uniform_color([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>])   <span class="comment"># red</span></span><br><span class="line">    inlier_cloud.paint_uniform_color([<span class="number">0.8</span>, <span class="number">0.8</span>, <span class="number">0.8</span>])  <span class="comment"># gray</span></span><br><span class="line">    o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_noisy</span>(<span class="params">image, nb_points=<span class="number">30</span>, radius=<span class="number">0.02</span></span>):</span></span><br><span class="line">    height, width = image.shape[:<span class="number">2</span>]</span><br><span class="line">    point = image[..., <span class="number">3</span>:<span class="number">6</span>]</span><br><span class="line">    point = point.reshape(height * width, <span class="number">3</span>)</span><br><span class="line">    pc = o3d.geometry.PointCloud()</span><br><span class="line">    pc.points = o3d.utility.Vector3dVector(point)</span><br><span class="line">    <span class="comment"># convert outlier coordinates to 0</span></span><br><span class="line">    down_sample_points = <span class="number">1</span></span><br><span class="line">    uni_down_src_pc = pc.uniform_down_sample(every_k_points=down_sample_points)</span><br><span class="line">    <span class="comment"># delete points that have few neighborhood points around a sphere of a given radius</span></span><br><span class="line">    cl1, ind = uni_down_src_pc.remove_radius_outlier(nb_points=nb_points, radius=radius)</span><br><span class="line">    <span class="comment"># display outlier and inlier</span></span><br><span class="line">    <span class="comment"># display_inlier_outlier(pc, ind)</span></span><br><span class="line">    ind = <span class="built_in">set</span>(ind)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(height * width):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> ind:</span><br><span class="line">            point[i] = np.zeros((<span class="number">1</span>, <span class="number">3</span>), dtype=np.float32)</span><br><span class="line">    point = point.reshape(height, width, <span class="number">3</span>)</span><br><span class="line">    image[..., <span class="number">3</span>:<span class="number">6</span>] = point</span><br><span class="line">    image[..., <span class="number">9</span>:] = point</span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_process</span>(<span class="params">data</span>):</span></span><br><span class="line">    intrinsics_path = data[<span class="string">&#x27;intrinsics_path&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> intrinsics_path.endswith(<span class="string">&#x27;txt&#x27;</span>):</span><br><span class="line">        intrinsics = []</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(intrinsics_path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">                intrinsics.append(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>, line.split()))[:-<span class="number">1</span>])</span><br><span class="line">        intrinsics = np.array(intrinsics[:-<span class="number">1</span>], dtype=np.float32)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        intrinsics = np.load(intrinsics_path)</span><br><span class="line"></span><br><span class="line">    color_image_path = os.path.join(data_path, data[<span class="string">&quot;color&quot;</span>])</span><br><span class="line">    depth_image_path = os.path.join(data_path, data[<span class="string">&quot;depth&quot;</span>])</span><br><span class="line">    image = load_image(color_image_path, depth_image_path, intrinsics)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># mask = get_mask_from_dist(image)  # move_dragon</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># crop and normalize</span></span><br><span class="line">    crop_size = input_height, input_width</span><br><span class="line">    image = crop(image, crop_size, crop_type)</span><br><span class="line">    image = normalize(image, normal_type=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># mask image</span></span><br><span class="line">    mask = load_mask(data[<span class="string">&quot;mask&quot;</span>])  <span class="comment"># (h, w)</span></span><br><span class="line">    mask = crop(mask, crop_size, crop_type)</span><br><span class="line">    mask = np.where(mask, <span class="literal">True</span>, <span class="literal">False</span>)</span><br><span class="line">    image = np.where(np.tile(mask, <span class="number">4</span>), image, <span class="number">0.</span>)   <span class="comment"># (h, w, 12)  normal_RGB+normal_xyz+rgb+xyz</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># point cloud denoising</span></span><br><span class="line">    image = remove_noisy(image)</span><br><span class="line">    <span class="keyword">return</span> image, mask, intrinsics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_data_process</span>(<span class="params">img_num, data_path</span>):</span></span><br><span class="line">    pre_data = []</span><br><span class="line">    <span class="keyword">for</span> i, img_number <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">range</span>(img_num)):</span><br><span class="line">        img_number = <span class="string">f&quot;<span class="subst">&#123;img_number:06d&#125;</span>&quot;</span></span><br><span class="line">        data = &#123;<span class="string">&#x27;color&#x27;</span>: data_path + <span class="string">&#x27;rgbd/frame-&#x27;</span> + img_number + <span class="string">&#x27;.color.png&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;depth&#x27;</span>: data_path + <span class="string">&#x27;rgbd/frame-&#x27;</span> + img_number + <span class="string">&#x27;.depth.png&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;mask&#x27;</span>: data_path + <span class="string">&#x27;/mask/mask&#x27;</span> + img_number + <span class="string">&#x27;.png&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;intrinsics_path&#x27;</span>: data_path + <span class="string">&#x27;colorIntrinsics.txt&#x27;</span>&#125;</span><br><span class="line">        image, mask, intrinsics = data_process(data)</span><br><span class="line">        <span class="comment"># cv2.imwrite(f&#x27;&#123;data_path&#125;/mask/mask&#123;img_number&#125;.png&#x27;, mask)</span></span><br><span class="line">        pre_data.append([image, mask, intrinsics])</span><br><span class="line">        <span class="built_in">print</span>(i)</span><br><span class="line">    <span class="keyword">return</span> pre_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map_3d_to_2d</span>(<span class="params">point_set, intrinsics, height, width</span>):</span></span><br><span class="line">    <span class="comment"># x = KX / z_c</span></span><br><span class="line">    point_rearr = point_set.transpose(<span class="number">1</span>, <span class="number">0</span>)  <span class="comment"># (3, num_points)</span></span><br><span class="line">    point_proj2D = np.divide(np.matmul(intrinsics, point_rearr), point_rearr[<span class="number">2</span>:, :])</span><br><span class="line">    point_pred = point_proj2D[:<span class="number">2</span>, :].transpose(<span class="number">1</span>, <span class="number">0</span>)  <span class="comment"># (num_points, 2)  u v</span></span><br><span class="line">    pred_image = np.zeros((height, width, <span class="number">3</span>), dtype=np.float32)</span><br><span class="line">    alpha = <span class="number">1.5</span> <span class="keyword">if</span> data_type == <span class="string">&#x27;kinect&#x27;</span> <span class="keyword">else</span> <span class="number">2</span>  <span class="comment"># 640/width  480/height</span></span><br><span class="line">    <span class="comment"># normalization, truncation, assignment</span></span><br><span class="line">    point_pred_int = np.<span class="built_in">round</span>(point_pred / alpha).astype(np.<span class="built_in">int</span>)  <span class="comment"># (num_points, 2)  u v</span></span><br><span class="line">    point_pred_int[..., <span class="number">0</span>] = np.clip(point_pred_int[..., <span class="number">0</span>], <span class="number">0</span>, width - <span class="number">1</span>)</span><br><span class="line">    point_pred_int[..., <span class="number">1</span>] = np.clip(point_pred_int[..., <span class="number">1</span>], <span class="number">0</span>, height - <span class="number">1</span>)</span><br><span class="line">    pred_image[point_pred_int[..., <span class="number">1</span>], point_pred_int[..., <span class="number">0</span>]] = point_set</span><br><span class="line">    <span class="keyword">return</span> pred_image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">uneven_upsample_based_mask</span>(<span class="params">pred_image, mask_image, radius</span>):</span></span><br><span class="line">    <span class="comment"># pred_image: h*w*3 xyz  mask_image: h*w*3</span></span><br><span class="line">    up_image = pred_image.copy()</span><br><span class="line">    <span class="comment"># the index that is inside mask and the current point is null</span></span><br><span class="line">    mask_image_inf = np.where(mask_image, <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)) + pred_image</span><br><span class="line">    <span class="comment"># n1: number of points to be interpolated  2:uv</span></span><br><span class="line">    idx = np.argwhere(mask_image_inf[..., <span class="number">0</span>] == <span class="number">0</span>)  <span class="comment"># (n1, 2)</span></span><br><span class="line">    <span class="comment"># n2: neighbor count  2:uv</span></span><br><span class="line">    neighbors = np.array(neighbors_list[radius])  <span class="comment"># (n2, 2)</span></span><br><span class="line">    n1, n2 = idx.shape[<span class="number">0</span>], neighbors.shape[<span class="number">0</span>]</span><br><span class="line">    idx_expand = np.tile(np.expand_dims(idx, axis=-<span class="number">1</span>), n2).swapaxes(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    neighbors_expand = np.tile(np.expand_dims(neighbors, axis=-<span class="number">1</span>), n1).swapaxes(<span class="number">0</span>, <span class="number">2</span>).swapaxes(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    coordinate = idx_expand + neighbors_expand  <span class="comment"># (n1, n2, 2)</span></span><br><span class="line">    <span class="comment"># remove those that are not in mask and have no coordinate value</span></span><br><span class="line">    coordinate[..., <span class="number">0</span>] = np.where(coordinate[..., <span class="number">0</span>] &gt;= input_height, input_height - <span class="number">1</span>, coordinate[..., <span class="number">0</span>])</span><br><span class="line">    coordinate[..., <span class="number">0</span>] = np.where(coordinate[..., <span class="number">0</span>] &lt; <span class="number">0</span>, <span class="number">0</span>, coordinate[..., <span class="number">0</span>])</span><br><span class="line">    coordinate[..., <span class="number">1</span>] = np.where(coordinate[..., <span class="number">1</span>] &gt;= input_width, input_width - <span class="number">1</span>, coordinate[..., <span class="number">1</span>])</span><br><span class="line">    coordinate[..., <span class="number">1</span>] = np.where(coordinate[..., <span class="number">1</span>] &lt; <span class="number">0</span>, <span class="number">0</span>, coordinate[..., <span class="number">1</span>])</span><br><span class="line">    x_val = mask_image_inf[coordinate[..., <span class="number">0</span>], coordinate[..., <span class="number">1</span>]][..., <span class="number">0</span>]  <span class="comment"># (n1, n2)</span></span><br><span class="line">    <span class="comment"># set the true to 1, false to 0</span></span><br><span class="line">    neighbor_mask = np.where((x_val == <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)) | (x_val == <span class="number">0</span>), <span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># (n1, n2)</span></span><br><span class="line">    <span class="comment"># calculate distance matrix</span></span><br><span class="line">    D = np.linalg.norm(coordinate - idx_expand, axis=<span class="number">2</span>) + <span class="number">1e-6</span>  <span class="comment"># (n1, n2)</span></span><br><span class="line">    <span class="comment"># calculate the inverse distance weight and update the new matrix</span></span><br><span class="line">    W = (<span class="number">1</span> / D) / np.expand_dims(np.<span class="built_in">sum</span>(<span class="number">1</span> / D * neighbor_mask, axis=<span class="number">1</span>), axis=<span class="number">1</span>)  <span class="comment"># (n1, n2)</span></span><br><span class="line">    diff_val = np.matmul((neighbor_mask * W).reshape(n1, <span class="number">1</span>, n2),</span><br><span class="line">                         pred_image[coordinate[..., <span class="number">0</span>], coordinate[..., <span class="number">1</span>]]).reshape(n1, <span class="number">3</span>)</span><br><span class="line">    up_image[idx[..., <span class="number">0</span>], idx[..., <span class="number">1</span>]] = diff_val  <span class="comment"># (n1, 3) xyz</span></span><br><span class="line">    <span class="keyword">return</span> up_image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">up_sample</span>(<span class="params">pred_point, mask_image, intrinsics, radius, interpolation_type, ratio</span>):</span></span><br><span class="line">    <span class="comment"># point: n*3   mask_image: h*w*3</span></span><br><span class="line">    height, width = mask_image.shape[<span class="number">0</span>], mask_image.shape[<span class="number">1</span>]</span><br><span class="line">    pred_image = map_3d_to_2d(pred_point, intrinsics, height, width)  <span class="comment"># (h, w, 3) xyz</span></span><br><span class="line">    pred_image = np.where(mask_image, pred_image, <span class="number">0</span>)  <span class="comment"># (h, w, 3)</span></span><br><span class="line">    up_point_image = uneven_upsample_based_mask(pred_image, mask_image, radius)</span><br><span class="line"></span><br><span class="line">    tw, th = up_point_image.shape[<span class="number">1</span>] * ratio, up_point_image.shape[<span class="number">0</span>] * ratio</span><br><span class="line">    <span class="comment"># INTER_NEAREST  INTER_AREA = INTER_LINEAR</span></span><br><span class="line">    interpolation = cv2.INTER_NEAREST <span class="keyword">if</span> interpolation_type == <span class="string">&#x27;nearest&#x27;</span> <span class="keyword">else</span> cv2.INTER_LINEAR</span><br><span class="line">    up_point_image = cv2.resize(up_point_image, (tw, th), interpolation=interpolation)</span><br><span class="line">    mask_image_float = np.where(mask_image, <span class="number">1.</span>, <span class="number">0.</span>)</span><br><span class="line">    <span class="comment"># uses nearest neighbor interpolation, linear interpolation has serrated edges</span></span><br><span class="line">    mask_image_float = cv2.resize(mask_image_float, (tw, th), interpolation=interpolation)</span><br><span class="line">    up_mask_image_bool = np.where(mask_image_float == <span class="number">1.</span>, <span class="literal">True</span>, <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    intrinsics = intrinsics / <span class="number">2</span> <span class="keyword">if</span> data_type == <span class="string">&#x27;dataset&#x27;</span> <span class="keyword">else</span> intrinsics / <span class="number">1.5</span></span><br><span class="line">    point_image = backproject_depth(up_point_image[..., -<span class="number">1</span>] * <span class="number">1000</span>, intrinsics * ratio)</span><br><span class="line">    <span class="comment"># interpolation edge processing: remove edge interference</span></span><br><span class="line">    point_set = point_image[up_mask_image_bool].reshape(-<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> point_set, up_mask_image_bool  <span class="comment"># (point_num, 3)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">color_interpolation</span>(<span class="params">color_img, mask_image_bool, interpolation_type, ratio</span>):</span></span><br><span class="line">    interpolation = cv2.INTER_NEAREST <span class="keyword">if</span> interpolation_type == <span class="string">&#x27;nearest&#x27;</span> <span class="keyword">else</span> cv2.INTER_LINEAR</span><br><span class="line">    tw, th = color_img.shape[<span class="number">1</span>] * ratio, color_img.shape[<span class="number">0</span>] * ratio</span><br><span class="line">    up_color_image = cv2.resize(color_img, (tw, th), interpolation=interpolation)</span><br><span class="line">    color_set = up_color_image[mask_image_bool].reshape(-<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> color_set  <span class="comment"># (point_num, 3)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform_visual</span>(<span class="params">points</span>):</span></span><br><span class="line">    matrix = np.array(</span><br><span class="line">        [[<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],</span><br><span class="line">         [<span class="number">0.0</span>, -<span class="number">1.0</span>, <span class="number">0.0</span>],</span><br><span class="line">         [<span class="number">0.0</span>, <span class="number">0.0</span>, -<span class="number">1.0</span>]]</span><br><span class="line">    )</span><br><span class="line">    points = np.matmul(points, matrix.transpose())</span><br><span class="line">    <span class="keyword">return</span> points</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reconstruction</span>(<span class="params">image, mask, intrinsics, radius=<span class="number">8</span>, ratio=<span class="number">2</span>, interpolation_type=<span class="string">&#x27;linear&#x27;</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param radius: the neighborhood radius of the sample</span></span><br><span class="line"><span class="string">    :param ratio: sampling multiple</span></span><br><span class="line"><span class="string">    :param interpolation_type: nearest area linear</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    t1 = time.time()</span><br><span class="line">    point = image[..., <span class="number">9</span>:][mask]</span><br><span class="line">    point_pred = point[np.where(point != <span class="number">0</span>)].reshape(-<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># print(&#x27;before sample：&#x27;, len(point_pred))</span></span><br><span class="line">    point_up_sample, mask_image_bool = up_sample(point_pred, mask, intrinsics, radius, interpolation_type, ratio)</span><br><span class="line">    <span class="comment"># print(&#x27;after sample：&#x27;, len(point_up_sample))</span></span><br><span class="line">    t2 = time.time()</span><br><span class="line">    pred_color = color_interpolation(image[..., :<span class="number">3</span>], mask_image_bool, interpolation_type, ratio)</span><br><span class="line">    t3 = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;the time of point sample:<span class="subst">&#123;t2 - t1&#125;</span>, the time of color sample:<span class="subst">&#123;t3 - t2&#125;</span>&#x27;</span>)</span><br><span class="line">    point_up_sample = transform_visual(point_up_sample)</span><br><span class="line">    <span class="keyword">return</span> point_up_sample, pred_color</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reconstruct_and_visualize</span>(<span class="params">pre_data, out_path, save_img=<span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(out_path):</span><br><span class="line">        os.makedirs(out_path)</span><br><span class="line">    vis = o3d.visualization.Visualizer()</span><br><span class="line">    vis.create_window(width=<span class="number">960</span> * <span class="number">2</span>, height=<span class="number">640</span> * <span class="number">2</span>, left=<span class="number">10</span>, top=<span class="number">10</span>)</span><br><span class="line">    pcd = o3d.geometry.PointCloud()</span><br><span class="line">    <span class="keyword">for</span> i, (image, mask, intrinsics) <span class="keyword">in</span> <span class="built_in">enumerate</span>(pre_data):</span><br><span class="line">        point_up_sample, pred_color = reconstruction(image, mask, intrinsics)</span><br><span class="line">        pcd.points = o3d.utility.Vector3dVector(point_up_sample.reshape(-<span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line">        pcd.colors = o3d.utility.Vector3dVector(pred_color.reshape(-<span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line">        <span class="comment"># visual the single image</span></span><br><span class="line">        <span class="comment"># o3d.visualization.draw_geometries([pcd])</span></span><br><span class="line">        vis.add_geometry(pcd)</span><br><span class="line">        vis.poll_events()</span><br><span class="line">        vis.update_renderer()</span><br><span class="line">        <span class="keyword">if</span> save_img:</span><br><span class="line">            vis.capture_screen_image(<span class="string">f&quot;<span class="subst">&#123;out_path&#125;</span><span class="subst">&#123;i:06d&#125;</span>.png&quot;</span>)</span><br><span class="line">    vis.destroy_window()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    crop_type = <span class="string">&#x27;inter_nearest&#x27;</span></span><br><span class="line">    input_height, input_width = <span class="number">240</span>, <span class="number">320</span></span><br><span class="line">    obj = <span class="string">&#x27;move_dragon&#x27;</span></span><br><span class="line">    data_type = <span class="string">&#x27;dataset&#x27;</span></span><br><span class="line">    img_num = <span class="number">90</span></span><br><span class="line">    data_path = <span class="string">f&#x27;/home/PycharmProjects/data/<span class="subst">&#123;obj&#125;</span>/&#x27;</span></span><br><span class="line"></span><br><span class="line">    pre_data = batch_data_process(img_num, data_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;data preprocess done!&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    out_path = data_path + <span class="string">&#x27;/recon_img/&#x27;</span></span><br><span class="line">    reconstruct_and_visualize(pre_data, out_path)</span><br></pre></td></tr></table></figure><p>参考：</p><blockquote><p>Open3d之非阻塞可视化：<a href="https://blog.csdn.net/u014072827/article/details/113766353?spm=1001.2014.3001.5506">https://blog.csdn.net/u014072827/article/details/113766353?spm=1001.2014.3001.5506</a></p></blockquote><h1 id="Python实现传统2D-3D配准——SIFT-SURF-BRISK-ORB-AKAZE-ICP"><a href="#Python实现传统2D-3D配准——SIFT-SURF-BRISK-ORB-AKAZE-ICP" class="headerlink" title="Python实现传统2D/3D配准——SIFT/SURF/ BRISK/ORB/AKAZE/ICP"></a>Python实现传统2D/3D配准——SIFT/SURF/ BRISK/ORB/AKAZE/ICP</h1><ol><li><strong>导入使用到的包</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> open3d <span class="keyword">as</span> o3d</span><br><span class="line"><span class="keyword">import</span> cv2</span><br></pre></td></tr></table></figure><ol><li><strong>基于传统特征点匹配的2D配准函数。</strong>函数输入为想要配准的source图和target图，两个图像均为维度<code>(h, w, 3)</code>的ndarray。函数可以选择使用不同的特征提取方式：SIFT/SURF/ BRISK/ORB/AKAZE。函数实现了匹配点、配准图的可视化。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">akaze_registration2d</span>(<span class="params">source_image, target_image, optical_flow_gt=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># running speed and robustness comparison: SIFT &lt; SURF &lt; BRISK &lt; FREAK &lt; ORB &lt; AKAZE</span></span><br><span class="line">    <span class="comment"># initial</span></span><br><span class="line">    sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line">    surf = cv2.xfeatures2d.SURF_create()</span><br><span class="line">    brisk = cv2.BRISK_create()</span><br><span class="line">    orb = cv2.ORB_create()</span><br><span class="line">    akaze = cv2.AKAZE_create()</span><br><span class="line">    <span class="comment"># find key points and descriptions</span></span><br><span class="line">    kp1, des1 = akaze.detectAndCompute(source_image, <span class="literal">None</span>)</span><br><span class="line">    kp2, des2 = akaze.detectAndCompute(target_image, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># BFMatcher (Brute force computing)</span></span><br><span class="line">    bf = cv2.BFMatcher()   <span class="comment"># cv2.NORM_HAMMING, crossCheck=True</span></span><br><span class="line">    <span class="comment"># matches = bf.match(des1, des2)</span></span><br><span class="line">    matches = bf.knnMatch(des1, des2, k=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    # get the flann matcher</span></span><br><span class="line"><span class="string">    FLANN_INDEX_KDTREE = 0</span></span><br><span class="line"><span class="string">    # para1：indexParams</span></span><br><span class="line"><span class="string">    #    for SIFT and SURF: index_params=dict(algorithm=FLANN_INDEX_KDTREE, trees=5)</span></span><br><span class="line"><span class="string">    #    for ORB: index_params=dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12)</span></span><br><span class="line"><span class="string">    indexParams = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)</span></span><br><span class="line"><span class="string">    # para2：searchParams (the number of recursive traversals)</span></span><br><span class="line"><span class="string">    searchParams = dict(checks=50)</span></span><br><span class="line"><span class="string">    # ues FlannBasedMatcher to find the nearest neighbor </span></span><br><span class="line"><span class="string">    flann = cv2.FlannBasedMatcher(indexParams, searchParams)</span></span><br><span class="line"><span class="string">    # use knnMatch and return matches</span></span><br><span class="line"><span class="string">    matches = flann.knnMatch(des1, des2, k=2)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># sort by similarity</span></span><br><span class="line">    matches = <span class="built_in">sorted</span>(matches, key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>].distance)</span><br><span class="line">    <span class="comment"># rotation test</span></span><br><span class="line">    good_matches = []</span><br><span class="line">    n = <span class="number">50</span></span><br><span class="line">    <span class="keyword">for</span> d1, d2 <span class="keyword">in</span> matches:</span><br><span class="line">        <span class="comment"># the smaller the coefficient, the fewer the matching points</span></span><br><span class="line">        <span class="keyword">if</span> d1.distance &lt; <span class="number">0.9</span> * d2.distance:</span><br><span class="line">            good_matches.append([d1])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># draw matches</span></span><br><span class="line">    <span class="comment"># img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[: n], img2, flags=2)</span></span><br><span class="line">    img3 = cv2.drawMatchesKnn(np.uint8(source_image), kp1, np.uint8(target_image), kp2, good_matches, <span class="literal">None</span>, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)</span><br><span class="line">    plt.imshow(img3.astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line">    plt.show()</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;akaze_matches.jpg&#x27;</span>, img3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># select matching key</span></span><br><span class="line">    ref_matched_kpts = np.float32([kp1[m[<span class="number">0</span>].queryIdx].pt <span class="keyword">for</span> m <span class="keyword">in</span> good_matches]).reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    sensed_matched_kpts = np.float32([kp2[m[<span class="number">0</span>].trainIdx].pt <span class="keyword">for</span> m <span class="keyword">in</span> good_matches]).reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    plt.ion()  <span class="comment"># change the display mode to interactive mode</span></span><br><span class="line">    ndarray_image = np.concatenate([source_image, target_image], axis=<span class="number">1</span>)  <span class="comment"># (h, 2w, 3)</span></span><br><span class="line">    plt.imshow(ndarray_image.astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line">    plt.show()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;akaze_registration2d.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate homography</span></span><br><span class="line">    H, status = cv2.findHomography(ref_matched_kpts, sensed_matched_kpts, cv2.RANSAC, <span class="number">5.0</span>)</span><br><span class="line">    <span class="comment"># transform</span></span><br><span class="line">    warped_image = cv2.warpPerspective(source_image, H, (source_image.shape[<span class="number">1</span>], source_image.shape[<span class="number">0</span>]))</span><br><span class="line">    warped_image = cv2.cvtColor(warped_image, cv2.COLOR_RGB2BGR)</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;akaze_warped.jpg&#x27;</span>, warped_image)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate error</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> optical_flow_gt:</span><br><span class="line">        error_matrix = np.zeros((ref_matched_kpts.shape[<span class="number">0</span>],))</span><br><span class="line">        num = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(ref_matched_kpts.shape[<span class="number">0</span>]):</span><br><span class="line">            u, v = <span class="built_in">round</span>(ref_matched_kpts[i, <span class="number">0</span>, <span class="number">0</span>]), <span class="built_in">round</span>(ref_matched_kpts[i, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">            <span class="keyword">if</span> np.isinf(optical_flow_gt[v, u, <span class="number">0</span>]):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            u_error = <span class="built_in">abs</span>(optical_flow_gt[v, u, <span class="number">0</span>]) - <span class="built_in">abs</span>(ref_matched_kpts[i, <span class="number">0</span>, <span class="number">0</span>] - sensed_matched_kpts[i, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">            v_error = <span class="built_in">abs</span>(optical_flow_gt[v, u, <span class="number">1</span>]) - <span class="built_in">abs</span>(ref_matched_kpts[i, <span class="number">0</span>, <span class="number">1</span>] - sensed_matched_kpts[i, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">            error = math.sqrt(u_error ** <span class="number">2</span> + v_error ** <span class="number">2</span>)</span><br><span class="line">            error_matrix[i] = error</span><br><span class="line">            <span class="keyword">if</span> num &lt; n:</span><br><span class="line">                plt.plot([ref_matched_kpts[i, <span class="number">0</span>, <span class="number">0</span>], sensed_matched_kpts[i, <span class="number">0</span>, <span class="number">0</span>] + source_image.shape[<span class="number">1</span>]],</span><br><span class="line">                         [ref_matched_kpts[i, <span class="number">0</span>, <span class="number">1</span>], sensed_matched_kpts[i, <span class="number">0</span>, <span class="number">1</span>]],</span><br><span class="line">                         color=[(<span class="number">10</span>+<span class="number">3</span>*i)/<span class="number">255</span>, (<span class="number">80</span>+i)/<span class="number">255</span>, <span class="number">220</span>/<span class="number">255</span>], linewidth=<span class="number">0.5</span>, marker=<span class="string">&#x27;.&#x27;</span>, markersize=<span class="number">2</span>)</span><br><span class="line">            num += <span class="number">1</span></span><br><span class="line">        <span class="comment"># remove invalid error</span></span><br><span class="line">        error_matrix = error_matrix[error_matrix != <span class="number">0</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;akaze EPE2D error: %f pixel &#x27;</span> % np.mean(error_matrix), error_matrix.shape[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><ol><li><strong>ICP算法3D配准函数。</strong>函数输入为想要配准的source点云和target点云，两个点云均为维度<code>(n, 3)</code>的ndarray，<code>n</code>表示点的数量，<code>3</code>表示点的三维xyz坐标。函数使用两种方式实现了ICP匹配算法及结果的可视化。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">icp_registration3d</span>(<span class="params">source_point, target_point, target_point_gt=<span class="literal">None</span></span>):</span></span><br><span class="line">    source_pcd = o3d.geometry.PointCloud()</span><br><span class="line">    num_point = source_point.shape[<span class="number">0</span>]</span><br><span class="line">    idx = random.sample(<span class="built_in">range</span>(num_point), num_point)</span><br><span class="line">    source_point = source_point[idx]</span><br><span class="line">    source_pcd.points = o3d.utility.Vector3dVector(source_point)</span><br><span class="line">    source_pcd.paint_uniform_color([<span class="number">255</span>/<span class="number">255</span>, <span class="number">127</span>/<span class="number">255</span>, <span class="number">0</span>/<span class="number">255</span>])  <span class="comment"># orange</span></span><br><span class="line">    target_pcd = o3d.geometry.PointCloud()</span><br><span class="line">    target_pcd.points = o3d.utility.Vector3dVector(target_point)</span><br><span class="line">    target_pcd.paint_uniform_color([<span class="number">50</span>/<span class="number">255</span>, <span class="number">205</span>/<span class="number">255</span>, <span class="number">50</span>/<span class="number">255</span>])  <span class="comment"># green</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    threshold = 1.0  # the threshold of the moving range</span></span><br><span class="line"><span class="string">    trans_init = np.asarray([[1, 0, 0, 0],  # 4x4 identity matrix</span></span><br><span class="line"><span class="string">                             [0, 1, 0, 0],  # Initial matrix: no displacement, no rotation</span></span><br><span class="line"><span class="string">                             [0, 0, 1, 0],  </span></span><br><span class="line"><span class="string">                             [0, 0, 0, 1]])</span></span><br><span class="line"><span class="string">    reg_p2p = o3d.pipelines.registration.registration_icp(source_pcd, target_pcd, threshold, trans_init, o3d.pipelines.registration.TransformationEstimationPointToPoint())</span></span><br><span class="line"><span class="string">    source_pcd.transform(reg_p2p.transformation)</span></span><br><span class="line"><span class="string">    target_pred_pcd = source_pcd</span></span><br><span class="line"><span class="string">    target_point_pred = np.array(source_pcd.points)</span></span><br><span class="line"><span class="string">    target_pred_pcd.paint_uniform_color([67 / 255, 110 / 255, 238 / 255])  # blue</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    c0 = np.mean(source_point, axis=<span class="number">0</span>)</span><br><span class="line">    c1 = np.mean(target_point, axis=<span class="number">0</span>)</span><br><span class="line">    H = (source_point - c0).transpose() @ (target_point - c1)</span><br><span class="line">    U, S, Vt = np.linalg.svd(H)</span><br><span class="line">    R = np.dot(Vt.T, U.T)</span><br><span class="line">    t = c1 - R @ c0</span><br><span class="line">    target_point_pred = np.dot(source_point, R.transpose()) + t</span><br><span class="line">    target_pred_pcd = o3d.geometry.PointCloud()</span><br><span class="line">    target_pred_pcd.points = o3d.utility.Vector3dVector(target_point_pred)</span><br><span class="line">    target_pred_pcd.paint_uniform_color([<span class="number">67</span>/<span class="number">255</span>, <span class="number">110</span>/<span class="number">255</span>, <span class="number">238</span>/<span class="number">255</span>])  <span class="comment"># blue</span></span><br><span class="line">  </span><br><span class="line">    vis = o3d.visualization.Visualizer()</span><br><span class="line">    vis.create_window()</span><br><span class="line">    vis.add_geometry(target_pred_pcd)</span><br><span class="line">    vis.add_geometry(target_pcd)</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    # Alignment</span></span><br><span class="line"><span class="string">    align_colors = [[(10+2*i)%255/255, 80/255, 200/255] for i in range(num_point)]</span></span><br><span class="line"><span class="string">    icp_points = np.concatenate([target_point_pred, target_point], axis=0)</span></span><br><span class="line"><span class="string">    icp_lines = [[i, i + num_point] for i in range(num_point)]</span></span><br><span class="line"><span class="string">    icp_align = o3d.geometry.LineSet(</span></span><br><span class="line"><span class="string">        points=o3d.utility.Vector3dVector(icp_points),</span></span><br><span class="line"><span class="string">        lines=o3d.utility.Vector2iVector(icp_lines))</span></span><br><span class="line"><span class="string">    icp_align.colors = o3d.utility.Vector3dVector(align_colors)</span></span><br><span class="line"><span class="string">    vis.add_geometry(icp_align)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># vis.update_geometry()</span></span><br><span class="line">    vis.poll_events()</span><br><span class="line">    vis.update_renderer()</span><br><span class="line">    vis.run()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate error</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> target_point_gt:</span><br><span class="line">        point_error = np.linalg.norm(target_point_pred - target_point_gt, axis=<span class="number">1</span>, <span class="built_in">ord</span>=<span class="number">2</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;ICP EPE3D error: %f m&#x27;</span> % np.mean(point_error))</span><br></pre></td></tr></table></figure><ol><li><strong>函数调用。</strong>输入想要配准的2d图像和3d点云。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">data</span>):</span></span><br><span class="line">    source_color = data[<span class="string">&#x27;source_color&#x27;</span>]  <span class="comment"># (h, w, 3)</span></span><br><span class="line">    target_color = data[<span class="string">&#x27;target_color&#x27;</span>]  <span class="comment"># (h, w, 3)</span></span><br><span class="line">    akaze_registration2d(source_color, target_color)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># n: number of points</span></span><br><span class="line">    source_point = data[<span class="string">&#x27;source_point&#x27;</span>]         <span class="comment"># (n, 3)</span></span><br><span class="line">    target_point = data[<span class="string">&#x27;source_target_point&#x27;</span>]  <span class="comment"># (n, 3)</span></span><br><span class="line">    icp_registration3d(source_point, target_point)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Computer Vision </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Daily Book</title>
      <link href="/2023/12/17/Daily-Book/"/>
      <url>/2023/12/17/Daily-Book/</url>
      
        <content type="html"><![CDATA[<table border="1" style="border-collapse: collapse;">  <tr>        <th colspan="4">Never Stop Reading</th>  </tr>    <tr>     <th align='center'>📅Date</th>     <th align='center'>👩‍💻Book</th>     <th align='center'>🧳Tag</th>     <th>⭐Rating</th>    </tr>    <tr>      <td align='center'>2023年12月17日</td>      <td align='center'>《人类简史：从动物到上帝》</td>      <td align='center'>历史、认知</td>      <td>🌟🌟🌟🌟</td>          </tr>     <tr>      <td align='center'>2023年12月21日</td>      <td align='center'>《刘擎西方现代思想讲义》</td>      <td align='center'>哲学</td>      <td>🌟🌟🌟🌟</td>          </tr>     <tr>      <td align='center'>2023年12月24日</td>      <td align='center'>《不能承受的生命之轻》</td>      <td align='center'>哲学、文学</td>      <td>🌟🌟🌟🌟🌟</td>          </tr>     <tr>      <td align='center'>2024年1月9日</td>      <td align='center'>《穷查理宝典：查理·芒格智慧箴言录》</td>      <td align='center'>投资、哲理</td>      <td>🌟🌟🌟</td>          </tr> </table><h1 id="《人类简史》尤瓦尔·赫拉利（以色列）"><a href="#《人类简史》尤瓦尔·赫拉利（以色列）" class="headerlink" title="《人类简史》尤瓦尔·赫拉利（以色列）"></a>《人类简史》尤瓦尔·赫拉利（以色列）</h1><div align="center">  <img src="Humankind_History.png" height=85% width=85%></div><div align="center">  <img src="History.png" height=55% width=55%></div><p>◆ 在历史的路上，有三大重要革命：大约7万年前，“认知革命”（Cognitive Revolution）让历史正式启动。大约12000年前，“农业革命”（Agricultural Revolution）让历史加速发展。而到了大约不过是500年前，“科学革命”（Scientific Revolution）可以说是让历史画下句点而另创新局。这本书的内容，讲述的就是这三大革命如何改变了人类和其他生物。</p><p><strong>第一部分 认知革命</strong></p><p>◆ 所谓“想象的现实”指的是某件事人人都相信，而且只要这项共同的信念仍然存在，力量就足以影响世界。</p><p>◆ 通过文字创造出想象的现实，就能让大批互不相识的人有效合作，而且效果还不只如此。正由于大规模的人类合作是以虚构的故事作为基础，只要改变所讲的故事，就能改变人类合作的方式。只要在对的情境之下，这些故事就能迅速改变。</p><p>◆ 智人发明出了许许多多的想象现实，也因而发展出许许多多的行为模式，而这正是我们所谓“文化”的主要成分。等到文化出现，就再也无法停止改变和发展，这些无法阻挡的变化，就成了我们说的“历史”。</p><p>◆ 有些学者声称自己能够知道采集者当时的感受，但从他们的理论中能够了解的，与其说是石器时代的宗教观，还不如说是他们的偏见。</p><p>◆ 第一波的灭绝浪潮是由于采集者的扩张，接着第二波灭绝浪潮则是因为农民的扩张；这些教训，让我们得以从一个重要观点来看今日的第三波灭绝浪潮：由工业活动所造成的物种灭绝。</p><p>◆ 对全世界上所有的大型动物来说，这场人类洪水的唯一幸存者可能只剩下人类自己，还有其他登上诺亚方舟但只作为人类盘中佳肴的家禽家畜。</p><p><strong>第二部分 农业革命</strong></p><p>◆ 其实不是我们驯化了小麦，而是小麦驯化了我们。“驯化”（domesticate）一词来自拉丁文“domus”，意思就是“房子”。但现在关在房子里的可不是小麦，而是智人。</p><p>◆ 如果要衡量某种物种演化成功与否，评断标准就在于世界上其DNA螺旋的拷贝数的多寡。这很类似于货币的概念，就像今天如果要说某家公司行不行，我们看的是它的市值有多少钱，而不是它的员工开不开心；物种的演化成功，看的就是这个物种DNA拷贝数在世界上的多寡。如果世界上不再有某物种的DNA拷贝，就代表该物种已经绝种，也等于公司没有钱而宣告倒闭。而如果某个物种还有许多个体带着它的DNA拷贝存在这个世上，就代表着这个物种演化成功、欣欣向荣。从这种角度看来，1000份DNA拷贝永远都强过100份。这正是农业革命真正的本质：让更多的人却以更糟的状况活下去。</p><p>◆ 但没有人发现究竟发生了什么事。每一代人都只是继续着上一代生活的方式，在这里修一点，那里改一些。但矛盾的是，一连串为了让生活更轻松的“进步”，最后却像是在这些农民的身上加了一道又一道沉重的枷锁。“为什么人类会犯下如此致命的误判？其实人类在历史上一直不断重蹈覆辙，道理都相同：因为我们无法真正了解各种决定最后的结果。</p><p>◆ 奢侈品史上常有这样的情况，就是原本的奢侈品往往最后会成为必需品，而且带来新的义务。等到习惯某种奢侈品，就开始认为这是天经地义。接着就是一种依赖。最后，生活中就再也不能没有这种奢侈品了。</p><p>◆ 现在看来，虚构故事的力量强过任何人的想象。农业革命让人能够开创出拥挤的城市、强大的帝国，接着人类就开始幻想出关于伟大的神灵、祖国、有限公司的故事，好建立起必要的社会连接。虽然人类的基因演化仍然一如既往慢如蜗牛，但人类的想象力却是极速奔驰，建立起了地球上前所未有的大型合作网络。</p><p>◆ 演化的基础是差异，而不是平等。每个人身上带的基因码都有些许不同，而且从出生以后就接受着不同的环境影响，发展出不同的特质，导致不同的生存概率。“生而平等”其实该是“演化各有不同”。浪漫主义告诉我们，为了要尽量发挥潜力，就必须尽量累积不同的经验。必须体会不同的情感，尝试不同的关系，品尝不同的美食，还必须学会欣赏不同风格的音乐。而其中最好的一种办法，就是摆脱日常生活及工作，远离熟悉的环境，前往遥远的国度，好亲身“体验”不同的文化、气味、美食和规范。我们总会不断听到浪漫主义的神话，告诉我们“那次的经验让我眼界大开，从此整个生活都不一样了”。</p><p>◆ 身为人类，我们不可能脱离想象所建构出的秩序。每一次我们以为自己打破了监狱的高墙、迈向自由的前方，其实只是到了另一间更大的监狱，把活动范围稍稍加以扩大。</p><p>◆ 文字对人类历史所造成最重要的影响：它逐渐改变了人类思维和看待这个世界的方式。过去的自由连接、整体思考，已经转变为分割思考、官僚制度。</p><p><strong>第三部分 人类的融合统一</strong></p><p>◆ 学者认为每种文化都自成一格、和谐共存，而且都有独特的不变本质。每一群人都会有自己的世界观，和社会、法律及政治系统，而且各自运作顺畅，就像是行星绕着太阳一样。据这种观点，文化只要独立不受影响，就不会有所改变，而会依照原本的步调，朝向原本的方向持续下去。直到出现了外界力量干预，才会造成改变。但现在，多数的文化学者都认定事情正好相反。虽然每种文化都有代表性的信仰、规范和价值，但会不断流动改变。只要环境或邻近的文化改变，文化就会有所改变及因应。除此之外，文化内部也会自己形成一股改变的动力。就算是环境完全与外界隔绝，生态也十分稳定，还是无法避免改变。如果是物理学的法则，绝不会有不一致的例外情形，但既然这些是人类自己想象创造出的秩序，内部就会有各式各样的矛盾。文化一直想弭平这些矛盾，因此就会促成改变。</p><p>◆ 人类不同的想法、概念和价值观也能逼着我们思考、批评、重新评价。一切要求一致，反而让心灵呆滞。如果说每个文化都需要有些紧张、有点冲突、有无法解决的两难，才能让文化更加精彩，那么身处任何文化中的人就都必然有些互相冲突的信念以及互相格格不入的价值观。正因为这种情况实在太普遍，甚至还有个特定的名词来形容：认知失调（cognitive dissonance）。一般认为认知失调是人类心理上的一种问题，但这其实是一项重要的特性，如果人真的无法同时拥有互相抵触的信念和价值观，很可能所有的文化都将无从建立，也无以为继。</p><p>◆ 公元前的1000年间，出现了三种有可能达到全球一家概念的秩序，相信这些秩序，就有可能相信全球的人类都“在一起”，都由同一套规则管辖，让所有人类都成了“我们”（至少有这个可能），“他们”也就不复存在。这三种全球秩序，首先第一种是经济上的货币秩序，第二种是政治上的帝国秩序，而第三种则是宗教上的全球性宗教，像是佛教、基督教和伊斯兰教。</p><p>◆ 正因为有了金钱概念，财富的转换、储存和运送都变得更容易也更便宜，后来才能发展出复杂的商业网络以及蓬勃的市场经济。要是没有钱，市场和商业网络的规模、活力和复杂程度都必然相当有限。可以说金钱就是一种相互信任的系统，而且还不是随随便便的某种系统：金钱正是有史以来最普遍也最有效的互信系统。</p><p>◆ 像这样的文化多元性和疆界灵活性，不仅让帝国独树一格，更让帝国站到了历史的核心。正是这两项特征，让帝国能够在单一的政治架构下纳入多元的族群与生态区，让越来越多人类与整个地球逐渐融合为一。</p><p>◆ 文化的涵化（acculturation）与同化（assimilation）终于打破了新成员和旧精英之间的障碍。被征服者不再认为帝国是个外来占领他们的政体，而征服者也真心认为这些属民是自己帝国的一员。终于所有的“他们”都成了“我们。</p><p>◆ 我们今天常认为宗教造成的是歧视、争端、分裂。但在金钱和帝国之外，宗教正是第三种让人类统一的力量。正因为所有的社会秩序和阶级都只是想象的产物，所以它们也十分脆弱，而且社会规模越大，反而就越脆弱。而在历史上，宗教的重要性就在于让这些脆弱的架构有了超人类的合法性。有了宗教之后，就能说法律并不只是人类自己的设计和想象，而是来自一种绝对的神圣最高权柄。这样一来，至少某些基本的法则便不容动摇，从而确保社会稳定。</p><p>◆ 从历史上来看，一神论就像是个万花筒，承继了一神论、二元论、多神论和泛神论，收纳在同一个神圣论述之下。结果就是，基督徒大致上是信奉一神论的上帝，相信二元论的魔鬼，崇拜多神论的圣人，还相信泛神论的鬼魂。像这样同时有着不同甚至矛盾的思想，而又结合各种不同来源的仪式和做法，宗教学上有一个特别的名称：综摄（syncretism）。很有可能，综摄才是全球最大的单一宗教。</p><p>◆ 人遇到事情通常就会产生欲念，而欲念总是会造成不满。遇到不喜欢的事，就想躲开；遇到喜欢的事，就想维持并增加这份愉快。但正因如此，人心就永远不满、永远不安。这点在碰上不悦的时候格外明显，像是感觉疼痛的时候，只要疼痛持续，我们就一直感到不满，用尽办法想要解决。然而，就算是遇上欢乐的事，我们也从不会真正满足，而是一直担心这种欢乐终将结束或是无法再持续或增强。</p><p>◆ 根据佛教经典，释迦牟尼本人就达到了涅槃，从痛苦中完全解脱。而在这之后他就被称为“佛陀”，意为“觉悟者”。接着，佛陀一生前往各地普传佛法，希望让所有人离苦得乐。佛陀的教诲一言以蔽之：痛苦来自欲望；要从痛苦中解脱，就要放下欲望；而要放下欲望，就必须训练心智，体验事物的本质。</p><p>◆ 历史不像是物理学或经济学，目的不在于做出准确预测。我们之所以研究历史，不是为了要知道未来，而是要拓展视野，要了解现在的种种绝非“自然”，也并非无可避免。未来的可能性远超过我们的想象。</p><p><strong>第四部分 科学革命</strong></p><p>◆ 如果要在过去500年间挑出一个最重大、具代表性的一刻，一定就是1945年7月16日上午5点29分45秒。就在这一秒，美国科学家在新墨西哥的阿拉莫戈多引爆了第一颗原子弹。从这时开始，人类不仅有了改变历史进程的能力，更有了结束历史进程的能力。</p><p>◆ 科学革命并不是“知识的革命”，而是“无知的革命”。真正让科学革命起步的伟大发现，就是发现“人类对于最重要的问题其实毫无所知”。</p><p>◆ 现代科学和现代帝国背后的动力都是一种不满足，觉得在远方一定还有什么重要的事物，等着他们去探索、去掌握。然而，科学和帝国之间的连接还不仅如此而已。两者不只动机相同，连做法也十分类似。对现代欧洲人来说，建立帝国就像是一项科学实验，而要建立某个科学学科，也就像是一项建国大计。</p><p>◆ 真正让银行（以及整个经济）得以存活甚至大发利市的，其实是我们对未来的信任。“信任”就是世上绝大多数金钱的唯一后盾。</p><p>◆ 资本主义之名正是由此而来。所谓的“资本主义”（Capitalism），认为“资本”（capital）与“财富”（wealth）有所不同。资本指的是投入生产的各种金钱、物品和资源。而财富指的则是那些埋在地下或是浪费在非生产性活动的金钱、物品和资源。</p><p>◆ 这是自由市场资本主义美中不足之处。它无法保证利润会以公平的方式取得或是以公平的方式分配。而且相反的是，因为人类有追求利润和经济成长的渴望，就会决定盲目扫除一切可能的阻挠。等到“成长”成了无上的目标、不受其他道德伦理考虑的制衡，就很容易衍生成一场灾难。</p><p>◆ 工业革命的核心，其实就是能源转换的革命。我们已经一再看到，我们能使用的能源其实无穷无尽。讲得更精确，唯一的限制只在于我们的无知。每隔几十年，我们就能找到新的能源来源，所以人类能用的能源总量其实在不断增加。</p><p>◆ 甚至是我们现在如此看重的“自由”，也可能是让我们不那么快乐的原因。虽然我们可以自己选择另一半、选择朋友、选择邻居，但他们也可以选择离开我们。现代社会每个人都拥有了前所未有的自由，能够决定自己要走哪条路，但也让我们越来越难真正信守承诺、不离不弃。于是，社群和家庭的凝聚力下降而解体，这个世界让我们感到越来越孤独。</p><p>◆ 佛教认为，快乐既不是主观感受到愉悦，也不是主观觉得生命有意义，反而是在于放下追求主观感受这件事。如果我们太看重这些内部的波动，就会变得太过执迷，心灵也就焦躁不安、感到不满。每次碰上不快，就感觉受苦。而且就算已经得到快感，因为我们还希望快感能够增强或是害怕快感将会减弱，所以心里还是不能感到满足。追求这些主观感受十分耗费心神，而且终是徒劳，只是让我们受制于追求本身。因此，苦的根源既不在于感到悲伤或疼痛，也不在于感觉一切没有意义。苦真正的根源就在于“追求”主观感受这件事，不管追求的是什么，都会让人陷入持续的紧张、困惑和不满之中。</p><h1 id="《刘擎西方现代思想讲义》刘擎"><a href="#《刘擎西方现代思想讲义》刘擎" class="headerlink" title="《刘擎西方现代思想讲义》刘擎"></a>《刘擎西方现代思想讲义》刘擎</h1><div align="center">  <img src="Modern_Western_Thought.png" height=40% width=40%></div><p><strong>导论</strong></p><p>◆ 个人主观价值绝对提升，自然秩序被打破，理性秩序建立，这些都是古今之变的一部分。简单地说，古今之变，就是自然变成了不自然。这并不是说客观世界从自然变成了不自然，而是说我们看待世界的方式改变了。古代人相信有一个外在于人的自然秩序，这个秩序有它自身的目的和意义。但现在我们不再相信有什么上天注定的意义，我们相信意义是由人赋予的。</p><p><strong>第一章 现代思想的成年</strong></p><p>◆ 到了怎么样的境界可以称为真正的成年？我认为大概有两个标志：第一是明白自己，对自己的过往有真正的理解；第二是反思自己，能看透自己存在的问题。一个人成年的决定性标志就是开始自觉的自我反思：你不只是在过自己的生活，而且能够有意识地反观自省你的生活。这有些像是孔子说的“四十不惑”。</p><p>◆ <strong>德国 马克斯•韦伯 1864-1920</strong>。韦伯发现，工业革命、科学革命、地理大发现，这些大事件背后有一个统一的思想动力，就是“理性主义”。当时人们有一种普遍的看法，认为过去的不幸都是由于蒙昧和无知，如果用理性清除掉蒙昧和无知，我们就会走向真理，越来越幸福。<br>◆ 韦伯对现代性的四个重要论断：第一个是“世界的祛魅”，第二个是“诸神之争”，第三个是“工具理性的扩张”，最后一个则是“现代的铁笼”。<br>◆ 破除悲观，获得清明，达到从容一这才是韦伯思想带给我们的真正启示。罗曼•罗兰说过一句话：“世界上只有一种英雄主义，那就是在看清生活的真相之后，依然热爱生活。”我们现在做的，就是“看清生活的真相”。</p><p><strong>第二章 现代人的精神危机</strong></p><p>◆ 我们会不断追问生命的意义，这种追问会遇到死亡和贪欲这两大难题。应对这种挑战，我们需要确立可靠的人生信仰。在酉方的传统社会，人们主要是依靠信奉宗教来应对。但经过了启蒙理性主义的洗礼，接受宗教信仰不再是理所当然的默认选项。现代人倾向于依靠理性来求证和确认信仰的可靠性，这样接受信仰才不是盲从。但是，信仰与理性之间存在着鸿沟，这靠理性论证本身难以弥合，确立信仰在现代世界因此变得非常困难。</p><p>◆ <strong>德国 弗里德里希·威廉·尼采 1844-1900</strong>。到底什么是虚假的思想呢？尼采给出的答案是四个字，“形而上学”。你也许知道，形而上学是西方哲学最早的一个术语。“形而上”，顾名思义，就是“在实体之上”。尼采概括说，形而上学有三大信念：第一，相信在感知的表象世界背后有一个更真实的本质世界；第二，相信这个混乱的世界实际上是有目的的；第三，相信这个纷乱多样的世界背后有一种统一性。<br>◆ 面对无意义的世界和无意义的生命，人应该立足于现实，直面无意义的荒谬，以强大的生命本能舞蹈，在生命活动中创造出价值。用尼采的话说，就是“成为你自己”。这样一来，虚无不再会让你沮丧和绝望，反倒会给你最广阔的创造自我意义的空间，虚无让人变成了积极的创造者，这就是积极的虚无主义。<br>◆ 我们越是运用更多的眼睛、不同的眼睛去观察同一个东西，我们对这个东西的“概念”就越“完整”。我们也能越“客观”。也就是说，视角主义教给我们的，不是分裂的必然，而是谦逊的必要。一个人的视角并不是天生固定的，而是在自身经历中形成的。改变自己的视角绝非易事，但这仍然是有可能的，它取决于我们的选择。我们应该做的是，试着去改变自己的视角，超越自己的视角去理解他人，寻找让不同视角互相理解、融合出共同视角的可能性。<br>◆ 在这个意义上，我们一面铭记苏格拉底的教诲，“未经反省的人生是不值得过的”（The unexamined life is not worth living），另一面也不要陷入“过度省察的人生”（over-examined life）。人生不是一个先要制定完美蓝图，再去施工的工程项目，人生也不是一场先要确定剧本，再去表演的电影。我自己20岁左右的时候有一个“执念”，觉得对于生命的终极目标，必须先有一个正确可靠的答案，才能开始真正的生活，否则就是虚度生命。其实不然，我们的人生都是“边想边做”的，而且想和做是分不开的。</p><p>◆ <strong>奥地利 西格蒙德·弗洛伊德 1856-1939</strong>。人生意义的两大难题就是面对死亡和欲望。如何超越欲望的卑微，走向人性的崇高，这是现代精神危机中的一个重要问题。而弗洛伊德的影响不是解决了这个问题，而是取消了这个问题：如果我们接受了欲望的正当性，欲望本身不再是卑微可耻的，也就用不着去“超越欲望”了。</p><p>◆ <strong>法国 让一保罗•萨特 1905-1980</strong>。作为人，我们永远无法填满自己的虚无。用萨特的哲学术语来说，就是我们的“存在结构会溢出（我们）所占有的对象”。没有得到的时候当然不满足，得到之后又会产生新的不满足。作家王尔德有句名言，“生活中只有两种悲剧：一个是没有得到我们想要的，另外一个是得到了我们想要的”。<br>◆ 人永远不会“是”什么，而是永远都正在“成为”什么。在这个意义上，人是自由的，甚至人就是自由本身。还是那个比喻，站到舞台上，你可以扮演任何角色，每一个角色都不是你本人，但正因为如此，你的行动才是自由，因为你没有被任何一个角色所定义。<br>◆ 萨特两个著名的观点：第一，自由选择是很沉重的负担；第二，“他人就是地狱”。</p><p><strong>第三章 20世纪的教训</strong></p><p>◆ 资源匮乏与人性自利这两个假设，是社会现实状况的反映，这也意味着公共秩序无法自然形成，需要某种具有强制性的政治权威建立和维护。公共秩序首先要求一套公共的规则，经常体现为习俗或者法律；其次要求落实规则的执行力，而无论是规则的建立还是实施，都需要政治权威来执行。</p><p>◆ 20世纪的危机不是历史的偶然产物，而是内在于现代化思想之中。德国的纳粹主义、苏联式的社会主义和英美的资本主义，是三种不同的现代性规划，它们都有各自的危机或困境，但都与现代理性主义的社会构想密切相关。</p><p>◆ <strong>英国 齐格蒙特•鲍曼 1925-2017</strong>。从实践到理念，再到历史中的疑点，在鲍曼完整而清晰的分析中，我们看到，大屠杀不是历史上野蛮状态的重现，也不是一场偶然的悲剧。大屠杀的许多关键要素都内在地蕴藏于现代理性之中。这场灾难，是现代理性如何变得与道德和人性完全背道而驰的一个历史力证。</p><p>◆ <strong>德国 汉娜·阿伦特 1906-1975</strong>。过去对道德有一套传统的认识，康德有一句名言，“人是目的，而不仅仅是手段”。如果你把他人仅仅当作自己实现利益的手段，那就践踏了人的尊严，是不道德的。<br>◆ “极端之恶”和“平庸之恶”，其实是一体两面。纳粹大屠杀是一种极端的恶，但这种极端的恶，是经由一些“平庸”的罪犯犯下的。这些罪犯身上的这种“恶的平庸性”，其实质是不去思考，是丧失了思考能力。<br>◆ 道德的真正含义不是循规蹈矩，而是做出自己独立的是非对错的判断。独立判断究竟要怎么做？阿伦特曾经说，“就各种特殊情况做出判断而言，没有什么恒常的通行标准，也不存在什么确定无疑的规则”。我们只能在具体的处境中，冒着风险，真诚地去做出自己独立的判断，并为此承担责任。这是现代社会的公民格外艰巨的道德任务。</p><p>◆ <strong>奥地利 卡尔·波普尔 1902-1994</strong>。波普尔最著名的“证伪主义”理论可以概括为一句话：科学理论的标志不是它能够被证明是对的，而是它可以被证明为错的。波普尔就这样改变了我们对科学的理解。科学理论不是真理的代名词，只是一些尚未被证伪的假设。。所以在波普尔看来，一方面，我们并不能找到历史发展的绝对规律，另一方面，人类知识的增长本身也会改变历史的进程。历史决定论在根本上就是无法成立的。</p><p>◆ <strong>英国 弗里德里希•哈耶克 1899-1992</strong>。在哈耶克看来，理性有两个作用。第一就是追求知识。但是，理性并不能穷尽所有的知识。有句名言说，你知道的越多，你不知道的也就越多。想用理性去穷尽知识，这就是理性的自负，是一种幻想。所以，理性有第二个作用，就是认识到理性知识本身的局限性，对此保持审慎和怀疑。<br>◆ 康德曾经说，人类的不成熟状态就是不敢公开大胆地运用理性。哈耶克则进一步揭示出，如果妄想用理性彻底征服无知，消除所有的不确定性，这是人类的另一种不成熟。事实上，人类真正的成熟，是在勇敢运用理性的同时，直面自己永远不可能完全摆脱的无知，勇敢地与不确定性共存。</p><p>◆ <strong>英国 以赛亚•伯林 1909-1997</strong>。强调价值冲突无法根除，这是伯林价值多元论的重要特征。伯林有一段话说得触目惊心：我们要在同等终极的目的、同等绝对的要求之间做出选择，且某些目的之实现必然无可避免地导致其它目的之牺牲，所以，（我们）需要选择，需要为了一些终极价值牺牲另一些终极价值，这就是人类困境的永久特征。<br>◆ 自由实际上有两种，一种是消极自由，就是不受到外部的干涉和阻碍；另一种则是积极自由，就是可以用理性来掌控、实现自己的目标。消极自由是摆脱障碍的自由，但伯林对“障碍”做了四项限定：外部性限定；人为性限定；机会限定；重要性限定。</p><p>◆ <strong>德裔美籍 赫伯特•马尔库塞 1898-1979</strong>。马尔库塞曾说，像美国这样的发达工业社会是一种“新型的极权主义”，它不是用恐怖的手段来控制大众，而是用无尽的消费和享受来贿赂大众，让人们陷入“舒舒服服的不自由”之中，难以察觉社会对自己的控制，也就无从反抗。在这种新的控制模式中，违背或超越主流的另类观念、愿望和目标，只有两种命运：要么被排斥消灭掉；要么就是按照主流世界的原则被转化，转化为现存体制能接受的方式继续存活。</p><p><strong>第四章 自由主义及其批判者</strong></p><p>◆ <strong>美国 约翰•罗尔斯 1921-2002</strong>。罗尔斯通过无知之幕的思想实验，推理论证了一个正义的社会契约中最关键的两条原则。第一条原则是要保障平等的基本自由，第二条原则是，社会经济的不平等分配，必须满足两个限定条件，一个是“公平的机会平等”，一个是要满足差异原则。</p><p>◆ <strong>美国 罗伯特·诺齐克 1938-2002</strong>。罗尔斯的理论是一种“模式正义”理论，就是社会经济的分配必须满足某种结构模式。诺齐克反对任何“模式正义”理论。他认为，只要你允许人们的自由交易，那么任何既定的结构模式都无法维系，必须通过强制的再分配才能回到既定的模式。在他看来，“模式正义”在道德上是不可接受的，因为这样做就是把一部分人当作了其他人福祉的工具，违背了康德“人是目的，而不只是手段”的道德理想。</p><p>◆ <strong>美国 罗纳德·德沃金 1931-2013</strong>。在德沃金看来，一个社会如果实现了“平等的尊重与关怀”，那么社会对个人的奖赏或惩罚，就应该是针对个人的选择，或者说个人的“志向”，而不是针对那些个人无法选择的天赋因素。换句话说，我们应该敏感地回应个人的志向，也应当尽可能排除天赋因素，也就是“迟钝地”对待个人禀赋造成。这个观点有一个很典雅的中文翻译，叫作“敏于志向，钝于禀赋”。</p><p>◆ <strong>美国 迈克尔·桑德尔 1953</strong>。这就是“作为社群成员的义务”，它的道德约束性源于社群主义的道德认知：你生而带有一种历史，你的生活故事是更为宏大的社会故事的一部分，也蕴含于无数他人的故事之中，包括历史上你的前辈的故事。隔断了这种联系，就割裂了你的存在。正因如此，人们应当为自己（哪怕未曾谋面的）祖辈的行为担负责任。</p><p>◆ <strong>美国 迈克尔·沃尔泽 1935</strong>。自由主义的理论真实反映了现实，所谓“孤立的自我”确实存在。他们并不是脱离社会的存在，而恰恰是被现在这个社会所塑造的结果。也就是说，个人确实是被社会塑造的，社群主义的这个观点没有错。但它的错误在于，没有看到现代社会已经改变了，正是这种新型的社会造就了“孤立的个体”。现代社会的转变，一个突出的特点就是高度的“流动性”，总是在不停地移动和变化。</p><p>◆ <strong>加拿大 查尔斯·泰勒 1931</strong>。泰勒的研究发现，西方在道德思考的历史中发展出了一种“内在化”的要求：道德不只是迫于外界压力去做正确的事情，而是要和自己内心的良知相契合。比如，奥古斯丁就说过，“通向上帝的道路经由我们的内心”。卢梭把这种与自己内心的接触感，表达为我们的“存在之感受”。再到后来，本真性成为伦理世界的重心，是我们作为真正的、完整的人不可缺少的要素。本真性的理想，一方面让我们忠实于自己的内心感受，一方面要求我们不要陷入唯我论的独白，积极地介入对话和反思，这是自我通向共同背景的通道，把我们和一个更开阔的世界联系在一起。最终，向对话和反思开放，让自我变得更加清醒、更加丰富，才能更好地“成为你自己”。</p><p>◆ <strong>德国 尤尔根·哈贝马斯 1929</strong>。韦伯非常担忧工具理性的无限扩张，哈贝马斯也格外重视这个问题。他认为如果“生活世界”的规范原则仅仅屈从于工具理性，那就是“系统对生活世界的殖民”。而交往理性为我们的生活世界确立了理性规范的原则基础，以此能够抵御“系统的殖民”。这关乎我们的自由、尊严、爱和正义。</p><p><strong>尾声 后冷战时代的争论</strong></p><p>◆ <strong>日裔美籍 弗朗西斯·福山 1952</strong>。福山相信，这种斗争比阶级斗争更加根本。只要人类获得了承认不是相互对等的，历史就有矛盾冲突，也就有了发展的动力。直到有一天，普遍而平等的相互承认来临了，发展的动力就被耗尽了，历史的火车头也就停下来了。对福山来说，自由民主制在原则上已经实现了这种平等的相互承认，所以他宣告“历史终结了”。</p><p>◆ <strong>美国 萨缪尔·亨廷顿 1927-2008</strong>。亨廷顿是一个政治现实主义者，他认为文明差异不可消除，冲突不可根除，只能管控；世界秩序只能建立在多种文明共存的基础之上。</p><p>◆ 人类因为理性而伟大，因为知道理性的局限而成熟。</p><h1 id="《不能承受的生命之轻》米兰·昆德拉（捷克）"><a href="#《不能承受的生命之轻》米兰·昆德拉（捷克）" class="headerlink" title="《不能承受的生命之轻》米兰·昆德拉（捷克）"></a>《不能承受的生命之轻》米兰·昆德拉（捷克）</h1><div align="center">  <img src="Life_Light.jpg" height=40% width=40%></div><p><strong>第一章 轻与重</strong></p><p>◆ 人永远都无法知道自己该要什么，因为人只能活一次，既不能拿它跟前世相比，也不能在来生加以修正。没有任何方法可以检验哪种抉择是好的，因为不存在任何比较。一切都是马上经历，仅此一次，不能准备。好像一个演员没有排练就上了舞台。如果生命的初次排练就已经是生命本身，那么生命到底会有什么价值？正因为这样，生命才总是像一张草图。但“草图”这个词还不确切，因为一张草图是某件事物的雏形，比如一幅画的草稿，而我们生命的草图却不是任何东西的草稿，它是一张成不了画的草图。托马斯自言自语：einmal ist keinmal，这是一个德国谚语，是说一次不算数，一次就是从来没有。只能活一次，就和根本没有活过一样。</p><p>◆ 跟一个女人做爱和跟一个女人睡觉，是两种截然不同，甚至几乎对立的感情。爱情并不是通过做爱的欲望（这可以是对无数女人的欲求）体现的，而是通过和她共眠的欲望（这只能是对一个女人的欲求）而体现出来的。</p><p>◆ 星期六和星期日，他感觉到温馨的生命之轻从未来的深处向他飘来。星期一，他却感到从未曾有过的沉重。重得连俄国人的千万吨坦克也微不足道。没有比同情心更重的了。哪怕我们自身的痛苦，也比不上同别人一起感受的痛苦沉重。为了别人，站在别人的立场上，痛苦会随着想象而加剧，在千百次的回荡反射中越来越深重。</p><p>◆ 我们都觉得，我们生命中的爱情若没有分量、无足轻重，那简直不可思议；我们总是想象我们的爱情是它应该存在的那种，没有了爱情，我们的生命将不再是我们应有的生命。我们都坚信，满腹忧郁、留着吓人的长发的贝多芬本人，是在为我们伟大的爱情演奏《Es muss sein！》（非如此不可）。</p><p><strong>第二章 灵与肉</strong></p><p>◆ 人生如同谱写乐章。人在美感的引导下，把偶然的事件（贝多芬的一首乐曲、车站的一次死亡）变成一个主题，然后记录在生命的乐章中。犹如作曲家谱写奏鸣曲的主旋律，人生的主题也在反复出现、重演、修正、延展。安娜可以用任何一种别的方式结束生命，但是车站、死亡这个难忘的主题和爱情的萌生结合在一起，在她绝望的一刹那，以凄凉之美诱惑着她。人就是根据美的法则在谱写生命乐章，直至深深的绝望时刻的到来，然而自己却一无所知。因此我们不能指责小说，说被这些神秘的偶然巧合所迷惑（例如，沃伦斯基、安娜、站台和死亡的巧合，贝多芬、托马斯、特蕾莎和白兰地的巧合），但我们有理由责备人类因为对这些偶然巧合视而不见而剥夺了生命的美丽。</p><p>◆ 一个不断要求“出人头地”的人，应该料到总有一天会感到发晕。发晕是怎么回事？是害怕摔下去？但是，站在有结实的护栏的平台，我们怎么还发晕呢？发晕，并非害怕摔下来，而是另一回事。是我们身下那片空虚里发出的声音，它在引诱我们，迷惑我们；是往下跳的渴望，我们往往为之而后怕，拼命去抗拒这种渴望。</p><p>◆ 我可以说眩晕是沉醉于自身的软弱之中。意识到自己的软弱，却并不去抗争，反而自暴自弃。人一旦迷醉于自身的软弱，便会一味软弱下去，会在众人的目光下倒在街头，倒在地上，倒在比地面更低的地方。</p><p><strong>第三章 不解之词</strong></p><p>◆ 假若人还年轻，他们的生命乐章不过刚刚开始，那他们可以一同创作旋律，交换动机（像托马斯和萨比娜便交换产生了圆顶礼帽这一动机），但是，当他们在比较成熟的年纪相遇，各自的生命乐章已经差不多完成，那么，在每个人的乐曲中，每个词，每件物所指的意思便各不相同。</p><p>◆ 身为女人，并不是萨比娜选择的生存境界。既然不是选择的结果，便算不上功绩也算不上失败。面对一种强加给我们的状态，萨比娜想，就必须找到一种相适应的态度。在她看来，对生来是女人这一事实进行反抗，与以之为荣耀一样，是荒唐的。</p><p>◆ 背叛。打从孩提时代起，爸爸和小学老师就反复向我们灌输，说这是世上可以想得到的最可恨的事。可到底什么是背叛？背叛，就是脱离自己的位置。背叛，就是摆脱原位，投向未知。萨比娜觉得再没有比投身未知更美妙的了。</p><p>◆ 非刻意的美。是的。还可以说是错误的美。美从世界上彻底消失之前，还会存在片刻，却是因错而生。错误的美，是美的历史末期。</p><p>◆ 在富裕的社会里，人们用不着去干体力活，从事的都是脑力活动。大学越来越多，学生也越来越多。为了获取文凭，他们得找到论文题目。题目是无限的，因为一切都可以论述。档案馆里堆的那一捆捆发黑的论文，比墓地还要凄惨，即便到了万灵节，也不会有人去看一眼。文化就在大批的制造、言语的泛滥、数量的失控中逐渐消亡。相信我，在你原来的国家的一部禁书，就远远胜过在我们的大学里随口乱喷的亿万言。</p><p>◆ 她的悲剧不是因为重，而是在于轻。压倒她的不是重，而是不能承受的生命之轻。萨比娜感觉自己周围一片虚空。这虚空是否就是一切背叛的终极？直至此时，她显然仍未明了，这也是可以理解的：追求的终极永远是朦胧的。期盼嫁人的年轻女子期盼的是她完全不了解的东西。追逐荣誉的年轻人根本不识荣誉为何物。赋予我们的行为以意义的，我们往往对其全然不知。萨比娜也不清楚隐藏在自己叛逆的欲望背后的究竟是什么目的。不能承受的生命之轻，目的就是这个吗？</p><p><strong>第四章 灵与肉</strong></p><p>◆ 这只能说明一点：世界在变成一个集中营。特蕾莎几乎从童年时代起就开始用这个词来表达她对自己的家庭生活的看法。集中营，就是日日夜夜，人们永远挤着压着在一起生活的一个世界。残酷和暴力只不过是其次要特征（而且绝非必然）。集中营，是对私生活的彻底剥夺。普罗恰兹卡虽在自己家里与朋友喝酒聊天，但却无处躲避，他是活在集中营里（他居然不知道，这是他致命的错误！）。特蕾莎以前和母亲住在一起，也是活在集中营里。从那以后，她明白了集中营绝无特别之处，没有什么值得让人惊讶的，而是某种命定的、根本性的东西，来到世上，就是来到它的中间，不拼尽全力，就不可能从中逃出去。</p><p>◆ 特蕾莎从童年时代起脑子里就总在琢磨这些问题。因为真正严肃的问题，是孩子能提出来的问题。只有最天真的问题才真正是严肃的问题。这些问题都是没有答案的。没有答案的问题是一道令你无路可走的障碍。换言之，正是这些没有答案的问题标志着人类可能性的局限，划出我们存在的疆界。</p><p>◆ 特蕾莎知道，爱情诞生的时刻就像这样：女人无法抗拒呼唤她受了惊吓的灵魂的声音，男人无法抗拒灵魂专注于他声音的女人。在爱情的陷阱面前，托马斯从来不是安全的，特蕾莎只能每时每刻为他担惊受怕。</p><p>◆ 要逃避痛苦，最常见的，就是躲进未来。在时间的轨道上，人们想象有一条线，超脱了这条线，当前的痛苦便不复存在。但是特蕾莎看不到她面前的这条线。惟有回顾过去，才能带给她一丝安慰。</p><p>◆ 她出了门，朝河堤走去。她想看看伏尔塔瓦河。她想站在河岸上，久久地望着河水，因为看着流动的河水，可以让人心静，可以消除人的痛苦。河水一个世纪一个世纪在不断流淌，人间的故事就在河边发生。它们发生，第二天就被遗忘，而河水依旧在不停地流淌。她重又凝望着河水。她感到无尽的悲哀。她明白她所看到的，是永别。永别生活，生活正带着所有的色彩逝去。</p><p><strong>第五章 轻与重</strong></p><p>◆ 做的是自己完全不在乎的事，真美。从事的不是内心的“es muss sein”逼着去做的职业，一下班，就可把工作丢在脑后，托马斯终于体会到了这些人的幸福（而从前他总是对他们心存怜悯）。在这之前，他还从来没有感受过不在乎带来的快乐。以往每当手术没有如他所愿，出了问题，他就会绝望，会睡不着觉，甚至对女人都提不起兴致。职业的“es muss sein”就像吸血鬼一样吸他的血。</p><p>◆ “我”的独特性恰恰隐藏在人类无法想象的那一部分。我们能够想象的，仅仅是众人身上一致、相同之处。个别的“我”，区别于普遍，因此预先猜不出，估不了，需要在他者身上揭示它，发掘它，征服它。</p><p>◆ 看来，大脑中有一个专门的区域，我们可称之为诗化记忆，它记录的，是让我们陶醉，令我们感动，赋予我们的生活以美丽的一切。我已经说过，隐喻是危险的。爱由隐喻而起。换言之：爱开始于一个女人以某句话印在我们诗化记忆中的那一刻。</p><p>◆ 人只能活一回，我们无法验证决定的对错，因为，在任何情况下，我们只能做一个决定。上天不会赋予我们第二次、第三次、第四次生命以供比较不同的决定。历史如同个人生命。捷克人仅有一部历史，它和托马斯的生命一样，将终结于某一天，无法上演第二回。假如捷克历史可以重演，每一回都尝试另一种可能性，比较不同的结果，这肯定是有益的。缺了这样的经验，所有的推测都只是假设的游戏。Einmal ist keinmal.一次不算数。一次就是从来没有。波希米亚的历史不会重演，欧洲的历史也不会重演。波希米亚和欧洲的历史是两张草图，出自命中注定无法拥有生死经验的人类之笔。历史和个人生命一样轻，不能承受地轻，轻若鸿毛，轻若飞扬的尘埃，轻若明日即将消失的东西。</p><p><strong>第六章 伟大的进军</strong></p><p>◆ 如果打入地狱与享有特权是惟一且同一的，如果高贵和粗俗之间没有丝毫区分，如果上帝之子可以因粪便而遭人指责，那么人类存在就会失去其整个维度，成为不能承受之轻。于是，斯大林之子扑向带电的铁丝网，好像把自己的身体扔到天平上，被失去维度的世界的无限之轻所举起，可怜巴巴地向上飘去。</p><p>◆ 媚俗的根源就是对生命的绝对认同。媚俗是把人类生存中根本不予接受的一切都排除在视野之外。媚俗是掩盖死亡的一道屏风。在被遗忘以前，我们会变为媚俗。媚俗，是存在与遗忘之间的中转站。</p><p>◆ 在极权的媚俗之王国，总是先有答案并排除一切新问题。所以极权的媚俗的真正对手就是爱发问的人。问题就像裁开装饰画布的刀让人看到隐藏其后的东西。萨比娜就是这样向特蕾莎解释那些油画的意义的：前面是明明白白的谎言，后面则隐现出让人无法理解的真相。</p><p>◆ 在媚俗被当作谎言的情况下，媚俗必定处于非媚俗的境地。媚俗一旦失去其专横的权力，它就像人类的任何一个弱点一样令人心动。因为我们中没有一个是超人，不可能完全摆脱媚俗。不管我们心中对它如何蔑视，媚俗总是人类境况的组成部分。</p><p>◆ 弗兰茨喜欢陶醉其中的伟大进军之思想，便是把各个时代、各种倾向的左的人们团结在一起的政治媚俗。伟大进军，尽管障碍重重，但它是一种壮观的前行，是通向博爱、平等、正义、幸福乃至更远的征程，因为只有征途上多险阻，进军才能堪称伟大的进军。</p><p>◆ 我想起了那位在布拉格组织签名请愿运动、要求赦免政治犯的记者。他很清楚这种请愿运动帮不了犯人，其真正的目的不是为了真的就能释放那些犯人，而是为了明白仍然有人无所畏惧。他所做的也近乎是在演戏，但他没有别的可能。在行动和演戏之间，他别无选择。他惟有一种选择：要么演戏，要么什么也不干。在某些情况下，人注定要演戏。他们与沉默势力的抗争（反对河对岸的沉默势力，反对变成无声的窃听器藏在墙中的警察），是一个剧团向一支军队发起的战斗。</p><p>◆ 我们全都需要有人注视我们。根据我们生活所追求的不同的目光类型，可以将我们分成四类。第一类追求那种被无数不知名的人注视的目光，换句话说，就是公众的目光。第二类是那种离开了众多双熟悉的眼睛注视的目光就活不下去的人。那些不知疲倦地在组织鸡尾酒会和宴会的，就属此类。他们比第一类人更快活，因为第一类人若失去了公众，就会想象着自己生命殿堂的灯火全都熄灭了，而这种事在每个人身上迟早都会发生的。而第二类人却相反，他们最终总是能得到某种目光。接下来是第三类，这类人必须活在所爱之人的目光下，他们的境况与第一类人同样危险。一旦所爱的人闭上眼睛，其生命殿堂也将陷入黑暗之中。最后是第四类，也是最少见的一类，他们生活在纯属想象、不在身边的人的目光下。这类人是梦想家。</p><p>◆ 惩罚一个不知道自己做了什么的人，是野蛮的行径。</p><p><strong>第七章 卡列宁的微笑</strong></p><p>◆ 也许正是谁也不愿在农村呆下去，国家才丧失了对农村的管制权。当农民不再是土地的主人，而只是一名被雇来种地的职工时，他就不再依恋这片家园和自己所从事的工作，他一无所有，因而也不惧怕会失去什么。这种漠然的态度倒使得农村保持了相当大的自主权和自由的空间。</p><p>◆ 幸好，我们同他人的关系在何种程度上取决于我们的感情，即我们的爱还是不爱，是善待还是仇视，而且，它们在何种程度预先受个人实力对比的制约，这是永远都无法下确切定义的。人类真正的善心，只对那些不具备任何力量的人才能自由而纯粹地体现出来。人类真正的道德测试（是最为彻底的测试，但它处于极深的层次，往往不为我们注意），是看他与那些受其支配的东西如动物之间的关系如何。人类根本的失败，就是这方面造成的，其为“根本”，是因为其他的一切失误均由此而产生。</p><p>◆ 这是些探讨爱情、度量其深度、对其进行种种猜测和研究的问题，也许正是它们将爱情扼杀了。如果我们没有能力爱，也许正是因为我们总渴望得到别人的爱，也就是说我们总希望从别人那儿得到什么（爱），而不是无条件地投入其怀中并且只要他这个人的存在。</p><p>◆ 人类之时间不是循环转动的，而是直线前进。这就是为什么人类不可能幸福的缘故，因为幸福是对重复的渴望。</p><p>◆ 恐惧是一种撞击，是彻底失去理智的一瞬间。恐惧没有一丝美的痕迹。看见的，只是所期待的未知事件的一束强光。忧虑则相反，它意味着我们是有所知的。托马斯和特蕾莎知道等待他们的是什么。恐惧之强光被蒙上了，于是我们发现世界沐浴在淡蓝色的、温柔的光线中，使从前最丑陋的事物变得再也美丽不过。</p><p>◆ “使命？特蕾莎，那是无关紧要的事。我没有使命。任何人都没有使命。当你发现自己是自由的，没有任何使命时，便是一种极大的解脱。</p><h1 id="《穷查理宝典：查理·芒格智慧箴言录》彼得·考夫曼-美"><a href="#《穷查理宝典：查理·芒格智慧箴言录》彼得·考夫曼-美" class="headerlink" title="《穷查理宝典：查理·芒格智慧箴言录》彼得·考夫曼(美)"></a>《穷查理宝典：查理·芒格智慧箴言录》彼得·考夫曼(美)</h1><blockquote><p>非功利性读书《穷查理宝典》 个人推荐指数：★★★☆☆</p><p>我并不热衷于投资之道，也无需以此积累财富，但在朋友的诚挚推荐下，期然翻开《穷查理宝典》。然而我并没有感受到预期的启发，此刻反思，或许是因为这本书和我的现状不契合。<br>全书浩瀚篇章，但是2/3都是对芒格人格魅力和投资哲学的赞美，冗余的叙述结构，错落无序的编排，让我无法专注。即便如此，书中芒格所极力推崇的被视为老生常谈的普世智慧——强烈的好奇心、持续学习进步、专注、逆向思维、多元学科学习…——它们历经时间洗礼，仍不失其独特的启示。<br>当然，也可能是我没看进去，或许这正是挑战我既有认知边界的书。接受广泛的意见与批评和多元的态度和观点。</p></blockquote><p><strong>第九章 第一章 查理·芒格传略</strong></p><p>◆ 最接近把一个人的生活重新过一遍的事情是回忆那种生活，并用文字记录下来，让这种回忆尽可能地长久。</p><p>◆ 和‘已逝的伟人’交朋友，这听起来很好玩，但如果你确实在生活中与那些有杰出思想的已逝的伟人成为朋友，那么我认为你会过上更好的生活，得到更好的教育。这种方法比简单地给出一些基本概念好得多。</p><p><strong>第一十章 歌颂长者： 芒格论晚年</strong></p><p>◆ 《论老年》最著名的段落当属下面这段了不起的总结：“晚年的最佳保护铠甲是一段在它之前被悉心度过的生活，一段被用于追求有益的知识、光荣的功绩和高尚的举止的生活；过着这种生活的人从青年时代就致力于提升他自己，而且将会在晚年收获它们产生的最幸福的果实；这不仅是因为有益的知识、光荣的功绩和高尚的举止将会陪伴他终生，甚至直到他生命的最后一刻，也会因为见证了正直的人生的良心和对过往美好功绩的回忆将会给灵魂带来无上的安慰。”</p><p><strong>第一十一章 忆念： 晚辈谈芒格</strong></p><p>◆ 我们的经验往往会验证一个长久以来的观念：只要做好准备，在人生穷查理宝典中抓住几个机会，迅速地采取适当的行动，去做简单而合乎逻辑的事情，这辈子的财富就会得到极大的增长。上面提到的这种机会很少，它们通常会落在不断地寻找和等待、充满求知欲望而又热衷于对各种不同的可能性作出分析的人头上。这样的机会来临之后，如果获胜的几率极高，那么动用过去的谨慎和耐心得来的资源，重重地压下赌注就可以了。</p><p><strong>第一十三章 第三章 芒格主义：查理的即席谈话</strong></p><p>◆ “当今一切都能够通过科学得到解释，除了艺术。你可以登上月球，或者可以在海底漫步，或者做任何你想做的事，但绘画依然是绘画，因为它不是科学所能研究的。它依然是个问题。而答案只能从它本身去寻找。”你遇到的困难更大，但这并不意味着你没办法做得好——只是需要更多时间而已。但那有什么关系呢，你能活得更长久啊。</p><p>◆ 每天起床的时候，争取变得比你从前更聪明一点。认真地、出色地完成你的任务。慢慢地，你会有所进步，但这种进步不一定很快。但你这样能够为快速进步打好基础……每天慢慢向前挪一点。到最后——如果你足够长寿的话——大多数人得到了他们应得的东西。</p><p><strong>第一十六章 第二讲 论基本的、普世的智慧， 及其与投资管理和商业的关系</strong></p><p>◆ 使用新技术将会为你节省多少成本。然而，他们并没有进行第二步分析——也就是弄清楚有多少钱会落在你手里，多少钱会流向消费者。</p><p><strong>第一十七章 第三讲 论基本的、普世的智慧（修正稿）</strong></p><p>◆ 如果你想要改变行为，那么就必须改变动机。</p><p><strong>第二十三章 第九讲 论学院派经济学：考虑跨学科需求之后的优点和缺点</strong></p><p>◆ 凯恩斯说：“介绍新观念倒不是很难，难的是清除那些旧观念。”爱因斯坦说得更好，他把他那些成功的理论归功于“好奇、专注、毅力和自省”。他说的自省就是摧毁你们自己最热爱、最辛苦才得到的观念。如果你们确实能够善于摧毁你们自己的错误观念，那是一种了不起的才华。</p><p><strong>第二十四章 第十讲 在南加州大学GOULD法学院毕业典礼上的演讲</strong></p><p>◆ 历史是时代的见证，真理的火炬，记忆的生命，生活的老师和古人的使者。</p><p>◆ 如果你想要说服别人，要诉诸利益，而非诉诸理性。</p><p>◆ 我认为爱比克泰德的态度能够引导人们作出正确的反应。他认为生活中的每一次不幸，无论多么倒霉，都是一个锻炼的机会。他认为每一次不幸都是吸取教训的良机。人们不应该在自怜中沉沦，而是应该利用每次打击来提高自我。</p>]]></content>
      
      
      <categories>
          
          <category> Daily </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Work &amp; Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Daily English</title>
      <link href="/2023/12/07/Daily-English/"/>
      <url>/2023/12/07/Daily-English/</url>
      
        <content type="html"><![CDATA[<h3 id="2023年12月"><a href="#2023年12月" class="headerlink" title="2023年12月"></a>2023年12月</h3><p>（7）知己知彼，百战不殆。<br>Know the enemy and know yourself, in a hundred battles, you will never be defeated.</p><div align="center">  <img src="231207.png" height=40% width=40%></div><p>（8）你这么固守传统，怎么可能成为改革先驱呢？<br>How are you gonna be a revolutionary, if you’re such a traditionalist?</p><div align="center">  <img src="231208.png" height=40% width=40%></div><p>（11）上善若水，水善利万物而不争。<br>The supreme good is like water, which nourishies all things without trying to.</p><div align="center">  <img src="231211.png" height=40% width=40%></div><p>（12）星空之城，你是否只为我一人闪耀？星空之城，世间有太多不可明了。谁知道，我感觉到你我初次拥抱时，所怀有的那些梦想，都已一一实现。<br>City of stars. Are you shining just for me? City of stars. There’s so much that I can’t see. Who knows. I felt it from the first embrace I shared with you. That now our dreams. They’ve finally come true.</p><div align="center">  <img src="231212.png" height=45% width=45%></div><p>（13）拿不定主意时，照原路再走一次是明智之举。<br>When in doubt, I find retracing my steps to be a wise place to begin.</p><div align="center">  <img src="231213.png" height=40% width=40%></div><p>（14）我欣赏你的毅力，但有时谨慎才是勇敢的真谛。<br>I admire your persistence, but sometimes discretion is the better part of valour.</p><div align="center">  <img src="231214.png" height=40% width=40%></div><p>（15）为了别人改变，就是欺骗自己。<br>To change for others is to lie to yourself.</p><div align="center">  <img src="231215.png" height=40% width=40%></div><p>（18）两年时间不算什么，浪费它也是件超简单的事，但只需微小的行动，切实的付出和坚持，你能让这两年变得价值连城。<br>Two years is nothing and extremely easy to waste, but with small actions, substantial commitment and consistency, you can make it count, a lot.</p><div align="center">  <img src="231218.png" height=40% width=40%></div><p>（19）所以我只是扮演好自己的角色，祈祷你会回心转意，但我却无法让你明白，有些事只有爱才可以解释。<br>So I’ll just play my part. Pray you’ll have a change of heart. But I can’t make you see it though. That’s something only love can do.</p><div align="center">  <img src="231219.png" height=35% width=35%></div><p>（20）你可以用尽一生去害怕未知的事物，去担心未来要走的路。但其实未来恰恰来自于我们当下做出的决定，无论是基于爱意还是恐惧。<br>You can spend your whole life imagining ghosts, worrying about the pathway to the future, but all there will ever be is what’s happening here, and the decisions we make in this moment, which are based in either love or fear.</p><div align="center">  <img src="231220.png" height=45% width=45%></div><p>（21）用温柔的方式，你也能撼动这个世界。<br>In a gentle way, you can shake the world.</p><div align="center">  <img src="231221.png" height=40% width=40%></div><p>（22）礼节和传统都很好，但如果它们开始控制我们，它们也就失去用处了。<br>Manners and tradition are all very well, but once they start to control us, they’ve outlived their usefulness.</p><div align="center">  <img src="231222.png" height=40% width=40%></div><p>（25）这个圣诞我不再许愿，漂亮的玩具、精美的礼物变得毫无意义，因为有你在我身边，我就拥有了一切。<br>So I won’t ask for anything. No shiny toys or fancy things, Cause I’ve got everything I need. With you here next to me.</p><div align="center">  <img src="231225.png" height=40% width=40%></div><p>（26）太平盛世，环球同此凉热。<br>In a peaceful world young and old. Might share alike your warmth and cold!</p><div align="center">  <img src="231226.png" height=40% width=40%></div><p>（27）有些鸟儿注定是关不住的，它们的羽毛太鲜亮了。<br>Some birds aren’t meant to be caged. Their feathers are just too bright.</p><div align="center">  <img src="231227.png" height=40% width=40%></div><p>（28）在这个世上，办事情一旦偷懒就一定做不好。<br>In this world, you can either do things the easy way or the right way.</p><div align="center">  <img src="231228.png" height=40% width=40%></div><p>（29）你遇到了成千上万的人，没有一个能真正触动你心灵。直到遇见那么一个人，于是你的人生都永远改变了。<br>You meet thousands of people, and none of them really touch you. And then you meet one person, ans your life is changed forever.</p><div align="center">  <img src="231229.png" height=40% width=40%></div><h3 id="2024年1月"><a href="#2024年1月" class="headerlink" title="2024年1月"></a>2024年1月</h3><p>（2）你和我应该立下约定，将救赎带回来。有爱的地方，我会在你身边。<br>You and I must make a pact. We must bring salvation back. Where there is love, I’ll be there.</p><div align="center">  <img src="240102.png" height=40% width=40%></div><p>（3）我的一生被三种简单却又无比热烈的激情所控制：对爱的渴望，对知识的探索，和对人类苦难的难以抑制的怜悯。<br>There passions, simple but overwhelmingly strong, have governed my life: the longing for love, the search for knowledge, and unbearable pity for the suffering of mankind.</p><div align="center">  <img src="240103.png" height=40% width=40%></div><p>（4）世人都晓神仙好，惟有功名忘不了。古今将相今何方，荒家一堆草没了。<br>Their minds yearn to ascend, Yet fame still holds sway. Their glory fades through time, in tombs of somber gray.</p><div align="center">  <img src="240104.png" height=40% width=40%></div><p>（5）欺负我们的人就不是朋友了。只有强大才能不被人欺，所以从现在起，我们就要奋发图强。<br>A friend who bullies us is no longer a friend. And since bullies only respond to strength, from now onward, I will be prepared to be much stronger.</p><div align="center">  <img src="240105.png" height=40% width=40%></div><p>（8）天赋是随机的，你可能会拥有它，但这意味着什么呢？但性格是可以观察到的，是可以见证的。品格是后天习得的，也是代代传承下来的。<br>Talent is random. You might have it, but what does it mean? But character is observed. It is witnessed. Character is taught and it’s passed down.</p><div align="center">  <img src="240108.png" height=40% width=40%></div><p>（9）我势不可挡，我已摆脱桎梏。我所向披靡，我战无不胜。我力有万钧，我永不漫灭。<br>I’m unstoppable. I’m a Porsche with no brakes. I’m invincible. Yeah, I win every single game. I’m powerful. I don’t need batteries to play.</p><div align="center">  <img src="240109.png" height=40% width=40%></div><p>（10）你想成为哪类人，并不取决于你的能力，而是取决于你的选择。<br>It is not our abilities that show what we truly are. It is our choices.</p><div align="center">  <img src="240110.png" height=40% width=40%></div><p>（11）人爱者有力，爱人者勇。<br>Being deeply loved by someone gives you strength, while loving someone deeply gives you courage.</p><div align="center">  <img src="240111.png" height=40% width=40%></div><p>（12）幸福就是：知足。如果你对你的生活和你所做的事情感到满意，那么你会非常快乐、富足。<br>Happiness is one word: contentment. If you’re content with your life and what you’re doing, I think you’re then very very happy and very very rich.</p><div align="center">  <img src="240112.png" height=40% width=40%></div><p>（15）觉得沮丧代表你活在过去；觉得焦虑说明你活在未来；平静泰然才证明你活在当下。<br>If you’re sad, then you mind is in the past. If you’re anxious, your mind will be in the future. But if you’re peaceful and if you’re still, your mind is in the present moment.</p><div align="center">  <img src="240115.png" height=40% width=40%></div><p>（16）我跟所有人说我还算熬的过去。在摇摇欲坠的天堂幻境中，我们之间没有界限。这是与你一起度过的心碎之夏。<br>It’s cool. That’s what I tell’em. No rules in breakable heaven. But ooh, Whoa oh. It’s a cruel summer With you.</p><div align="center">  <img src="240116.png" height=40% width=40%></div><p>（17）衡量我们生命意义的唯一方式，就是珍惜他人的生命。<br>The only way that we can measure the significance of our own lives is by valuing the lives of others.</p><div align="center">  <img src="240117.png" height=40% width=40%></div><p>（18）责人者远，责己者半，不责者达。<br>The man who blames others has a long way in his joureney to go. The man who blames himself is halfway there. And the man who blames no one has already arrived.</p><div align="center">  <img src="240118.png" height=40% width=40%></div><p>（19）想和平共处的唯一方法，就是看他们是否准备好原谅。<br>The only way anyone can live in peace is if they’re prepared to forgive.</p><div align="center">  <img src="240119.png" height=40% width=40%></div><h3 id="2024年2月"><a href="#2024年2月" class="headerlink" title="2024年2月"></a>2024年2月</h3><p>（23）元宵节是春节的最后一天，对于在外工作和求学的游子来说，他们即将惜别团聚，满怀乡思，再次踏上新一年的征程。<br>Lantern Festival is the last day of Chinese New Year celebrations. For those working and studying away from home, it is time to bid farewell to their families and set out a journey in a brand new year.</p><div align="center">  <img src="240223.png" height=40% width=40%></div><p>（26）即使是再小的善举，也有充足的力量能打动人心，照亮黑暗的日子<br>。我将以乐观和勇气面对这一年。<br>Even the smallest act of kindness has the power to touch hearts and brighten days. I plan to face this year with optimism and courage.</p><div align="center">  <img src="240226.png" height=40% width=40%></div>]]></content>
      
      
      <categories>
          
          <category> Daily </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Work &amp; Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Number Theory and Geometry</title>
      <link href="/2023/07/05/Number-Theory-and-Geometry/"/>
      <url>/2023/07/05/Number-Theory-and-Geometry/</url>
      
        <content type="html"><![CDATA[<h1 id="数论与几何"><a href="#数论与几何" class="headerlink" title="数论与几何"></a>数论与几何</h1><p>这部分知识点比较考验数学功底和思维。</p><p>水塘抽样（Reservoir Sampling）是一系列的随机算法，其目的在于从包含n个项目的集合S中选取k个样本，其中n为一很大或未知的数量，尤其适用于不能把所有n个项目都存放到内存的情况。水塘抽样由于空间小，时间复杂度低，可以用于大数据流中的随机抽样问题。</p><p>遍历集合，当我们第 i 次遇到值为 target 的元素时，随机选择区间 $[0,i)$ 内的一个整数，如果其等于 0，则将返回值置为该元素的下标，否则返回值不变。设 nums 中有 k 个值为 target 的元素，该算法会保证这 k 个元素的下标成为最终返回值的概率均为 $1/k$，证明如下：<br>$\begin{aligned} &amp;P(第\ i\ 次遇到值为\ \textit{target}\ \ 的元素的下标成为最终返回值)\<br>=&amp;P(第\ i\ 次随机选择的值= 0) \times P(第\ i+1\ 次随机选择的值\ne 0) \times \cdots \times P(第\ k\ 次随机选择的值\ne 0)\<br>=&amp;\dfrac{1}{i} \times (1-\dfrac{1}{i+1}) \times \cdots \times (1-\dfrac{1}{k})\<br>=&amp;\dfrac{1}{i} \times \dfrac{i}{i+1} \times \cdots \times \dfrac{k-1}{k}\<br>=&amp;\dfrac{1}{k} \end{aligned}$</p><ul><li><code>num = random.choice(list())</code>：在list中随机返回一个num</li><li><code>num = random.randrange(start, end, step)</code>：指定排列中随机返回一个num</li><li>求a和b的最大公约数 和 最小公倍数为：<code>math.gcd(a, b)</code> 和 <code>a * b / gcd(a, b)</code></li><li>给定一个整数：不同的质因子数量$\omega$，所有的质因子数量$\Omega$</li></ul><h2 id="高中基础"><a href="#高中基础" class="headerlink" title="高中基础"></a>高中基础</h2><ul><li>从n个不同的元素中取出m个元素的<strong>排列数</strong>：$A(n,m)=A^m_n=n(n-1)(n-2)…(n-m+1)=\frac{n!}{(n-m)!}$</li><li>从n个不同的元素中取出m个元素的<strong>组合数</strong>：$C(n,m)=C(n,n-m)=\frac{A^m_n}{m!}=\frac{n!}{m!(n-m)!}$</li><li>规定$0!=1$。python中对应函数分别为<code>itertools.permutations(list, m)</code>;<code>itertools.combinations(list, m)</code>。<code>math.perm(n, k)</code>;<code>math.comb(n, k)</code>从n个项目中选择k个项目(不重复且无顺序)的排列数和组合数。</li><li>等差数列通项：$a_n=a_1+(n-1)d=a_m+(n-m)d$，求和公式：$S_n=na_1+\frac{n(n-1)}{2}d=\frac{n(a_1+a_n)}{2}$</li><li>等比数列通项：$a_n=a_1q^{n-1}=a_mq^{n-m}$，求和公式：$S_n=\frac{a_1(1-q^n)}{1-q}=\frac{a_1-a_nq}{1-q}$</li></ul><h3 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">数论与几何</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>         <td><a href=https://leetcode.cn/problems/factorial-trailing-zeroes/description>✅172. 阶乘后的零</td>        <td>因子5的数量必小于2的数量，循环计算n除5的结果数</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/preimage-size-of-factorial-zeroes-function/description>✅阶乘函数后 K 个零</td>        <td>末尾0为k+1的数量的左边界 - 末尾0为k个的数量的左边界 = 末尾0为k的数量</td>         <td>🌟🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/count-primes/description>✅204. 计数质数</td>        <td>埃氏筛：质数的倍数肯定是合数</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/powx-n/description>✅50. Pow(x, n)</td>        <td>10的二进制为1010，即x^10=x^2*x^8</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/super-pow/description>✅372. 超级次方</td>        <td>正序逆序计算均可</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/random-pick-index/solutions/1444589/sui-ji-shu-suo-yin-by-leetcode-solution-ofsq>✅398. 随机数索引</td>        <td>水塘抽样</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/linked-list-random-node/description>✅382. 链表随机节点</td>        <td>水塘抽样</td>         <td>🌟🌟</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sort Algorithm</title>
      <link href="/2023/06/13/Sort-Algorithm/"/>
      <url>/2023/06/13/Sort-Algorithm/</url>
      
        <content type="html"><![CDATA[<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><p>排序算法是一种将一组元素按照特定规则进行排列的算法。tips：</p><ul><li>稳定指如果a原本在b前面，而a=b，排序之后a仍然在b的前面。</li><li>二维数组.sort(key=lambda x: x[0]) 根据指定二维数组的第一个元素升序排序</li><li>二维数组.sort(key=lambda x: (x[0], -x[1]))根据指定二维数组的第一个元素升序排序，若第一个元素相等，按第二个元素降序排序</li><li>sort()排序的时间复杂度为O(NlogN)，使用的是归并排序。</li><li>自定义排序函数<code>array.sort(key=functools.cmp_to_key=sort_function)</code></li></ul><p>稳定性是指待排序元素中相等的元素在排序后相对位置不变。想象下两个相等元素在快排的树中，位置靠前的那个被拿到P位置，那么这两个元素的相对位置就变了，最终排序结果就是不稳定的。但如果是在归并排序树中，每次都将元素们对半分开再按大小合并，即使相等元素被放入左右两个子树，只要最后按原来元素位置顺序遍历合并，就能保证相等元素的相对位置跟原来一样，所以归并排序可以是稳定的</p><table>    <tr>        <th align='center', colspan="3">排序算法</th>    </tr>    <tr>        <th>算法</th>        <th>思想</th>        <th>复杂度</th>        <th>稳定性</th>    </tr>    <tr>        <td>冒泡排序（Bubble Sort）</td>        <td>重复比较相邻的两个元素，如果顺序不正确则交换，直到整个序列排序完成</td>         <td>O(n^2)</td>         <td>稳定</td>    </tr>    <tr>        <td>插入排序（Insertion Sort）</td>        <td>将待排序的元素逐个插入已排序的序列中的适当位置，直到整个序列排序完成</td>         <td>O(n^2)</td>         <td>稳定</td>    </tr>    <tr>        <td>选择排序（Selection Sort）</td>        <td>在未排序的序列中选择最小（或最大）的元素，将其放置在已排序序列的末尾，重复这个过程直到整个序列排序完成</td>         <td>O(n^2)</td>         <td>不稳定</td>    </tr>    <tr>        <td>快速排序（Quick Sort）</td>        <td>选择一个基准元素，将序列分为两个子序列，左边的子序列都小于基准元素，右边的子序列都大于基准元素，然后对两个子序列进行递归排序</td>         <td>O(nlogn)</td>         <td>不稳定</td>    </tr>    <tr>        <td>归并排序（Merge Sort）</td>        <td>将序列递归分为两个子序列，对每个子序列进行排序，然后合并两个有序子序列以得到排序后的序列</td>         <td>O(nlogn)</td>         <td>稳定</td>    </tr>    <tr>        <td>堆排序（Heap Sort）</td>        <td>将待排序序列构建为一个最大（或最小）堆，然后逐个从堆中取出最大（或最小）元素，重建堆，直到整个序列排序完成</td>         <td>O(nlogn)</td>         <td>稳定</td>    </tr>    <tr>        <td>希尔排序（Shell Sort）</td>        <td>将待排序序列按照一定的增量进行分组，对每个分组使用插入排序，然后逐步缩小增量直至为1，最后进行一次完整的插入排序</td>         <td>O(nlogn)</td>         <td>稳定</td>    </tr></table><h3 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 冒泡排序</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span> - i):</span><br><span class="line">            <span class="keyword">if</span> arr[j] &gt; arr[j + <span class="number">1</span>]:</span><br><span class="line">                arr[j], arr[j + <span class="number">1</span>] = arr[j + <span class="number">1</span>], arr[j]</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line"><span class="comment"># 插入排序</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertion_sort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">        key = arr[i]</span><br><span class="line">        j = i - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> j &gt;= <span class="number">0</span> <span class="keyword">and</span> arr[j] &gt; key:</span><br><span class="line">            arr[j + <span class="number">1</span>] = arr[j]</span><br><span class="line">            j -= <span class="number">1</span></span><br><span class="line">        arr[j + <span class="number">1</span>] = key</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择排序</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selection_sort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>):</span><br><span class="line">        min_index = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">if</span> arr[j] &lt; arr[min_index]:</span><br><span class="line">                min_index = j</span><br><span class="line">        arr[i], arr[min_index] = arr[min_index], arr[i]</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line"><span class="comment"># 快速排序</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(arr) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> arr</span><br><span class="line">    pivot = arr[<span class="number">0</span>]   <span class="comment"># 随机索引random.randint(0,len(arr)-1) 或 随机打乱 random.shuffle(arr)</span></span><br><span class="line">    left = [x <span class="keyword">for</span> x <span class="keyword">in</span> arr[<span class="number">1</span>:] <span class="keyword">if</span> x &lt;= pivot]</span><br><span class="line">    right = [x <span class="keyword">for</span> x <span class="keyword">in</span> arr[<span class="number">1</span>:] <span class="keyword">if</span> x &gt; pivot]</span><br><span class="line">    <span class="keyword">return</span> quick_sort(left) + [pivot] + quick_sort(right)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 带有重复元素的数组快排</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span>(<span class="params">arr, l, r</span>):</span></span><br><span class="line">    <span class="keyword">if</span> l &gt;= r:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    less, p = partition(arr, l, r)</span><br><span class="line">    quick_sort(arr, l, less - <span class="number">1</span>)</span><br><span class="line">    quick_sort(arr, p, r)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partition</span>(<span class="params">arr, l, r</span>):</span></span><br><span class="line">    <span class="comment"># 优化：随机选取piovt</span></span><br><span class="line">    random_idx = random.randint(l, r)</span><br><span class="line">    arr[l], arr[random_idx] = arr[random_idx], arr[l]</span><br><span class="line">    piovt = arr[l]</span><br><span class="line">    i, j = l + <span class="number">1</span>, r + <span class="number">1</span></span><br><span class="line">    less = l</span><br><span class="line">    <span class="keyword">while</span> i &lt; j:</span><br><span class="line">        <span class="keyword">if</span> arr[i] &lt; piovt:</span><br><span class="line">            less += <span class="number">1</span></span><br><span class="line">            arr[i], arr[less] = arr[less], arr[i]</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> arr[i] == piovt:</span><br><span class="line">            i += <span class="number">1</span>   <span class="comment"># i最后指定的是&gt;piovt的元素</span></span><br><span class="line">        <span class="keyword">elif</span> arr[i] &gt; piovt:</span><br><span class="line">            j -= <span class="number">1</span>   <span class="comment"># j最后指定的是第一个&gt;piovt的元素</span></span><br><span class="line">            arr[i], arr[j] = arr[j], arr[i]  </span><br><span class="line">    arr[l], arr[less] = arr[less], arr[l]   <span class="comment"># less最后指定的是&lt;piovt的元素，交换后less-1&lt;piovt</span></span><br><span class="line">    <span class="keyword">return</span> less, j</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数组中无重复元素</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span>(<span class="params">arr, l, r</span>):</span></span><br><span class="line">    <span class="keyword">if</span> l &gt;= r:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    p = partition(arr, l, r)</span><br><span class="line">    quick_sort(arr, l, p - <span class="number">1</span>)</span><br><span class="line">    quick_sort(arr, p + <span class="number">1</span>, r)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partition</span>(<span class="params">arr, l, r</span>):</span></span><br><span class="line">    <span class="comment"># 优化：随机选取piovt</span></span><br><span class="line">    random_idx = random.randint(l, r)</span><br><span class="line">    arr[l], arr[random_idx] = arr[random_idx], arr[l]</span><br><span class="line">    piovt = arr[l]</span><br><span class="line">    i, j = l + <span class="number">1</span>, r</span><br><span class="line">    <span class="keyword">while</span> i &lt;= j:</span><br><span class="line">        <span class="keyword">while</span> i &lt; r <span class="keyword">and</span> arr[i] &lt;= pivot:</span><br><span class="line">            i += <span class="number">1</span>  <span class="comment"># while结束时恰好 nums[i] &gt; pivot</span></span><br><span class="line">        <span class="keyword">while</span> j &gt; l <span class="keyword">and</span> arr[j] &gt; pivot:</span><br><span class="line">            j -= <span class="number">1</span>  <span class="comment"># while结束时恰好 nums[j] &lt;= pivot</span></span><br><span class="line">        <span class="comment"># 此时 [l, i) &lt;= pivot and (j, r] &gt; pivot</span></span><br><span class="line">        <span class="keyword">if</span> i &gt;= j:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        arr[i], arr[j] = arr[j], arr[i]</span><br><span class="line">    arr[l], arr[j] = arr[j], arr[l]   <span class="comment"># 交换后j为piovt</span></span><br><span class="line">    <span class="keyword">return</span> j</span><br><span class="line">            </span><br><span class="line"><span class="comment"># random.shuffle(nums)    # 优化：随机选取piovt</span></span><br><span class="line">quick_sort(nums, <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span>)</span><br><span class="line"><span class="keyword">return</span> nums</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 归并排序</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(arr) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> arr</span><br><span class="line">    mid = <span class="built_in">len</span>(arr) // <span class="number">2</span></span><br><span class="line">    left = merge_sort(arr[:mid])</span><br><span class="line">    right = merge_sort(arr[mid:])</span><br><span class="line">    <span class="keyword">return</span> merge(left, right)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">left, right</span>):</span></span><br><span class="line">    merged = []</span><br><span class="line">    i = j = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(left) <span class="keyword">and</span> j &lt; <span class="built_in">len</span>(right):</span><br><span class="line">        <span class="keyword">if</span> left[i] &lt;= right[j]:</span><br><span class="line">            merged.append(left[i])</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            merged.append(right[j])</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(left):</span><br><span class="line">        merged.append(left[i])</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> j &lt; <span class="built_in">len</span>(right):</span><br><span class="line">        merged.append(right[j])</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> merged</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 堆排序</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapify</span>(<span class="params">arr, n, i</span>):</span></span><br><span class="line">    largest = i</span><br><span class="line">    left = <span class="number">2</span> * i + <span class="number">1</span></span><br><span class="line">    right = <span class="number">2</span> * i + <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> left &lt; n <span class="keyword">and</span> arr[left] &gt; arr[largest]:</span><br><span class="line">        largest = left</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> right &lt; n <span class="keyword">and</span> arr[right] &gt; arr[largest]:</span><br><span class="line">        largest = right</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> largest != i:</span><br><span class="line">        arr[i], arr[largest] = arr[largest], arr[i]</span><br><span class="line">        heapify(arr, n, largest)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_sort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(arr)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 建堆：升序排序用大顶堆</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n // <span class="number">2</span> - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">        heapify(arr, n, i)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 排序</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">        arr[i], arr[<span class="number">0</span>] = arr[<span class="number">0</span>], arr[i]</span><br><span class="line">        heapify(arr, i, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 希尔排序</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shell_sort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(arr)</span><br><span class="line">    gap = n // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> gap &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(gap, n):</span><br><span class="line">            temp = arr[i]</span><br><span class="line">            j = i</span><br><span class="line">            <span class="keyword">while</span> j &gt;= gap <span class="keyword">and</span> arr[j - gap] &gt; temp:</span><br><span class="line">                arr[j] = arr[j - gap]</span><br><span class="line">                j -= gap</span><br><span class="line">            arr[j] = temp</span><br><span class="line">        gap //= <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> arr</span><br></pre></td></tr></table></figure><blockquote><p><a href="https://www.cnblogs.com/onepixel/p/7674659.html">十大经典排序算法（动图演示）</a></p></blockquote><h3 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">排序算法</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/sort-an-array/description>✅912. 排序数组</td>        <td>API、归并排序、快排（随机piovt+三路优化）、堆排序</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/count-of-smaller-numbers-after-self/description>✅315. 计算右侧小于当前元素的个数</td>        <td>归并排序</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/shu-zu-zhong-de-ni-xu-dui-lcof/description>✅剑指 Offer 51. 数组中的逆序对</td>        <td>同上，归并排序</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/reverse-pairs/description>✅493. 翻转对</td>        <td>借助归并排序</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/count-of-range-sum/description>✅327. 区间和的个数</td>        <td>前缀和+归并排序</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/kth-largest-element-in-an-array/description>✅215. 数组中的第K个最大元素</td>        <td>优先队列；基于快速选择的快排</td>         <td>🌟🌟</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Interview Experience</title>
      <link href="/2023/06/05/Interview-Experience/"/>
      <url>/2023/06/05/Interview-Experience/</url>
      
        <content type="html"><![CDATA[<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="线性和逻辑回归模型"><a href="#线性和逻辑回归模型" class="headerlink" title="线性和逻辑回归模型"></a>线性和逻辑回归模型</h2><p>经典的机器学习模型，用于解决分类和回归问题。</p><ul><li>线性模型（Linear Models）：一种基本的统计模型，用于建立输入特征与输出之间的线性关系。基本形式是：<code>y = w₁x₁ + ... + wₙxₙ + b</code>，<code>y</code>表示输出变量，<code>x₁, ..., xₙ</code>表示输入特征，<code>w₁, ..., wₙ</code>表示特征的权重，<code>b</code>表示偏差或截距。模型通过学习特征的权重和偏差，以最小化预测值与真实值之间的差距。线性模型简单、可解释性强、计算效率高，适用于特征与输出之间存在线性关系的问题。</li><li>逻辑回归模型（Logistic Regression）：一种用于二分类问题的线性模型，通过逻辑函数（sigmoid函数）将线性模型的输出转化为概率值，从而进行分类。逻辑回归模型的基本形式是：<code>p = 1 / (1 + exp(-(w₁x₁ + ... + wₙxₙ + b)))</code>其中，<code>p</code>表示样本属于某个类别的概率。模型通过学习特征的权重和偏差，以最大化似然函数或最小化对数损失函数来拟合训练数据，并进行分类预测。逻辑回归模型模型简单、可解释性强、计算效率高，广泛应用于二分类问题。逻辑回归模型还可以通过正则化技术来防止过拟合。</li><li>区别：<ul><li>输出类型：线性模型常用于回归问题，输出是连续值。逻辑回归模型用于二分类问题，输出是概率值或类别标签。</li><li>输出转换：线性模型直接使用线性函数进行预测。逻辑回归模型通过逻辑函数（sigmoid函数）将线性模型的输出转化为概率值，从而进行分类。</li><li>损失函数：线性模型通常使用均方误差MSE或平均绝对误差等回归损失函数。逻辑回归模型使用对数损失函数或交叉熵损失函数来最小化分类误差。</li></ul></li><li>联系：<ul><li>线性模型是逻辑回归模型的一种特例。当逻辑回归模型中只有一个二分类输出变量，并且特征与输出之间存在线性关系时，逻辑回归模型退化为线性模型。</li><li>逻辑回归模型可以使用线性模型的方法进行参数估计。逻辑回归模型的参数估计可以通过最大似然估计或梯度下降等方法来获得，类似于线性模型的参数估计。</li></ul></li></ul><h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p>逻辑回归假设数据服从伯努利分布，通过极大似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的。</p><p>假设：</p><ul><li>假设数据服从伯努利分布(非正即反，概率和为1)。</li><li>假设模型的输出值是样本为正例的概率。</li></ul><p>损失函数：<br>逻辑回归中用到sigmoid函数，若用均方误差则为非凸函数，有多个极小值，采用梯度下降法容易陷入局部最优解中。<br>逻辑回归其实是概率类模型，通过极大似然估计（MLE）推导逻辑回归损失函数。目的是将所得似然函数极大化，而损失函数是最小化。</p><p>求解：<br>最小二乘法的误差符合正态分布，而逻辑回归的误差符合的是二项分布，所以不能用最小二乘法来作为损失函数，那么能够用最大似然预计来做。使用梯度下降法求解。</p><ul><li>如果用最小二乘法，目标函数就是 $E<em>{w,b}=\sum</em>{i=1}^{m}\left ( y<em>{i}-\frac{1}{1+e^{-\left ( w^{T}x</em>{i}+b \right )}}\right )^2$ ,是非凸的，不容易求解，会得到局部最优。</li><li>如果用最大似然估计，目标函数就是对数似然函数： $l<em>{w,b}=\sum</em>{i=1}^{m}\left ( -y<em>{i}\left ( w^{T}x</em>{i}+b \right )+ln\left ( 1+e^{w^{T}x_{i}+b} \right ) \right )$ ,是关于 (w,b) 的高阶连续可导凸函数，可以方便通过一些凸优化算法求解，比如梯度下降法、牛顿法等。</li></ul><p>优点：</p><ol><li>直接对分类可能性进行建模，无需实现假设数据分布，这样就避免了假设分布不准确所带来的问题。</li><li>形式简单，模型的可解释性非常好，特征的权重可以看到不同的特征对最后结果的影响。 </li><li>除了类别，还能得到近似概率预测，这对许多需利用概率辅助决策的任务很有用。</li></ol><p>缺点：</p><ol><li>准确率不是很高，因为形势非常的简单，很难去拟合数据的真实分布。</li><li>本身无法筛选特征。</li></ol><p>推导：</p><div align="center">  <img src="logistic_regression.png" height=70% width=70%></div><p><a href="https://cloud.tencent.com/developer/article/1373192#:~:text=关于逻辑回归，可以用一句话来总结：,逻辑回归假设数据服从伯努利分布，通过极大似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的%E3%80%82">从零开始学会逻辑回归（一）</a></p><h2 id="二分类和多分类的损失函数"><a href="#二分类和多分类的损失函数" class="headerlink" title="二分类和多分类的损失函数"></a>二分类和多分类的损失函数</h2><div class="table-container"><table><thead><tr><th>分类问题</th><th>输出层激活函数</th><th>损失函数</th><th>说明</th></tr></thead><tbody><tr><td>二分类</td><td>Sigmoid</td><td>二分类交叉熵损失函数（binary_crossentropy）</td><td>sigmoid作为最后一层输出，不能把最后一层的输出看作成一个分布，因为加起来不为1。应将最后一层的每个神经元看作一个分布</td></tr><tr><td>多分类</td><td>Softmax</td><td>多类别交叉熵损失函数（categorical_crossentropy）</td><td>Softmax后最后一层输出概率相加为1</td></tr><tr><td>多标签分类</td><td>Sigmoid</td><td>二分类交叉熵损失函数（binary_crossentropy）</td><td>计算一个样本各个标签的损失取平均值。把一个多标签问题转化为在每个标签上的二分类问题</td></tr></tbody></table></div><ul><li>BCE Loss: $L=\frac{1}{N}\sum_iL_i=\frac{1}{N}\sum_i[y_ilog(p_i)+(1-y_i)log(1-p_i)]$</li><li>CE Loss: $L=\frac{1}{N}\sum<em>iL_i=-\frac{1}{N}\sum_i \sum^M</em>{c=1}y<em>{ic}log(p</em>{ic})$</li></ul><p><a href="https://zhuanlan.zhihu.com/p/617375968">二分类和多分类的激活函数和损失</a></p><h2 id="二分类为什么用交叉熵损失而不用MSE损失？"><a href="#二分类为什么用交叉熵损失而不用MSE损失？" class="headerlink" title="二分类为什么用交叉熵损失而不用MSE损失？"></a>二分类为什么用交叉熵损失而不用MSE损失？</h2><ul><li>对概率分布更敏感： 交叉熵损失更适用于概率分布的比较，而二分类问题通常涉及到概率的预测。交叉熵损失能够衡量实际概率分布与预测概率分布之间的差异，更加敏感和有效。</li><li>梯度更新更好： 在分类问题中，交叉熵损失函数的梯度更为明确和稳定，相比之下，均方误差损失可能会导致训练过程中梯度消失或梯度爆炸的问题。</li><li>更好地表达分类目标： 交叉熵损失更加关注正确类别的预测概率，而均方误差对所有类别的预测概率都进行了平方差的计算，可能会导致对错误类别的概率影响不够明显。</li></ul><h2 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h2><p>令y表示数据的label，f(x)表示测试数据的预测值，$\overline{f(x)}$表示学习算法对所有数据集的期望预测值。则偏差表示期望预测值$\overline{f(x)}$与标记y之间的差距，差距越大说明偏差越大；而方差是测试预测值f(x)与预测值的期望值$\overline{f(x)}$之间的差距，差距越大说明方差越大。偏差表征模型对数据的拟合能力；而方差表征数据集的变动导致的学习性能的变化，也就是泛化能力。</p><h2 id="Layer-Normalization-和-Batch-Normalization"><a href="#Layer-Normalization-和-Batch-Normalization" class="headerlink" title="Layer Normalization 和 Batch Normalization"></a>Layer Normalization 和 Batch Normalization</h2><p>“独立同分布”的数据能让人很快地发觉数据之间的关系，因为不会出现像过拟合等问题。为了解决ICS（internal covarivate shift内部协变量漂移）问题，即数据分布会发生变化，对下一层网络的学习带来困难。一般在模型训练之前，需要对数据做归一化。</p><p>LayerNorm，对单个样本的所有维度特征做归一化，对模型中每个子层的输入归一化处理，使得每个特征的均值为0，方差为1。有助于缓解内部协变量偏移的问题，提高模型的训练效率和鲁棒性。</p><p>batch normalization是对一批样本的同一纬度特征做归一化。强行将数据转为均值为0，方差为1的正态分布，使得数据分布一致，并且避免梯度消失。而梯度变大意味着学习收敛速度快，能够提高训练速度。设batch_size为m，网络在向前传播时，网络 中每个神经元都有m个输出，BN就是将每个神经元的m个输出进行归一化处理。</p><ul><li>标准化：求得均值为0，方差为1的标准正态分布 $\bar{x}_{i}$</li><li>尺度变换和偏移：获得新的分布 $y_i$。均值为 β，方差为 γ（其中偏移 β 和尺度变换 γ 为需要学习的参数）。该过程有利于数据分布和权重的互相协调。</li></ul><p>区别:</p><ul><li>从操作上看：BN是对同一个batch内的所有数据的同一个特征数据进行操作；而LN是对同一个样本进行操作。</li><li>从特征维度上看：BN中，特征维度数=均值or方差的个数；LN中，一个batch中有batch_size个均值和方差。</li></ul><p>关系:</p><ul><li>BN 和 LN 都可以比较好的抑制梯度消失和梯度爆炸的情况。BN不适合RNN、transformer等序列网络，不适合文本长度不定和batchsize较小的情况，适合于CV中的CNN等网络；</li><li>而LN适合用于NLP中的RNN、transformer等网络，因为sequence的长度可能是不一致的。</li><li>如果把一批文本组成一个batch，BN就是对每句话的第一个词进行操作，BN针对每个位置进行缩放就不符合NLP的规律了。</li></ul><p>小结:</p><ul><li>经过BN的归一化再输入激活函数，得到的值大部分会落入非线性函数的线性区，导数远离导数饱和区，避免了梯度消失，这样来加速训练收敛过程。</li><li>归一化技术就是让每一层的分布稳定下来，让后面的层能在前面层的基础上“安心学习”。BatchNorm就是通过对batch size这个维度归一化来让分布稳定下来（但是BN没有解决ISC问题）。LayerNorm则是通过对Hidden size这个维度归一。</li></ul><p><a href="https://blog.csdn.net/qq_35812205/article/details/122330669">【深度学习】batch normalization和layer normalization区别</a></p><h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><p>为什么要从原问题转换为对偶问题求解？</p><ul><li>不等式约束方程需要写成min max的形式来得到最优解。而这种写成这种形式对x不能求导，这种形式只能对拉格朗日乘子$\alpha$求导，所以我们需要转换成max min的形式，这时候，x就在里面了，这样就能对x求导了。而为了满足这种对偶变换成立，就需要满足KKT条件（KKT条件是原问题与对偶问题等价的必要条件，当原问题是凸优化问题时，变为充要条件）。只用求解$\alpha$系数，而$\alpha$系数只有支持向里才非0，其它全部为0。</li><li>对偶问题将原始问题中的约束转为了对偶问题中的等式约束</li><li>方便核函数的引入，推广到非线性分类问题</li><li>改变了问题的复杂度。由求特征向量w转化为求比例系数a，在原始问题下，求解的复杂度与样本的维度有关，即w的维度。在对偶问题下，只与样本数量有关。</li></ul><p><a href="https://blog.csdn.net/xiaocong1990/article/details/83037848">SVM从原始问题到对偶问题的转换及原因</a><br><a href="https://www.zhihu.com/question/35602879">SVM中，高斯核为什么会把原始维度映射到无穷多维？</a></p><h2 id="数据不均衡"><a href="#数据不均衡" class="headerlink" title="数据不均衡"></a>数据不均衡</h2><p>数据不均衡（如正例很少，负例很多）解决办法：</p><ol><li>欠采样：对负例进行欠采样。一种代表性算法是将负例分成很多份，每次用其中一份和正例一起训练，最后用集成学习综合结果。</li><li>过采样：对正例进行过采样。一种代表性方法是对正例进行线性插值来获得更多的正例。</li><li>调整损失函数：训练时正常训练，分类时将数据不均衡问题加入到决策过程中。例如在我做的文本检测项目中，正常训练，但是判断某个像素是否是文本时 $Loss=-\beta{Y}log\hat{Y}-(1-\beta)(1-Y)log(1-\hat{Y})$，其中Y是样本的标记，$\hat{Y}$是预测值，β是负样本和总体样本的比值。通过加入 β和1−β使得数量较少的正样本得到更多的关注，不至于被大量的负样本掩盖。</li><li>组合/集成学习：例如正负样本比例1:100，则将负样本分成100份，正样本每次有放回采样至与负样本数相同，然后取100次结果进行平均。</li><li>数据增强：单样本增强如几何变换、颜色变换、增加噪声；多样本组合增强如Smote类、SamplePairing、Mixup等方法在特征空间内构造已知样本的邻域值样本；基于深度学习数据增强</li></ol><h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><p>目标是从原始特征集中选择最相关、最有用的特征，以提高模型性能和泛化能力。常用特征选择方法：</p><ul><li>过滤式：独立于学习算法，据特征的统计属性对特征评估和排序。包括相关系数、卡方检验、信息增益、互信息法等。过滤式方法计算快速、简单，适用于高维数据，但可能忽略特征之间的相互关系。<ul><li>方差选择：计算特征在数据中的方差来判断是否保留。特征方差低于预先设定的阈值，这个特征可能没有足够的变化，对分类回归任务可能没有太大贡献，可以被移除。</li><li>相关系数：用来衡量两个变量之间线性关系强度的指标。计算特征与目标变量之间的相关系数，选择与目标变量具有较高相关性的特征。</li><li>卡方检验：适用于分类问题中的特征选择。计算特征与目标变量之间的卡方统计量，来衡量特征和目标之间的独立性。选择卡方值较大的特征，与目标变量更相关。</li><li>互信息：衡量两个变量之间相关性的指标。计算特征与目标变量之间的互信息，选择与目标变量具有较高互信息的特征。</li></ul></li><li>嵌入式（Embedded）：特征选择与学习算法的训练过程结合，特征选择作为学习算法的一部分。在学习算法中直接考虑特征的重要性，通过正则化、惩罚项或决策树剪枝等方式选择特征。嵌入式方法包括L1正则化（Lasso）、决策树的特征重要性、正则化的线性模型等。嵌入式方法可以在模型训练过程中自动选择特征，减少了特征选择的额外计算开销。</li><li>包裹式（Wrapper）：使用机器学习模型评估特征的重要性。在特征子集上进行交叉验证，选择性能最好的特征子集进行特征选择。基于树模型的方法（如决策树和随机森林）可以评估特征的重要性。树模型通过计算特征在树中的分裂次数和平均分裂增益衡量特征对模型的贡献。它直接使用最终学习算法对每个特征子集进行评估，可以更好地捕捉特征之间的相互作用。包裹式方法包括递归特征消除和遗传算法等。包裹式方法计算开销大、耗时长，适用于小规模数据和特定问题。</li></ul><h2 id="排序模型"><a href="#排序模型" class="headerlink" title="排序模型"></a>排序模型</h2><p>旨在根据用户偏好和上下文信息，预测每个项目的相关性或排名，为用户提供最相关和个性化的结果。模型输入包括：</p><ul><li>特征：描述每个项目的属性和上下文信息，如项目标签、关键词、评分、发布时间、用户特征等。特征可以是离散的、连续的或文本类型的。</li><li>用户信息：包括用户历史行为、兴趣偏好、地理位置等，用于个性化推荐和排序。</li><li>上下文信息：指在排序过程中可能影响用户偏好的其他因素，如时间、设备类型、浏览环境等。</li></ul><p>常见排序模型包括：</p><ul><li>点击率预测模型：通过预测用户点击每个项目的概率进行排序。包括逻辑回归、梯度提升树、神经网络等。</li><li>排序神经网络：使用神经网络来学习项目之间的相对排名关系。包括RankNet、LambdaRank和ListNet等。</li><li>线性模型和特征工程：基于线性模型结合特征工程技术学习特征权重和组合。包括线性回归、排序SVM等。</li><li>排序树模型：使用决策树排序，如LambdaMART和GBDT等。<br>模型训练中常用损失函数包括交叉熵损失函数、均方误差损失函数、排序损失函数（如NDCG）等。为提高排序模型性能，可以采用特征选择、特征组合、正则化等技术。</li></ul><h2 id="树模型进行特征工程的原因"><a href="#树模型进行特征工程的原因" class="headerlink" title="树模型进行特征工程的原因"></a>树模型进行特征工程的原因</h2><ul><li>改善模型性能： 特征工程有助于提取更具预测性的特征，可以帮助模型更好地拟合数据，提升模型的预测性能。</li><li>降低过拟合风险： 合适的特征工程可以帮助模型更好地泛化到新的数据集上，降低过拟合的风险，提高模型的稳定性和泛化能力。</li><li>减少计算复杂度： 特征工程有助于减少特征空间的维度，从而减少计算复杂度，并加速模型的训练和预测过程。</li><li>提高可解释性： 通过合理的特征工程，可以使得模型更易于解释和理解，有助于深入理解数据特征对模型预测的影响。</li><li>解决特征相关性和噪音问题： 特征工程有助于发现和处理特征之间的相关性和噪音，使模型更加健壮。</li></ul><h2 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h2><p>一种基于boosting增强策略的加法模型，训练时采用前向分布算法进行贪婪学习，迭代地训练一系列弱学习器，并将它们组合成一个强大的集成模型。每次迭代都学习一棵CART树来拟合之前t-1棵树的预测结果与训练样本真实值的残差。</p><h2 id="LR和GBDT"><a href="#LR和GBDT" class="headerlink" title="LR和GBDT"></a>LR和GBDT</h2><p>LR是线性模型，可解释性强，很容易并行化，但学习能力有限，需要大量的人工特征工程。GBDT是非线性模型，具有天然的特征组合优势，特征表达能力强，但是树与树之间无法并行训练，且树模型很容易过拟合；当在高维稀疏特征的场景下，LR的效果一般会比GBDT好。</p><h2 id="RF和GBDT"><a href="#RF和GBDT" class="headerlink" title="RF和GBDT"></a>RF和GBDT</h2><p>相同点：都是由多棵树组成，最终的结果都是由多棵树一起决定。<br>不同点：</p><ul><li>集成学习：RF属于bagging思想，而GBDT是boosting思想</li><li>偏差-方差权衡：RF不断的降低模型的方差，而GBDT不断的降低模型的偏差</li><li>训练样本：RF每次迭代的样本是从全部训练集中有放回抽样形成的，而GBDT每次使用全部样本</li><li>并行性：RF的树可以并行生成，而GBDT只能顺序生成(需要等上一棵树完全生成)</li><li>最终结果：RF最终是多棵树进行多数表决（回归问题是取平均），而GBDT是加权融合</li><li>数据敏感性：RF对异常值不敏感，而GBDT对异常值比较敏感</li><li>泛化能力：RF不易过拟合，而GBDT容易过拟合</li></ul><h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><p>eXtreme Gradient Boosting用于解决分类和回归问题。基于梯度提升框架，集成多个弱学习器（决策树）逐步改善模型的预测能力。原理：</p><ul><li>损失函数：回归问题常用平方损失函数；分类问题常用对数损失函数。</li><li>弱学习器：用决策树作弱学习器。决策树是一种基于特征的分层划分，每个节点对应一个特征及其划分条件。XGBoost中决策树通过贪婪算法生成，每次选择最大程度降低损失函数的特征和划分点。</li><li>梯度提升：使用梯度提升法集成多个弱学习器。每轮迭代中根据当前模型的预测结果计算损失函数的梯度，并将其作为新目标训练。新弱学习器通过拟合当前目标逐步改进模型预测能力。为控制每个弱学习器的贡献，引入了学习率缩小每轮迭代的步长。</li><li>正则化：防止模型过拟合。正则化项由两部分组成：L1正则化（Lasso）和L2正则化（Ridge）。L1正则化使部分特征权重变零，实现特征选择；L2正则化对权重惩罚，降低模型的复杂度。</li><li>树剪枝：构建决策树采用自动树剪枝策略。计算每个叶节点的分数与正则化项比较，决定是否剪枝。剪枝过程从树的底部开始，逐步向上剪除对模型贡献较小的分支。</li><li>特征重要性评估：提供一种度量特征重要性的方法，评估每个特征对模型预测的贡献程度。训练中会跟踪每个特征被用于划分的次数及划分后带来的增益。计算特征的重要性得分。</li></ul><h3 id="二阶泰勒展开优势"><a href="#二阶泰勒展开优势" class="headerlink" title="二阶泰勒展开优势"></a>二阶泰勒展开优势</h3><ul><li>xgboost是以MSE为基础推导出来的，xgboost的目标函数展开就是一阶项（残差）+二阶项的形式，而其他类似logloss这样的目标函数不能表示成这种形式。为了后续推导的统一，将目标函数进行二阶泰勒展开，就可以直接自定义损失函数了，只要二阶可导即可，增强了模型的扩展性。</li><li>二阶信息能够让梯度收敛的更快更准确，类似牛顿法比SGD收敛更快。一阶信息描述梯度变化方向，二阶信息可以描述梯度变化方向是如何变化的。<br><a href="https://www.zhihu.com/question/61374305">xgboost是用二阶泰勒展开的优势在哪？</a></li></ul><h3 id="为什么快"><a href="#为什么快" class="headerlink" title="为什么快"></a>为什么快</h3><ul><li>分块并行：训练前每个特征按特征值进行排序并存储为Block结构，后面查找特征分割点时重复使用，并且支持并行查找每个特征的分割点</li><li>候选分位点：每个特征采用常数个分位点作为候选分割点</li><li>CPU cache 命中优化： 使用缓存预取的方法，对每个线程分配一个连续的buffer，读取每个block中样本的梯度信息并存入连续的Buffer中。</li><li>Block 处理优化：Block预先放入内存；Block按列进行解压缩；将Block划分到不同硬盘来提高吞吐</li></ul><h3 id="防止过拟合"><a href="#防止过拟合" class="headerlink" title="防止过拟合"></a>防止过拟合</h3><ul><li>目标函数添加正则项：叶子节点个数+叶子节点权重的L2正则化</li><li>列抽样：训练的时候只用一部分特征（不考虑剩余的block块即可）</li><li>子采样：每轮计算可以不使用全部样本，使算法更加保守</li><li>shrinkage: 可以叫学习率或步长，为了给后面的训练留出更多的学习空间</li></ul><h3 id="处理缺失值"><a href="#处理缺失值" class="headerlink" title="处理缺失值"></a>处理缺失值</h3><ul><li>XGBoost允许特征存在缺失值。在特征k上寻找最佳 split point 时，不会对该列特征 missing 的样本进行遍历，而只对该列特征值为 non-missing 的样本上对应的特征值进行遍历，通过这个技巧来减少了为稀疏离散特征寻找 split point 的时间开销。</li><li>在逻辑实现上，为了保证完备性，会将该特征值missing的样本分别分配到左叶子结点和右叶子结点，两种情形都计算一遍后，选择分裂后增益最大的那个方向（左分支或是右分支），作为预测时特征值缺失样本的默认分支方向。</li></ul><h3 id="树停止生长条件"><a href="#树停止生长条件" class="headerlink" title="树停止生长条件"></a>树停止生长条件</h3><ul><li>当新引入的一次分裂所带来的增益Gain&lt;0时，放弃当前的分裂。这是训练损失和模型结构复杂度的博弈过程。</li><li>当树达到最大深度时，停止建树，树深度太深容易过拟合，需要设置一个超参数max_depth。</li><li>引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值，也会放弃此次分裂。这涉及到一个超参数:最小样本权重和，是指如果一个叶子节点包含的样本数量太少也会放弃分裂，防止树分的太细。</li></ul><h3 id="处理不平衡数据"><a href="#处理不平衡数据" class="headerlink" title="处理不平衡数据"></a>处理不平衡数据</h3><ul><li>如采用AUC评估模型性能，可以通过设置scale_pos_weight参数来平衡正样本和负样本的权重。如正负样本比例为1:10时，scale_pos_weight可以取10；</li><li>如果在意预测概率(预测得分的合理性)，不能重新平衡数据集(会破坏数据的真实分布)，应该设置max_delta_step参数为一个有限数字（如1）来帮助收敛。max_delta_step参数通常不进行使用，二分类下的样本不均衡问题是这个参数唯一的用途。</li></ul><h3 id="树剪枝"><a href="#树剪枝" class="headerlink" title="树剪枝"></a>树剪枝</h3><ul><li>在目标函数中增加了正则项：使用叶子结点的数目和叶子结点权重的L2模的平方，控制树的复杂度。</li><li>在结点分裂时，定义了一个阈值，如果分裂后目标函数的增益小于该阈值，则不分裂。</li><li>当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值（最小样本权重和），也会放弃此次分裂。</li><li>XGBoost 先从顶到底建立树直到最大深度，再从底到顶反向检查是否有不满足分裂条件的结点，进行剪枝。</li></ul><h3 id="选择最佳分裂点"><a href="#选择最佳分裂点" class="headerlink" title="选择最佳分裂点"></a>选择最佳分裂点</h3><p>XGBoost在训练前预先将特征按照特征值进行了排序，并存储为block结构，以后在结点分裂时可以重复使用该结构。因此，可以采用特征并行的方法利用多个线程分别计算每个特征的最佳分割点，根据每次分裂后产生的增益，最终选择增益最大的那个特征的特征值作为最佳分裂点。<br>如果在计算每个特征的最佳分割点时，对每个样本都进行遍历，计算复杂度会很大，这种全局扫描的方法并不适用大数据的场景。</p><p>XGBoost提供了一种直方图近似算法，使用weighted quantile sketch算法近似地找到best split，对特征排序后仅选择常数个候选分裂位置作为候选分裂点。<br>按比例来选择，从n个样本中抽取k个样本来进行计算，取k个样本中的最优值作为split value，这样就大大减少了运算数量。按样本均分会导致loss分布不均匀，取到的分位点会有偏差。我们要均分的是loss，而不是样本的数量。将样本对应的残差二阶导h作为划分依据，将同范围h占比的特征值划分到同一范围内。残差二阶导差异越大的地方，样本分布越稀疏，反之则稠密。加权意义在于把候选节点选取的机会更多地让于二阶导更大的地方，同时忽略导数差异小的节点。</p><h3 id="Scalable性"><a href="#Scalable性" class="headerlink" title="Scalable性"></a>Scalable性</h3><ul><li>基分类器的scalability：弱分类器可以支持CART决策树，也可以支持LR和Linear。</li><li>目标函数的scalability：支持自定义loss function，只需要其一阶、二阶可导。有这个特性是因为泰勒二阶展开，得到通用的目标函数形式。</li><li>学习方法的scalability：Block结构支持并行化，支持Out-of-core计算。</li></ul><p>当数据量太大不能全部放入主内存的时候，为了使得out-of-core计算称为可能，将数据划分为多个Block并存放在磁盘上。计算时使用独立的线程预先将Block放入主内存，因此可以在计算的同时读取磁盘。但是由于磁盘IO速度太慢，通常更不上计算的速度。因此，需要提升磁盘IO的销量。Xgboost采用了2个策略：</p><ul><li>Block压缩（Block Compression）：将Block按列压缩，读取的时候用另外的线程解压。对于行索引，只保存第一个索引值，然后只保存该数据与第一个索引值之差(offset)，一共用16个bits来保存offset，因此，一个block一般有2的16次方个样本。</li><li>Block拆分（Block Sharding）：将数据划分到不同磁盘上，为每个磁盘分配一个预取（pre-fetcher）线程，并将数据提取到内存缓冲区中。然后，训练线程交替地从每个缓冲区读取数据。这有助于在多个磁盘可用时增加磁盘读取的吞吐量。</li></ul><h3 id="特征重要性"><a href="#特征重要性" class="headerlink" title="特征重要性"></a>特征重要性</h3><ul><li>weight ：该特征在所有树中被用作分割样本的特征的总次数。</li><li>gain ：该特征在其出现过的所有树中产生的平均增益。</li><li>cover ：该特征在其出现过的所有树中的平均覆盖范围。<br>注意：覆盖范围这里指的是一个特征用作分割点后，其影响的样本数量，即有多少样本经过该特征分割到两个子节点。</li></ul><h3 id="调参步骤"><a href="#调参步骤" class="headerlink" title="调参步骤"></a>调参步骤</h3><p>首先需初始化一些基本变量，如：<code>max_depth = 5, min_child_weight = 1, gamma = 0, subsample, colsample_bytree = 0.8, scale_pos_weight = 1</code>，确定learning rate和estimator的数量 lr可先用0.1，用<code>xgboost.cv()</code>来寻找最优的estimators。</p><ul><li><code>max_depth, min_child_weight</code>: 首先将这两个参数设置为较大的数，通过迭代方式不断修正，缩小范围。max_depth每棵子树的最大深度，check from range(3,10,2)。min_child_weight子节点的权重阈值，check from range(1,6,2)。 如果一个结点分裂后，它的所有子节点的权重之和都大于该阈值，该叶子节点才可以划分。</li><li><code>gamma</code>: 最小划分损失min_split_loss，check from 0.1 to 0.5，对于一个叶子节点，当对它采取划分之后，损失函数的降低值的阈值。如果大于该阈值，则该叶子节点值得继续划分。如果小于该阈值，则该叶子节点不值得继续划分。</li><li><code>subsample, colsample_bytree</code>: subsample是对训练的采样比例，colsample_bytree是对特征的采样比例，both check from 0.6 to 0.9</li><li>正则化参数。alpha 是L1正则化系数，try 1e-5, 1e-2, 0.1, 1, 100。lambda 是L2正则化系数</li><li>降低学习率：降低学习率的同时增加树的数量，通常最后设置学习率为0.01~0.1</li></ul><h3 id="过拟合解决方案"><a href="#过拟合解决方案" class="headerlink" title="过拟合解决方案"></a>过拟合解决方案</h3><p>有两类参数可以缓解：</p><ol><li>用于直接控制模型的复杂度。包括max_depth,min_child_weight,gamma 等参数</li><li>用于增加随机性，从而使得模型在训练时对于噪音不敏感。包括subsample,colsample_bytree</li></ol><p>直接减小learning rate，但需要同时增加estimator参数。</p><h3 id="对缺失值不敏感"><a href="#对缺失值不敏感" class="headerlink" title="对缺失值不敏感"></a>对缺失值不敏感</h3><p>对存在缺失值的特征，一般的解决方法是：</p><ul><li>离散型变量：用出现次数最多的特征值填充；</li><li>连续型变量：用中位数或均值填充；</li></ul><p>一些模型如SVM和KNN，其模型原理中涉及到了对样本距离的度量，如果缺失值处理不当，最终会导致模型预测效果很差。而树模型对缺失值的敏感度低，大部分时候可以在数据缺失时时使用。原因是，一棵树中每个结点在分裂时，寻找的是某个特征的最佳分裂点（特征值），完全可以不考虑存在特征值缺失的样本，如果某些样本缺失的特征值缺失，对寻找最佳分割点的影响不是很大。</p><p>XGBoost对缺失数据有特定的处理方法, 因此，对于有缺失值的数据在经过缺失处理后：</p><ul><li>当数据量很小时，优先用朴素贝叶斯</li><li>数据量适中或者较大，用树模型，优先XGBoost</li><li>数据量较大，也可以用神经网络</li><li>避免使用距离度量相关的模型，如KNN和SVM</li></ul><h2 id="XGBoost和RF单棵树哪个更深？"><a href="#XGBoost和RF单棵树哪个更深？" class="headerlink" title="XGBoost和RF单棵树哪个更深？"></a>XGBoost和RF单棵树哪个更深？</h2><p>RF单颗树更深。Boosting主要关注降低偏差，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成；Bagging主要关注降低方差，因此它在不剪枝的决策树、神经网络等学习器上效用更为明显。<br>Bagging算法会并行地训练很多不同的分类器来降低方差variance：$E[h−E(h)]$,因为采用了相互独立的基分类器多了以后，h的值自然就会靠近E(h)。所以对于每个基分类器来说，目标就是降低偏差bias,所以会采用深度很深甚至不剪枝的决策树。对于Boosting来说，每一步会在上一轮的基础上更加拟合原数据，所以可以保证偏差bias,所以对于每个基分类器来说，问题就在于如何选择variance更小的分类器，即更简单的分类器，所以我们选择了深度很浅的决策树。</p><h2 id="XGBoost和GBDT"><a href="#XGBoost和GBDT" class="headerlink" title="XGBoost和GBDT"></a>XGBoost和GBDT</h2><ul><li>梯度提升决策树：都属于梯度提升决策树算法。集成学习方法，组合多个决策树逐步减小预测误差，提高模型性能。</li><li>目标函数：使用相同的目标函数，通过最小化残差的平方和优化模型。每一轮迭代中，都会构建一个新的决策树来拟合前面模型的残差，以纠正之前模型的预测误差。</li><li>特征工程：都支持类别型特征和缺失值的处理。在构建决策树时能自动处理类别型特征，不需要独热编码等转换。</li></ul><p>区别：</p><ul><li>基分类器：XGBoost基分类器不仅支持CART决策树，还支持线性分类器，此时XGBoost相当于带L1和L2正则化项的Logistic回归(分类问题)或者线性回归(回归问题)。</li><li>正则化策略：XGBoost引入正则化防止过拟合，包括L1和L2正则化控制模型的复杂度。</li><li>算法优化：XGBoost使用近似贪心算法选择最佳分裂点，使用二阶导数信息更精准逼近真实的损失函数，来提高模型的拟合能力。支持自定义损失函数，只要损失函数一阶、二阶可导，可扩展性好。</li><li>样本权重：XGBoost引入样本权重概念，对不同样本赋予不同权重，从而对模型训练产生不同影响。在处理不平衡数据集或处理样本噪声时非常有用。</li><li>并行计算：XGBoost在多个线程上同时进行模型训练，使用并行计算和缓存优化加速训练过程。不是tree维度的并行，而是特征维度的并行。XGBoost预先将每个特征按特征值排好序，存储为块结构，分裂结点时可以采用多线程并行查找每个特征的最佳分割点，极大提升训练速度。GBDT通常是顺序训练的，无法直接进行并行化。</li><li>列抽样：XGBoost支持列采样，与随机森林类似，用于防止过拟合。</li></ul><h2 id="XGBoost和LightGBM"><a href="#XGBoost和LightGBM" class="headerlink" title="XGBoost和LightGBM"></a>XGBoost和LightGBM</h2><ul><li>梯度提升决策树：都属于梯度提升决策树算法。集成学习方法，组合多个决策树逐步减小预测误差，提高模型性能。</li><li>特征工程：都支持类别型特征和缺失值的处理。在构建决策树时能自动处理类别型特征，不需要独热编码等转换。还能处理带缺失值的数据。</li><li>分布式训练：都支持分布式训练，可在分布式计算框架（如Spark）上运行。</li></ul><p>区别：</p><ul><li>算法速度：LightGBM在训练和预测速度上更快。LightGBM采用基于梯度的直方图决策树算法来加速训练过程，减少内存使用和计算复杂度。</li><li>内存占用：LightGBM具有更低的内存占用，适用于处理大规模数据集。使用了互斥特征捆绑算法和直方图算法来减少内存使用，提高了算法的扩展性。</li><li>正则化策略：都支持正则化策略来防止过拟合。XGBoost采用基于树的正则化（如最大深度、最小子样本权重等），LightGBM采用基于叶子节点的正则化（如叶子数、最小叶子权重等）。</li><li>数据并行和特征并行：XGBoost使用数据并行化，将数据划分为多个子集，每个子集在不同的计算节点上进行训练。LightGBM使用特征并行化，将特征划分为多个子集，每个子集在不同的计算节点上进行训练。</li></ul><ol><li>树生长策略：XGB采用level-wise(按层生长)的分裂策略，LGB采用leaf-wise的分裂策略。XGB对每一层所有节点做无差别分裂，但是可能有些节点增益非常小，对结果影响不大，带来不必要的开销。Leaf-wise是在所有叶子节点中选取分裂收益最大的节点进行的，但是很容易出现过拟合问题，所以需要对最大深度做限制 。</li><li>分割点查找算法：XGB使用特征预排序算法，LGB使用基于直方图的切分点算法，优势如下：<ul><li>减少内存占用，比如离散为256个bin时，只需要用8位整形就可以保存一个样本被映射为哪个bin(这个bin可以说就是转换后的特征)，对比预排序的exact greedy算法来说（用int_32来存储索引+ 用float_32保存特征值），可以节省7/8的空间。</li><li>计算效率提高，预排序的Exact greedy对每个特征都需要遍历一遍数据，并计算增益，复杂度为𝑂(#𝑓𝑒𝑎𝑡𝑢𝑟𝑒×#𝑑𝑎𝑡𝑎)。而直方图算法在建立完直方图后，只需要对每个特征遍历直方图即可，复杂度为𝑂(#𝑓𝑒𝑎𝑡𝑢𝑟𝑒×#𝑏𝑖𝑛𝑠)。</li><li>LGB还可以使用直方图做差加速，一个节点的直方图可以通过父节点的直方图减去兄弟节点的直方图得到，从而加速计算。实际上xgboost的近似直方图算法也类似于LGB这里的直方图算法，但xgboost的近似算法比LGB慢很多。XGB在每一层都动态构建直方图，XGB的直方图算法不是针对某个特定的feature，而是所有feature共享一个直方图(每个样本的权重是二阶导)，所以每一层都要重新构建直方图，而LGB中对每个特征都有一个直方图，所以构建一次直方图就够</li></ul></li><li>支持离散变量：XGB无法直接输入类别型变量，需要事先对类别型变量进行编码（如独热编码），而LightGBM可以直接处理类别型变量。</li><li>缓存命中率：XGB使用Block结构的缺点是取梯度时，是通过索引来获取的，而这些梯度的获取顺序是按照特征的大小顺序，导致非连续的内存访问，使得CPU cache缓存命中率低，影响算法效率。而LGB是基于直方图分裂特征的，梯度信息都存储在一个个bin中，所以访问梯度是连续的，缓存命中率高。</li><li>并行策略不同：<ul><li>特征并行 ：LGB特征并行的前提是每个worker留有一份完整的数据集，但是每个worker仅在特征子集上进行最佳切分点的寻找；worker之间需要相互通信，通过比对损失来确定最佳切分点；然后将这个最佳切分点的位置进行全局广播，每个worker进行切分即可。XGB的特征并行与LGB的最大不同在于XGB每个worker节点中仅有部分的列数据，也就是垂直切分，每个worker寻找局部最佳切分点，worker之间相互通信，然后在具有最佳切分点的worker上进行节点分裂，再由这个节点广播一下被切分到左右节点的样本索引号，其他worker才能开始分裂。二者的区别就导致了LGB中worker间通信成本明显降低，只需通信一个特征分裂点即可，而XGB中要广播样本索引。</li><li>数据并行 ：当数据量很大，特征相对较少时，可采用数据并行策略。LGB中先对数据水平切分，每个worker上的数据先建立起局部的直方图，然后合并成全局的直方图，采用直方图相减的方式，先计算样本量少的节点的样本索引，然后直接相减得到另一子节点的样本索引，这个直方图算法使得worker间的通信成本降低一倍，因为只用通信以此样本量少的节点。XGB中的数据并行也是水平切分，然后单个worker建立局部直方图，再合并为全局，不同在于根据全局直方图进行各个worker上的节点分裂时会单独计算子节点的样本索引，因此效率贼慢，每个worker间的通信量也就变得很大。</li><li>投票并行（LGB）：当数据量和维度都很大时，选用投票并行，该方法是数据并行的一个改进。数据并行中的合并直方图的代价相对较大，尤其是当特征维度很大时。大致思想是：每个worker首先会找到本地的一些优秀的特征，然后进行全局投票，根据投票结果，选择top的特征进行直方图的合并，再寻求全局的最优分割点。</li></ul></li></ol><p><a href="https://blog.csdn.net/weixin_44852067/article/details/126756120?spm=1001.2014.3001.5506">XGBoost面试题整理</a></p><h2 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h2><ul><li>定义：ROC曲线下的面积（横坐标为假阳性率FPR，纵坐标为真阳性率TPR/召回），ROC曲线对于模型预估的一个正例，如果真实标签是正例，就往上走，如果是负例，就往左走，遍历完所有样本形成的曲线就是ROC曲线。</li><li>含义：随机抽出一对样本（一个正样本，一个负样本），然后用训练得到的分类器来对这两个样本进行预测，预测得到正样本的概率大于负样本概率的概率。</li><li>计算方法：<ol><li>$AUC=\frac{\sum I(P<em>{正样本}, P</em>{负样本})}{M*N}$。在$M*N$对样本里（$M$和$N$分别表示正负样本的数量），统计正样本的预测概率大于负样本的预测概率的个数。</li><li>$AUC=\frac{\sum_{i\in 正样本}rank(i)-\frac{M(M+1)}{2}}{M*N}$。$rank(i)$表示按照预估概率升序排序后正样本$i$的排序编号。对预估概率得分相同，将其排序编号取平均作为新的排序编号。</li></ol></li><li>参考：<ul><li><a href="https://zhuanlan.zhihu.com/p/558301363">【回归基础】深入理解AUC指标</a></li><li><a href="https://blog.csdn.net/qq_22238533/article/details/78666436">AUC的计算方法</a></li></ul></li></ul><h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>激活函数的主要作用是引入非线性变换，没有激活函数，神经网络层数再多，也只是简单的线性变换，无法处理复杂任务。</p><ol><li>阶跃函数：用于二分类，但导数始终为0，不能用于反向传播，理论意义大于实际意义。</li><li>sigmoid函数：$f(x)=\frac{1}{1+e^{-x}}$，用于二分类，X靠近0的时候，一点小小的值变化也能引起Y很大变化，说明函数区域将数值推向极值，很适合二分类。X远离0时，X值变化对Y起作用很小，函数的导数变化也很小，在反向传播中几乎起不到更新梯度的作用；且sigmoid函数只能得到正值，在很多情况下不适用。</li><li>tanh函数：$f(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$，对sigmoid函数的改进，函数值在(-1, 1)之间，改善了sigmoid函数只能得到正值的缺点，其他特点与sigmoid函数一模一样。</li><li>ReLU函数：近年使用广泛，优点是当输入值是负值时，输出值为0，意味着一段时间内只有部分神经元被激活，神经网络的这种稀疏性使其变得高效且易于计算。但X小于0时函数梯度为0，意味着反向传播时权重得不到更新，那么正向传播过程中输出值为0的神经元永远得不到激活，变成了死神经元。</li><li>Leaky ReLU函数：解决了死神经元的问题。</li><li>Softmax函数：可以看作是用作多分类的激活函数，将神经网络的输出值变成概率。</li><li>线性激活函数：效果等同于未激活，在Keras中不激活时就是用f(x)=x这一激活函数。二分类时用sigmoid函数和tanh函数，但存在梯度消失问题时应避免使用这两种函数。ReLU函数适用于绝大多数情况，如果存在梯度不更新的问题时可以用Leaky ReLU函数替代。</li></ol><h2 id="Softmax函数及求导"><a href="#Softmax函数及求导" class="headerlink" title="Softmax函数及求导"></a>Softmax函数及求导</h2><p>Softmax函数通常用于多分类问题中，它将一个包含任意实数的 K 维向量（K 是类别数量）映射为一个概率分布，每个类别的预测概率值都在 0 到 1 之间，所有类别的概率总和为 1。Softmax函数的作用是将原始得分转换为概率值，使得模型的输出更符合实际的概率分布。函数公式：<script type="math/tex">S_i=\frac{e^{a_i}}{\sum ^K_{k=1} e^{a_k}}</script><br>其中，$a$ 是输入向量，上述公式表示第 $i$ 个类别的输出概率。函数求导分类讨论：</p><ul><li>当 $i=j$时：<script type="math/tex">\frac{\partial S_i}{\partial a_j}=\frac{e^{a_i}\sum-e^{a_j}e^{a_i}}{\sum ^2}=S_i-S_iS_j</script></li><li>当 $i\not =j$时：<script type="math/tex">\frac{\partial S_i}{\partial a_j}=\frac{0-e^{a_j}e^{a_i}}{\sum ^2}=-S_iS_j</script></li></ul><p><a href="https://blog.csdn.net/cassiePython/article/details/80089760">Softmax函数及其导数</a></p><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><ul><li>梯度下降法（Gradient Descent）：最基本最常用的优化算法。通过计算损失函数关于参数的梯度，以负梯度方向更新参数，使损失函数最小化。梯度下降法有多个变种，如批量梯度下降、随机梯度下降和小批量梯度下降。<ul><li>$g<em>t=▽f(θ</em>{t−1}), △θ_t=−η∗g_t$</li><li>批梯度下降：每次使用所有数据用于更新梯度，使得梯度总是朝着最小的方向更新，但数据量很大的时候更新速度太慢，容易陷入局部最优。</li><li>随机梯度下降：每次使用一条数据来更新梯度，在梯度更新过程中梯度可能上升也可能下降，但总的来说梯度还是朝着最低的方向前进；最后梯度会在极小值附近徘徊。随机梯度下降的梯度更新速度快于批梯度下降，且由于每次梯度的更新方向不确定，陷入局部最优的时候有可能能跳出该局部极小值。</li><li>mini-batch梯度下降：介于批梯度下降和随机梯度下降之间，每次用若干条数据更新梯度。mini-batch梯度下降可以使用矩阵的方式来计算梯度，因此速度快于随机梯度下降，且同样具有跳出局部最优的特点。</li></ul></li><li>动量优化器（Momentum）：引入动量项加速收敛过程。在参数更新时考虑之前的更新方向，在梯度方向上积累速度。如果本次梯度衰减方向与上一次相同，则可以加速梯度下降；如果不一致，则抑制梯度的改变。有助于在平坦区域中加快学习速度并减少震荡。<ul><li>$m<em>t=μ∗m</em>{t−1}+(1−μ)g_t$ </li><li>$△θ_t=−η∗m_t$</li></ul></li><li>自适应动量估计（Adaptive Moment Estimation，Adam）：基于一阶矩估计和二阶矩估计的自适应优化器。结合了动量和学习率衰减机制，并具有自适应学习率调整。在很多情况下能快速收敛。</li><li>自适应学习率优化器（Adagrad、RMSProp）：Adagrad和RMSProp是常用的自适应学习率优化器。Adagrad适应性地调整参数的学习率，对于稀疏梯度的问题表现较好。RMSProp通过指数加权平均的方式动态调整学习率，适用于非平稳或具有较大梯度变化的问题。用初始学习率除以通过衰减系数控制的梯度平方和的平方根，相当于给每个参数赋予了各自的学习率。梯度相对平缓的地方，累积梯度小，学习率会增大；梯度相对陡峭的地方，累积梯度大，学习率会减小。从而加速训练。<ul><li>RMSprop: $n<em>t=νn</em>{t−1}+(1−ν)g_t^2$</li><li>$△θ_t=−\frac{η}{\sqrt{n_t+ϵ}}*g_t$</li></ul></li><li>Adam：本质上是带有动量项的RMSprop，结合了两者的优点，可以为不同的参数计算不同的自适应学习率，实践中常用。<ul><li>$m<em>t=μm</em>{t−1}+(1−μ)g_t$</li><li>$n<em>t=νn</em>{t−1}+(1−ν)g_t^2$</li><li>$\hat m_t=\frac{m_t}{1−μ^t}$</li><li>$\hat n_t=\frac{n_t}{1−ν^t}$</li><li>$△θ_t=-\frac{η}{\sqrt{\hat n_t+ϵ}}$ </li></ul></li><li>AdamW：Adam的变种，主要用于解决权重衰减（weight decay）在Adam中的问题。在计算梯度更新时，将权重衰减的计算从梯度中分离出来，并将其应用于参数更新之前。使得权重衰减仅影响参数的更新方向，而不会降低参数的更新速度。优势在于更好地控制权重衰减的影响，减轻过度正则化的问题，使模型更易优化和训练。</li></ul><h2 id="残差连接"><a href="#残差连接" class="headerlink" title="残差连接"></a>残差连接</h2><p>Residual Connection跳跃连接技术，在模型中将输入信号与输出信号进行直接连接。作用：</p><ul><li>促进信息传递：使模型更容易传递信息和梯度，避免梯度消失或梯度爆炸，特别是在处理深层网络时。</li><li>简化优化问题：可以简化优化问题，使模型更易于优化和训练。</li><li>提高模型表达能力：允许模型保留更多的低层特征信息，使模型更好地捕捉输入序列中的细节和上下文信息。</li></ul><h2 id="DNN-CNN-RNN对比"><a href="#DNN-CNN-RNN对比" class="headerlink" title="DNN,CNN,RNN对比"></a>DNN,CNN,RNN对比</h2><div align="center">  <img src="DNN-CNN-RNN.png" height=45% width=45%></div><h2 id="池化层反向传播"><a href="#池化层反向传播" class="headerlink" title="池化层反向传播"></a>池化层反向传播</h2><p>反向传播在经过池化层的时候梯度的数量发生了变化。如2*2的池化操作，第L+1层梯度数量是L层的1/4，所以每个梯度要对应回4个梯度。</p><ul><li>mean_pooling：正向传播时取周围4个像素的均值，所以反向传播将梯度平均分成4分，再分给上一层。</li><li>max_pooling：正向传播时取周围4个像素的最大值保留，其余的值丢弃，所以反向传播时将梯度对应回最大值的位置，其他位置取0。一般来说，为了知道最大值的位置，深度学习框架在正向传播时就用max_id来记录4个像素中最大值的位置。</li></ul><h2 id="浅层、深层神经网络差别"><a href="#浅层、深层神经网络差别" class="headerlink" title="浅层、深层神经网络差别"></a>浅层、深层神经网络差别</h2><p>神经网络中，权重参数是给数据做线性变换，而激活函数给数据带来的非线性变换。增加某一层神经元数量是在增加线性变换的复杂性，而增加网络层数是在增加非线性变换的复杂性。理论上，浅层神经网络就能模拟任何函数，但需要巨大的数据量，而深层神经网络可以用更少的数据量来学习到更好的拟合。</p><h2 id="防止过拟合-1"><a href="#防止过拟合-1" class="headerlink" title="防止过拟合"></a>防止过拟合</h2><p>过拟合是模型学习能力太强大，把部分数据的不太一般的特性都学到了，并当成了整个样本空间的特性。防过拟合方法：</p><ul><li>L2正则化。原loss是$L_0$，加入L2正则化后loss是$L_0+\frac{\lambda}{2n}||W||^2$，L的梯度是$\frac{\partial{L}}{\partial{W}}=\frac{\partial{L_0}}{\partial{W}}+\frac{\lambda}{n}{W}$，$\frac{\partial{L}}{\partial{b}}=\frac{\partial{L_0}}{\partial{b}}$,可以看出，L2正则化只对W有影响，对b没有影响。而加入L2正则化后的梯度更新：$W=W-\alpha(\frac{\partial{L_0}}{\partial{W}}+\frac{\lambda}{n}{W})=(1-\frac{\alpha\lambda}{n})W-\alpha\frac{\partial{L_0}}{\partial{W}}$，相比于原梯度更新公式，改变的是$(1-2\alpha\lambda)W$这里，而由于$\alpha、\lambda、n$都是正数，所以$(1-\frac{\alpha\lambda}{n})&lt;1$。因此，L2正则化使得反向传播更新参数时W参数比不添加正则项更小。在过拟合中，由于对每个数据都拟合得很好，所以函数的变化在小范围内往往很剧烈，而要使函数在小范围内剧烈变化，就是要W参数值很大。L2正则化抑制了这种小范围剧烈变化，使得拟合程度“刚刚好”。</li><li>L1正则化。原loss是$L_0$，加入L1正则化后loss是$L=L_0+\frac{\lambda}{n}|W|$, L的梯度是$\frac{\partial{L}}{\partial{W}}=\frac{\partial{L_0}}{\partial{W}}+\frac{\lambda}{n}|W|$,$\frac{\partial{L}}{\partial{b}}=\frac{\partial{L_0}}{\partial{b}}$, 可以看出，L1正则化只对W有影响，对b没有影响。而加入L1正则化后的梯度更新：$W=W-\alpha(\frac{\partial{L_0}}{\partial{W}}+\frac{\lambda}{n}{|W|})=W-\frac{\lambda}{n}|W|-\alpha\frac{\partial{L_0}}{\partial{W}}$, 如果W为正，相对于原梯度就减小；如W为负，相对于原梯度就增大。所以，L1正则化使得参数W在更新时向0靠近使得参数W具有稀疏性。而权重趋近0，也就相当于减小了网络复杂度，防止过拟合。</li><li>Dropout。每次训练时，有一部分神经元不参与更新，而且每次不参与更新的神经元是随机的。随着训练的进行，每次用神经元就能拟合出较好的效果，少数拟合效果不好的也不会对结果造成太大的影响。</li><li>增大数据量。过拟合是学习到了部分数据集的特有特征，那么增大数据集就能有效的防止这种情况出现。</li><li>Early stop。数据分为训练集、验证集和测试集，每个epoch后都用验证集验证一下，如果随着训练的进行训练集loss持续下降，而验证集loss先下降后上升，说明出现了过拟合，应该立即停止训练。</li><li>Batch Normalization。每次都用一个mini_batch的数据来计算均值和反差，这与整体的均值和方差存在一定偏差，从而带来了随机噪声，起到了与Dropout类似的效果，从而减轻过拟合。</li><li>L1 / L2对比：<ul><li>L1（拉格朗日Lasso）正则假设参数先验分布是Laplace分布，可以使权重稀疏，保证模型的稀疏性，某些参数等于0，产生稀疏权值矩阵，用于特征选择；</li><li>L2（岭回归Ridge）正则假设参数先验分布是Gaussian分布，可以使权重平滑，保证模型的稳定性，也就是参数的值不会太大或太小。</li><li>在实际使用中，如果特征是高维稀疏的，则使用L1正则；如果特征是低维稠密的，则使用L2正则</li></ul></li></ul><h2 id="BN层的计算"><a href="#BN层的计算" class="headerlink" title="BN层的计算"></a>BN层的计算</h2><p>神经网络反向传播后每一层的参数都会发生变化，在下一轮正向传播时第 $l$ 层的输出值 $Z^l=W\cdot{A}^{l-1}+b$ 也会发生变化，导致第 $l$ 层的 $A^l=relu(Z^l)$ 发生变化。而 $A^l$ 作为第 $l+1$ 层的输入， $l+1$ 就需要去适应适应这种数据分布的变化，这就是神经网络难以训练的原因之一。<br>为此，Batch Normalization的做法是调整数据的分布来改变这一现象，具体做法如下：</p><ul><li>训练: 一般每次训练数据都是一个batch，假设 $m=batch_size$，则：<ol><li>计算各个特征均值 $\mu=\frac{1}{m}\sum_{i=1}^{m}z^i$，其中 $z^i$ 表示第 $i$ 条数据</li><li>计算方差 $\sigma^2=\frac{1}{m}\sum_{i=1}^{m}(z^i-\mu)^2$</li><li>归一化后的 $Z_{norm}^i=\frac{z^i-\mu}{\sqrt{\sigma^2+\epsilon}}$，$\epsilon$ 表示一个极小值，防止计算出现Nan</li><li>这样调整分布后能加速训练，但之前层学习到的参数信息可能会丢失，所以加入参数 $\gamma$、$\beta$ 调整： $\widetilde{Z}^i=\gamma{Z_{norm}^i}+\beta$</li></ol></li><li>反向传播: <script type="math/tex; mode=display">\frac{\partial{L}}{\partial{Z_{norm}^i}}=\frac{\partial{L}}{\partial{\widetilde{Z}^i}}\lambda</script><script type="math/tex; mode=display">\frac{\partial{L}}{\partial\lambda}=\frac{\partial{L}}{\partial{\widetilde{Z}^i}}Z_{norm}^i</script><script type="math/tex; mode=display">\frac{\partial{L}}{\partial\beta}=\frac{\partial{L}}{\partial{\widetilde{Z}^i}}</script><script type="math/tex; mode=display">\frac{\partial{L}}{\partial\sigma^2}=\frac{\partial{L}}{\partial{Z_{norm}^i}}\frac{\partial{Z_{norm}^i}}{\partial\sigma^2}=\frac{\partial{L}}{\partial{Z_{norm}^i}}(-\frac{1}{2})(\sigma^2+\epsilon)^{\frac{-3}{2}}</script><script type="math/tex; mode=display">\frac{\partial{L}}{\partial\mu}=\frac{\partial{L}}{\partial{Z_{norm}^i}}\frac{\partial{Z_{norm}^i}}{\partial\mu}+\frac{\partial{L}}{\partial\sigma^2}\frac{\partial{\sigma^2}}{\partial{\mu}}=\frac{\partial{L}}{\partial{Z_{norm}^i}}\frac{-1}{\sqrt{\sigma^2+\epsilon}}+\frac{\partial{L}}{\partial\sigma^2}\frac{-2\sum_{i=1}^{m}(z^i-\mu)}{m}</script><script type="math/tex; mode=display">\frac{\partial{L}}{\partial{Z^i}}=\frac{\partial{L}}{\partial{Z_{norm}^i}}\frac{\partial{Z_{norm}^i}}{\partial{Z^i}}+\frac{\partial{L}}{\partial\sigma^2}\frac{\partial{\sigma^2}}{\partial{Z^i}}+\frac{\partial{L}}{\partial\mu}\frac{\partial\mu}{\partial{Z^i}}=\frac{\partial{L}}{\partial{Z_{norm}^i}}\frac{1}{\sqrt{\sigma^2+\epsilon}}+\frac{\partial{L}}{\partial\sigma^2}\frac{2(Z^i-\mu)}{m}+\frac{\partial{L}}{\partial\mu}\frac{1}{m}</script></li><li>测试: 测试时一般每次只送入一个数据，计算其均值和方差都是有偏估计，但训练过程中保存了每一组batch每一层的均值和方差，则对每一层都可以使用均值和方差的无偏估计：<script type="math/tex; mode=display">\mu_{test}=E(\mu_{batch})</script><script type="math/tex; mode=display">\sigma^2_{test}=\frac{m}{m-1}E(\sigma^2_{batch})</script>然后计算该层的输出：$\widetilde{Z}^i=\gamma{\frac{Z^i<em>{test}-\mu}{\sqrt{\sigma</em>{test}^2+\epsilon}}}+\beta$</li><li>加在哪里: 原始论文中加在激活函数前面，但改论文部分作者主张加在激活函数后面，从实践上来说也是加在激活函数后面效果更好。</li><li>局限: 实验表明，当batch_size小于8时，BN反而会带来负面作用；不适用于RNN</li></ul><h2 id="负梯度方向是函数局部值最快的方向"><a href="#负梯度方向是函数局部值最快的方向" class="headerlink" title="负梯度方向是函数局部值最快的方向"></a>负梯度方向是函数局部值最快的方向</h2><p>假设存在函数f(x)，l是任意方向的单位向量，要现在的目的就是要找到一个l使得f(x+l)−f(x)的变化值最大。根据公式有$f(x+l)-f(x)=<grad_f, l>$，所以原问题变为找到l使得$|grad_f|<em>|l|</em>cos(\theta)$最大，其中θ是 l与$grad_f$的夹角），很明显$\theta=0$时该值最大，也就是说l方向就是$grad_f$的方向，从而证明梯度方向是使得函数局布值变化最快的方向。</p><h2 id="softmax-loss和cross-entropy"><a href="#softmax-loss和cross-entropy" class="headerlink" title="softmax loss和cross entropy"></a>softmax loss和cross entropy</h2><p>输入数据经过神经网络后得到的logits是一个[n, 1]向量（n表示进行n分类），此时向量中的数字可以是负无穷到正无穷的任意数字，经过softmax函数后才转换为概率。交叉熵函数形式与softmax loss函数几乎一样，当cross entropy的输入是softmax函数函数的输出时，二者就完全一样。将网络输出的预测值logit先用使用Softmax转换为预测概率值再传入 Cross Entropy Loss，就得到了最终的Softmax Loss。</p><ul><li>softmax: $P<em>i=\frac{e^i}{\sum</em>{k=1}^{n}e^k}$</li><li>softmax loss:$L=-\sum_{i=1}^{n}y_ilogp_i$</li><li>cross entropy:$L=-\sum_{i=1}^{n}y_ilogp_i$</li><li>logistic regression: $L=-y_ilogp_i-(1-y_i)log(1-p_i)$</li></ul><h2 id="全连接层作用"><a href="#全连接层作用" class="headerlink" title="全连接层作用"></a>全连接层作用</h2><ol><li>“分类”，将卷积层提取到的特征进行维数调整，同时融合各通道之间的信息。</li><li>在迁移学习的过程中，有全连接层的模型比没有全连接层的表现更好。</li></ol><h2 id="RNN和LSTM"><a href="#RNN和LSTM" class="headerlink" title="RNN和LSTM"></a>RNN和LSTM</h2><p>RNN的优缺点：</p><ul><li>优点：<ul><li>参数共享： RNN在每个时间步都使用相同的参数，因此在训练和预测时具有较小的计算负担。 </li><li>灵活性： RNN可以处理各种长度的序列输入，并且可以用于不同的任务，如语言模型、时间序列预测等。</li></ul></li><li>缺点：<ul><li>梯度消失或爆炸： RNN在处理长期依赖关系时容易出现梯度消失或爆炸的问题，导致难以捕捉远距离的依赖关系。</li><li>短期记忆限制： RNN的短期记忆相对较弱，难以有效地记住较长的历史信息。</li></ul></li></ul><p>LSTM的优缺点：</p><ul><li>优点：<ul><li>长期依赖关系： LSTM通过门控机制（遗忘门、输入门、输出门）有效地解决了长期依赖问题，能够更好地捕捉长距离的序列依赖关系。</li><li>记忆单元： LSTM引入了记忆单元，可以保留和更新信息，有助于记住长序列中的重要信息。</li><li>防止梯度消失： LSTM通过门控机制可以更有效地控制梯度的流动，减少了梯度消失或爆炸的问题。</li></ul></li><li>缺点：<ul><li>计算复杂度高： LSTM相对于普通的RNN计算量更大，因为它包含更多的门控单元和参数。</li><li>可能出现过拟合： LSTM模型相对复杂，可能在小样本数据上容易出现过拟合的情况。</li></ul></li></ul><h2 id="Transformer相对LSTM的优势"><a href="#Transformer相对LSTM的优势" class="headerlink" title="Transformer相对LSTM的优势"></a>Transformer相对LSTM的优势</h2><ul><li>Transformer更快，对较长的序列建模效果更好，减少了对顺序信息的依赖性，不需要前面的信息来更新后面的隐状态。Transformer能更好的处理长期依赖问题，使得它在生成式任务中的表现尤为突出。</li><li>Transformer需要更多的数据来训练。但是transformer并行训练，速度更快；用更多的数据训练lstm，表现却不会再提升，上限低；很多efficient transformer减少了计算复杂度，或者加入一些先验信息来减少对预训练的依赖，都取得了很好的performance。</li></ul><h2 id="RNN不用Relu要用tanh函数？"><a href="#RNN不用Relu要用tanh函数？" class="headerlink" title="RNN不用Relu要用tanh函数？"></a>RNN不用Relu要用tanh函数？</h2><p>CNN中用ReLU函数能解决梯度消失的问题是因为Relu函数梯度为1，能解决梯度爆炸的问题是因为反向传播时W互不相同，它们连乘很大程度上能抵消梯度爆炸的效果；而RNN中用Relu是若干个W连乘，不能解决梯度爆炸的问题。所以想要解决RNN中的梯度消失问题，一般都是用LSTM。</p><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>一种基于自注意力机制的序列到序列（Sequence-to-Sequence）模型，用于处理NLP任务，解决长依赖问题和并行计算效率的平衡。相比于RNN模型Transformer使用全局的自注意力机制，使模型可以同时关注输入序列的所有位置，更好地捕捉长距离依赖关系。Transformer引入多头注意力机制提高了模型的表达能力。Transformer两个关键组件组成：Encoder和Decoder。编码器将输入序列编码为一系列上下文相关的表示，解码器用这些表示生成目标序列。</p><ul><li>编码器，输入序列经过多层自注意力层和前馈神经网络层处理。自注意力层中输入序列的每个位置都与其他位置进行注意力计算，以获取位置之间的相关性。使得模型能够在不同位置之间建立上下文关联，能够处理长距离的依赖关系。</li><li>解码器，除自注意力层和前馈神经网络层，还包含一个编码器-解码器注意力层。交叉注意力层将编码器中的信息与解码器的当前位置关联，在生成目标序列时获得更好的上下文信息。</li><li>Transformer端到端训练，最大化目标序列的条件概率来进行模型优化。训练中使用掩码注意力（Masked Attention）确保解码器只能看到当前位置之前输入，避免信息泄露。</li></ul><p>Transformer优点：</p><ul><li>能处理长距离依赖关系，适用于处理包含长序列的任务。</li><li>并行计算效率高，使得模型在GPU上能够进行高效训练和推理。</li><li>具有较好的表示能力和泛化能力，在多个NLP任务上取得了优异的性能。<br>Transformer对大规模数据和计算资源的需求较高，对某些任务可能需要更多的参数调优和数据预处理。</li></ul><h3 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h3><p>单词在句子中的位置以及排列顺序是非常重要的，引入词序信息有助于理解语义。循环神经网络本身就是一种顺序结构，天生就包含了词在序列中的位置信息。当抛弃循环神经网络结构，完全采用Attention取而代之，这些词序信息就会丢失，模型就没有办法知道每个词在句子中的相对和绝对的位置信息。因此有必要把词序信号加到词向量上帮助模型学习这些信息，位置编码（Positional Encoding）就是用来解决这种问题的方法。</p><p>好的位置编码方案需满足：</p><ol><li>能为每个时间步输出一个独一无二的编码；</li><li>不同长度的句子之间，任何两个时间步之间的距离应该保持一致；</li><li>模型应该能毫不费力地泛化到更长的句子。它的值应该是有界的；</li><li>必须是确定性的。</li></ol><p>Transformer位置编码不是单一的一个数值，而是包含句子中特定位置信息的d维向量（非常像词向量）。编码没有整合进模型，而是用这个向量让每个词具有它在句子中的位置的信息。换句话说，通过注入词的顺序信息来增强模型输入。<br>把512维的向量两两一组，每组都是一个sin和一个cos，这两个函数共享同一个频率 $w_i$，共256组，从0开始编号，最后一组编号是255。sin/cos函数的波长（由$w_i$决定）则从 2π 增长到 2π * 10000。位置编码性质：</p><ul><li>两个位置编码的点积(dot product)仅取决于偏移量 △t，也即两个位置编码的点积可以反应出两个位置编码间的距离。</li><li>位置编码的点积是无向的，即$PE<em>t^T*PE</em>{t+△t}=PE<em>t^T*PE</em>{t-△t}$</li></ul><p><a href="https://zhuanlan.zhihu.com/p/454482273">Transformer学习笔记一：Positional Encoding（位置编码）</a><br><a href="https://zhuanlan.zhihu.com/p/106644634">一文读懂Transformer模型的位置编码</a></p><h3 id="head降维"><a href="#head降维" class="headerlink" title="head降维"></a>head降维</h3><p>Transformer的多头注意力看上去是借鉴了CNN中同一卷积层内使用多个卷积核的思想，原文中使用 8 个“scaled dot-product attention”，在同一“multi-head attention”层中，输入均为“KQV”，同时进行注意力的计算，彼此之前参数不共享，最终将结果拼接起来，这样可以允许模型在不同的表示子空间里学习到相关的信息。即希望每个注意力头只关注最终输出序列中一个子空间，互相独立。核心思想在于抽取到更加丰富的特征信息。如果只使用 one head 并且维度为 $d<em>{model}$ ，相较于 8 head 并且维度为 $d</em>{model} / 8$，存在高维空间下学习难度较大的问题，文中实验也证实了这一点，于是将原有的高维空间转化为多个低维子空间并再最后进行拼接，取得了更好的效果，十分巧妙。</p><p><a href="https://www.zhihu.com/question/350369171">transformer中multi-head attention中每个head为什么要进行降维？</a></p><h3 id="自注意力比例系数"><a href="#自注意力比例系数" class="headerlink" title="自注意力比例系数"></a>自注意力比例系数</h3><p>$d_k$是词向量/隐藏层的维度，Q<em>K的维度也是$d_k$，Q</em>K越大，相乘后的varience越大，除以$d_k$来平衡。</p><ol><li>除以根号$d_k$防止输入softmax的值过大，导致偏导数趋近于0</li><li>选择根号$d_k$可以使得Q*K的结果满足期望为0，方差为1的分布，类似于归一化。</li></ol><h3 id="预测与推理阶段都使用mask原因"><a href="#预测与推理阶段都使用mask原因" class="headerlink" title="预测与推理阶段都使用mask原因"></a>预测与推理阶段都使用mask原因</h3><ul><li>训练阶段：训练时计算loss，是用当前decoder输入所有单词对应位置的输出$y_1,y_2,…,y_t$与真实的翻译结果ground truth去分别算cross entropy loss，然后把t个loss加起来，如果使用self-attention，那么$y_1$这个输出里包含了$x_1$右侧单词信息（包含要预测下一个单词$x_2$的信息），用到了未来信息，属于信息泄露。</li><li>预测阶段：预测阶段要保持重复单词预测结果是一样的，这样不仅合理，而且可以增量更新（预测时会选择性忽略重复的预测词，只摘取最新预测的单词拼接到输入序列中），如果关掉dropout，那么当预测序列是$x_1, x_2, x_3$时的输出结果，应该是和预测序列是$x_1, x_2, x_3, x_4$的前3个位置结果是一样的（增量更新）；同时与训练时的模型架构保持一致，前向传播的方式是一致的。</li></ul><p><a href="https://zhuanlan.zhihu.com/p/419748171">从训练和预测角度来理解Transformer中Masked Self-Attention的原理</a></p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p><a href="https://zhuanlan.zhihu.com/p/179959751">通过pytorch深入理解transformer中的自注意力(self attention)</a></p><h2 id="BERT和GPT区别"><a href="#BERT和GPT区别" class="headerlink" title="BERT和GPT区别"></a>BERT和GPT区别</h2><p>二者都是采用「预训练+微调」的范式，</p><ul><li>BERT：几乎就是为「无监督预训练+下游任务微调」的范式量身定制的模型。BERT使用的掩码语言模型任务没有生成文本的能力，但换来的是双向编码的能力，这让模型拥有了更强的文本编码性能。主要用于解决语言理解相关的任务，如问答、语义关系抽取等。BERT更适用于在已有标注数据上微调的场景。</li><li>GPT：基于生成式预训练的思想开发，为了保留生成文本的能力，只能采用单向编码。主要用于解决语言生成相关的任务，如文本生成、机器翻译等。GPT更适用于在大量未标注数据上预训练的场景。</li></ul><h2 id="深度学习模型和树模型的优缺点"><a href="#深度学习模型和树模型的优缺点" class="headerlink" title="深度学习模型和树模型的优缺点"></a>深度学习模型和树模型的优缺点</h2><p>深度学习模型的优缺点：</p><ul><li>优点：<ul><li>擅长处理复杂数据： 对于大规模数据、高维数据和非线性关系，深度学习模型通常能够提供更好的拟合能力。</li><li>特征学习能力强： 能够自动学习和提取数据的特征，减少对特征工程的需求。</li><li>泛化能力强： 在大数据集上训练时，深度学习模型可能会产生更好的泛化效果，适用于更广泛的场景。</li></ul></li><li>缺点：<ul><li>需要大量数据和计算资源： 深度学习模型对于大规模数据集和复杂模型的训练需要大量的数据和高性能计算资源。</li><li>需要调参和调优： 模型架构复杂，需要仔细调整超参数和优化模型结构。</li><li>可解释性差</li></ul></li></ul><p>树模型的优缺点：</p><ul><li>优点：<ul><li>易解释性强：能够直观地展示特征重要性和决策过程。</li><li>对少量数据处理得当： 在数据较少或者数据质量较差的情况下，树模型表现通常较好。</li><li>训练和预测速度快： 相对于深度学习模型，树模型的训练速度快，适合于处理中小规模的数据集。</li></ul></li><li>缺点：<ul><li>容易过拟合： 在某些情况下，树模型容易过拟合，尤其是当树的深度较大或没有采用适当的剪枝措施时。</li><li>不擅长处理复杂关系： 对于复杂的非线性关系，树模型可能不如深度学习模型表现得好。</li><li>需要人工特征工程： 对于传统的决策树模型，通常需要手动进行特征工程，挑选和构建合适的特征。</li></ul></li></ul><h1 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h1><h2 id="图像处理中一般用最大池化而不用平均池化"><a href="#图像处理中一般用最大池化而不用平均池化" class="headerlink" title="图像处理中一般用最大池化而不用平均池化"></a>图像处理中一般用最大池化而不用平均池化</h2><p>池化的主要目的：</p><ol><li>保持主要特征不变的同时减小了参数</li><li>保持平移、旋转、尺度不变性，增强了神经网络的鲁棒性</li></ol><p>最大池化更能捕捉图像上的变化、梯度的变化，带来更大的局部信息差异化，从而更好地捕捉边缘、纹理等特征。</p><h2 id="计算感受野"><a href="#计算感受野" class="headerlink" title="计算感受野"></a>计算感受野</h2><p>卷积层(conv)和池化层(pooling)都会影响感受野,激活函数层通常对于感受野没有影响,当前层的步长并不影响当前层的感受野,感受野和填补(padding)没有关系, 计算当层感受野的公式如下: </p><script type="math/tex; mode=display">RF_{i+1}=RF_i+(k-1) \times S_i</script><p>其中, $RF_{i+1}$ 表示当前层的感受野,  $RF_i$ 表示上一层的感受野, $k$ 表示卷积核的大小, $S_i$ 表示之前所有层的步长的乘积(不包括本层),公式如下: </p><script type="math/tex; mode=display">S_i=\prod^i_{i+1}Stride_i</script><p><a href="https://zhuanlan.zhihu.com/p/113487374">感受野(Receptive Field)的理解与计算</a></p><h1 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h1><h2 id="径向基函数神经网络"><a href="#径向基函数神经网络" class="headerlink" title="径向基函数神经网络"></a>径向基函数神经网络</h2><p>Radial Basis Function NN一种基于人工神经网络的模型，使用径向基函数作为激活函数。通常由三层组成：输入层、隐藏层和输出层。隐藏层神经元的径向基函数将输入数据映射到高维特征空间。常用径向基函数包括高斯函数、多项式函数和超球函数等。RBFNN训练过程分为两步：中心点选择和权重计算。中心点选择通过一定的聚类方法确定隐藏层神经元的中心点，常见方法包括k-means聚类和高斯混合模型。权重计算通过解线性方程组来确定隐藏层神经元与输出层之间的连接权重，可使用最小二乘法或正则化方法进行求解。相比于传统前馈神经网络的优势：</p><ul><li>非线性逼近能力强：径向基函数的使用使RBFNN更好逼近非线性函数和复杂的数据分布。</li><li>适应性好：对输入数据的分布没有要求，适用于各种类型的数据。</li><li>快速训练：训练通常比传统神经网络更快，因为隐藏层神经元的权重可以通过解线性方程组来直接计算。</li></ul><p>挑战和注意事项：</p><ul><li>中心点选择的准确性对网络性能至关重要，不当的中心点选择可能导致网络性能下降。</li><li>隐藏层神经元数量选择是一个关键问题，过多神经元可能过拟合，过少神经元无法充分表示数据复杂性。</li><li>RBFNN的结构和训练过程相对复杂，需要合理的参数选择和调优，以及适当的数据预处理和特征选择。</li></ul><h2 id="因果森林"><a href="#因果森林" class="headerlink" title="因果森林"></a>因果森林</h2><p>Causal Forest一种用于因果推断的基于决策树的集成学习算法，旨在从观测数据中推断出因果关系。通过构建多个决策树（回归树）模型来估计因果效应，并将它们组合起来得到最终的因果估计结果。每个决策树模型都在不同的数据子集上训练，可以捕捉到不同的因果关系。算法步骤：</p><ul><li>数据准备：从观测数据中选出一个特征作为因果变量（Treatment），一个或多个特征作为响应变量（Outcome），以及其他可能的特征作为控制变量（Covariates）。</li><li>决策树训练：对每棵决策树，用因果变量和控制变量作为输入特征，响应变量作为目标进行训练。决策树的切分规则和叶子节点的取值根据因果效应优化。</li><li>因果效应估计：对于每个观测样本，通过在决策树中预测，得到不同因果变量取值下的响应变量预测值。计算因果效应作为不同因果变量取值下的响应变量预测值的差异。</li><li>因果估计的组合：将多棵决策树的因果效应估计结果进行组合，通常采用简单或加权平均方式。最终得到的组合结果作为因果效应的估计。</li></ul><p>因果森林算法优势：可以处理高维、非线性和交互效应等复杂情况，对于处理隐藏的混淆变量也较为有效。能够在不倚赖任何预设模型前提下，从数据中自动推断因果效应。<br>限制：对于因果变量和响应变量之间的非线性关系可能存在一定的限制。此外，算法的性能和效果也受到数据质量、样本量和特征选择等因素的影响。</p><h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h2><p>数据预处理：按照control数据量是treatment数据量10倍随机采样，并根据<code>0&lt;diff_cvr&lt;=0.4</code>对原数据（obs）进⾏筛选，<br>PSI公式： <code>psi = sum((实际占比-预期占比) * ln(实际占比/预期占比))</code>。psi小于0.1时变量稳定性很高。群体稳定性指标PSI(Population Stability Index)是衡量模型的预测值与实际值偏差大小的指标。<br>收益评估 <code>ROI = delta收益 / delta投资 = tau / cvr1</code></p><h1 id="大数据处理"><a href="#大数据处理" class="headerlink" title="大数据处理"></a>大数据处理</h1><h2 id="Spark的核心构件"><a href="#Spark的核心构件" class="headerlink" title="Spark的核心构件"></a>Spark的核心构件</h2><p>Spark是一个通用的、分布式计算框架，用于大规模数据处理和分析。它提供了许多核心构件用于构建高性能、可扩展的分布式应用程序。核心构件：</p><ul><li>基础模块Spark Core，提供分布式任务调度、内存管理、错误恢复、存储管理和与底层资源管理系统的交互等功能。定义了RDD（弹性分布式数据集）抽象，支持数据的并行处理和分布式计算。</li><li>Spark SQL，用于处理结构化数据。提供了对结构化数据的高级查询、SQL查询、数据集的操作和集成的机器学习功能。Spark SQL支持多种数据源，包括Hive、Avro、Parquet等，并提供了DataFrame和DataSet两种API。</li><li>流处理模块Spark Streaming，用于实时数据的处理和分析。支持从各种数据源（如Kafka、Flume、HDFS等）读取实时数据流，并提供高级API来进行数据处理和转换。Spark Streaming使用微批处理的方式，将实时数据划分为小批量进行处理，实现低延迟的流处理。</li><li>机器学习库MLlib，提供一组分布式的机器学习算法和工具。包括常见机器学习算法（如分类、回归、聚类、推荐等），特征提取、模型评估和调优等功能。MLlib支持使用DataFrame和DataSet进行数据操作和特征工程，并提供分布式计算能力。</li><li>图处理库GraphX，用于处理大规模图数据。提供图的创建、转换、操作和算法等功能，支持基于顶点和边属性的图分析。GraphX提供高效的分布式图计算引擎，与Spark其他模块集成，使图计算和图分析更加高效和灵活。</li><li>Spark还提供了一些其他扩展模块和工具，如SparkR（用于R语言的接口）、Spark on Kubernetes（在Kubernetes上运行Spark应用程序）等。</li></ul><h2 id="Spark数据倾斜"><a href="#Spark数据倾斜" class="headerlink" title="Spark数据倾斜"></a>Spark数据倾斜</h2><p>原理：在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，如按照key聚合或join。如果某个key对应的数据量特别大的话，就会发生数据倾斜。整个Spark作业的运行进度是由运行时间最长的那个task决定的。</p><p>原因：常用的且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。出现数据倾斜时，可能是代码中使用了这些算子中的某一个所导致的。</p><p>解决方案：由于Spark都是基于RDD的特性，所以可以用纯RDD的方法，实现和Spark SQL一模一样的功能。在Spark Core中的数据倾斜的七种解决方案，全部都可以直接套用在Spark SQL上。</p><ol><li>聚合源数据：<ul><li>原理：使用 Hive ETL 预处理数据，对数据按照key进行聚合，或预先和其他表进行join，然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表。此时由于数据已经预先进行过聚合或join，在Spark作业中就不需要使用原先的shuffle类算子执行这类操作。</li><li>优点：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。</li><li>缺点：治标不治本，Hive ETL中还是会发生数据倾斜。</li></ul></li><li>过滤导致倾斜的key：在sql中用where条件<ul><li>原理： 动态判定哪些key的数据量最多然后再进行过滤，可以使用sample算子对RDD进行采样，计算出每个key的数量，取数据量最多的key过滤掉即可。</li><li>优点：实现简单，效果好，可以完全规避掉数据倾斜。</li><li>缺点：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。s</li></ul></li><li>提高shuffle并行度：groupByKey(1000)，spark.sql.shuffle.partitions（默认是200）<ul><li>原理：该参数设置了shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，如group by、join需要设置一个参数，即spark.sql.shuffle.partitions，代表了shuffle read task的并行度。增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。</li><li>优点：实现起来简单，可以有效缓解和减轻数据倾斜的影响。</li><li>缺点：只是缓解了数据倾斜，没有彻底根除问题，效果有限。</li></ul></li><li>两阶段聚合（局部聚合+全局聚合）：双重groupBy，改写SQL，两次groupBy<ul><li>原理：将原本相同的key通过附加随机前缀的方式，变成多个不同的key，可以让原本被一个task处理的数据分散到多个task上去做局部聚合，解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，得到最终的结果。</li><li>优点：对于聚合类的shuffle操作导致的数据倾斜，效果不错。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。</li><li>缺点：仅仅适用于聚合类的shuffle操作，适用范围较窄。如果是join类的shuffle操作，还得用其他的解决方案。</li></ul></li><li>reduce join转换为map join：<ul><li>原理：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用需要的方式连接起来。</li><li>优点：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。</li><li>缺点：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。需要将小表进行广播会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。</li></ul></li><li>采样倾斜key并分拆join操作：纯Spark Core的一种方式，sample、filter等算子<ul><li>原理：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。</li><li>优点：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。</li><li>缺点：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，这种方式也不适合。</li></ul></li><li>使用随机前缀和扩容RDD进行join<ul><li>原理：将原先一样的key通过附加随机前缀变成不一样的key，然后就可以将这些处理后的“不同key”分散到多个task中去处理，而不是让一个task处理大量的相同key。该方案与“解决方案六”的不同之处就在于，上一种方案是尽量只对少数倾斜key对应的数据进行特殊处理，由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能对整个RDD进行数据扩容，对内存资源要求很高。</li><li>优点：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。</li><li>缺点：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。</li></ul></li></ol><p><a href="https://zhuanlan.zhihu.com/p/441715583">万字详解 Spark 数据倾斜及解决方案</a></p><h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>MapReduce是hadoop的核心组件之一，hadoop要分布式包括两部分，一是分布式文件系统hdfs,一是分布式计算框，就是MapReduce。MapReduce的思想就是“分而治之”。</p><ul><li>Mapper负责“分”，把复杂的任务分解为若干个“简单的任务”来处理。“简单的任务”包含三层含义：一是数据或计算的规模相对原任务要大大缩小；二是就近计算原则，即任务会分配到存放着所需数据的节点上进行计算；三是这些小任务可以并行计算，彼此间几乎没有依赖关系。</li><li>Reducer负责对map阶段的结果进行汇总。用户可以根据具体问题设置Reducer数量，通过在mapred-site.xml配置文件里设置参数mapred.reduce.tasks的值，缺省值为1。</li></ul><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h2 id="树结构在操作系统中的应用"><a href="#树结构在操作系统中的应用" class="headerlink" title="树结构在操作系统中的应用"></a>树结构在操作系统中的应用</h2><p><a href="https://www.zhihu.com/question/20176446">数据结构与算法中，树一般会应用在哪些方面？为什么？</a></p><h2 id="TensorFlow和PyTorch区别及优缺点对比"><a href="#TensorFlow和PyTorch区别及优缺点对比" class="headerlink" title="TensorFlow和PyTorch区别及优缺点对比"></a>TensorFlow和PyTorch区别及优缺点对比</h2><p>两者之间最重要的区别是这些框架定义计算图的方式。Tensorflow1.0 创建的是静态图（2.0为动态图），PyTorch 是动态图。Tensorflow1.0 中，必须定义模型的整个计算图，然后运行 ML 模型。在 PyTorch 中，可以随时随地定义/操作图形。这在 RNN 中使用可变长度输入时比较有用。</p><ul><li>模型可用性：PyTorch 在研究领域占据主导地位。虽然 TensorFlow 2 解决了研究者使用该框架进行研究的一些痛点，但 PyTorch 却没有给研究者回头的理由。此外，TensorFlow 两大版本之间的向后兼容性问题只会让这种趋势愈演愈烈。</li><li>部署便捷性：TensorFlow 胜出。TensorFlow 依然在部署方面占有优势。Serving 和 TFLite 比 PyTorch 的同类型工具要稳健一些。而且，将 TFLite 与谷歌的 Coral 设备一起用于本地 AI 的能力是许多行业的必备条件。PyTorch Live 只专注于移动平台，而 TorchServe 仍处于起步阶段。</li><li>生态系统：TensorFlow 更胜一筹。尽管 PyTorch (Facebook) 和 TensorFlow (Google) 有很多相似和共享的资源，。谷歌投入巨资确保深度学习的每个相关领域都有完善的产品。与 Google Cloud 和 TFX 的紧密集成使端到端的开发过程变得轻而易举，而将模型移植到 Google Coral 设备的便利性让 TensorFlow 在某些行业取得了压倒性的胜利。</li><li>参考：<ul><li><a href="https://zhuanlan.zhihu.com/p/37102973">PyTorch VS TensorFlow：细数两者的不同之处</a></li><li><a href="https://zhuanlan.zhihu.com/p/466991365">2022 年了，PyTorch 和 TensorFlow 你选哪个？</a></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Reading Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph Theory</title>
      <link href="/2023/06/04/Graph-Theory/"/>
      <url>/2023/06/04/Graph-Theory/</url>
      
        <content type="html"><![CDATA[<h1 id="图论"><a href="#图论" class="headerlink" title="图论"></a>图论</h1><p>基本知识点：</p><ul><li>顶点（Vertex）：图由一组顶点组成，每个顶点可以表示一个实体或对象。</li><li>边（Edge）：顶点之间的连接关系称为边。边可以是有向的（从一个顶点指向另一个顶点）或无向的（没有方向性）。</li><li>权重（Weight）：在有权图中，每条边可能会有一个与之关联的权重，用于表示顶点之间的距离、成本或其他度量。</li><li>度（Degree）：在无向图中，度就是每个节点相连的边的条数。对于有向图，分为入度（指向该顶点的边的数量）和出度（从该顶点出发的边的数量）。</li><li>邻接顶点（Adjacent Vertices）：对于一个顶点，与之直接相连的顶点称为邻接顶点。</li><li>路径（Path）：图中的路径是指由边连接的顶点序列。路径的长度是指路径上的边的数量。</li><li>环（Cycle）：如果路径的起点和终点是同一个顶点，并且没有重复的边，则称该路径为环。</li><li>连通图（Connected Graph）：在无向图中，如果任意两个顶点之间都存在路径，则该图被称为连通图。</li><li>强连通图（Strongly Connected Graph）：在有向图中，如果任意两个顶点之间都存在双向路径，则该图被称为强连通图。</li><li>最短路径（Shortest Path）：在带权图中，最短路径是指连接两个顶点之间权重和最小的路径。</li><li>图的表示方法：图可以使用邻接矩阵、邻接表等方式进行表示。邻接矩阵是一个二维矩阵，用于表示顶点之间的连接关系。邻接表是使用链表或数组表示每个顶点及其邻接顶点的列表。相比于邻接矩阵，邻接表需要的存储空间少，但是无法快速判断两个节点是否相邻。</li><li>最小生成树（Minimum Spanning Tree）：在带权无向图中，最小生成树是指连接图中所有顶点，并且边的权重和最小的树。</li><li>常见的图算法：常见的图算法包括深度优先搜索（DFS）、广度优先搜索（BFS）、Dijkstra算法（用于寻找最短路径）、拓扑排序、Prim算法和Kruskal算法（用于求最小生成树）等。</li><li>图的遍历代码：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 记录被遍历过的节点</span></span><br><span class="line">visited = []</span><br><span class="line"><span class="comment"># 记录从起点到当前节点的路径，用于判断是否成环</span></span><br><span class="line">onPath = []</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; 图遍历框架 &quot;&quot;&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">traverse</span>(<span class="params">graph, s</span>):</span></span><br><span class="line">    <span class="keyword">if</span> visited[s]:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 经过节点 s，标记为已遍历</span></span><br><span class="line">    visited[s] = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 做选择：标记节点 s 在路径上</span></span><br><span class="line">    onPath[s] = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> neighbor <span class="keyword">in</span> graph.neighbors(s):</span><br><span class="line">        traverse(graph, neighbor)</span><br><span class="line">    <span class="comment"># 撤销选择：节点 s 离开路径</span></span><br><span class="line">    onPath[s] = <span class="literal">False</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="常见图算法"><a href="#常见图算法" class="headerlink" title="常见图算法"></a>常见图算法</h2><h3 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h3><p>拓扑排序（Topological Sorting）是一种对有向无环图（DAG）进行排序的算法。它可以找到一个满足所有依赖关系的顺序，使得对于图中的每一对有向边 (u, v)，顶点 u 都在顶点 v 之前。通俗说即把一幅图「拉平」，且这个「拉平」的图里面所有箭头方向都是一致的。如果一幅有向图中存在环是无法进行拓扑排序的，因为肯定做不到所有箭头方向一致；反过来，如果一幅图是「有向无环图」，那么一定可以进行拓扑排序。</p><ul><li>基本思想：通过不断移除图中的入度为 0 的顶点，直到所有顶点都被处理完毕。</li><li>具体步骤：<ul><li>初始化：创建一个空的结果列表 result，以及一个队列 queue。</li><li>计算顶点的入度：遍历有向图的所有顶点，计算每个顶点的入度（即指向该顶点的边的数量），并将入度为 0 的顶点加入队列 queue。</li><li>拓扑排序：不断从队列中取出顶点，将其加入结果列表 result，并将其相邻顶点的入度减 1。如果减 1 后的入度为 0，将该顶点加入队列。</li><li>输出结果：当队列为空时，所有顶点都已经被处理，并且按照拓扑排序的顺序加入了结果列表 result。将结果列表 result 返回作为拓扑排序的结果。</li></ul></li><li>时间复杂度为 $O(V + E)$，其中 V 表示顶点的数量，E 表示边的数量。这是因为每个顶点和每条边都需要被访问一次。</li><li>代码：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">topological_sort</span>(<span class="params">graph</span>):</span></span><br><span class="line">    <span class="comment"># 统计每个顶点的入度</span></span><br><span class="line">    in_degree = &#123;v: <span class="number">0</span> <span class="keyword">for</span> v <span class="keyword">in</span> graph&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算每个顶点的入度</span></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> graph:</span><br><span class="line">        <span class="keyword">for</span> neighbor <span class="keyword">in</span> graph[v]:</span><br><span class="line">            in_degree[neighbor] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个队列用于存储入度为0的顶点</span></span><br><span class="line">    queue = deque([v <span class="keyword">for</span> v <span class="keyword">in</span> in_degree <span class="keyword">if</span> in_degree[v] == <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 存储拓扑排序的结果</span></span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 执行拓扑排序</span></span><br><span class="line">    <span class="keyword">while</span> queue:</span><br><span class="line">        v = queue.popleft()</span><br><span class="line">        result.append(v)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将相邻顶点的入度减1，并将入度变为0的顶点加入队列</span></span><br><span class="line">        <span class="keyword">for</span> neighbor <span class="keyword">in</span> graph[v]:</span><br><span class="line">            in_degree[neighbor] -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> in_degree[neighbor] == <span class="number">0</span>:</span><br><span class="line">                queue.append(neighbor)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果图中存在环路，则无法进行拓扑排序</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(result) != <span class="built_in">len</span>(graph):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;The graph contains a cycle.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">graph = &#123;</span><br><span class="line">    <span class="string">&#x27;A&#x27;</span>: [<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;B&#x27;</span>: [<span class="string">&#x27;D&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;C&#x27;</span>: [<span class="string">&#x27;D&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;D&#x27;</span>: [<span class="string">&#x27;E&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;E&#x27;</span>: []</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">result = topological_sort(graph)</span><br><span class="line"><span class="built_in">print</span>(result)    <span class="comment"># [&#x27;A&#x27;, &#x27;C&#x27;, &#x27;B&#x27;, &#x27;D&#x27;, &#x27;E&#x27;]</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="二分图"><a href="#二分图" class="headerlink" title="二分图"></a>二分图</h3><p>二分图（Bipartite Graph），也称为二部图，是图论中一种特殊的图结构。</p><ul><li>基本概念：二分图是指一个图可以将所有顶点分为两个不相交的顶点集合，且图中的每条边的两个端点分别属于不同的顶点集合。</li><li>判断：判断一个图是否为二分图有多种方法，其中最常用的方法是使用深度优先搜索（DFS）或广度优先搜索（BFS）进行染色。通过从任意一个顶点开始，将其染成一种颜色，然后按照染色规则继续染色相邻的顶点，如果在染色过程中发现相邻顶点已经染成了相同的颜色，则图不是二分图；如果染色完成后没有发现相邻顶点染成相同的颜色，则图是二分图。</li><li>应用：二分图可以用于建模和解决各种问题，例如匹配问题、调度问题、分配问题等。最大匹配问题可以在二分图上求解，而匈牙利算法是常用于解决最大匹配问题的算法之一。</li><li>代码：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_bipartite</span>(<span class="params">graph</span>):</span></span><br><span class="line">    <span class="comment"># 定义三种颜色：0 表示未染色，1 表示染成红色，-1 表示染成蓝色</span></span><br><span class="line">    colors = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">node, color</span>):</span></span><br><span class="line">        colors[node] = color</span><br><span class="line">        <span class="keyword">for</span> neighbor <span class="keyword">in</span> graph[node]:</span><br><span class="line">            <span class="keyword">if</span> neighbor <span class="keyword">not</span> <span class="keyword">in</span> colors:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> dfs(neighbor, -color):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">elif</span> colors[neighbor] == color:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对每个顶点进行DFS染色判断</span></span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> graph:</span><br><span class="line">        <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> colors:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> dfs(node, <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">graph = &#123;</span><br><span class="line">    <span class="string">&#x27;A&#x27;</span>: [<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;B&#x27;</span>: [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;D&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;C&#x27;</span>: [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;D&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;D&#x27;</span>: [<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;E&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;E&#x27;</span>: [<span class="string">&#x27;D&#x27;</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">result = is_bipartite(graph)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure></li></ul><h3 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a>并查集</h3><p>并查集（Union-Find）算法是一个专门针对「动态连通性」的算法。</p><ul><li>「连通」是一种等价关系，也就是说具有如下三个性质：<ol><li>自反性：节点 p 和 p 是连通的。</li><li>对称性：如果节点 p 和 q 连通，那么 q 和 p 也连通。</li><li>传递性：如果节点 p 和 q 连通，q 和 r 连通，那么 p 和 r 也连通。</li></ol></li><li>UF时间复杂度：<ul><li>find 主要功能就是从某个节点向上遍历到树根，其时间复杂度就是树的高度。我们可能习惯性地认为树的高度就是 logN，但这并不一定。logN 的高度只存在于平衡二叉树，对于一般的树可能出现极端不平衡的情况，使得「树」几乎退化成「链表」，树的高度最坏情况下可能变成 N。find, union, connected 的时间复杂度都是 O(N)。</li><li>平衡性优化（按秩合并）+路径压缩：构造函数初始化数据结构需要 O(N) 的时间和空间复杂度；连通两个节点 union、判断两个节点的连通性 connected、计算连通分量 count 所需的时间复杂度均为 O(1)。</li></ul></li><li>平衡性优化（按秩合并）+路径压缩：<ol><li>用 parent 数组记录每个节点的父节点，相当于指向父节点的指针，所以 parent 数组内实际存储着一个森林（若干棵多叉树）。</li><li>用 size 数组记录着每棵树的重量，目的是让 union 后树依然拥有平衡性，保证各个 API 时间复杂度为 O(logN)，而不会退化成链表影响操作效率。</li><li>在 find 函数中进行路径压缩，保证任意树的高度保持在常数，使得各个 API 时间复杂度为 O(1)。使用了路径压缩之后，可以不使用 size 数组的平衡优化。</li></ol></li><li>tip：二维坐标映射到一维的常用技巧：二维坐标 (x,y) 可以转换成 x * n + y 这个数（m 是棋盘的行数，n 是棋盘的列数）</li><li>代码：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UF</span>:</span></span><br><span class="line">    <span class="comment"># 连通分量个数</span></span><br><span class="line">    count: <span class="built_in">int</span></span><br><span class="line">    <span class="comment"># 存储每个节点的父节点</span></span><br><span class="line">    parent: <span class="type">List</span>[<span class="built_in">int</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># n 为图中节点的个数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n: <span class="built_in">int</span></span>):</span></span><br><span class="line">        self.count = n</span><br><span class="line">        self.parent = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]  <span class="comment"># 初始时，每个元素的父节点指向自身</span></span><br><span class="line">        self.rank = [<span class="number">0</span>] * size  <span class="comment"># 记录每个集合的秩（树的高度）</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将节点 p 和节点 q 连通</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">union</span>(<span class="params">self, p: <span class="built_in">int</span>, q: <span class="built_in">int</span></span>):</span></span><br><span class="line">        rootP = self.find(p)</span><br><span class="line">        rootQ = self.find(q)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> rootP == rootQ:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># self.parent[rootQ] = rootP</span></span><br><span class="line">        <span class="keyword">if</span> rootP != rootQ:</span><br><span class="line">            <span class="keyword">if</span> self.rank[rootP] &lt; self.rank[rootQ]:</span><br><span class="line">                self.parent[rootP] = rootQ</span><br><span class="line">            <span class="keyword">elif</span> self.rank[rootP] &gt; self.rank[rootQ]:</span><br><span class="line">                self.parent[rootQ] = rootP</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.parent[rootQ] = rootP</span><br><span class="line">                self.rank[rootP] += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 两个连通分量合并成一个连通分量</span></span><br><span class="line">        self.count -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断节点 p 和节点 q 是否连通</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connected</span>(<span class="params">self, p: <span class="built_in">int</span>, q: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        rootP = self.find(p)</span><br><span class="line">        rootQ = self.find(q)</span><br><span class="line">        <span class="keyword">return</span> rootP == rootQ</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find</span>(<span class="params">self, x: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.parent[x] != x:   <span class="comment"># 递归查找根节点，并进行路径压缩</span></span><br><span class="line">            self.parent[x] = self.find(self.parent[x])</span><br><span class="line">        <span class="keyword">return</span> self.parent[x]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回图中的连通分量个数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">count</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.count</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    fa = list(range(m * n))</span></span><br><span class="line"><span class="string">    def find(x):</span></span><br><span class="line"><span class="string">        if fa[x] != x:</span></span><br><span class="line"><span class="string">            fa[x] = find(fa[x])</span></span><br><span class="line"><span class="string">        return fa[x]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    def union((x, y), (i, j)):</span></span><br><span class="line"><span class="string">        fa[find(x * n + y)] = fa[find(i * n + j)]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="最小生成树"><a href="#最小生成树" class="headerlink" title="最小生成树"></a>最小生成树</h3><p>最小生成树（Minimum Spanning Tree，MST）算法是用于在连通加权图中找到一棵生成树，使得树上所有边的权重之和最小。生成树是原图的一个子图，它包含了所有的顶点和一部分边，且形成一个无环连通图。最小生成树算法主要有 Prim 算法（普里姆算法）和 Kruskal 算法（克鲁斯卡尔算法）两种，这两种算法虽然都运用了贪心思想。</p><ul><li>贪心思路：将所有边按照权重从小到大排序，从权重最小的边开始遍历，如果这条边和最小生成树中的其它边不会形成环，则这条边是最小生成树的一部分，将它加入最小生成树集合；否则，这条边不是最小生成树的一部分，不要把它加入最小生成树集合。</li><li>Prim 算法：Prim 算法是从一个起点的切分（一组横切边）开始执行类似 BFS 算法的逻辑，借助切分定理和优先级队列动态排序的特性，从这个起点「生长」出一棵最小生成树。它以贪心的方式选择边，每次选择与当前生成树连接的最小权重边所连接的顶点，并将该边加入生成树。Prim 算法可以使用优先队列来选择最小权重边，保证了边的选择是按照权重递增的顺序进行的。Prim 算法不需要事先对所有边排序，而是利用优先级队列动态实现排序的效果，Prim 算法类似于 Kruskal 的动态过程。每次切分都能找到最小生成树的一条边，然后又可以进行新一轮切分，直到找到最小生成树的所有边为止。<ul><li>复杂度分析：假设一幅图的节点个数为V，边的条数为E，首先需要O(E)的空间装所有边，而且 Union-Find 算法也需要O(V)的空间，所以 Kruskal 算法总的空间复杂度就是O(V + E)。时间复杂度主要耗费在排序，需要O(ElogE)的时间，Union-Find 算法所有操作的复杂度都是O(1)，套一个 for 循环也不过是O(E)，所以总的时间复杂度为O(ElogE)。</li></ul></li><li>Kruskal 算法：Kruskal 算法将图中的边按权重排序，然后从最小权重边开始逐步添加到生成树中。在添加边的过程中，需要确保不形成环路，即新添加的边与已有的边不构成环。Kruskal 算法使用并查集数据结构来判断边的两个顶点是否处于同一个连通分量，从而避免形成环路。<ul><li>时间复杂度：复杂度主要在优先级队列 pq 的操作上，由于 pq 里面装的是图中的「边」，假设一幅图边的条数为 E，那么最多操作 O(E) 次 pq。每次操作优先级队列的时间复杂度取决于队列中的元素个数，取最坏情况就是 O(logE)。所以总的时间复杂度为O(ElogE)。</li></ul></li><li>代码：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> heapq <span class="keyword">import</span> heappop, heappush</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prim</span>(<span class="params">graph</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(graph)</span><br><span class="line">    visited = [<span class="literal">False</span>] * n</span><br><span class="line">    min_heap = []</span><br><span class="line">    min_span_tree = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从顶点 0 开始构建最小生成树</span></span><br><span class="line">    start_vertex = <span class="number">0</span></span><br><span class="line">    heappush(min_heap, (<span class="number">0</span>, start_vertex))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> min_heap:</span><br><span class="line">        weight, vertex = heappop(min_heap)</span><br><span class="line">        <span class="keyword">if</span> visited[vertex]:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        visited[vertex] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> weight != <span class="number">0</span>:</span><br><span class="line">            min_span_tree.append((weight, vertex))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> neighbor, edge_weight <span class="keyword">in</span> graph[vertex]:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> visited[neighbor]:</span><br><span class="line">                heappush(min_heap, (edge_weight, neighbor))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> min_span_tree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kruskal</span>(<span class="params">graph</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(graph)</span><br><span class="line">    disjoint_set = DisjointSet(n)</span><br><span class="line">    min_span_tree = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将图中的边按权重排序</span></span><br><span class="line">    edges = [(weight, u, v) <span class="keyword">for</span> u <span class="keyword">in</span> <span class="built_in">range</span>(n) <span class="keyword">for</span> v, weight <span class="keyword">in</span> graph[u]]</span><br><span class="line">    edges.sort()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> weight, u, v <span class="keyword">in</span> edges:</span><br><span class="line">        <span class="keyword">if</span> disjoint_set.find(u) != disjoint_set.find(v):</span><br><span class="line">            disjoint_set.union(u, v)</span><br><span class="line">            min_span_tree.append(weight)</span><br></pre></td></tr></table></figure></li></ul><h2 id="最短路径算法"><a href="#最短路径算法" class="headerlink" title="最短路径算法"></a>最短路径算法</h2><h3 id="Floyd-Warshall"><a href="#Floyd-Warshall" class="headerlink" title="Floyd-Warshall"></a>Floyd-Warshall</h3><p>Floyd-Warshall 算法是一种用于求解所有顶点对之间（多源）最短路径的算法。它可以处理带有正权边或负权边的有向图或无向图，但不适用于存在负权环的情况。</p><ul><li>基本思想：通过动态规划的方式逐步计算每对顶点之间的最短路径。它维护一个二维数组，称为距离矩阵，其中的元素 dist[u][v] 表示顶点 u 到顶点 v 的最短路径的长度。</li><li>基本步骤：<ol><li>初始化：将距离矩阵的对角线元素设为 0，表示每个顶点到自身的距离为 0。对于有边相连的顶点，将距离矩阵的相应位置设为边的权重；对于没有边相连的顶点，将距离矩阵的相应位置设为无穷大。</li><li>迭代更新：对于每个顶点 k，依次考虑所有顶点对 (i, j) 的距离。如果通过顶点 k 可以获得更短的路径，则更新距离矩阵中的值 dist[i][j]。</li><li>返回结果：最终的距离矩阵就是所有顶点对之间的最短路径。</li></ol></li><li>代码：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">INF = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">floyd_warshall</span>(<span class="params">graph</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(graph)</span><br><span class="line">    dist = [[INF] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化距离矩阵</span></span><br><span class="line">    <span class="keyword">for</span> u <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> v, weight <span class="keyword">in</span> graph[u]:</span><br><span class="line">            dist[u][v] = weight</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 迭代更新</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                <span class="keyword">if</span> dist[i][k] + dist[k][j] &lt; dist[i][j]:</span><br><span class="line">                    dist[i][j] = dist[i][k] + dist[k][j]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dist</span><br></pre></td></tr></table></figure></li></ul><h3 id="Dijkstra"><a href="#Dijkstra" class="headerlink" title="Dijkstra"></a>Dijkstra</h3><p>在 BFS 算法框架详解 用的是普通的队列 Queue 来遍历多叉树，而对于加权图的最短路径来说，得用优先级队列 PriorityQueue自动排序的特性，将路径权重较小的节点排在队列前面，以此为基础施展 BFS 算法，也就变成了 Dijkstra 算法。</p><p>Dijkstra 算法是一种用于解决带有非负权边的单源最短路径问题的算法。它能够找到从起点到图中所有其他顶点的最短路径。</p><ul><li>基本思想：通过逐步松弛顶点来逐步确定最短路径。它维护一个距离数组，记录从起点到每个顶点的最短路径估计值。算法的迭代过程中，每次选择距离数组中值最小的顶点，并对其邻接顶点进行松弛操作，更新距离数组中的值。通过不断选择最短路径估计值最小的顶点，最终可以确定起点到其他所有顶点的最短路径。Dijkstra 可以理解成一个带 dp table（或者说备忘录）的 BFS 算法。</li><li>算法条件：加权有向图，没有负权重边</li><li>基本步骤：<ol><li>初始化：将起点的距离设为 0，其余顶点的距离设为无穷大。</li><li>迭代更新：重复以下步骤，直到所有顶点都被处理或者没有可选顶点为止：选择距离数组中值最小的顶点作为当前顶点；对当前顶点的邻接顶点进行松弛操作，更新距离数组中的值。</li><li>返回结果：最终的距离数组就是起点到所有顶点的最短路径。</li></ol></li><li>时间复杂度： O(ElogV)，其中 E 代表图中边的条数，V 代表图中节点的个数。因为理想情况下优先级队列中最多装 V 个节点，对优先级队列的操作次数和 E 成正比，所以整体的时间复杂度就是 O(ElogV)。</li><li>代码：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line">INF = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dijkstra</span>(<span class="params">graph, start</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(graph)</span><br><span class="line">    distance = [INF] * n</span><br><span class="line">    distance[start] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    min_heap = [(<span class="number">0</span>, start)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> min_heap:</span><br><span class="line">        dist, u = heapq.heappop(min_heap)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果当前顶点已经处理过，则跳过</span></span><br><span class="line">        <span class="keyword">if</span> dist &gt; distance[u]:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> v, weight <span class="keyword">in</span> graph[u]:</span><br><span class="line">            new_dist = distance[u] + weight</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果找到了更短的路径，则更新距离数组和堆中的值</span></span><br><span class="line">            <span class="keyword">if</span> new_dist &lt; distance[v]:</span><br><span class="line">                distance[v] = new_dist</span><br><span class="line">                heapq.heappush(min_heap, (new_dist, v))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> distance</span><br></pre></td></tr></table></figure></li></ul><h3 id="Bellman-Ford"><a href="#Bellman-Ford" class="headerlink" title="Bellman-Ford"></a>Bellman-Ford</h3><p>Bellman-Ford 算法是一种用于解决带有负权边的单源最短路径问题的算法。它可以应对图中存在负权边和负权环的情况。</p><ul><li>基本思想：通过逐步松弛边的权重来逐步逼近最短路径。它维护一个距离数组，记录从起点到每个顶点的最短路径估计值。算法的迭代过程中，通过对每条边进行松弛操作，不断更新距离数组中的值，直到无法再进行松弛为止。</li><li>基本步骤：<ol><li>初始化：将起点的距离设为 0，其余顶点的距离设为无穷大。</li><li>迭代更新：对于图中的每条边，逐步松弛边的权重。对于边 (u, v) 来说，如果从起点到顶点 u 的路径经过边 (u, v) 能够获得更短的路径，则更新顶点 v 的距离值。</li><li>检测负权环：在迭代更新的过程中，如果存在顶点的距离值发生变化，则说明图中存在负权环。由于负权环可以无限次地减小路径的长度，因此 Bellman-Ford 算法可以通过检测负权环来判断是否存在无限小的最短路径。</li><li>返回结果：如果不存在负权环，则最终的距离数组就是起点到所有顶点的最短路径。</li></ol></li><li>时间复杂度：O(V * E)，其中 V 是顶点的数量，E 是边的数量。</li><li>代码：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">INF = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bellman_ford</span>(<span class="params">graph, start</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(graph)</span><br><span class="line">    distance = [INF] * n</span><br><span class="line">    distance[start] = <span class="number">0</span></span><br><span class="line">    predecessor = [-<span class="number">1</span>] * n</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> u <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">for</span> v, weight <span class="keyword">in</span> graph[u]:</span><br><span class="line">                <span class="keyword">if</span> distance[u] != INF <span class="keyword">and</span> distance[u] + weight &lt; distance[v]:</span><br><span class="line">                    distance[v] = distance[u] + weight</span><br><span class="line">                    predecessor[v] = u</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检测负权环</span></span><br><span class="line">    <span class="keyword">for</span> u <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> v, weight <span class="keyword">in</span> graph[u]:</span><br><span class="line">            <span class="keyword">if</span> distance[u] != INF <span class="keyword">and</span> distance[u] + weight &lt; distance[v]:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;Graph contains a negative weight cycle.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># # Check for negative-weight cycles，并记录环路径negative_cycle</span></span><br><span class="line">    <span class="comment"># negative_cycle = None</span></span><br><span class="line">    <span class="comment"># for u in range(n):</span></span><br><span class="line">    <span class="comment">#     for v, weight in graph[u]:</span></span><br><span class="line">    <span class="comment">#         if distance[u] + weight &lt; distance[v]:</span></span><br><span class="line">    <span class="comment">#             # Negative-weight cycle found</span></span><br><span class="line">    <span class="comment">#             negative_cycle = []</span></span><br><span class="line">    <span class="comment">#             cycle_vertex = v</span></span><br><span class="line">    <span class="comment">#             while cycle_vertex not in negative_cycle:</span></span><br><span class="line">    <span class="comment">#                 negative_cycle.append(cycle_vertex)</span></span><br><span class="line">    <span class="comment">#                 cycle_vertex = predecessor[cycle_vertex]</span></span><br><span class="line">    <span class="comment">#             negative_cycle.append(cycle_vertex)</span></span><br><span class="line">    <span class="comment">#             negative_cycle.reverse()</span></span><br><span class="line">    <span class="comment">#             break</span></span><br><span class="line">    <span class="comment">#     if negative_cycle is not None:</span></span><br><span class="line">    <span class="comment">#         break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line"></span><br><span class="line">graph = [</span><br><span class="line">    [(<span class="number">1</span>, <span class="number">4</span>), (<span class="number">2</span>, <span class="number">2</span>)],</span><br><span class="line">    [(<span class="number">3</span>, <span class="number">3</span>)],</span><br><span class="line">    [(<span class="number">1</span>, <span class="number">1</span>), (<span class="number">3</span>, -<span class="number">5</span>)],</span><br><span class="line">    [(<span class="number">4</span>, <span class="number">2</span>)],</span><br><span class="line">    []</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">start_vertex = <span class="number">0</span></span><br><span class="line">distances = bellman_ford(graph, start_vertex)</span><br><span class="line"><span class="built_in">print</span>(distances)</span><br></pre></td></tr></table></figure></li></ul><h3 id="SPFA"><a href="#SPFA" class="headerlink" title="SPFA"></a>SPFA</h3><p>SPFA（Shortest Path Faster Algorithm）是一种用于求解带有负权边的单源最短路径问题的算法。它是对 Bellman-Ford 算法的一种优化，通过使用队列进行松弛操作的选择，减少了不必要的重复操作，从而提高了算法的效率。</p><ul><li>基本步骤：</li></ul><ol><li>初始化：将起点的距离设为 0，其余顶点的距离设为无穷大。将起点加入队列中。</li><li>迭代更新：从队列中取出一个顶点，并对其邻接顶点进行松弛操作。如果通过当前顶点 u 可以获得更短的路径，则更新邻接顶点 v 的距离值，并将 v 加入队列中（如果 v 不在队列中）。继续迭代，直到队列为空。</li><li>检测负权环：通过统计每个顶点的入队次数来实现的。如果某个顶点入队的次数超过图中顶点的数量，即超过了 n 次（n 是顶点的数量），则说明存在负权环。</li><li>返回结果：如果不存在负权环，则最终的距离数组就是起点到所有顶点的最短路径。</li></ol><ul><li>时间复杂度：一般情况下的时间复杂度是 O(kE)，其中 k 是松弛操作的次数，E 是边的数量。在大多数情况下，SPFA 算法的运行时间要比 Bellman-Ford 算法更快。</li><li>代码：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"></span><br><span class="line">INF = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spfa</span>(<span class="params">graph, start</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(graph)</span><br><span class="line">    distance = [INF] * n</span><br><span class="line">    distance[start] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    queue = deque()</span><br><span class="line">    queue.append(start)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 记录每个顶点入队的次数。如果某个顶点的入队次数超过 n 次，则直接返回 &quot;存在负权环&quot;。</span></span><br><span class="line">    count = [<span class="number">0</span>] * n</span><br><span class="line">    count[start] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> queue:</span><br><span class="line">        u = queue.popleft()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> v, weight <span class="keyword">in</span> graph[u]:</span><br><span class="line">            new_dist = distance[u] + weight</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> new_dist &lt; distance[v]:</span><br><span class="line">                distance[v] = new_dist</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> v <span class="keyword">not</span> <span class="keyword">in</span> queue:</span><br><span class="line">                    queue.append(v)</span><br><span class="line">                    count[v] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 检测负权环</span></span><br><span class="line">                    <span class="keyword">if</span> count[v] &gt; n:</span><br><span class="line">                        <span class="keyword">return</span> <span class="string">&quot;存在负权环&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> distance</span><br></pre></td></tr></table></figure></li></ul><h3 id="A-算法"><a href="#A-算法" class="headerlink" title="A*算法"></a>A*算法</h3><p>A*算法是一种启发式搜索算法，用于在图形表示的问题中找到最短路径或最优解。它结合了Dijkstra算法的广度优先搜索和贪心算法的启发式评估，以在搜索过程中更快地找到目标。</p><ul><li>基本思想：通过维护一个开放列表和一个关闭列表来搜索图形中的节点。开放列表存储待扩展的节点，而关闭列表存储已经访问过的节点。在每一步中，A算法根据节点的启发式评估值选择最有希望的节点进行扩展。这个启发式评估值通常是一个估计值，用于预测从当前节点到目标节点的最短路径代价。</li><li>基本步骤：<ol><li>将起点加入开放列表，并设置起点的启发式评估值（例如，预估的从起点到目标节点的最短路径代价）。</li><li>重复以下步骤直到找到目标节点或开放列表为空：从开放列表中选择启发式评估值最低的节点作为当前节点。将当前节点从开放列表中移除，并将其加入关闭列表。如果当前节点是目标节点，搜索结束，找到了最短路径或最优解。否则，对当前节点的所有邻接节点进行如下操作：如果邻接节点已经在关闭列表中，则跳过该节点。如果邻接节点不在开放列表中，将其加入开放列表，并计算它的启发式评估值。如果邻接节点已经在开放列表中，更新其启发式评估值为更低的值（如果需要）。</li><li>如果开放列表为空，表示无法到达目标节点，搜索结束。</li></ol></li><li>注意：A算法的效率和搜索结果的质量高度依赖于所选择的启发式评估函数。一个合理的启发式评估函数能够提供较为准确的路径代价估计，从而指导搜索过程朝着最有希望的方向前进。但如果启发式评估函数不准确或不适当，可能会导致搜索结果不是最优解或搜索效率较低。因此，在使用A算法时，选择和设计合适的启发式评估函数非常重要。</li><li>代码：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heuristic</span>(<span class="params">node, goal</span>):</span></span><br><span class="line">    <span class="comment"># 启发式评估函数，计算当前节点到目标节点的估计代价</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">abs</span>(node[<span class="number">0</span>] - goal[<span class="number">0</span>]) + <span class="built_in">abs</span>(node[<span class="number">1</span>] - goal[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">astar</span>(<span class="params">graph, start, goal</span>):</span></span><br><span class="line">    <span class="comment"># 初始化数据结构</span></span><br><span class="line">    open_list = []</span><br><span class="line">    closed_set = <span class="built_in">set</span>()</span><br><span class="line">    came_from = &#123;&#125;</span><br><span class="line">    g_score = &#123;start: <span class="number">0</span>&#125;</span><br><span class="line">    f_score = &#123;start: heuristic(start, goal)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将起点加入开放列表</span></span><br><span class="line">    heapq.heappush(open_list, (f_score[start], start))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> open_list:</span><br><span class="line">        current = heapq.heappop(open_list)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current == goal:</span><br><span class="line">            <span class="comment"># 找到目标节点，构建路径并返回</span></span><br><span class="line">            path = []</span><br><span class="line">            <span class="keyword">while</span> current <span class="keyword">in</span> came_from:</span><br><span class="line">                path.append(current)</span><br><span class="line">                current = came_from[current]</span><br><span class="line">            path.append(start)</span><br><span class="line">            <span class="keyword">return</span> path[::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        closed_set.add(current)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> neighbor <span class="keyword">in</span> graph[current]:</span><br><span class="line">            <span class="keyword">if</span> neighbor <span class="keyword">in</span> closed_set:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算当前节点到邻接节点的实际代价</span></span><br><span class="line">            tentative_g_score = g_score[current] + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> neighbor <span class="keyword">not</span> <span class="keyword">in</span> open_list:</span><br><span class="line">                open_list.append((f_score.get(neighbor, <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)), neighbor))</span><br><span class="line">            <span class="keyword">elif</span> tentative_g_score &gt;= g_score.get(neighbor, <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            came_from[neighbor] = current</span><br><span class="line">            g_score[neighbor] = tentative_g_score</span><br><span class="line">            f_score[neighbor] = tentative_g_score + heuristic(neighbor, goal)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开放列表为空，无法到达目标节点</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例使用</span></span><br><span class="line">graph = &#123;</span><br><span class="line">    (<span class="number">0</span>, <span class="number">0</span>): [(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">0</span>)],</span><br><span class="line">    (<span class="number">0</span>, <span class="number">1</span>): [(<span class="number">0</span>, <span class="number">0</span>), (<span class="number">1</span>, <span class="number">1</span>)],</span><br><span class="line">    (<span class="number">1</span>, <span class="number">0</span>): [(<span class="number">0</span>, <span class="number">0</span>), (<span class="number">1</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">0</span>)],</span><br><span class="line">    (<span class="number">1</span>, <span class="number">1</span>): [(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">1</span>)],</span><br><span class="line">    (<span class="number">2</span>, <span class="number">0</span>): [(<span class="number">1</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">1</span>)],</span><br><span class="line">    (<span class="number">2</span>, <span class="number">1</span>): [(<span class="number">1</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">0</span>)]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">start = (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">goal = (<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">path = astar(graph, start, goal)</span><br><span class="line"><span class="keyword">if</span> path:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;找到最短路径：&quot;</span>, path)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;无法到达目标节点&quot;</span>)</span><br></pre></td></tr></table></figure></li></ul><h2 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h2><table>    <tr>        <th align='center', colspan="3">图论</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/all-paths-from-source-to-target/description>✅797. 所有可能的路径</td>        <td>经典回溯</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/course-schedule/description>✅207. 课程表</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/course-schedule-ii/description>✅210. 课程表 II</td>        <td>拓扑排序</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/is-graph-bipartite/description>✅785. 判断二分图</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/possible-bipartition/description>✅886. 可能的二分法</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/surrounded-regions/description>✅130. 被围绕的区域</td>        <td>并查集</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/find-the-city-with-the-smallest-number-of-neighbors-at-a-threshold-distance/description>✅1334. 阈值距离内邻居最少的城市</td>        <td>Floyd</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-cost-to-convert-string-i>✅2976. 转换字符串的最小成本 I</td>        <td>Floyd</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/satisfiability-of-equality-equations/description>✅990. 等式方程的可满足性</td>        <td>Kruskal 算法</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/min-cost-to-connect-all-points/description>✅1584. 连接所有点的最小费用</td>        <td>Kruskal + prim</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/network-delay-time/description>✅743. 网络延迟时间</td>        <td>标准dijkstra</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/path-with-minimum-effort/description>✅1631. 最小体力消耗路径</td>        <td>从上下左右都更新时用图</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/path-with-maximum-probability/description>✅1514. 概率最大的路径</td>        <td>无向图是双向图</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/find-the-town-judge/description>✅997. 找到小镇的法官</td>        <td>计算出入度</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/cheapest-flights-within-k-stops/description>✅787. K 站中转内最便宜的航班</td>        <td>dijkstra、DP</td>         <td>🌟🌟</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Divide and Conquer</title>
      <link href="/2023/05/29/Divide-and-Conquer/"/>
      <url>/2023/05/29/Divide-and-Conquer/</url>
      
        <content type="html"><![CDATA[<h1 id="分治算法"><a href="#分治算法" class="headerlink" title="分治算法"></a>分治算法</h1><p>分治算法，先「分」后「治」，核心思想是将原问题划分为若干个规模较小且相互独立的子问题，然后递归地解决这些子问题，最后将子问题的解合并得到原问题的解。</p><ul><li>最优子结构性质（Optimal Substructure）：如果原问题的解可以通过合并子问题的解得到，且子问题的解可以独立地计算，那么问题具有最优子结构性质。</li><li>时间复杂度：分治算法的时间复杂度通常可以通过递归的深度和每层的操作复杂度来分析。常见的分治算法的时间复杂度一般为$O(nlogn)$。</li><li>示例算法：常见的应用了分治思想的算法有归并排序（Merge Sort）、快速排序（Quick Sort）、Karatsuba乘法算法（用于大整数乘法）等。</li></ul><h3 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h3><ol><li><p>归并排序（Merge Sort）：归并排序的思想是通过递归地将数组划分为两个子数组，直到子数组的长度为1或0，然后再逐步合并两个有序子数组。合并时，比较两个子数组的首元素，将较小的元素放入合并数组中，直到其中一个子数组的元素全部合并完成，然后将另一个子数组的剩余元素直接添加到合并数组的末尾。</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(arr) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> arr</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 划分数组为两个子数组</span></span><br><span class="line">    mid = <span class="built_in">len</span>(arr) // <span class="number">2</span></span><br><span class="line">    left = arr[:mid]</span><br><span class="line">    right = arr[mid:]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 递归地对子数组进行排序</span></span><br><span class="line">    left = merge_sort(left)</span><br><span class="line">    right = merge_sort(right)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 合并两个有序子数组</span></span><br><span class="line">    <span class="keyword">return</span> merge(left, right)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">left, right</span>):</span></span><br><span class="line">    merged = []</span><br><span class="line">    i, j = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 比较两个子数组的元素，并按顺序合并</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(left) <span class="keyword">and</span> j &lt; <span class="built_in">len</span>(right):</span><br><span class="line">        <span class="keyword">if</span> left[i] &lt;= right[j]:</span><br><span class="line">            merged.append(left[i])</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            merged.append(right[j])</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将剩余的元素添加到合并数组中</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(left):</span><br><span class="line">        merged.append(left[i])</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> j &lt; <span class="built_in">len</span>(right):</span><br><span class="line">        merged.append(right[j])</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> merged</span><br></pre></td></tr></table></figure></li><li><p>快速排序（Quick Sort）：选择一个基准元素，通过将数组划分为左右两个部分，使得左侧部分的元素都小于等于基准元素，右侧部分的元素都大于等于基准元素，然后递归地对左右两部分进行排序，最终得到完全有序的数组。</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(arr) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> arr</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 选择基准元素</span></span><br><span class="line">    pivot = arr[<span class="number">0</span>]</span><br><span class="line">    left = []</span><br><span class="line">    right = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将数组中小于基准元素的放入左侧，大于基准元素的放入右侧</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(arr)):</span><br><span class="line">        <span class="keyword">if</span> arr[i] &lt;= pivot:</span><br><span class="line">            left.append(arr[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            right.append(arr[i])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 递归地对左右两部分进行排序</span></span><br><span class="line">    left = quick_sort(left)</span><br><span class="line">    right = quick_sort(right)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 合并左右两部分和基准元素</span></span><br><span class="line">    <span class="keyword">return</span> left + [pivot] + right</span><br></pre></td></tr></table></figure></li></ol><h3 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">分治算法</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/different-ways-to-add-parentheses/description>✅241. 为运算表达式设计优先级</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/merge-k-sorted-lists/description>✅23. 合并 K 个升序链表</td>        <td>归并排序</td>         <td>🌟🌟🌟</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Greedy Algorithm</title>
      <link href="/2023/05/21/Greedy-Algorithm/"/>
      <url>/2023/05/21/Greedy-Algorithm/</url>
      
        <content type="html"><![CDATA[<h1 id="贪心算法"><a href="#贪心算法" class="headerlink" title="贪心算法"></a>贪心算法</h1><p>贪心算法（Greedy algorithm）是一种常用的算法设计策略，用于解决优化问题。它的基本思想是在每一步选择中都采取当前状态下的最优选择，希望通过局部最优选择的累积，达到全局最优解。知识点：</p><ul><li>贪心选择性质：贪心算法每一步都选择当前最优解，不考虑未来的结果。它通常通过贪心选择性质来判断当前最优解是否会导致最终的全局最优解。</li><li>最优子结构：问题具有最优子结构性质意味着最优解可以通过子问题的最优解来构造。贪心算法常常利用最优子结构性质来推导问题的最优解。</li><li>适用性：贪心算法适用于一些特定类型的问题，如活动选择问题、霍夫曼编码、最小生成树等。对于一些问题，贪心算法可能会得到近似最优解，但不一定是全局最优解。</li><li>与动态规划的区别：贪心算法与动态规划类似，都是求解优化问题的方法。然而，贪心算法每一步的选择都只考虑当前状态，不需要保存子问题的解。而动态规划则需要记录并利用子问题的解来构建最优解。</li></ul><p>虽然贪心算法具有一定的局限性，无法解决所有优化问题，但在一些特定情况下，它具有简单、高效的优势，并且可以用于快速求解近似最优解的问题。比如一个算法问题使用暴力解法需要指数级时间，如果能使用动态规划消除重叠子问题，就可以降到多项式级别的时间，如果满足贪心选择性质，那么可以进一步降低时间复杂度，达到线性级别的。</p><h3 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">动态规划——贪心</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/non-overlapping-intervals/description>✅435. 无重叠区间</td>        <td>【贪心】排序</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-number-of-arrows-to-burst-balloons/description>✅452. 用最少数量的箭引爆气球</td>        <td>【贪心】排序</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/remove-covered-intervals/description>✅1288. 删除被覆盖区间</td>        <td>【贪心】排序</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/merge-intervals/description>✅56. 合并区间</td>        <td>【贪心】排序</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/interval-list-intersections/description>✅986. 区间列表的交集</td>        <td>【贪心】排序</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/video-stitching/description>✅1024. 视频拼接</td>        <td>【贪心】排序 很绕</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://www.lintcode.com/problem/920/description>✅920 · 会议室</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://www.lintcode.com/problem/919>✅919 · 会议室 II</td>        <td>差分思想</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/jump-game/description>✅55. 跳跃游戏</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/jump-game-ii/description>✅45. 跳跃游戏 II</td>        <td>还是很难</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/gas-station/description>✅134. 加油站</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/split-array-into-consecutive-subsequences/description>✅659. 分割数组为连续子序列</td>        <td>斗地主：记录freq和need</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/pancake-sorting/description>✅969. 煎饼排序</td>        <td></td>         <td>🌟🌟</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git</title>
      <link href="/2023/05/20/Git/"/>
      <url>/2023/05/20/Git/</url>
      
        <content type="html"><![CDATA[<p>原文链接：</p><ul><li><a href="https://blog.csdn.net/keiven_/article/details/112112292">Git相关命令</a></li><li><a href="https://blog.csdn.net/keiven_/article/details/116841540">部署开发环境相关命令</a></li></ul><h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><p>之前学java开发特意学了项目管理工具git，好久不用了乌龟也不能使用了，现在要捡起来记一下笔记。</p><h2 id="项目提交"><a href="#项目提交" class="headerlink" title="项目提交"></a>项目提交</h2><ol><li>在GitHub上创建一个repositories</li><li>找到自己想要提交的代码的文件夹目录，右键<code>git bash here</code></li><li>依此执行以下命令：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br><span class="line">git add 想要提交的文件</span><br><span class="line">git commit -m <span class="string">&quot;提交说明&quot;</span></span><br><span class="line">git remote add origin 仓库地址</span><br><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure></li><li>输入github账户用户名和密码</li></ol><h2 id="更新仓库"><a href="#更新仓库" class="headerlink" title="更新仓库"></a>更新仓库</h2><ol><li>进入要上传的文件路径，<code>git status</code>检查是否在该分支下，若不在，切换分支<code>git checkout 分支名</code>。</li><li>依此执行以下命令：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git add 更新的文件名</span><br><span class="line">git commit -m <span class="string">&quot;更新说明&quot;</span></span><br><span class="line">git pull<span class="comment"># 拉取当前分支最新代码</span></span><br><span class="line">git push origin master <span class="comment"># 上传</span></span><br></pre></td></tr></table></figure></li><li>输入github账户用户名和密码<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$</span> git config -<span class="literal">-global</span> user.name <span class="string">&quot;你的GitHub登陆名&quot;</span></span><br><span class="line"><span class="variable">$</span> git config -<span class="literal">-global</span> user.email <span class="string">&quot;你的GitHub注册邮箱&quot;</span> </span><br></pre></td></tr></table></figure></li></ol><h2 id="其他git常用命令"><a href="#其他git常用命令" class="headerlink" title="其他git常用命令"></a>其他git常用命令</h2><blockquote><p>公司开发分支为develop，员工个人开发分支为lxf_develop<br>员工每次开发需要将develop分支merge到自己分支，在此基础上开发<br>开发后再提交merge develop request</p></blockquote><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换到主分支develop</span></span><br><span class="line">git checkout develop</span><br><span class="line"><span class="comment"># 检查当前分支</span></span><br><span class="line">git branch</span><br><span class="line"><span class="comment"># 将develop分支代码拉到本地</span></span><br><span class="line">git pull</span><br><span class="line"><span class="comment"># 切换到个人分支</span></span><br><span class="line">git checkout lxf_develop</span><br><span class="line"><span class="comment"># 将develop分支合并到lxf_develop</span></span><br><span class="line">git merge develop</span><br><span class="line"></span><br><span class="line">git clone url<span class="comment"># 克隆项目代码</span></span><br></pre></td></tr></table></figure><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><blockquote><p><a href="https://blog.csdn.net/baidu_15309965/article/details/118144507?spm=1001.2014.3001.5506">报错:LibreSSL SSL_connect: SSL_ERROR_SYSCALL in connection to github.com:443</a><br><a href="https://blog.csdn.net/wufantastic/article/details/91488651?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522163532720516780261985249%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=163532720516780261985249&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-91488651.pc_search_all_es&amp;utm_term=LibreSSL%20SSL_connect:%20SSL_ERROR_SYSCALL%20in%20connection%20to%20github.com:443%20&amp;spm=1018.2226.3001.4187">git使用代理出现LibreSSL SSL_connect: SSL_ERROR_SYSCALL in connection to github.com:443 错误</a><br><a href="https://blog.csdn.net/blueheart20/article/details/78767806?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=xcrun:%20error:%20invalid%20active%20d&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-78767806.nonecase&amp;spm=1018.2226.3001.4187">Mac下xcrun: error: invalid active developer path问题解决方法</a></p></blockquote><h1 id="Python环境部署"><a href="#Python环境部署" class="headerlink" title="Python环境部署"></a>Python环境部署</h1><h2 id="虚拟环境"><a href="#虚拟环境" class="headerlink" title="虚拟环境"></a>虚拟环境</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看python版本</span></span><br><span class="line">python(<span class="number">3</span>) -<span class="literal">-version</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有的虚拟环境，带有星号*的为当前虚拟环境</span></span><br><span class="line">conda info <span class="literal">-e</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建虚拟环境</span></span><br><span class="line">conda create <span class="literal">-n</span> your_venv_name python=x.x</span><br><span class="line">virtualenv your_venv_name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入指定虚拟环境</span></span><br><span class="line">activate your_venv_name(Windows)</span><br><span class="line">source your_venv_name(Linux)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出当前虚拟环境</span></span><br><span class="line">deactivate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除虚拟环境</span></span><br><span class="line">conda remove <span class="literal">-n</span> your_venv_name -<span class="literal">-all</span></span><br></pre></td></tr></table></figure><h2 id="pip安装"><a href="#pip安装" class="headerlink" title="pip安装"></a>pip安装</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看已安装模块</span></span><br><span class="line">pip list</span><br><span class="line">pip freeze</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量安装</span></span><br><span class="line">pip freeze &gt; requirements.txt</span><br><span class="line">pip install <span class="literal">-r</span> requirements.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 普通下载</span></span><br><span class="line">pip install virtualenv<span class="comment"># 安装虚拟环境</span></span><br></pre></td></tr></table></figure><p>第一步将依赖库导入到requirements.txt 文件中，未指定路径就是保存在用户目录下<br>第二步为批量安装requirements.txt文件中的库</p><h2 id="nltk-data下载"><a href="#nltk-data下载" class="headerlink" title="nltk_data下载"></a>nltk_data下载</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;from nltk.book import *<span class="comment"># 可以用来查看nltk_data所在路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载数据集</span></span><br><span class="line">&gt;&gt;&gt;import nltk</span><br><span class="line">&gt;&gt;&gt;nltk.download()</span><br></pre></td></tr></table></figure><p>nltk_data下载github网址：<a href="https://github.com/nltk/nltk_data/tree/gh-pages">https://github.com/nltk/nltk_data/tree/gh-pages</a><br>使用时下载packages文件夹并重命名为nltk_data放在相应路径</p>]]></content>
      
      
      <categories>
          
          <category> Data Analysis and Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux</title>
      <link href="/2023/05/20/Linux/"/>
      <url>/2023/05/20/Linux/</url>
      
        <content type="html"><![CDATA[<table>  <tr>        <th colspan="3">Linux学习笔记</th></tr>  <tr>    <th>序号</th>    <th>笔记</th>    <th>说明</th>  </tr>  <tr>    <td>1-4</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/118567795>Linux常用命令</td>   <td>\</td>  </tr>  <tr>    <td>5</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/118092096>文本编辑器    Vim</td>   <td>\</td>  </tr>    <tr>    <td>10</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/118520901>Shell基础</td>   <td>\</td>  </tr>      <tr>    <td>11</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/118915274>Shell编程</td>   <td>\</td>  </tr>    </tr>      <tr>    <td>*</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/118242420>远程服务器运行代码</td>   <td>\</td>  </tr></table><p><strong>参考资料</strong>：</p><blockquote><p><a href="https://www.bilibili.com/video/BV1mW411i7Qf?p=12">史上最牛的Linux视频教程——兄弟连</a><br><a href="https://blog.csdn.net/yy150122/article/details/106146414">从零开始学习Linux笔记</a><br><a href="https://docs.qq.com/doc/DVmhOaFdyeXN5RnJX">Linux听课笔记</a></p><p><a href="https://blog.csdn.net/luansj/article/details/97272672">Linux常用命令大全（非常全！！！）</a><br><a href="https://thinkwon.blog.csdn.net/article/details/104588679">Linux面试题（2020最新版）</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Data Analysis and Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Database</title>
      <link href="/2023/05/20/Database/"/>
      <url>/2023/05/20/Database/</url>
      
        <content type="html"><![CDATA[<div align="center">  <img src="Database.png" height=75% width=75%></div><table>  <tr>        <th colspan="3">学习笔记目录</th></tr>  <tr>    <th>数据库</th>    <th>笔记</th>    <th>说明</th>  </tr>  <tr>     <td rowspan="6">MySQL</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/113800431>1数据库操作</td>    <td>\</td>     </tr>    <tr>    <td><a href=https://blog.csdn.net/keiven_/article/details/113800617>2约束、数据库备份和还原</td>    <td>\</td>     </tr><tr>    <td><a href=https://blog.csdn.net/keiven_/article/details/113800681>3多表查询</td>    <td>\</td>     </tr><tr>    <td><a href=https://blog.csdn.net/keiven_/article/details/113800698>4事务</td>    <td>\</td>     </tr>  <tr>    <td><a href=https://blog.csdn.net/keiven_/article/details/113800741>5DCL：管理用户、授权</td>    <td>\</td>     </tr>  <tr>    <td><a href=https://blog.csdn.net/keiven_/article/details/113800788>6JDBC、数据库线程池、Spring JDBC</td>    <td>\</td>     </tr>    <tr>   <td rowspan="1">Redis</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/113800968>Redis</td>    <td>\</td>       </tr>      <tr>   <td rowspan="1">MongoDB</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/119113638>MongoDB</td>    <td>\</td>     </tr>  </tr>      <tr>   <td rowspan="1">数据仓库工具</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/117909784>Hive</td>    <td>\</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Analysis and Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Summary NG</title>
      <link href="/2023/05/19/Summary-NG/"/>
      <url>/2023/05/19/Summary-NG/</url>
      
        <content type="html"><![CDATA[<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><table>  <tr>    <th colspan="3">机器学习笔记目录</th></tr>  <tr>    <th>Week</th>    <th>知识点</th>    <th>编程练习</th>  </tr>   <tr>    <td>1</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/111932604>引言、单变量线性回归、线性代数回顾</td>    <td>\</td>   <tr>    <td>2</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/112132038>多变量线性回归、Octave教程</td>    <td>Linear regression</td>  </tr> <tr>    <td>3</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/112172033>逻辑回归、正则化</td>    <td>Logistic regression & Normalization</td>  </tr>  <tr>    <td>4</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/112188037>神经网络</td>    <td>Multi-Classification & Neural network</td>  </tr>  <tr>    <td>5</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/112203088>神经网络的学习</td>    <td>Backpropagation & Neural network</td>  </tr>  <tr>    <td>6</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/112802852>应用机器学习的建议、机器学习系统的设计</td>    <td>Bais & Variance</td>  </tr>  <tr>    <td>7</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/113736923>支持向量机</td>    <td>SVM</td>  </tr>  <tr>    <td>8</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/113783960>聚类、降维</td>    <td>Kmeans & PCA</td>  </tr>  <tr>    <td>9</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/113788270>异常检测、推荐系统</td>    <td>Anomaly detection & Recommender system</td>  </tr>   <tr>    <td>10</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/113792259>大规模机器学习、应用实例：图片文字识别</td>    <td>\</td>  </tr>     <tr align='center'>    <td colspan="3"><a href=https://github.com/xfliu1998/Machine-Learning>吴恩达机器学习系列课程编程作业github网址</td>  </tr></table><p><strong>机器学习参考资料：</strong></p><blockquote><p><a href="https://www.kesci.com/home/column/5dd7524c83b6ff002c786fff">吴恩达《机器学习》</a><br><a href="https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes">吴恩达老师的机器学习课程个人笔记</a></p></blockquote><h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><table>  <tr>        <th colspan="4">吴恩达深度学习笔记</th></tr>  <tr>    <th>课程</th>    <th>编号</th>    <th>理论笔记</th>    <th>编程作业</th>  </tr>  <tr>     <td rowspan="4">神经网络和深度学习</td>    <td>1.1</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/108642729>深度学习介绍</td>   <td>\</td>  </tr>  <tr>    <td>1.2</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/108684452>神经网络编程基础</td>    <td ><a href=https://blog.csdn.net/keiven_/article/details/108857063>识别猫的程序</td>  </tr>   <tr>    <td>1.3</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/108909904>浅层神经网络</td>   <td ><a href=https://blog.csdn.net/keiven_/article/details/108968809>单隐藏层的平面数据分类</td>  </tr>   <tr>    <td>1.4</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/109008141>深层神经网络</td>   <td ><a href=https://blog.csdn.net/keiven_/article/details/109106557>搭建多层神经网络及其应用</td>  </tr>  <tr>     <td rowspan="3">改善深层神经网络</td>    <td>2.1</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/109129282>深度学习实践方面</td>     <td><a href=https://blog.csdn.net/keiven_/article/details/109201916>初始化、梯度化、正则校验</td>  </tr>  <tr>    <td>2.2</td>    <td ><a href=https://blog.csdn.net/keiven_/article/details/109263093>超参数调试、正则化以及优化</td>     <td><a href=https://blog.csdn.net/keiven_/article/details/109320503>优化算法实战</td>  </tr>   <tr>    <td>2.3</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/109327554>超参数调试、Batch正则化和程序框架</td>   <td ><a href=https://blog.csdn.net/keiven_/article/details/109525888>TensorFlow入门</td>  </tr>    <tr>     <td rowspan="2">结构化机器学习项目</td>    <td>3.1</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/109534869>机器学习策略</td>   <td>\</td>  </tr>  <tr>    <td>3.2</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/109543457>机器学习策略</td>    <td >\</td>  </tr>  <tr>     <td rowspan="5">卷积神经网络</td>    <td>4.1</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/109575517>卷积神经网络</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/109667910>搭建卷积神经网络以及应用</td>  </tr>  <tr>    <td>4.2</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/109677679>深度卷积网络：实例探究</td>    <td ><a href=https://blog.csdn.net/keiven_/article/details/109695238>Keras入门与残差网络的搭建</td>  </tr>   <tr>    <td rowspan="2">4.3</td>    <td rowspan="2"><a href=https://blog.csdn.net/keiven_/article/details/109744918>目标检测</td>   <td ><a href=https://blog.csdn.net/keiven_/article/details/109921647>车辆识别</td>  </tr>  <tr>      <td ><a href=https://blog.csdn.net/keiven_/article/details/109891347>车辆识别（编程作业问题汇总）</td>  </tr>   <tr>    <td>4.4</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/109963551>特殊应用：人脸识别和神经风格转换</td>   <td ><a href=https://blog.csdn.net/keiven_/article/details/110134112>人脸识别和神经风格转换（问题未解决）</td>  </tr>    <tr>     <td rowspan="3">序列模型</td>    <td>5.1</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/110313630>循环序列模型</td>   <td><a href=https://blog.csdn.net/keiven_/article/details/110672557>搭建循环神经网络及其应用</td>  </tr>  <tr>    <td>5.2</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/110726609>自然语言处理与词嵌入</td>    <td ><a href=https://blog.csdn.net/keiven_/article/details/110831963>词向量的运算与Emoji生成器</td>  </tr>   <tr>    <td>5.3</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/110879777>序列模型和注意力机制</td>   <td ><a href=https://blog.csdn.net/keiven_/article/details/110955329>机器翻译与触发词检测</td>  </tr>  <tr align='center'>        <td colspan="4"><a href=https://blog.csdn.net/keiven_/article/details/110420610>深度学习编程作业与算法相关函数笔记</td></tr>  <tr align='center'>        <td colspan="4"><a href=https://github.com/xfliu1998/Deep-Learning>深度学习编程作业代码github网址</table><p><strong>深度学习参考资料</strong>：</p><blockquote><ul><li><a href="https://blog.csdn.net/u013733326/article/details/79827273">【目录】【中文】【deplearning.ai】【吴恩达课后作业目录】</a></li><li><a href="http://www.ai-start.com/dl2017/">深度学习笔记目录</a></li><li><a href="https://www.kesci.com/mw/project/5e20243e2823a10036b542da">深度学习课后170习题</a></li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> Machine Learning and Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> MachineLearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch</title>
      <link href="/2023/05/19/Pytorch/"/>
      <url>/2023/05/19/Pytorch/</url>
      
        <content type="html"><![CDATA[<p>根据龙良曲Pytorch学习视频整理，视频链接：<br><a href="https://www.bilibili.com/video/BV1Rv411y7oE?p=1">【计算机-AI】PyTorch学这个就够了！</a><br><a href="https://www.bilibili.com/video/BV1mh41167e3?p=1">(好课推荐)深度学习与PyTorch入门实战——主讲人龙良曲</a></p><div align="center">  <img src="summary.png" height=75% width=75%></div><table>  <tr>        <th colspan="4">学习笔记</th></tr></tr>   <tr>    <th>课程</th>    <th>编号</th>    <th>内容</th>    <th>备注</th>  </tr>   </tr>    <tr>     <td rowspan="9">Pytorch编程框架</td>    <td>1.1</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/119177137>Pytorch概述</td>   <td>0-3</td>      <tr>    <td>1.2</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/119611966>Pytorch基础</td>    <td >4-12</td>  </tr>   <tr>    <td>2.1</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/119574664>深度学习基础</td>    <td >13-24</td>  </tr>  <tr>    <td>2.2</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/119598868>深度学习策略</td>    <td >25-31</td>  </tr>    <tr>    <td>3.1</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/119612417>卷积神经网络</td>    <td >31-39</td>  </tr>    <tr>    <td>3.2</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/119651956>循环神经网络</td>    <td >40-46</td>  </tr>    <tr>    <td>3.3</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/119780667>自编码器</td>    <td >47-51</td>  </tr>    </tr>    <tr>    <td>3.4</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/119683828>对抗生成网络</td>    <td >52-58</td>  </tr>    </tr>    </tr>    <tr>    <td>4.1</td>    <td><a href=https://blog.csdn.net/keiven_/article/details/119781442>自定义数据集</td>    <td >59-62</td>  </tr>  </tr>  <tr></table>]]></content>
      
      
      <categories>
          
          <category> Machine Learning and Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Experimental Technique</title>
      <link href="/2023/05/19/Experimental-Technique/"/>
      <url>/2023/05/19/Experimental-Technique/</url>
      
        <content type="html"><![CDATA[<h3 id="1-设置随机种子"><a href="#1-设置随机种子" class="headerlink" title="1. 设置随机种子"></a>1. 设置随机种子</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">seed = <span class="number">1234</span></span><br><span class="line">os.environ[<span class="string">&#x27;PYTHONHASHSEED&#x27;</span>] = <span class="built_in">str</span>(seed)</span><br><span class="line">random.seed(seed)</span><br><span class="line">np.random.seed(seed)</span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">torch.cuda.manual_seed(seed)</span><br><span class="line">torch.cuda.manual_seed_all(seed)</span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br></pre></td></tr></table></figure><h3 id="2-参数加载"><a href="#2-参数加载" class="headerlink" title="2. 参数加载"></a>2. 参数加载</h3><ul><li>超参数加载，最常用的方法是使用<code>argparse</code>：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&quot;--local_rank&quot;</span>, default=-<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;node rank for distributed training&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--nproc_per_node&#x27;</span>, default=<span class="number">2</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;nums of process/gpu&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--nnode&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;nums of node&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--node_rank&#x27;</span>, default=<span class="number">0</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure></li><li>也可以使用yaml文件编写json格式的参数，通过以下方式加载：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">json格式</span></span><br><span class="line"><span class="string">model:</span></span><br><span class="line"><span class="string">  batch_size: 2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;config.yaml&quot;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    cfg = yaml.safe_load(f)</span><br><span class="line"><span class="keyword">return</span> cfg</span><br><span class="line">batch_size = cfg[<span class="string">&#x27;model&#x27;</span>][<span class="string">&#x27;batch_size&#x27;</span>]</span><br></pre></td></tr></table></figure></li></ul><h3 id="3-数据处理"><a href="#3-数据处理" class="headerlink" title="3. 数据处理"></a>3. 数据处理</h3><ul><li>自定义跳过脏数据 <code>return self.__getitem__(index + 1)</code></li><li>还有一种修改源文件的方法，我没调试成功。<blockquote><p><a href="https://panjinquan.blog.csdn.net/article/details/91129367">Pytorch自定义Dataset和DataLoader去除不存在和空的数据</a></p></blockquote></li></ul><h3 id="4-模型优化"><a href="#4-模型优化" class="headerlink" title="4. 模型优化"></a>4. 模型优化</h3><ul><li><p><strong>学习率衰减策略</strong>。大部分论文中使用的都是warmup + cosine_decay。实际上大家都是守着模型手动调</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> lr_decay_type == <span class="string">&#x27;warmup_step&#x27;</span>:</span><br><span class="line">    t, T = warmup_step, epochs</span><br><span class="line">    lr_lambda = <span class="keyword">lambda</span> epoch: (<span class="number">0.9</span> * epoch / t + <span class="number">0.1</span>) <span class="keyword">if</span> epoch &lt; t \</span><br><span class="line">        <span class="keyword">else</span> <span class="number">0.1</span> <span class="keyword">if</span> <span class="number">0.5</span> * (<span class="number">1</span> + math.cos(math.pi * (epoch - t) / (T - t))) &lt; <span class="number">0.1</span> \</span><br><span class="line">        <span class="keyword">else</span> <span class="number">0.5</span> * (<span class="number">1</span> + math.cos(math.pi * (epoch - t) / (T - t)))</span><br><span class="line">    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)</span><br><span class="line"><span class="keyword">elif</span> lr_decay_type == <span class="string">&#x27;consine_anneal&#x27;</span>:</span><br><span class="line">    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)</span><br><span class="line"><span class="keyword">elif</span> lr_decay_type == <span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">    scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=<span class="number">1</span>, end_factor=<span class="number">0.05</span>, total_iters=epochs*<span class="number">3117</span>)</span><br><span class="line"><span class="keyword">else</span>:  <span class="comment"># step</span></span><br><span class="line">    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=<span class="built_in">int</span>(<span class="number">1e9</span>), gamma=<span class="number">0.1</span>, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><blockquote><ul><li><a href="https://blog.csdn.net/m0_46204224/article/details/109745740?spm=1001.2014.3001.5506">pytorch实现Cosine learning rate&amp; warmup step decay(代码&amp;plot图都已注释，方便调试拷贝)</a></li><li><a href="https://blog.csdn.net/zisuina_2/article/details/103258573?spm=1001.2014.3001.5506">PyTorch torch.optim.lr_scheduler 学习率 - LambdaLR;StepLR;MultiStepLR;ExponentialLR</a></li></ul></blockquote></li><li><p><strong>分布式训练 + 混合精度加速训练</strong></p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">from</span> apex.parallel <span class="keyword">import</span> DistributedDataParallel</span><br><span class="line"><span class="keyword">from</span> apex <span class="keyword">import</span> amp</span><br><span class="line"><span class="keyword">import</span> torch.multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加环境变量</span></span><br><span class="line">os.environ[<span class="string">&quot;CUDA_VISBLE_DEVICES&quot;</span>] = <span class="string">&#x27;0,1&#x27;</span>   <span class="comment"># 双卡</span></span><br><span class="line">os.environ[<span class="string">&#x27;MASTER_ADDR&#x27;</span>] = <span class="string">&#x27;localhost&#x27;</span></span><br><span class="line">os.environ[<span class="string">&#x27;MASTER_PORT&#x27;</span>] = <span class="string">&#x27;23456&#x27;</span></span><br><span class="line">os.environ[<span class="string">&#x27;RANK&#x27;</span>] = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">os.environ[<span class="string">&#x27;CUDA_LAUNCH_BLOCKING&#x27;</span>] = <span class="string">&#x27;1&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span>(<span class="params">data_mode</span>):</span></span><br><span class="line">dataset = Dataset(...) </span><br><span class="line"><span class="comment"># data_single = next(iter(dataset))</span></span><br><span class="line"><span class="comment"># use num_workers to set parallel</span></span><br><span class="line"><span class="keyword">if</span> data_mode == <span class="string">&#x27;train&#x27;</span> <span class="keyword">or</span> data_mode == <span class="string">&#x27;val&#x27;</span>:</span><br><span class="line">    sampler = torch.utils.data.distributed.DistributedSampler(dataset)</span><br><span class="line">    loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=<span class="literal">False</span>, drop_last=<span class="literal">True</span>, num_workers=<span class="number">4</span>, pin_memory=<span class="literal">True</span>, sampler=sampler)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>, num_workers=<span class="number">0</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">return</span> loader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main_worker</span>(<span class="params">local_rank, args</span>):</span></span><br><span class="line"><span class="comment"># 初始化</span></span><br><span class="line">    global_rank = local_rank + args.node_rank * args.nproc_per_node</span><br><span class="line">    world_size = args.nnode * args.nproc_per_node</span><br><span class="line">    dist.init_process_group(backend=<span class="string">&quot;nccl&quot;</span>, init_method=<span class="string">&#x27;env://&#x27;</span>, rank=global_rank, world_size=world_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据和模型</span></span><br><span class="line">train_loader = load_data(data_mode=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">model = init_model()</span><br><span class="line">    para_num = <span class="built_in">sum</span>([param.nelement() <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters()])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Number of parameter: %.2fM&quot;</span> % (para_num / <span class="number">1e6</span>))</span><br><span class="line">    torch.cuda.set_device(local_rank)</span><br><span class="line">    model.cuda(local_rank)</span><br><span class="line">    model = DistributedDataParallel(model)</span><br><span class="line">model, optimizer = amp.initialize(model, optimizer, opt_level=<span class="string">&quot;O1&quot;</span>)</span><br><span class="line">    criterion = Loss(...)</span><br><span class="line">    criterion.cuda(local_rank)</span><br><span class="line">    train()</span><br><span class="line">    dist.destroy_process_group()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    mp.spawn(main_worker, nprocs=<span class="number">2</span>, args=(args,))</span><br></pre></td></tr></table></figure><blockquote><ul><li><a href="https://blog.csdn.net/PanYHHH/article/details/111750248?spm=1001.2014.3001.5506">Pytorch torch.distributed 实现单机多卡分布式训练</a></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/109485088?spm=1001.2014.3001.5506">pytorch原生支持的apex混合精度和nvidia apex混合精度AMP技术加速模型训练效果对比</a></li></ul></blockquote></li><li><p><strong>求导监测</strong></p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 正向传播开启自动求导异常侦测</span></span><br><span class="line">torch.autograd.set_detect_anomaly(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看参数梯度和更新情况</span></span><br><span class="line"><span class="keyword">for</span> name, parms <span class="keyword">in</span> model.named_parameters():</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;更新前/后&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;--&gt;name:&#x27;</span>, name)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;--&gt;para:&#x27;</span>, parms)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;--&gt;grad_requirs:&#x27;</span>, parms.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;--&gt;grad_value:&#x27;</span>, parms.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 反向传播求导侦测</span></span><br><span class="line"><span class="keyword">from</span> apex <span class="keyword">import</span> amp</span><br><span class="line"><span class="comment"># from torch.cuda import amp</span></span><br><span class="line"><span class="keyword">with</span> torch.autograd.detect_anomaly():</span><br><span class="line">    <span class="keyword">if</span> use_amp:</span><br><span class="line">        <span class="keyword">with</span> amp.scale_loss(loss, optimizer) <span class="keyword">as</span> scaled_loss:</span><br><span class="line">            scaled_loss.backward()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        loss.backward(retain_graph=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li><li><strong>继续训练</strong>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载模型的预训练参数</span></span><br><span class="line">pretrained_dict = torch.load(pretrained_model_path + pretrained_model, map_location=<span class="string">&#x27;cpu&#x27;</span>)[<span class="string">&#x27;state_dict&#x27;</span>]</span><br><span class="line">model_name.load_state_dict(&#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> pretrained_dict.items()&#125;, strict=<span class="literal">False</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载优化器的预训练参数</span></span><br><span class="line">pretrained_dict = torch.load(pretrained_model_path + pretrained_model, map_location=<span class="string">&#x27;cpu&#x27;</span>)[<span class="string">&#x27;optimizer&#x27;</span>]</span><br><span class="line">optimizer.load_state_dict(pretrained_dict)</span><br><span class="line"><span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:  <span class="comment"># 单独修改学习率</span></span><br><span class="line">    param_group[<span class="string">&quot;lr&quot;</span>] = lr</span><br><span class="line"><span class="keyword">del</span> pretrained_dict</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存训练好的模型</span></span><br><span class="line">checkpoint = &#123;</span><br><span class="line"><span class="comment"># &#x27;model&#x27;: Model(),     # 模型大的时候不建议保存</span></span><br><span class="line"><span class="string">&#x27;state_dict&#x27;</span>: model.state_dict(),</span><br><span class="line"><span class="string">&#x27;optimizer&#x27;</span>: optimizer.state_dict()</span><br><span class="line">&#125;</span><br><span class="line">checkpoint_path = output_path + <span class="string">&#x27;checkpoint_better.pkl&#x27;</span></span><br><span class="line">torch.save(checkpoint, checkpoint_path)</span><br></pre></td></tr></table></figure></li><li><strong>其他技巧</strong><blockquote><ul><li><a href="https://www.cnblogs.com/zhangxianrong/p/15086549.html">pytorch加速训练的17种方法</a></li><li><a href="https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one">在单个GPU上进行高效训练</a></li><li><strong>adamw_apex_fused</strong></li></ul></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning and Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic Programming</title>
      <link href="/2023/04/19/Dynamic-Programming/"/>
      <url>/2023/04/19/Dynamic-Programming/</url>
      
        <content type="html"><![CDATA[<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h1><p>动态规划（Dynamic Programming）算法是一种将大问题分解为子问题的优化算法，其基本思想是将问题分解为子问题，分别求解子问题的最优解，最后将子问题的最优解组合成原问题的最优解。知识点：</p><ul><li><strong>三要素</strong>：重叠子问题、最优子结构、状态转移方程</li><li><strong>实现</strong>：动态规划算法通常采用自底向上或自顶向下的方式进行求解。自底向上的方法需要先求解小规模的子问题，再根据子问题的解求解大规模的子问题，直至求解原问题。自顶向下的方法则是从原问题开始，逐步将问题分解为子问题，并通过记忆化搜索的方式将已经求解过的子问题记录下来，避免重复计算。即带「备忘录」的递归算法，把一棵存在巨量冗余的递归树通过「剪枝」，改造成了一幅不存在冗余的递归图，极大减少了子问题（即递归图中节点）的个数。</li><li><strong>应用</strong>：动态规划算法常用于求解具有重叠子问题和最优子结构的问题。如在路径规划、背包问题、编辑距离等领域。其中最经典的应用是背包问题，通过动态规划算法可以高效地求解背包问题的最优解。</li><li><strong>优化</strong>：动态规划算法的时间复杂度往往较高。常用的优化方法包括状态压缩、空间优化、滚动数组等。状态压缩可以将问题的状态表示压缩成一个整数或者一个二进制数，从而减少状态的存储空间。空间优化可以通过仅保存部分状态，避免保存所有状态，从而减少空间使用。滚动数组则是通过循环利用数组来减少空间使用。另外，在实际应用中可以根据问题的特点进行算法的优化，例如在路径规划中，可以使用A<em>算法等算法加速求解过程。<br>-<em>*类型题</em></em>：都具有递推性质<ol><li>求最优解，典型问题是背包问题，当前问题的最优解取决于子问题的最优解（最优子结构）。</li><li>计数类，如统计方案数的问题，当前问题的方案数取决于子问题的方案数。</li></ol></li></ul><p>遇到求最值的问题，基本都是由动态规划算法来解决</p><h3 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h3><ul><li>解决两个字符串的动态规划问题，一般都是用两个指针 i, j 分别指向两个字符串的最后，然后一步步往前移动，缩小问题的规模</li><li>像子数组、子序列这类问题，你就可以尝试定义 dp[i] 是以 nums[i] 为结尾的最大子数组和/最长递增子序列，因为这样定义更容易将 dp[i+1] 和 dp[i] 建立起联系，利用数学归纳法写出状态转移方程<ol><li>涉及两个字符串/数组时（比如最长公共子序列），dp 数组的含义如下：在子数组arr1[0..i]和子数组arr2[0..j]中，我们要求的子序列（最长公共子序列）长度为dp[i][j]。</li><li>只涉及一个字符串/数组时（比如本文要讲的最长回文子序列），dp 数组的含义如下：在子数组array[i..j]中，我们要求的子序列（最长回文子序列）的长度为dp[i][j]。</li></ol></li></ul><p><strong>解题步骤</strong>：</p><ol><li>确定 base case</li><li>确定「状态」，也就是原问题和子问题中会变化的变量</li><li>确定「选择」，也就是导致「状态」产生变化的行为</li><li>明确 dp 函数/数组的定义。根据 dp 数组的定义，运用数学归纳法的思想，假设 dp[0…i-1] 都已知，想办法求出 dp[i]，一旦这一步完成，整个题目基本就解决了。如果无法完成这一步，很可能就是 dp 数组的定义不够恰当，需要重新定义 dp 数组的含义；或者可能是 dp 数组存储的信息还不够，不足以推出下一步的答案，需要把 dp 数组扩大成二维数组甚至三维数组</li><li>动态规划问题的最后一步优化，如果我们发现每次状态转移只需要 DP table 中的一部分，那么可以尝试缩小 DP table 的大小，只记录必要的数据，从而降低空间复杂度。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自顶向下递归的动态规划</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dp</span>(<span class="params">状态<span class="number">1</span>, 状态<span class="number">2</span>, ...</span>):</span></span><br><span class="line">    <span class="keyword">for</span> 选择 <span class="keyword">in</span> 所有可能的选择:</span><br><span class="line">        <span class="comment"># 此时的状态已经因为做了选择而改变</span></span><br><span class="line">        result = 求最值(result, dp(状态<span class="number">1</span>, 状态<span class="number">2</span>, ...))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自底向上迭代的动态规划</span></span><br><span class="line"><span class="comment"># 初始化 base case</span></span><br><span class="line">dp[<span class="number">0</span>][<span class="number">0</span>][...] = base case</span><br><span class="line"><span class="comment"># 进行状态转移</span></span><br><span class="line"><span class="keyword">for</span> 状态<span class="number">1</span> <span class="keyword">in</span> 状态<span class="number">1</span>的所有取值：</span><br><span class="line">    <span class="keyword">for</span> 状态<span class="number">2</span> <span class="keyword">in</span> 状态<span class="number">2</span>的所有取值：</span><br><span class="line">        <span class="keyword">for</span> ...</span><br><span class="line">            dp[状态<span class="number">1</span>][状态<span class="number">2</span>][...] = 求最值(选择<span class="number">1</span>，选择<span class="number">2.</span>..)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><a href="https://leetcode.cn/problems/count-special-integers/solutions/1746956/shu-wei-dp-mo-ban-by-endlesscheng-xtgx/">灵神数位DP</a></p><p><a href="https://leetcode.cn/problems/sum-of-distances-in-tree/solutions/2345592/tu-jie-yi-zhang-tu-miao-dong-huan-gen-dp-6bgb/">灵神换跟DP</a></p><p><a href="https://leetcode.cn/problems/beautiful-arrangement/solutions/2787839/jiao-ni-yi-bu-bu-si-kao-zhuang-ya-dpcong-c6kd/">灵神状压DP</a></p><h3 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">动态规划</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/fibonacci-number/description>✅509. 斐波那契数</td>        <td>dp table记录重叠子问题</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/coin-change/description>✅322. 零钱兑换</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/edit-distance/description>✅72. 编辑距离</td>        <td>dp[i][j]表示长度为i的str1和长度为j的str2的最小编辑距离</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/longest-increasing-subsequence/description>✅300. 最长递增子序列</td>        <td>d[i]表示长度为i的最长上升子序列的末尾元素的最小值</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/russian-doll-envelopes/description>✅354. 俄罗斯套娃信封问题</td>        <td>二维转一维</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/maximum-subarray/description>❌✅53. 最大子数组和</td>        <td>滑动窗口、dp、前缀和  分治未解</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/longest-common-subsequence/description>✅1143. 最长公共子序列</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/longest-palindromic-substring/description>✅5. 最长回文子串</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/delete-operation-for-two-strings/description>✅583. 两个字符串的删除操作</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-ascii-delete-sum-for-two-strings/description>✅712. 两个字符串的最小ASCII删除和</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-insertion-steps-to-make-a-string-palindrome/description>✅1312. 让字符串成为回文串的最少插入次数</td>        <td></td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/longest-palindromic-subsequence/description>✅516. 最长回文子序列</td>        <td>画dp表</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/unique-paths/description>✅62. 不同路径</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/unique-paths-ii/description>✅63. 不同路径 II</td>        <td>滚动数组不会</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-path-sum/description>✅64. 最小路径和</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-falling-path-sum/description>✅931. 下降路径最小和</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/dungeon-game/description>✅174. 地下城游戏</td>        <td>反向DP</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/house-robber/description>✅198. 打家劫舍</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/house-robber-ii/description>✅213. 打家劫舍 II</td>        <td>分类讨论</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/house-robber-iii/description>✅337. 打家劫舍 III</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/best-time-to-buy-and-sell-stock/description>✅121. 买卖股票的最佳时机</td>        <td>只购买一次</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/description>❌✅122. 买卖股票的最佳时机 II</td>        <td>贪心 无限次购买</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-with-cooldown/description>✅309. 最佳买卖股票时机含冷冻期</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description>✅714. 买卖股票的最佳时机含手续费</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-iii/description>✅123. 买卖股票的最佳时机 III</td>        <td>特定的买卖次数</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-iv/description>✅188. 买卖股票的最佳时机 IV</td>        <td>买卖次数不限制</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/freedom-trail/description>✅514. 自由之路</td>        <td>画dp表判断循环方向和顺序</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/climbing-stairs/description>✅70. 爬楼梯</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/min-cost-climbing-stairs/description>✅746. 使用最小花费爬楼梯</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/distinct-subsequences/description>✅115. 不同的子序列</td>        <td></td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/word-break/description>✅139. 单词拆分</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/word-break-ii/description>✅140. 单词拆分 II</td>        <td></td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/greatest-sum-divisible-by-three/description>✅1262. 可被三整除的最大和</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/decremental-string-concatenation/description>✅2746. 字符串连接删减字母</td>        <td>记忆化搜索 单词的开头和结尾</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/maximum-subarray-sum-with-one-deletion/description>✅1186. 删除一次得到子数组最大和</td>        <td>最大子数组和+删除一个元素</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/predict-the-winner/description>✅486. 预测赢家</td>        <td>dp[i][j]表示从i到j当前玩家与另一玩家分数差的最大值</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/cheapest-flights-within-k-stops/description>✅787. K 站中转内最便宜的航班</td>        <td>dijkstra、DP</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/regular-expression-matching/description>✅10. 正则表达式匹配</td>        <td>记忆化搜索+递归：分情况讨论</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/super-egg-drop/description>✅887. 鸡蛋掉落</td>        <td>二分代替线性搜索，minMax</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/burst-balloons/description>✅312. 戳气球</td>        <td>dp[i][j]表示nums[i:j]开区间获得硬币的最大数量，枚举最后被戳破的气球</td>         <td>🌟🌟🌟</td>     </tr></table><h2 id="背包问题"><a href="#背包问题" class="headerlink" title="背包问题"></a>背包问题</h2><p>变体：</p><ul><li>0/1背包问题（0/1 Knapsack Problem）：在给定的一组物品中，每个物品要么全部选取，要么不选取。每个物品只能选择一次放入背包中。</li><li>完全背包问题（Unbounded Knapsack Problem）：在给定的一组物品中，每个物品的数量是无限的，可以重复选择放入背包中。每个物品可以选择多次放入背包中。</li><li>多重背包问题（Multiple Knapsack Problem）：在给定的一组物品中，每个物品有一个限制数量。每个物品可以选择多次放入背包中，但是放入的数量不能超过其限制数量。</li><li>分组背包问题（Group Knapsack Problem）：将物品分为若干组，每组中的物品只能选择一个放入背包中。每个物品只能选择一次放入背包中。</li><li>有限背包问题（Bounded Knapsack Problem）：在给定的一组物品中，每个物品有一个限制数量。每个物品只能选择一次放入背包中，且放入的数量不能超过其限制数量。</li><li>带价值上限的背包问题（Knapsack Problem with Value Limit）：在给定的一组物品中，每个物品有一个限制数量和一个价值上限。每个物品只能选择一次放入背包中，且放入的数量和总价值不能超过其限制。</li></ul><p>0/1背包问题和完全背包问题是经典的NP问题。在求解背包问题时，需要遍历所有可能的物品组合来寻找最优解，而这个过程的时间复杂度通常是指数级的。因此，背包问题属于一类需要指数级时间复杂度的问题，即NP问题。</p><p>NP（Non-deterministic Polynomial time）是一个计算复杂性理论中的重要概念，它是指“非确定多项式时间”。一个问题属于NP，意味着对于该问题的一个解，可以在多项式时间内进行验证。然而，与确定性算法不同，NP问题目前没有已知的高效算法可以在多项式时间内找到解。<br>一个经典的NP问题是旅行商问题（Traveling Salesman Problem，TSP），即寻找最短的路径，使得一个旅行商可以依次访问一系列城市并返回起始城市，而且每个城市只能访问一次。<br>另一个重要的概念是NP完全性（NP-completeness），它指的是一类NP问题，被认为是计算上最难的问题之一。如果一个问题是NP完全的，那么它在多项式时间内可归约为任何其他的NP问题。<br>虽然目前尚未找到多项式时间的算法来解决所有的NP问题，但在实际应用中，我们可以采用启发式算法、近似算法和优化技巧等方法来求解NP问题的近似解或者找到满足特定要求的解。</p><h3 id="算法框架-1"><a href="#算法框架-1" class="headerlink" title="算法框架"></a>算法框架</h3><p><strong>0/1背包</strong>：给定一个背包的容量C和n个物品，每个物品有两个属性：重量w和价值v。在限定的背包容量下选择物品，使得放入背包的物品总价值最大。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knapsack_01</span>(<span class="params">weights, values, capacity</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(weights)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># dp[i][j]表示在前i个物品中选择物品放入容量为j的背包中的最大价值。</span></span><br><span class="line">    dp = [[<span class="number">0</span>] * (capacity + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n + <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># base case: dp[0][j] = 0（表示没有物品可选时的最大价值为0）; dp[i][0] = 0（表示容量为0时无法放入任何物品，所以最大价值为0）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, capacity + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> weights[i - <span class="number">1</span>] &lt;= j:</span><br><span class="line">                dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - weights[i - <span class="number">1</span>]] + values[i - <span class="number">1</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i][j] = dp[i - <span class="number">1</span>][j]</span><br><span class="line"></span><br><span class="line">    selected_items = []</span><br><span class="line">    j = capacity</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> dp[i][j] != dp[i - <span class="number">1</span>][j]:</span><br><span class="line">            selected_items.append(i - <span class="number">1</span>)</span><br><span class="line">            j -= weights[i - <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[n][capacity], selected_items[::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例用法</span></span><br><span class="line">weights = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]  <span class="comment"># 物品的重量</span></span><br><span class="line">values = [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]  <span class="comment"># 物品的价值</span></span><br><span class="line">capacity = <span class="number">8</span>  <span class="comment"># 背包的容量</span></span><br><span class="line"></span><br><span class="line">max_value, selected_items = knapsack_01(weights, values, capacity)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最大价值:&quot;</span>, max_value)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选中的物品索引:&quot;</span>, selected_items)</span><br></pre></td></tr></table></figure><p><strong>完全背包</strong>：给定一个背包的容量C和n个物品，每个物品有两个属性：重量w和价值v。在容量有限的背包中，可以选择<strong>任意数量</strong>的物品放入背包中，使得物品的总重量不超过背包容量，并且总价值最大。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knapsack_unbounded</span>(<span class="params">weights, values, capacity</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(weights)</span><br><span class="line">    dp = [<span class="number">0</span>] * (capacity + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, capacity + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> weights[j] &lt;= i:</span><br><span class="line">                dp[i] = <span class="built_in">max</span>(dp[i], dp[i - weights[j]] + values[j])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[capacity]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例用法</span></span><br><span class="line">weights = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]  <span class="comment"># 物品的重量</span></span><br><span class="line">values = [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]  <span class="comment"># 物品的价值</span></span><br><span class="line">capacity = <span class="number">8</span>  <span class="comment"># 背包的容量</span></span><br><span class="line"></span><br><span class="line">max_value = knapsack_unbounded(weights, values, capacity)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最大价值:&quot;</span>, max_value)</span><br></pre></td></tr></table></figure><h3 id="力扣指南-1"><a href="#力扣指南-1" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">动态规划——背包</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/partition-equal-subset-sum/description>✅416. 分割等和子集</td>        <td>【01背包】注意逻辑</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/coin-change-ii/description>✅518. 零钱兑换 II</td>        <td>【完全背包】好难</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/target-sum/description>✅494. 目标和</td>        <td>【01背包】</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/ones-and-zeroes/description>✅474. 一和零</td>        <td>【01背包】</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/perfect-squares/description>✅279. 完全平方数</td>        <td>【完全背包】</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=>❌879. 盈利计划</td>        <td>【01背包】</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=>❌1049. 最后一块石头的重量 II</td>        <td>【01背包】</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=>❌1230. 抛掷硬币</td>        <td>【01背包】</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=>❌1449. 数位成本和为目标值的最大数字</td>        <td>【完全背包】</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=>❌322.</td>        <td>【完全背包】</td>         <td>🌟🌟</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Search and Backstrack</title>
      <link href="/2023/04/12/Search-and-Backstrack/"/>
      <url>/2023/04/12/Search-and-Backstrack/</url>
      
        <content type="html"><![CDATA[<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h1><ul><li>定义：是指一个问题可以被分解为更小的、相同或类似的问题，并且这些子问题可以通过递归调用算法本身来解决。</li><li>基本情况：递归算法必须具有一个基本情况，这是递归的结束条件。当问题的规模足够小，可以直接解决时，递归算法就会停止递归。</li><li>递归调用：递归算法通过递归调用自身来解决问题。每个递归调用都会将问题规模缩小到一个更小的子问题上，直到达到基本情况。</li><li>栈空间：递归算法使用栈空间来存储每个递归调用的上下文信息。每次递归调用都会将当前的上下文信息推入栈空间，当递归结束时，栈空间会弹出上一个上下文信息。</li><li>递归与迭代：递归算法与迭代算法是算法设计中的两种主要思想。递归算法通过递归调用自身来解决问题，而迭代算法则使用循环来解决问题。</li><li>时间复杂度：粗略估算方法就是用递归函数调用次数（递归树的节点数） x 递归函数本身的复杂度。</li></ul><h1 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h1><h2 id="深度优先搜索"><a href="#深度优先搜索" class="headerlink" title="深度优先搜索"></a>深度优先搜索</h2><p>深度优先搜索（Depth-First Search，DFS）是一种图遍历算法，它从起始顶点开始，依次访问其所有相邻顶点，并递归地对每个相邻顶点进行深度优先搜索，直到遍历完整个图。知识点：</p><ul><li><strong>栈</strong>：DFS可以使用栈来实现。从起始顶点开始，将其压入栈中，然后循环执行以下操作：从栈中取出一个顶点，并访问其所有未访问的相邻顶点，将其压入栈中。直到栈为空，搜索结束。</li><li><strong>递归</strong>：DFS也可以使用递归实现。从起始顶点开始，依次递归地访问其所有相邻顶点，直到遍历完整个图。递归实现的优点是代码简洁清晰，但也有可能导致栈溢出。</li><li><strong>标记数组</strong>：为了避免重复访问已经访问过的顶点，DFS通常使用一个布尔类型的标记数组来记录每个顶点是否已经访问过。</li><li><strong>拓扑排序</strong>：DFS可以用来实现拓扑排序。拓扑排序是对有向无环图的所有顶点进行排序的一种算法。通过DFS，可以将图中的所有顶点按照其依赖关系排序，从而实现拓扑排序。</li><li><strong>时间复杂度</strong>：DFS的时间复杂度取决于搜索过程中访问每个顶点的次数。对于稠密图，每个顶点都会被访问一次，因此时间复杂度为 $O(V^2)$，其中 $V$ 是顶点数。对于稀疏图，时间复杂度可以达到 $O(V+E)$，其中 $E$ 是边数。</li><li><strong>空间复杂度</strong>：DFS靠递归的堆栈记录⾛过的路径，要找到最短路径得把⼆叉树中所有树杈都探索完才能对⽐出最短的路径有多⻓，DFS 算法空间复杂度最坏情况下是树⾼度$O(logN)$ 。</li><li><strong>应用</strong>：DFS通常用于解决一些搜索深度较小的问题，例如拓扑排序、连通性判断等。由于DFS搜索深度较大时容易出现堆栈溢出等问题，因此需要选择合适的算法实现。</li></ul><h3 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">深度优先搜索</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/surrounded-regions/description>✅130. 被围绕的区域</td>        <td>从边界开始处理</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/number-of-islands/description>✅200. 岛屿数量</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/pacific-atlantic-water-flow/description>✅417. 太平洋大西洋水流问题</td>        <td>双边界逆流而上</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minesweeper/description>✅529. 扫雷游戏</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/number-of-closed-islands>✅1254. 统计封闭岛屿的数目</td>        <td>去除边界</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/number-of-enclaves/description>✅1020. 飞地的数量</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/max-area-of-island/description>✅695. 岛屿的最大面积</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/count-sub-islands/description>✅1905. 统计子岛屿</td>        <td></td>         <td>🌟🌟</td>     </tr></table><h2 id="深度优先搜索——树专项"><a href="#深度优先搜索——树专项" class="headerlink" title="深度优先搜索——树专项"></a>深度优先搜索——树专项</h2><p>二叉树解题的思维模式分两类：</p><ol><li>遍历：通过遍历一遍二叉树得到答案，用一个 traverse 函数配合外部变量来实现</li><li>分解：定义一个递归函数，通过子问题（子树）的答案推导出原问题的答案，写出这个递归函数的定义，并充分利用这个函数的返回值<br>思考：如果单独抽出一个二叉树节点，它需要做什么事情？需要在什么时候（前/中/后序位置）做？其他的节点不用你操心，递归函数会帮你在所有节点上执行相同的操作。</li></ol><h3 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">traverse</span>(<span class="params">root: <span class="type">Optional</span>[TreeNode]</span>):</span></span><br><span class="line">    <span class="comment"># root 需要做什么？在这做。</span></span><br><span class="line">    <span class="comment"># 其他的不⽤ root 操⼼，抛给框架</span></span><br><span class="line">    traverse(root.left)</span><br><span class="line">    traverse(root.right)</span><br></pre></td></tr></table></figure><h3 id="力扣指南-1"><a href="#力扣指南-1" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">树</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/binary-tree-inorder-traversal/description>✅94. 二叉树的中序遍历</td>        <td>框架递归</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/construct-binary-tree-from-preorder-and-inorder-traversal/description>✅105. 从前序与中序遍历序列构造二叉树</td>        <td>前序遍历递归</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/construct-binary-tree-from-inorder-and-postorder-traversal/description>✅106. 从中序与后序遍历序列构造二叉树</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/balanced-binary-tree/description>✅110. 平衡二叉树</td>        <td>递归</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-depth-of-binary-tree/description>✅111. 二叉树的最小深度</td>        <td>递归</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/path-sum/description>✅112. 路径总和</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/flatten-binary-tree-to-linked-list/description>✅114. 二叉树展开为链表</td>        <td>分解法：通过子问题求解原问题</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/populating-next-right-pointers-in-each-node>✅116. 填充每个节点的下一个右侧节点指针</td>        <td>借助中间节点</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/populating-next-right-pointers-in-each-node-ii>✅117. 填充每个节点的下一个右侧节点指针 II</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/binary-tree-maximum-path-sum/description>✅124. 二叉树中的最大路径和</td>        <td></td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/sum-root-to-leaf-numbers/description>✅129. 求根节点到叶节点数字之和</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/binary-tree-right-side-view/description>✅199. 二叉树的右视图</td>        <td>记录深度 跟右左遍历</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/count-complete-tree-nodes/description>✅222. 完全二叉树的节点个数</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/invert-binary-tree/description>✅226. 翻转二叉树</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/lowest-common-ancestor-of-a-binary-tree/description>✅236. 二叉树的最近公共祖先</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/binary-tree-paths/description>✅257. 二叉树的所有路径</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/serialize-and-deserialize-binary-tree/description>✅297. 二叉树的序列化与反序列化</td>        <td></td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/sum-of-left-leaves/description>✅404. 左叶子之和</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/diameter-of-binary-tree/description>✅543. 二叉树的直径</td>        <td>最大路径为当前节点的左右子树最大高度和</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/find-duplicate-subtrees/description>✅652. 寻找重复的子树</td>        <td>中序遍历无法确定唯一的序列化字符串</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/maximum-binary-tree/description>✅654. 最大二叉树</td>        <td>分解法构造</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/construct-binary-tree-from-preorder-and-postorder-traversal/description>✅889. 根据前序和后序遍历构造二叉树</td>        <td></td>         <td>🌟🌟</td>     </tr></table><h2 id="深度优先搜索——二叉搜索树专项"><a href="#深度优先搜索——二叉搜索树专项" class="headerlink" title="深度优先搜索——二叉搜索树专项"></a>深度优先搜索——二叉搜索树专项</h2><h3 id="算法框架-1"><a href="#算法框架-1" class="headerlink" title="算法框架"></a>算法框架</h3><p>二叉搜索树的题本质都是中序遍历或者利用其性质任意节点的值要⼤于等于左⼦树所有节点的值且要⼩于等于右边⼦树的所有节点的值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BST</span>(<span class="params">root: <span class="type">Optional</span>[TreeNode], target</span>):</span></span><br><span class="line">    <span class="keyword">if</span> root.val == target:</span><br><span class="line">        <span class="comment"># 到⽬标，做点什么</span></span><br><span class="line">    <span class="keyword">if</span> root.val &lt; target:</span><br><span class="line">        BST(root.right, target)</span><br><span class="line">    <span class="keyword">if</span> root.val &gt; target:</span><br><span class="line">        BST(root.left, target)</span><br></pre></td></tr></table></figure></p><h3 id="力扣指南-2"><a href="#力扣指南-2" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">二叉搜索树</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/validate-binary-search-tree>✅98. 验证二叉搜索树</td>        <td>二叉搜索树中序遍历递增</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/recover-binary-search-tree/description>✅99. 恢复二叉搜索树</td>        <td>交换节点的值而不是交换地址</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/convert-sorted-array-to-binary-search-tree/description>✅108. 将有序数组转换为二叉搜索树</td>        <td>二分转换</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/convert-sorted-list-to-binary-search-tree/description>✅109. 有序链表转换二叉搜索树</td>        <td>左闭又开二分</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/lowest-common-ancestor-of-a-binary-search-tree/description>✅235. 二叉搜索树的最近公共祖先</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/kth-smallest-element-in-a-bst/description>✅230. 二叉搜索树中第K小的元素</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/serialize-and-deserialize-bst/description>✅449. 序列化和反序列化二叉搜索树</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/delete-node-in-a-bst/description>✅450. 删除二叉搜索树中的节点</td>        <td>用右子树的最左节点替换跟节点</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-absolute-difference-in-bst/description>✅530. 二叉搜索树的最小绝对差</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/convert-bst-to-greater-tree/description>✅538/1038. 把二叉搜索树转换为累加树</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/search-in-a-binary-search-tree/description>✅700. 二叉搜索树中的搜索</td>        <td>利用递增性质二分</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/insert-into-a-binary-search-tree/description>✅701. 二叉搜索树中的插入操作</td>        <td>找到要插入的位置定义节点</td>         <td>🌟🌟</td>     </tr></table><h2 id="广度优先搜索BFS"><a href="#广度优先搜索BFS" class="headerlink" title="广度优先搜索BFS"></a>广度优先搜索BFS</h2><p>广度优先搜索（Breadth-First Search，BFS）是一种图遍历算法，它从起始顶点开始，逐层访问其相邻顶点，并记录每个顶点到起始顶点的距离。知识点：</p><ul><li><strong>队列</strong>：BFS可以使用队列来实现。从起始顶点开始，将其放入队列中，然后循环执行以下操作：从队列中取出一个顶点，并访问其所有未访问的相邻顶点，将其放入队列中。直到队列为空，搜索结束。</li><li><strong>标记数组</strong>：为了避免重复访问已经访问过的顶点，BFS通常使用一个布尔类型的标记数组来记录每个顶点是否已经访问过。同时，为了记录每个顶点到起始顶点的距离，可以使用一个整型数组来存储每个顶点的距离。</li><li><strong>最短路径</strong>：BFS可以用来寻找无权图中起始顶点到其他顶点的最短路径。由于BFS是按层遍历的，因此可以保证从起始顶点到其他顶点的路径是最短的。</li><li><strong>连通性</strong>：BFS可以用来判断图的连通性。如果从起始顶点开始可以访问到所有其他顶点，则图是连通的；否则，图是不连通的。</li><li><strong>时间复杂度</strong>：BFS的时间复杂度取决于搜索过程中访问每个顶点的次数。对于稠密图，时间复杂度可以达到 $O(V^2)$，其中 $V$ 是顶点数。对于稀疏图，时间复杂度可以达到 $O(V+E)$，其中 E 是边数。</li><li><strong>空间复杂度</strong>：BFS 借助队列做到⼀次⼀步⻬头并进，是可以在不遍历完整棵树的条件下找到最短距离。BFS 算法队列中每次都会储存着⼆叉树⼀层的节点，最坏情况下空间复杂度是树的最底层节点的数量$O(N)$ 。</li><li><strong>应用</strong>：BFS通常用于解决一些搜索深度较大的问题，例如最短路径、最小生成树等。由于BFS按层遍历，因此可以保证从起始顶点到其他顶点的路径是最短的。</li><li><strong>变体</strong>：双向深度优先搜索（Bidirectional Depth-First Search，简称BDFS）可以在图或树中同时从起点和终点进行深度优先搜索，以期缩短搜索时间。<ul><li><strong>原理</strong>：BDFS是双向搜索的一种变形，它通过同时从起点和终点进行深度优先搜索，以期在中间遇到一条路径，从而找到起点和终点之间的最短路径。在搜索过程中，需要记录起点和终点的已访问状态，直到两个搜索过程汇合，或者找到一条最短路径。</li><li><strong>特点</strong>：BDFS与DFS的搜索方式类似，只是在搜索过程中从起点和终点同时进行搜索。相比于BFS，BDFS的空间复杂度较低，但是对于图中较长路径，可能会超时或者陷入死循环。</li><li><strong>实现</strong>：BDFS的实现需要在搜索过程中记录起点和终点的已访问状态，并且需要判断是否有路径在中间汇合，或者找到一条最短路径。通常可以使用哈希表等数据结构来记录已访问状态，以及使用双向队列等数据结构来记录搜索过程中的路径。</li><li><strong>应用</strong>：BDFS可以用于寻找起点和终点之间的最短路径，例如在网络中找到两个节点之间的最短路径，或者在迷宫中找到从起点到终点的最短路径。另外，BDFS还可以用于图的遍历，例如在社交网络中寻找特定人群之间的联系，或者在语言处理中寻找两个词语之间的关系。</li></ul></li></ul><h3 id="算法框架-2"><a href="#算法框架-2" class="headerlink" title="算法框架"></a>算法框架</h3><p>原地修改的问题可以不使用visited标记</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Set</span>, <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">adj</span>(<span class="params">self</span>) -&gt; <span class="type">List</span>[Node]:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BFS</span>(<span class="params">start: Node, target: Node</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">    q: <span class="type">List</span>[Node] = []  <span class="comment"># 核心数据结构</span></span><br><span class="line">    visited: <span class="type">Set</span>[Node] = <span class="built_in">set</span>()  <span class="comment"># 避免走回头路</span></span><br><span class="line"></span><br><span class="line">    q.append(start)  <span class="comment"># 将起点加入队列</span></span><br><span class="line">    <span class="comment"># visited.add(start)</span></span><br><span class="line">    step: <span class="built_in">int</span> = <span class="number">0</span>  <span class="comment"># 记录扩散的步数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> q:</span><br><span class="line">        sz: <span class="built_in">int</span> = <span class="built_in">len</span>(q)</span><br><span class="line">        <span class="comment"># 将当前队列中的所有节点向四周扩散</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(sz):</span><br><span class="line">            cur: Node = q.pop(<span class="number">0</span>)</span><br><span class="line">            <span class="comment"># 划重点：这里判断是否到达终点</span></span><br><span class="line">            <span class="keyword">if</span> cur <span class="keyword">is</span> target:</span><br><span class="line">                <span class="keyword">return</span> step</span><br><span class="line">            <span class="comment"># 将 cur 的相邻节点加入队列</span></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> cur.adj():</span><br><span class="line">                <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">                    q.append(x)</span><br><span class="line">                    visited.add(x)</span><br><span class="line">        <span class="comment"># 划重点：更新步数在这里</span></span><br><span class="line">        step += <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="力扣指南-3"><a href="#力扣指南-3" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">广度优先搜索</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-depth-of-binary-tree/description>✅111. 二叉树的最小深度</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/path-sum/description>✅112. 路径总和</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/populating-next-right-pointers-in-each-node/description>✅116. 填充每个节点的下一个右侧节点指针</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.c/problems/populating-next-right-pointers-in-each-node-ii/description>✅117. 填充每个节点的下一个右侧节点指针 II</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/surrounded-regions/description>✅130. 被围绕的区域</td>        <td>从边界开始处理</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/binary-tree-right-side-view/description>✅199. 二叉树的右视图</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/number-of-islands/description>✅200. 岛屿数量</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/sum-of-left-leaves/description>✅404. 左叶子之和</td>        <td>理解题意</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/pacific-atlantic-water-flow/description>✅417. 太平洋大西洋水流问题</td>        <td>双边界逆流而上</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minesweeper/description>✅529. 扫雷游戏</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/open-the-lock/description>✅752. 打开转盘锁</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/sliding-puzzle/description>✅773. 滑动谜题</td>        <td></td>         <td>🌟🌟🌟</td>     </tr></table><h1 id="回溯"><a href="#回溯" class="headerlink" title="回溯"></a>回溯</h1><p>回溯算法（Backtracking）是一种基于深度优先搜索的算法，它常用于在一组可能的解中搜索最优解。知识点：</p><ul><li><strong>原理</strong>：回溯算法是通过试错的方式进行搜索，即从一个可能的解开始搜索，如果发现当前解不可行，则回溯到上一步进行尝试。在搜索过程中需要记录当前已尝试的路径，并在每一步进行判断，如果当前路径已经不能满足要求，则需要进行回溯。</li><li><strong>实现</strong>：回溯算法通常采用递归实现，每次搜索的参数包括当前路径、已访问状态等。在搜索过程中需要进行剪枝，即在当前路径已经不能满足要求时，提前结束搜索。在实现过程中需要注意，回溯算法通常可以通过状态重置来进行回溯，也可以通过栈等数据结构来记录搜索过程。</li><li><strong>应用</strong>：回溯算法常用于求解组合、排列、子集等问题，例如在数独游戏中求解解，在密码破解中找到密码、图的遍历、求解最优化问题等。</li><li><strong>优化</strong>：回溯算法的时间复杂度往往较高，常用的优化方法包括剪枝、记忆化搜索等。剪枝可以在搜索过程中排除不必要的搜索路径，从而减少搜索时间。记忆化搜索可以将已经搜索过的结果记录下来，避免重复搜索。另外，在实际应用中可以根据问题的特点进行算法的优化，例如在图的遍历中，可以使用启发式搜索等算法加速搜索过程。</li><li><strong>时间复杂度</strong>：$O(n!)$，不像动态规划存在重叠⼦问题可以优化，回溯算法是纯暴⼒穷举。</li><li><strong>技巧</strong>：回溯的撤销选择取决于是否对原始选择列表修改，如果修改则需要撤销操作。</li></ul><h3 id="算法框架-3"><a href="#算法框架-3" class="headerlink" title="算法框架"></a>算法框架</h3><p>回溯问题实际上是⼀个决策树的遍历过程。需要思考 3 个问题：</p><ol><li>路径：已经做出的选择</li><li>选择列表：当前可以做的选择</li><li>结束条件：到达决策树底层，⽆法再做选择的条件</li></ol><p>排列题用used标记，组合题用start标记</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">result = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backtrack</span>(<span class="params">path, choice_list</span>):</span></span><br><span class="line">    <span class="keyword">if</span> target:</span><br><span class="line">        result.add(path)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">for</span> choice <span class="keyword">in</span> choice_list:</span><br><span class="line">        <span class="comment"># 做选择</span></span><br><span class="line">        backtrack(path, choice_list)</span><br><span class="line">        <span class="comment"># 撤销选择</span></span><br></pre></td></tr></table></figure><h3 id="力扣指南-4"><a href="#力扣指南-4" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">回溯</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/sudoku-solver/description>✅37. 解数独</td>        <td>有数字的剪枝；有可行解返回避免撤销</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/combination-sum/description>✅39. 组合总和</td>        <td>（元素无重可复选）每次复用start，使用整体剪纸避免无限递归</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/combination-sum-ii/description>✅40. 组合总和 II</td>        <td>剪枝掉超过target的</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/permutations/description>✅46. 全排列</td>        <td>时间复杂度为O(n×n!)</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/permutations-ii/description>✅47. 全排列 II</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/n-queens/description>✅51. N 皇后</td>        <td>python字符串为不可变类型，修改只能对字符串重新赋值</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/n-queens-ii/description>✅52. N 皇后 II</td>        <td></td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/combinations/description>✅77. 组合</td>        <td>同78</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/subsets/description>✅78. 子集</td>        <td>（元素无重不可复选）用start标记起始点避免产生重复</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/subsets-ii/description>✅90. 子集 II</td>        <td>剪枝走过的路径</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/combination-sum-iii/description>✅216. 组合总和 III</td>        <td>秒了</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/generate-parentheses/description>✅22. 括号生成</td>        <td></td>         <td>🌟🌟</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bit Arithmetic</title>
      <link href="/2023/03/27/Bit-Arithmetic/"/>
      <url>/2023/03/27/Bit-Arithmetic/</url>
      
        <content type="html"><![CDATA[<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h1><ul><li><strong>简介</strong>：程序中的所有数在计算机内存中都是以二进制的形式储存的。位运算就是直接对整数在内存中的二进制位进行操作。常见的运算符有与(&amp;)、或(|)、异或(^)、取反(~)、左移(&lt;&lt;)、右移(&gt;&gt;是带符号右移 &gt;&gt;&gt;无符号右移动)。</li><li><strong>优点</strong>：可以直接对二进制数进行操作，执行速度比较快，而且可以节省内存空间，特别是在处理大规模数据时，优势更加明显。</li><li><strong>应用场景</strong>：常用于处理二进制数据，如位图压缩、哈希表实现、位集合操作等。也可以用于加密算法、图像处理、网络协议等领域。</li><li><strong>时间复杂度</strong>：通常是$O(1)$，因为它们直接对二进制位进行操作，而不需要循环或递归等复杂的计算过程。</li><li><strong>技巧</strong>：<ol><li>按位与&amp;：<ul><li>判断一个数的奇偶性（<code>x &amp; 1 == 0</code>表示x是偶数，<code>x &amp; 1 == 1</code>表示x是奇数）</li><li>清零一个数的某一位(<code>x &amp;= ~(1 &lt;&lt; n)</code>表示将x的第n位清零)</li><li>判断一个数是否是2的幂次方。例如：<code>(x &amp; (x - 1)) == 0</code> 表示x是2的幂次方</li><li>Brian Kernighan算法：消除数字n的二进制表示中的最后一位1，也即计算汉明权重（Hamming Weight）：<code>n &amp; (n-1)</code></li><li>取出 x 的二进制表示中最低位的1 ：<code>x &amp; -x</code></li></ul></li><li>按位或|：<ul><li>将一个数的某一位设置为1 ( <code>x |= (1 &lt;&lt; n)</code> 表示将x的第n位设置为1)</li></ul></li><li>按位异或^：<ul><li>可以用来交换两个变量的值（<code>a ^= b; b ^= a; a ^= b;</code>）</li><li>检查一个数是否出现了奇数次。对于数组中出现两次的数，使用异或操作可以找到它们，任何数和其自身做异或运算，结果是0，即 <code>a ^ a = 0</code></li><li>任何数和 0 做异或运算，结果仍然是原来的数，即 <code>a ^ 0 = a</code></li><li>异或运算满足交换律和结合律，即<code>a ⊕ b ⊕ a = b ⊕ a ⊕ a = b ⊕ (a ⊕ a) = b ⊕ 0 = b</code></li></ul></li><li>左移位&lt;&lt;：可以用来计算2的幂次方（<code>1 &lt;&lt; n</code>表示2的n次方）</li><li>右移位&gt;&gt;：可以用来计算除以2的幂次方（<code>x &gt;&gt; n</code>表示将x除以2的n次方）</li></ol></li><li><strong>常用方法</strong>：<ul><li><code>bin()</code>获取数字的二进制值</li><li><code>ord()</code>输入单个字符返回其ASCII值（0-255）或unicode值</li><li><code>chr()</code>输入一个整数[0，255]返回其ASCII值</li><li><code>int(&quot;s&quot;,x)</code>将指定进制x的字符s转换成十进制值</li><li>正数的反码和补码都与原码相同。负数的二进制用补码表示。负数的反码为对该数的原码除符号位外各位取反。负数的补码为对该数的原码除符号位外各位取反，然后在最后一位加1 。</li></ul></li></ul><p>Python 没有 int, long 等不同长度变量，即在编程时无变量位数的概念。</p><ul><li>获取负数的补码：需要将数字与十六进制数 0xffffffff 相与。可s理解为舍去此数字 32 位以上的数字（将 32 位以上都变为 00），从无限长度变为一个 32 位整数。</li><li>返回前数字还原： 若补码 aaa 为负数（ 0x7fffffff 是最大的正数的补码 ），需执行 <code>~(a ^ x)</code> 操作，将补码还原至 Python 的存储格式。 a ^ x 运算将 1 至 32 位按位取反； ~ 运算是将整个数字取反；因此， ~(a ^ x) 是将 32 位以上的位取反，1 至 32 位不变</li></ul><blockquote><p>参考博客：</p><ul><li><a href="https://bigsai.blog.csdn.net/article/details/113245972">位运算介绍与经典例题总结</a></li><li><a href="https://blog.csdn.net/w464960660/article/details/94304069?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161197629816780266247321%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=161197629816780266247321&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-94304069.first_rank_v2_pc_rank_v29_10&amp;utm_term=%E4%BD%8D%E6%8E%A9%E7%A0%81&amp;spm=1018.2226.3001.4187">位掩码（BitMask）</a></li><li><a href="https://blog.csdn.net/mjLlm/article/details/101559522?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161214219916780299011814%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=161214219916780299011814&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-101559522.first_rank_v2_pc_rank_v29_10&amp;utm_term=unicode&amp;spm=1018.2226.3001.4187">Unicode详解</a></li></ul></blockquote><h3 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">位运算</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/add-binary/description>✅67. 二进制求和</td>        <td>简直不是人想出来的！！！</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/single-number/description>✅136. 只出现一次的数字</td>        <td>a ^ 0 = a; a ^ a = 0</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/single-number-ii/description>✅137. 只出现一次的数字 II</td>        <td>(a >> i) & 1 取出a的第i位</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/repeated-dna-sequences/description>✅187. 重复的DNA序列</td>        <td>用二进制表示x = ((x << 2) | bin[ch]) & ((1 << 20) - 1)</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/reverse-bits/description>❌✅190. 颠倒二进制位</td>        <td>还有个分治法</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/number-of-1-bits/description>✅191. 位1的个数</td>        <td>n & (n - 1)消除二进制n的最后一位1</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/bitwise-and-of-numbers-range/description>✅201. 数字范围按位与</td>        <td>寻找公共前缀，n&(n-1)消除最后一位1</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/power-of-two/description>✅231. 2 的幂</td>        <td>同191 260</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/single-number-iii/description>✅260. 只出现一次的数字 III</td>        <td>x的最后一位1：x & -x</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/missing-number/description>✅268. 丢失的数字</td>        <td>a ^ a = 0</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/find-the-duplicate-number/description>❌287. 寻找重复数</td>        <td>难以理解</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/maximum-product-of-word-lengths/description>✅318. 最大单词长度乘积</td>        <td>将字母用掩码表示，取并为0则表示二者没用重复字符</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/counting-bits/description>❌✅338. 比特位计数</td>        <td>x&(x-1)消除1，还有动态规划解法</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/power-of-four/description>✅342. 4的幂</td>        <td>4的幂是2的偶数次幂，且%3=1</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/sum-of-two-integers/description>✅371. 两整数之和</td>        <td>python整型无限长，用32位补码表示32位有符号整型，负数最高位全为1</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/find-the-difference/description>✅389. 找不同</td>        <td>ord(a), chr(1)</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/set-mismatch/description>✅645. 错误的集合</td>        <td>同260</td>         <td>🌟</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Papers Ideas</title>
      <link href="/2023/03/25/Papers-Ideas/"/>
      <url>/2023/03/25/Papers-Ideas/</url>
      
        <content type="html"><![CDATA[<p>在我科研迷茫时，感谢朱老师的分享：<a href="https://www.bilibili.com/video/BV1oX4y1d7X6/?spm_id_from=444.41.list.card_archive.click&amp;vd_source=486265fa677326a8f53894f05277bfb9">大模型时代下做科研的四个思路【论文精读·52】</a></p><h1 id="Efficient"><a href="#Efficient" class="headerlink" title="Efficient"></a>Efficient</h1><p>由于缺少计算资源，可以关注现有模型费时费力的模块进行efficient优化，如<strong>Efficient Attention</strong>优化（ Lean Former; Performer; Flash Attention）和主要应用于大模型的微调的<strong>Parameter Efficient Fine Tuning（PEFT）</strong>。PEFT包括<strong>Adapter</strong>和<strong>Prompt</strong>。</p><ul><li>《AIM: Adapting Image Models for Efficient Video Action Recognition》【ICLR2023】<a href="https://arxiv.org/abs/2302.03024">Arxiv</a><br>一个即插即用的模块，加入到Transformer中，原有的大模型训练时参数frozen，模型微调时只训练Adapter的模块参数。<div align="center"><img src="PEFT_1.png" height=90% width=90%><img src="PEFT_2.png" height=90% width=90%></div></li><li>《Parameter-Efficient Transfer Learning for NLP》<a href="https://arxiv.org/abs/1902.00751">Arxiv</a><div align="center"><img src="Adapter.png"></div></li><li>《Learning to Prompt for Vision-Language Models》【IJCV2022】<a href="https://arxiv.org/abs/2109.01134">Arxiv</a><div align="center"><img src="Prompt_vs_CoOp.png"><img src="CoOp.png"></div></li><li>《Visual Prompt Tuning》【ECCV2022】<a href="https://arxiv.org/abs/2203.12119">Arxiv</a><div align="center"><img src="Visual_prompt.png" height=90% width=90%></div></li><li>PEFT综述《Towards a Unified View of Parameter-Efficient Transfer Learning》【ICLR2022】<a href="https://arxiv.org/abs/2110.04366">Arxiv</a></li></ul><h1 id="Existing-Stuff"><a href="#Existing-Stuff" class="headerlink" title="Existing Stuff"></a>Existing Stuff</h1><p>目前的预训练模型和数据规模都很大，当计算资源少时尽量不要用预训练模型，可以选择Zero-shot或者Few-shot，或者Fine-tuning。可以借助存在的预训练模型（如CLIP）；融入新的研究方向（如Causality Learning因果学习；FFNet；In-Context Learning；Chain of Thought Prompting）也是很好的选择，不用担心竞争和刷榜。</p><ul><li>《Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations》【ICLR2023】<a href="https://arxiv.org/abs/2207.05027v1">Arxiv</a><br> 使用两个已经训练好的模型进行Object-centric Representations任务（较新的方向）<div align="center">  <img src="Object-centric-Representations.png" height=90% width=90%></div></li></ul><h1 id="Plug-and-play"><a href="#Plug-and-play" class="headerlink" title="Plug and play"></a>Plug and play</h1><p>做一些通用的即插即用的模块，包括模型模块（ResNet+Non-Local）、loss函数（Focal Loss）、数据增强方式（Mixup）。选取baseline进行实验，在模型上有一个统一的提升即可，而不需要在大模型上训练。</p><ul><li>《MixGen: A New Multi-Modal Data Augmentation》【WACV2023】<a href="https://arxiv.org/abs/2206.08358">Arxiv</a><br>多模态预训练任务的原属数据量已经很多，不需要进行数据增强，但是下游任务不同仍然需要数据增强。问题是多模态数据增强时有些信息会丢失（如颜色、位置）导致图像文本对不匹配。MixGen的初衷即尽可能保留更多的信息。<div align="center">  <img src="MixGen.png"></div></li></ul><h1 id="Dataset-evaluation-and-survey"><a href="#Dataset-evaluation-and-survey" class="headerlink" title="Dataset, evaluation and survey"></a>Dataset, evaluation and survey</h1><p>构建数据集；主要以分析为主的文章（如HELM语言模型评估）；综述文章。可以加深对领域的理解同时也具有一定的影响力。</p><ul><li>《BigDetection: A Large-scale Benchmark for Improved Object Detector Pre-training》<a href="https://arxiv.org/abs/2203.13249">Arxiv</a><br>合并三个已有数据集并进行各种处理。</li><li>《A Comprehensive Study of Deep Video Action Recognition》<a href="https://arxiv.org/abs/2012.06567">Arxiv</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Reading Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prefix Sum and Difference Array</title>
      <link href="/2023/03/22/Prefix-Sum-and-Difference-Array/"/>
      <url>/2023/03/22/Prefix-Sum-and-Difference-Array/</url>
      
        <content type="html"><![CDATA[<h1 id="前缀和"><a href="#前缀和" class="headerlink" title="前缀和"></a>前缀和</h1><ul><li><strong>简介</strong>：前缀和算法是一种常见的数组处理算法，通过预处理出数组的前缀和（Prefix Sum），可以在$O(1)$时间内快速求出任意区间的和。</li><li><strong>计算方式</strong>：对于一个长度为n的数组a，其前缀和数组prefix_sum的第i个元素表示a数组中前i-1个元素的和，计算公式为<code>prefix_sum[i+1] = prefix_sum[i] + a[i]</code>。初始化<code>prefix_sum=[0]*(len(a)+1)</code>。</li><li><strong>使用前缀和算法求解区间和</strong>：假设要求区间[l,r]的和，可以通过计算<code>prefix_sum[r+1]-prefix_sum[l]</code>来得到区间和。这是因为<code>prefix_sum[r+1]表示a数组前r个元素的和，</code>prefix_sum[l]`表示a数组前l-1个元素的和，两者相减即可得到区间[l,r]的和。</li><li><strong>应用场景</strong>：处理数组序列问题，如求解子数组的和、平均数、中位数等。也可以用于处理二维矩阵中的子矩阵问题。</li><li><strong>时间复杂度</strong>：预处理时间复杂度为$O(n)$，求解区间和的时间复杂度为$O(1)$，因此总的时间复杂度为$O(n)$。</li></ul><h3 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 判断数组内是否有等于k的连续子数组，或者有几个</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prefix_search</span>(<span class="params">self, k: <span class="built_in">int</span>, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) :</span></span><br><span class="line">    <span class="comment"># 计算前缀和数组，有时可以边遍历边计算，不用单独先计算前缀和</span></span><br><span class="line">    pre_sum = [<span class="number">0</span>] * (<span class="built_in">len</span>(nums) + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">        pre_sum[i+<span class="number">1</span>] = pre_sum[i] + nums[i]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums) + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 记录子前缀和信息</span></span><br><span class="line">        <span class="built_in">dict</span>[pre_sum[i]] += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 边遍历边记录前缀和</span></span><br><span class="line">        <span class="comment"># pre_sum += nums[i]</span></span><br><span class="line">        <span class="comment"># 转换问题pre_sum[i] - pre_sum[j] = k</span></span><br><span class="line">        target = pre_sum[i] - k</span><br><span class="line">        <span class="comment"># 判断target是否满足什么条件，返回结果（通常通过字典查询）</span></span><br><span class="line">        <span class="keyword">if</span> target <span class="keyword">in</span> <span class="built_in">dict</span>:</span><br><span class="line">            ans...</span><br></pre></td></tr></table></figure><p>二维前缀和<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MatrixSum</span>:</span></span><br><span class="line">    <span class="comment"># s[i + 1][j + 1]表示左上角为a[0][0]右下角为a[i][j]的子矩阵元素和 </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, matrix</span>):</span></span><br><span class="line">        m, n = <span class="built_in">len</span>(matrix), <span class="built_in">len</span>(matrix[<span class="number">0</span>])</span><br><span class="line">        s = [[<span class="number">0</span>] * (n + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m + <span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i, row <span class="keyword">in</span> <span class="built_in">enumerate</span>(matrix):</span><br><span class="line">            <span class="keyword">for</span> j, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(row):</span><br><span class="line">                s[i + <span class="number">1</span>][j + <span class="number">1</span>] = s[i + <span class="number">1</span>][j] + s[i][j + <span class="number">1</span>] - s[i][j] + x</span><br><span class="line">        self.s = s</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 返回左上角在 (r1,c1) 右下角在 (r2-1,c2-1) 的子矩阵元素和（类似前缀和的左闭右开）</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">query</span>(<span class="params">self, r1, c1, r2, c2</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.s[r2][c2] - self.s[r2][c1] - self.s[r1][c2] + self.s[r1][c1]</span><br></pre></td></tr></table></figure><br><a href="https://leetcode.cn/circle/discuss/UUuRex/">【图解】二维前缀和</a></p><h3 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">前缀和</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-size-subarray-sum/description>✅209. 长度最小的子数组</td>        <td>前缀和+二分bisect</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/product-of-array-except-self/description>✅238. 除自身以外数组的乘积</td>        <td>分别计算前后缀乘积</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/range-sum-query-immutable/description>✅303. 区域和检索 - 数组不可变</td>        <td>一维前缀和</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/range-sum-query-2d-immutable/description>✅304. 二维区域和检索 - 矩阵不可变</td>        <td>二维前缀和</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/max-sum-of-rectangle-no-larger-than-k/description>❌363. 矩形区域不超过 K 的最大数值和</td>        <td>二分+有序集合</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/continuous-subarray-sum/description>✅523. 连续的子数组和</td>        <td>sum[i]-sum[j]=n*k等效于sum[i]和sum[j]对k的余数相等，用哈希记录</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/contiguous-array/description>✅525. 连续数组</td>        <td>转换问题：求最长的连续子数组，其元素和为0</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/subarray-sum-equals-k/description>✅560. 和为 K 的子数组</td>        <td>sum[i]-sum[j]=k转化成sum[j]=sum[i]-k，用哈希记录</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/find-pivot-index/description>✅724. 寻找数组的中心下标 & 1991</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/binary-subarrays-with-sum/description>✅930. 和相同的二元子数组</td>        <td>同974</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/subarray-sums-divisible-by-k/description>✅974. 和可被 K 整除的子数组</td>        <td>同523，需要初始化{0:1}来记录前缀总和的情况</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/can-make-palindrome-from-substring/description>✅1177. 构建回文串检测</td>        <td>异或前缀和，计算奇偶数量</td>         <td>🌟🌟</td>     </tr></table><h1 id="前缀树"><a href="#前缀树" class="headerlink" title="前缀树"></a>前缀树</h1><p>前缀树，也称为字典树（Trie）或键树，是一种用于有效存储和检索字符串集合的树形数据结构。前缀树的主要特点是将共同的前缀存储在树的相同深度上，从根节点到每个叶子节点都表示一个字符串。这使得前缀树非常适合用于字符串匹配、前缀匹配和字典查询等应用。</p><ul><li>基本思想：利用共享的前缀信息，将字符按照从根节点到叶子节点的路径组织起来。根节点表示空字符串，每个非根节点表示一个字符。从根节点到叶子节点的路径上，经过的字符连接起来就是一个完整的字符串</li><li>TrieNode节点本身只存储val字段，并没有一个字段来存储字符，字符是通过子节点在父节点的children数组中的索引确定的。<br>形象理解就是，Trie 树用「树枝」存储字符串（键），用「节点」存储字符串（键）对应的数据（值）。</li></ul><h3 id="算法框架-1"><a href="#算法框架-1" class="headerlink" title="算法框架"></a>算法框架</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trie</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.children = [<span class="literal">None</span>] * <span class="number">26</span></span><br><span class="line">        self.isEnd = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 寻找前缀节点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">searchPrefix</span>(<span class="params">self, prefix</span>) -&gt; Trie:</span></span><br><span class="line">        node = self</span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> prefix:</span><br><span class="line">            ch = <span class="built_in">ord</span>(ch) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.children[ch]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">            node = node.children[ch]</span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 插入一个单词</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span>(<span class="params">self, word: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        node = self</span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> word:</span><br><span class="line">            ch = <span class="built_in">ord</span>(ch) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.children[ch]:</span><br><span class="line">                node.children[ch] = Trie()</span><br><span class="line">            node = node.children[ch]</span><br><span class="line">        node.isEnd = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除一个单词</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">remove</span>(<span class="params">self, word</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 寻找指定word在前缀树中的前缀字符串</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">searchWordPrefix</span>(<span class="params">self, word</span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        node = self</span><br><span class="line">        prefix = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> word:</span><br><span class="line">            idx = <span class="built_in">ord</span>(ch) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> node.isEnd == <span class="literal">True</span>:</span><br><span class="line">                <span class="keyword">return</span> prefix</span><br><span class="line">            <span class="keyword">if</span> node.children[idx] <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">            prefix += ch</span><br><span class="line">            node = node.children[idx]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断前缀树中是否存在某个单词</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self, word: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        node = self.searchPrefix(word)</span><br><span class="line">        <span class="keyword">return</span> node <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> node.isEnd</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断前缀树中是否存在某个单词 .表示通配符</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self, word: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">i, node</span>):</span></span><br><span class="line">            <span class="keyword">if</span> i == <span class="built_in">len</span>(word):</span><br><span class="line">                <span class="keyword">return</span> node.isEnd</span><br><span class="line">            <span class="keyword">if</span> word[i] != <span class="string">&#x27;.&#x27;</span>:</span><br><span class="line">                ch = <span class="built_in">ord</span>(word[i]) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> node.children[ch]:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                <span class="keyword">return</span> dfs(i + <span class="number">1</span>, node.children[ch])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> child <span class="keyword">in</span> node.children:</span><br><span class="line">                    <span class="keyword">if</span> child <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> dfs(i + <span class="number">1</span>, child):</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> dfs(<span class="number">0</span>, self.trie)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断前缀树中是否有某个前缀</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">startsWith</span>(<span class="params">self, prefix: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.searchPrefix(prefix) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="力扣指南-1"><a href="#力扣指南-1" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">前缀树</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/implement-trie-prefix-tree/description>✅208. 实现 Trie (前缀树)</td>        <td>TrieSet</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/replace-words/description>✅648. 单词替换</td>        <td>寻找前缀</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/design-add-and-search-words-data-structure/description>✅211. 添加与搜索单词 - 数据结构设计</td>        <td>带通配符的单词寻找</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/map-sum-pairs/description>✅677. 键值映射</td>        <td>TrieMap</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/word-search-ii/description>✅212. 单词搜索 II</td>        <td>前缀树+dfs回溯</td>         <td>🌟🌟🌟</td>     </tr></table><h1 id="差分数组"><a href="#差分数组" class="headerlink" title="差分数组"></a>差分数组</h1><p>差分数组（Difference Array）是一种常用的数据结构和算法，用于高效地处理数组区间的修改操作。差分数组可以将原始数组的部分元素的差值存储在新的数组中，从而实现在常数时间内对原数组区间进行修改和查询。知识点：</p><ul><li>原理：通过记录相邻元素之间的差值，将原始数组的修改操作转化为对差分数组的修改操作。通过修改差分数组，可以实现在常数时间内对原数组的区间进行增减操作。差分数组的元素值表示原始数组对应位置的增减值。</li><li>构建：遍历原始数组，计算相邻元素之间的差值，并将差值存储在差分数组中。时间复杂度为<code>O(N)</code>，其中<code>N</code>是原始数组的长度。</li><li>区间修改和查询：对原数组的区间<code>[l, r]</code>进行增加<code>k</code>的操作，只需要在差分数组中修改差分数组的<code>[l]</code>和<code>[r+1]</code>两个位置分别增加<code>k</code>和减去<code>k</code>：<code>diff[l]+ k; diff[r+1]-=k</code>。对原数组的区间进行查询，只需要查询差分数组的前缀和即可得到原数组的区间和。</li><li>应用：频繁对原始数组的某个区间的元素进行增减。例如区间加减操作、区间查询等。常见的应用包括求解数组区间的前缀和、动态区间修改等。</li><li>注意：使用差分数组时，需要注意边界条件和数组越界问题。在进行查询操作时，需要注意计算差分数组的前缀和时的下标范围。</li></ul><h3 id="算法框架-2"><a href="#算法框架-2" class="headerlink" title="算法框架"></a>算法框架</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 差分数组工具类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Difference</span>:</span></span><br><span class="line">    <span class="comment"># 差分数组</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(nums) &gt; <span class="number">0</span></span><br><span class="line">        self.diff = [<span class="number">0</span>] * <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="comment"># 根据初始数组构造差分数组</span></span><br><span class="line">        self.diff[<span class="number">0</span>] = nums[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            self.diff[i] = nums[i] - nums[i - <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 给闭区间 [i, j] 增加 val（可以是负数）</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">increment</span>(<span class="params">self, i: <span class="built_in">int</span>, j: <span class="built_in">int</span>, val: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        self.diff[i] += val</span><br><span class="line">        <span class="keyword">if</span> j + <span class="number">1</span> &lt; <span class="built_in">len</span>(self.diff):</span><br><span class="line">            self.diff[j + <span class="number">1</span>] -= val</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回结果数组</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">result</span>(<span class="params">self</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        res = [<span class="number">0</span>] * <span class="built_in">len</span>(self.diff)</span><br><span class="line">        <span class="comment"># 根据差分数组构造结果数组</span></span><br><span class="line">        res[<span class="number">0</span>] = self.diff[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(self.diff)):</span><br><span class="line">            res[i] = res[i - <span class="number">1</span>] + self.diff[i]</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="力扣指南-2"><a href="#力扣指南-2" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">差分数组</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/corporate-flight-bookings/description>✅1109. 航班预订统计</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/car-pooling/description>✅1094. 拼车</td>        <td></td>         <td>🌟🌟</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Double Pointer and Binary Search Algorithm</title>
      <link href="/2023/03/19/Double-Pointer-and-Binary-Search-Algorithm/"/>
      <url>/2023/03/19/Double-Pointer-and-Binary-Search-Algorithm/</url>
      
        <content type="html"><![CDATA[<h1 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h1><ul><li><strong>基本思想</strong>：使用两个指针分别指向数组或链表的头部、尾部或中间位置，并移动指针，解决问题。</li><li><strong>类型</strong>：<ul><li>快慢指针：快指针每次移动两个元素，慢指针每次移动一个元素，快慢指针常用于链表的中间节点查找、链表是否有环等问题。</li><li>左右指针：左指针从数组或链表的左侧开始移动，右指针从数组或链表的右侧开始移动，左右指针通常用于解决数组或链表中的查找、排序等问题。</li><li>滑动窗口</li></ul></li><li><strong>复杂度</strong>：时间复杂度通常为$O(n)$，空间复杂度为$O(1)$。</li><li><strong>应用场景</strong>：数组或链表中元素的查找、排序、去重、合并、分割等问题。常见的问题有两数之和、三数之和、反转链表等。</li><li><strong>注意</strong>：注意指针的初始位置、指针移动的条件和方向、循环退出的条件等。</li></ul><h2 id="快慢指针"><a href="#快慢指针" class="headerlink" title="快慢指针"></a>快慢指针</h2><p>主要解决链表中的问题。<br>快慢指针⼀般都初始化指向链表的头结点 head，前进时快指针 fast 每次走2步在前，慢指针 slow 每次走1步在后。</p><h3 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">双指针——快慢指针</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/remove-nth-node-from-end-of-list/description>✅19. 删除链表的倒数第 N 个结点</td>        <td>寻找链表倒数第k元素：fast先走k步，fast到尾部是slow的位置；需在初始化slow时添加一个首结点，否则删除的是倒数第n-1个结点</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/rotate-list/description>✅61. 旋转链表</td>        <td>fast先走k步找到倒数第k结点</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/linked-list-cycle/submissions/413647419>✅141. 环形链表</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/linked-list-cycle-ii/description>✅142. 环形链表 II</td>        <td>已知链表有环，返回环的起始位置：相遇时slow返回head，再相遇时为环起点</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/intersection-of-two-linked-lists/description>✅160. 相交链表</td>        <td>互相走一遍，再相遇时为交点</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/middle-of-the-linked-list>✅876. 链表的中间结点</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/delete-the-middle-node-of-a-linked-list/description>✅2095. 删除链表的中间节点</td>        <td></td>         <td>🌟🌟</td>     </tr></table><h2 id="左右指针"><a href="#左右指针" class="headerlink" title="左右指针"></a>左右指针</h2><p>主要解决数组或字符串的问题。二分查找也是典型的左右指针问题。<br>左右指针实际是两个索引值，一般初始化<code>left, right = 0, len(nums) - 1</code></p><h3 id="力扣指南-1"><a href="#力扣指南-1" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">双指针——左右指针</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/longest-palindromic-substring/description>✅5. 最长回文子串</td>        <td>中心扩展法，向两边移动指针判断是否为回文</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/container-with-most-water/description>✅11. 盛最多水的容器</td>        <td>典型的左右指针</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/remove-duplicates-from-sorted-array/description>✅26. 删除有序数组中的重复项</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/remove-element/description>✅27. 移除元素</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/trapping-rain-water>✅42. 接雨水</td>        <td>雨水=min(l, r) - height[i]</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/sort-colors/description>✅75. 颜色分类</td>        <td>除了左右指针还需要中间变量帮助遍历数组</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/remove-duplicates-from-sorted-list-ii/description>✅82. 删除排序链表中的重复元素 II</td>        <td>左右指针</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/partition-list/description>✅86. 分隔链表</td>        <td>注意要将链表最后的指针指向None</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/move-zeroes/description>✅283. 移动零</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/reverse-string/description>✅344. 反转字符串</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/trapping-rain-water-ii>❌407. 接雨水 II</td>        <td></td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/3sum/description>✅15. 三数之和</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/4sum/description>✅18. 四数之和</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/advantage-shuffle/description>✅870. 优势洗牌</td>        <td>田忌赛马</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/is-subsequence/description>✅392. 判断子序列</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/3sum-closest/description>✅16. 最接近的三数之和</td>        <td>同三数之和</td>         <td>🌟🌟</td>     </tr></table><h2 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h2><p>滑动窗口算法是一种基于双指针的算法，通常用于解决字符串和数组相关的问题。其基本思想是维护一个固定大小的窗口，通过移动窗口的左右边界来寻找目标值。</p><ul><li>窗口的大小：窗口的大小通常是固定的，可以根据问题要求进行调整。</li><li>窗口的移动：窗口的移动是通过移动左右指针来实现的。左指针通常指向窗口的起始位置，右指针指向窗口的结束位置。</li><li>窗口的维护：在移动窗口的过程中，需要维护窗口中的元素，可以使用哈希表或者数组等数据结构来维护。</li><li>窗口的更新：在窗口移动的过程中，需要更新窗口内的元素以及相关的数据结构。</li><li>窗口的判断：在滑动窗口算法中，需要判断当前窗口是否满足题目要求，如果满足则更新结果，如果不满足则继续移动窗口。</li><li>应用场景：滑动窗口算法通常用于求解最长子串、最短子串、子数组等问题。</li></ul><p><strong>时间复杂度</strong>：$O(N)$。虽然滑动窗口代码框架中有一个嵌套的 while 循环，但字符串/数组中的每个元素都只会进入窗口一次，然后被移出窗口一次，不会有某些元素多次进入和离开窗口，所以算法的时间复杂度就和字符串/数组的长度成正比。</p><h3 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h3><p>初始化<code>left = right = 0</code>，把索引左闭右开区间<code>[left, right)</code>称为一个「窗口」，左右指针轮流前进，窗口大小增增减减，窗口不断向右滑动。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">slidingWindow</span>(<span class="params">s: <span class="built_in">str</span></span>):</span></span><br><span class="line">    window = &#123;&#125;</span><br><span class="line">    left, right = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> right &lt; <span class="built_in">len</span>(s):</span><br><span class="line">        <span class="comment"># c 是将移入窗口的字符</span></span><br><span class="line">        c = s[right]</span><br><span class="line">        <span class="comment"># 增大窗口</span></span><br><span class="line">        right += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 进行窗口内数据的一系列更新</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">        <span class="comment"># debug 输出的位置</span></span><br><span class="line">        <span class="comment"># 注意在最终的解法代码中不要 print</span></span><br><span class="line">        <span class="comment"># 因为 IO 操作很耗时，可能导致超时</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;window: [&#123;&#125;, &#123;&#125;)&quot;</span>.<span class="built_in">format</span>(left, right))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 判断左侧窗口是否要收缩</span></span><br><span class="line">        <span class="keyword">while</span> window needs shrink:</span><br><span class="line">            <span class="comment"># d 是将移出窗口的字符</span></span><br><span class="line">            d = s[left]</span><br><span class="line">            <span class="comment"># 缩小窗口</span></span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 进行窗口内数据的一系列更新</span></span><br><span class="line">            ...</span><br></pre></td></tr></table></figure><h3 id="力扣指南-2"><a href="#力扣指南-2" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">双指针——滑动窗口</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/longest-substring-without-repeating-characters/description>✅3. 无重复字符的最长子串</td>        <td>没啥好说的，直接AC</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-window-substring/description>✅76. 最小覆盖子串</td>        <td>需要用字典defaultdict(int)记录</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/repeated-dna-sequences/description>❌187. 重复的DNA序列</td>        <td>需要位运算，到时候在做一遍</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/minimum-size-subarray-sum/description>✅209. 长度最小的子数组</td>        <td>没啥好说的，直接AC</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/contains-duplicate-ii/description>✅219. 存在重复元素 II</td>        <td>固定一个k大小的窗口</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/contains-duplicate-iii>❌220. 存在重复元素 III</td>        <td>需要使用有序集合</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/sliding-window-maximum>❌239. 滑动窗口最大值</td>        <td>仍然需要借助特殊数据结构</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/find-all-anagrams-in-a-string/description>✅438. 找到字符串中所有字母异位词</td>        <td>注意缩小窗口时更新valid方式</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/permutation-in-string/description>✅567. 字符串的排列</td>        <td>前面几个会了这个闭眼写</td>         <td>🌟🌟</td>     </tr></table><h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h1><ul><li><strong>简介</strong>：二分查找也叫折半查找，是一种在有序数组中查找目标元素的算法。该算法每次查找时将目标值与数组中间位置的元素进行比较，如果目标值小于中间元素，则在左半部分继续查找；如果目标值大于中间元素，则在右半部分继续查找；如果目标值等于中间元素，则直接返回中间位置的元素下标。通过不断地将查找范围缩小一半，最终找到目标元素或者确认目标元素不存在于数组中。</li><li><strong>时间复杂度</strong>：$O(logn)$，其中n表示数组的长度。因为每次查找可以将查找范围缩小一半，所以最多需要查找logn次。</li><li><strong>前提条件</strong>：数组必须是有序的。因为二分查找是通过比较目标元素和数组中间位置的元素来确定查找范围的，如果数组是无序的，那么就无法保证每次缩小查找范围。</li><li><strong>局限性</strong>：只能用于查找有序数组中的元素。如果数据不是有序的，需要先进行排序，时间复杂度会变为O(nlogn)；另外，二分查找也无法处理数组中存在重复元素的情况，需要使用变体来处理。</li></ul><h3 id="题目模版"><a href="#题目模版" class="headerlink" title="题目模版"></a>题目模版</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">nums, target</span>):</span></span><br><span class="line">    left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> left &lt;= right:</span><br><span class="line">        mid = left + (right - left) // <span class="number">2</span>  <span class="comment"># 防止left+right太大导致溢出，python中不会有这个问题</span></span><br><span class="line">        <span class="keyword">if</span> nums[mid] &lt; target:</span><br><span class="line">            left = mid + <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> nums[mid] &gt; target:</span><br><span class="line">            right = mid - <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> nums[mid] == target:</span><br><span class="line">            <span class="keyword">return</span> mid  <span class="comment"># 直接返回索引</span></span><br><span class="line">            <span class="comment"># left = mid + 1   # 如果寻找target的索引右边界，缩小左边界</span></span><br><span class="line">            <span class="comment"># right = mid - 1  # 如果寻找target的索引左边界，缩小右边界</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">    <span class="comment"># # 如果寻找target的索引右边界，判断右边界是否越界</span></span><br><span class="line">    <span class="comment"># if right &lt; 0 or nums[right] != target:</span></span><br><span class="line">    <span class="comment">#     return -1</span></span><br><span class="line">    <span class="comment"># # 如果寻找target的索引左边界，判断左边界是否越界</span></span><br><span class="line">    <span class="comment"># if left &gt;= len(nums) or nums[left] != target:</span></span><br><span class="line">    <span class="comment">#     return -1</span></span><br></pre></td></tr></table></figure><h3 id="力扣指南-3"><a href="#力扣指南-3" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">二分查找</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/median-of-two-sorted-arrays/description>❌4. 寻找两个正序数组的中位数</td>        <td></td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/search-in-rotated-sorted-array/description>✅33. 搜索旋转排序数组</td>        <td>判断哪部分有序再二分</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/find-first-and-last-position-of-element-in-sorted-array>✅34. 在排序数组中查找元素的第一个和最后一个位置</td>        <td>两次二分查找左右边界</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/search-insert-position/description>✅35. 搜索插入位置</td>        <td>典型二分</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/sqrtx/description>✅69. x 的平方根</td>        <td>注意判断返回边界</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/search-a-2d-matrix/description>✅74. 搜索二维矩阵</td>        <td>二维转换为一维进行二分</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/search-in-rotated-sorted-array-ii/description>✅81. 搜索旋转排序数组 II</td>        <td>多处理一步：缩小相等边界</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/find-minimum-in-rotated-sorted-array/description>✅153. 寻找旋转排序数组中的最小值</td>        <td>注意处理边界</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/find-minimum-in-rotated-sorted-array-ii/description>✅154. 寻找旋转排序数组中的最小值 II</td>        <td>多处理一步：缩小相等边界</td>         <td>🌟🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/find-peak-element/description>✅162. 寻找峰值</td>        <td>假设nums[n]=-inf</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/search-a-2d-matrix-ii/description>✅240. 搜索二维矩阵 II</td>        <td>矩阵以右上角为起点为二叉搜索树，z字查找</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/two-sum-ii-input-array-is-sorted/description>✅1167. 两数之和 II - 输入有序数组</td>        <td>求和问题都可以转换为二分查找target-其中一个数</td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/koko-eating-bananas/description>✅875. 爱吃香蕉的珂珂</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/capacity-to-ship-packages-within-d-days/description>✅1011. 在 D 天内送达包裹的能力</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/number-of-matching-subsequences/description>✅792. 匹配子序列的单词数</td>        <td></td>         <td>🌟🌟</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Stack, Queue and Heap</title>
      <link href="/2023/02/07/Stack-Queue-and-Heap/"/>
      <url>/2023/02/07/Stack-Queue-and-Heap/</url>
      
        <content type="html"><![CDATA[<p>参考API</p><ul><li><a href="https://www.php.cn/python/python-strings.html">基本数据结构Pythob常用API——php中文网</a></li></ul><p>数据结构的基本操作：遍历+访问（增删改查），包括线性和非线性两种形式。线性以for/while迭代为代表，非线性就是递归为代表。</p><h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h1><p>栈是后进先出（LIFO）：最后添加到栈中的元素最先被访问和删除。栈的操作只能在栈顶进行，不能直接访问或修改栈底的元素。应用：</p><ul><li>函数调用：栈常用于实现函数调用的调用栈。每次函数调用时，会将函数的执行上下文（如局部变量、返回地址等）压入栈中，并在函数返回时逐个弹出。</li><li>表达式求值：栈可以用于表达式求值的计算过程。例如，中缀表达式转换为后缀表达式时，需要借助栈来存储运算符。</li><li>括号匹配：栈可以用于检查括号是否匹配。当遇到左括号时，将其入栈；当遇到右括号时，检查栈顶元素是否为相应的左括号，如果匹配，则出栈，继续匹配下一个括号。</li></ul><h3 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 单调栈：维护一个值为单调不递减（增）的栈</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nextGreaterElement</span>(<span class="params">nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">    n = <span class="built_in">len</span>(nums)</span><br><span class="line">    <span class="comment"># 存放答案的数组</span></span><br><span class="line">    res = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    stack = [] </span><br><span class="line">    <span class="comment"># 倒着往栈里放</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 判定个子高矮</span></span><br><span class="line">        <span class="keyword">while</span> stack <span class="keyword">and</span> stack[-<span class="number">1</span>] &lt;= nums[i]:</span><br><span class="line">            <span class="comment"># 矮个起开，反正也被挡着了。。。</span></span><br><span class="line">            stack.pop()</span><br><span class="line">        <span class="comment"># nums[i] 身后的更大元素</span></span><br><span class="line">        res[i] = stack[-<span class="number">1</span>] <span class="keyword">if</span> s <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">        stack.append(nums[i])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 正序遍历的</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">        <span class="keyword">while</span> stack <span class="keyword">and</span> nums[i] &gt; nums[stack[-<span class="number">1</span>]]:</span><br><span class="line">            <span class="comment"># 当当前元素大于栈顶元素时，将栈顶元素弹出并更新结果数组</span></span><br><span class="line">            result[stack.pop()] = nums[i]</span><br><span class="line">        stack.append(i)  <span class="comment"># 将当前索引入栈</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">栈</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>         <td><a href=https://leetcode.cn/problems/remove-duplicate-letters>✅316. 去除重复字母</td>        <td>单调栈</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/flatten-nested-list-iterator/description>✅341. 扁平化嵌套列表迭代器</td>        <td>dfs；栈</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/next-greater-element-i/description>✅496. 下一个更大元素 I</td>        <td>单调栈</td>         <td>🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/daily-temperatures/description>✅739. 每日温度</td>        <td>单调栈</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/next-greater-element-ii/description>✅503. 下一个更大元素 II</td>        <td>环形数组 拼接</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/sliding-window-maximum/description>✅239. 滑动窗口最大值</td>        <td>优先队列；单调双端队列</td>         <td>🌟🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/implement-stack-using-queues/description>✅225. 用队列实现栈</td>        <td>两个队列辅助</td>         <td>🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/implement-queue-using-stacks/description>✅</td>        <td>一个输入栈，一个输出栈</td>         <td>🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/valid-parentheses/description>✅20. 有效的括号</td>        <td></td>         <td>🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/minimum-add-to-make-parentheses-valid/description>✅921. 使括号有效的最少添加</td>        <td></td>         <td>🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/minimum-insertions-to-balance-a-parentheses-string/description>✅1541. 平衡括号字符串的最少插入次数</td>        <td></td>         <td>🌟🌟</td>     </tr></table><h1 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h1><p>队列（Queue）遵循先进先出（First-In-First-Out，FIFO）的原则。队列中的元素按照插入的顺序排列，最先插入的元素在队列的前端，最后插入的元素在队列的后端。应用：</p><ul><li>广度优先搜索（BFS）：队列常用于实现广度优先搜索算法中的待访问节点的队列。将初始节点入队，并在搜索过程中依次将相邻节点入队，以保证按照层次进行访问。</li><li>缓冲区管理：队列常用于管理缓冲区，例如消息队列、任务队列等。新的消息或任务会被放入队列的末尾，然后按照顺序逐个处理。</li><li>模拟事件驱动：队列可以用于模拟事件驱动的系统，将待处理的事件按照顺序放入队列中，然后逐个处理。</li></ul><p>「单调队列」结构：既能够维护队列元素「先进先出」的时间顺序，又能够正确维护队列中所有元素的最值。「单调队列」这个数据结构主要用来辅助解决滑动窗口相关的问题。单调队列push方法依然在队尾添加元素，但是要把前面比自己小的元素都删掉，最终单调队列中的元素大小就会保持一个单调递减的顺序。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基本队列，可以指定最大容量（默认为无限）</span></span><br><span class="line">queue.Queue(maxsize)</span><br><span class="line"><span class="comment"># 后进先出队列，类似于栈。</span></span><br><span class="line">queue.LifoQueue(maxsize)</span><br><span class="line"><span class="comment"># 带有优先级的队列</span></span><br><span class="line">queue.PriorityQueue(maxsize)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 普通队列</span></span><br><span class="line"><span class="keyword">import</span> queue</span><br><span class="line">q = queue.Queue()  <span class="comment"># 初始化</span></span><br><span class="line">size = q.qsize() <span class="comment"># 队列长度</span></span><br><span class="line">q.put(item)  <span class="comment"># 添加元素</span></span><br><span class="line">i = q.get()  <span class="comment"># 取出左侧队头元素</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 双端队列</span></span><br><span class="line">q = collections.deque() <span class="comment"># 初始化</span></span><br><span class="line">q.append(item)          <span class="comment"># 队尾添加元素</span></span><br><span class="line">q.appendleft(item)      <span class="comment"># 队首添加元素</span></span><br><span class="line">s = <span class="built_in">len</span>(q)              <span class="comment"># 队列的长度</span></span><br><span class="line">item = q[index]         <span class="comment"># 指定索引的元素</span></span><br><span class="line">i = q.pop()             <span class="comment"># 删除队尾元素</span></span><br><span class="line">i = q.popleft()         <span class="comment"># 删除队首元素</span></span><br><span class="line">q.insert(index, item)   <span class="comment"># 指定位置插入元素</span></span><br><span class="line">q.remove(item)          <span class="comment"># 删除指定元素</span></span><br><span class="line">q.rotate(n)             <span class="comment"># 将双端队列的元素向右旋转n步，n为负数表示向左旋转</span></span><br><span class="line">q.extend(iterable)      <span class="comment"># 将可迭代对象的元素从右端依次添加到双端队列</span></span><br><span class="line">q.extendleft(iterable)  <span class="comment"># 将可迭代对象的元素从左端依次添加到双端队列</span></span><br></pre></td></tr></table></figure><h1 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h1><p>二叉堆（Binary Heap）二叉堆是一种完全二叉树，所以适合存储在数组中。</p><ul><li>主要操作：sink（下沉）和 swim（上浮），用以维护二叉堆的有序的性质</li><li>主要应用：「堆排序」和数据结构「优先级队列」<ul><li>优先级队列维护堆顶元素为最值（Python为小顶堆），不满足标准队列先进先出的时间顺序。其主要操作是插入和删除。插入是先插到最后，然后上浮到正确位置；删除是调换位置后再删除，然后下沉到正确位置。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line">heap = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">heapq.heapify(heap)                 <span class="comment"># 将列表转化为堆结构</span></span><br><span class="line">heapq.heappush(heap, <span class="number">4</span>)             <span class="comment"># 默认按照第一个元素升序排序，即小顶堆</span></span><br><span class="line">top_element = heapq.heappop(heap)   <span class="comment"># 移除并返回堆顶元素的值</span></span><br><span class="line">top_element = heap[<span class="number">0</span>]               <span class="comment"># 获取堆顶元素的值</span></span><br><span class="line">heapq.nlargest(n, nums)             <span class="comment"># 取出nums数组的前n大的数字</span></span><br><span class="line">heapq.nsmallest(n, nums)            <span class="comment"># 取出nums数组的前n小的数字</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Basic Data Structures</title>
      <link href="/2023/02/06/Basic-Data-Structures/"/>
      <url>/2023/02/06/Basic-Data-Structures/</url>
      
        <content type="html"><![CDATA[<p>参考API</p><ul><li><a href="https://www.php.cn/python/python-strings.html">基本数据结构Pythob常用API——php中文网</a></li></ul><p>数据结构的基本操作：遍历+访问（增删改查），包括线性和非线性两种形式。线性以for/while迭代为代表，非线性就是递归为代表。</p><h1 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h1><h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p>Python不支持单字符类型，也就是没有字符只有字符串，单字符在也是作为一个字符串使用。字符串具有不可变性，即一旦创建，就不能被修改，对字符串的操作通常会返回一个新的字符串，而不是在原始字符串上进行修改。Python的字符串同列表一样，也是序列的一种，可以进行迭代，也可以通过索引访问字符元素。用反斜杠()转义字符串中的特殊字符。</p><ul><li>常用语法：<ol><li><code>str.lower()</code>和<code>str.upper()</code>: 将字符串转换为小写或大写形式。</li><li><code>str.capitalize()</code>和<code>str.title()</code>: 将字符串的首字母或每个单词的首字母大写。</li><li><code>str.strip()</code>: 去除字符串两端的空格或指定的字符（默认为空格或换行符）。</li><li><code>str.split()</code>: 将字符串分割成一个列表，根据指定的分隔符将字符串分割。默认分割所有的空字符，包括空格、换行(\n)、制表符(\t)等。</li><li><code>str.join()</code>: 将列表或其他可迭代对象中的字符串元素连接成一个字符串。</li><li><code>str.replace()</code>: 将字符串中的指定子串替换为另一个子串。</li><li><code>str.find()</code>和<code>str.rfind()</code>: 在字符串中查找指定子串的第一次出现位置或最后一次出现位置。</li><li><code>str.count()</code>: 统计字符串中指定子串出现的次数。</li><li><code>str.isalpha()</code>、<code>str.isdigit()</code>、<code>str.isalnum()</code>: 检查字符串是否只包含字母、数字或字母和数字的组合。</li><li><code>str.splitlines()</code>: 将多行字符串拆分成行的列表。</li><li><code>str.format()</code>: 格式化字符串，将占位符替换为指定的值。</li><li><code>str.startswith()</code>和<code>str.endswith()</code>: 检查字符串是否以指定的子串开头或结尾。</li><li><code>str.islower()</code>、<code>str.isupper()</code>、<code>str.istitle()</code>: 检查字符串是否全部为小写、大写或标题形式（每个单词的首字母大写）。</li><li><code>readline(size)</code>从文件读取整行，包括 “\n” 字符。如果指定了一个非负数的参数，则返回指定大小的字节数，包括 “\n” 字符。</li></ol></li><li><p>ACM模式常用语法：</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())  <span class="comment"># 一般第一行表示数据的总行数</span></span><br><span class="line">data = []</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:  <span class="comment"># 知道数据总行数后可以使用for循环</span></span><br><span class="line">    s = sys.stdin.readline().strip()   <span class="comment"># sys.stdin可以用input()代替</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> s:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    data.append(s)</span><br><span class="line">    <span class="built_in">print</span>(s, end=<span class="string">&#x27; &#x27;</span>)   <span class="comment"># 输出s并以空格结尾</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入： 2 3 6 4 8 9</span></span><br><span class="line">data = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, sys.stdin.readline().strip().split()))  <span class="comment"># 转换为list</span></span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/weixin_42042056/article/details/105723084?spm=1001.2014.3001.5506">牛客网面试题输入输出的处理（python语言，包括readline()、strip()、split()的使用）</a></p></li><li><p>字符串匹配的经典算法：</p><ol><li>Knuth-Morris-Pratt算法（KMP）：KMP算法利用了模式串中已匹配的信息来尽量减少不必要的比较。通过构建一个部分匹配表（也称为next数组），可以在不匹配时直接跳过一部分字符，提高匹配效率。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># next数组表示pattern串中前缀后缀最长公共子串长度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calNext</span>(<span class="params">s2</span>):</span></span><br><span class="line">    j, i = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="built_in">next</span> = [<span class="number">0</span>] * <span class="built_in">len</span>(s2)</span><br><span class="line">    <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(s2):</span><br><span class="line">        <span class="keyword">if</span> s2[j] == s2[i]: </span><br><span class="line">            <span class="built_in">next</span>[i] = j + <span class="number">1</span></span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> j != <span class="number">0</span>:</span><br><span class="line">                j = <span class="built_in">next</span>[j - <span class="number">1</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">next</span>[i] = <span class="number">0</span></span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">next</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">KMP</span>(<span class="params">s1, s2, pos = <span class="number">0</span></span>):</span>   <span class="comment"># pos为开始比较的位置，一般为0</span></span><br><span class="line">    res = []</span><br><span class="line">    <span class="built_in">next</span> = calNext(s2)  <span class="comment"># [0, 0, 0, 1, 2, 0]</span></span><br><span class="line">    i, j = pos, <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(s1) <span class="keyword">and</span> j &lt; <span class="built_in">len</span>(s2):</span><br><span class="line">        <span class="keyword">if</span> s1[i] == s2[j]:</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> j != <span class="number">0</span>:</span><br><span class="line">                j = <span class="built_in">next</span>[j - <span class="number">1</span>]  <span class="comment"># 具有公共前缀的pattern字符索引</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> j == <span class="built_in">len</span>(s2):  <span class="comment"># 匹配到结尾了</span></span><br><span class="line">            res.append(i - j)  <span class="comment"># 返回第一个字母的索引</span></span><br><span class="line">            j = <span class="built_in">next</span>[j - <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> res  <span class="comment"># 所有匹配的开头索引列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 灵神版本kmp</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kmp</span>(<span class="params">text: <span class="built_in">str</span>, pattern: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">    m = <span class="built_in">len</span>(pattern)</span><br><span class="line">    pi = [<span class="number">0</span>] * m</span><br><span class="line">    c = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m):</span><br><span class="line">        v = pattern[i]</span><br><span class="line">        <span class="keyword">while</span> c <span class="keyword">and</span> pattern[c] != v:</span><br><span class="line">            c = pi[c - <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> pattern[c] == v:</span><br><span class="line">            c += <span class="number">1</span></span><br><span class="line">        pi[i] = c</span><br><span class="line"></span><br><span class="line">    res = []</span><br><span class="line">    c = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(text):</span><br><span class="line">        <span class="keyword">while</span> c <span class="keyword">and</span> pattern[c] != v:</span><br><span class="line">            c = pi[c - <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> pattern[c] == v:</span><br><span class="line">            c += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> c == <span class="built_in">len</span>(pattern):</span><br><span class="line">            res.append(i - m + <span class="number">1</span>)</span><br><span class="line">            c = pi[c - <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"> </span><br><span class="line">s1 = <span class="string">&quot;abxabcabcaby&quot;</span>  <span class="comment"># txt串</span></span><br><span class="line">s2 = <span class="string">&quot;abcaby&quot;</span>  <span class="comment"># pattern串</span></span><br><span class="line"><span class="built_in">print</span>(KMP(s1, s2))<span class="comment"># 6</span></span><br></pre></td></tr></table></figure></li><li>Rabin-Karp 算法是一种基于哈希函数的字符串匹配算法。它通过对主串和模式串分别计算哈希值，并比较哈希值来判断是否匹配。在匹配时，还需要处理哈希值冲突的情况。<ul><li>核心逻辑：把一个字符串对象转化成了一个数字，就是你设计的一个哈希算法，生成的数字就可以认为是字符串的哈希值。在滑动窗口中快速计算窗口中元素的哈希值，叫做滑动哈希技巧。我们不要每次都去一个字符一个字符地比较子串和模式串，而是维护一个滑动窗口，运用滑动哈希算法一边滑动一边计算窗口中字符串的哈希值，拿这个哈希值去和模式串的哈希值比较，这样就可以避免截取子串，从而把匹配算法降低为 <code>O(N)</code>。</li></ul></li><li>Boyer-Moore算法（BM）：BM算法是一种高效的字符串匹配算法，它利用了模式串的信息来跳过多个字符。通过构建好后缀表和坏字符表，可以根据模式串与主串中的字符不匹配的位置进行跳跃，提高匹配速度。</li></ol></li></ul><blockquote><p>参考博客：</p><ul><li><a href="https://blog.csdn.net/qq_40061421/article/details/82919264?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=KMP&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-82919264.first_rank_v2_pc_rank_v29_10">KMP详解</a></li><li><a href="https://blog.csdn.net/qq_44864169/article/details/108080114">油管最火KMP算法讲解，阿三哥的源代码！</a></li><li><a href="https://labuladong.github.io/algo/di-yi-zhan-da78c/shou-ba-sh-48c1d/hua-dong-c-88113/">滑动窗口算法延伸：RABIN KARP 字符匹配算法</a></li></ul></blockquote><h3 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">字符串</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>         <td><a href=https://leetcode.cn/problems/reverse-words-in-a-string/description>✅151. 反转字符串中的单词</td>        <td>str.split()默认为连续空格分割</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/multiply-strings/description>✅43. 字符串相乘</td>        <td>模拟乘法</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/basic-calculator-ii/description>✅227. 基本计算器 II</td>        <td></td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/basic-calculator/description>✅224. 基本计算器</td>        <td></td>         <td>🌟🌟🌟</td>     </tr></table><h1 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h1><ul><li><code>nums</code>和<code>nums[:]</code>区别：用nums只是将nums指向那个副本，而nums在内存中原来地址的值没有变化，用nums[:]就会将内存中地址对应的值改变。<a href="https://leetcode-cn.com/problems/merge-sorted-array/solution/gelthin-gui-bing-pai-xu-by-gelthin/">gelthin-解释为何要用 nums1[:]</a></li><li>reduce函数用法：求nums数组的和 <code>sum = reduce(lambda x, y: x+y, nums)</code></li><li><code>for j in zip(*grid)</code>可以取出二维数组grid中的列元素（tuple类型）。<em>grid 会将 grid 中的每个列表作为单独的参数传递给 zip() 函数。zip(</em>grid) 就会返回一个迭代器，每个元素都是一个元组，包含来自 grid 中每个列表的相应位置的元素。相当于将 grid 矩阵转置（将行变为列，将列变为行）。</li><li><code>itertools.accumulate(list, initial=0)</code>：结果为首项为0的list前缀和数组</li><li><code>itertools.pairwise(list/str)</code>：每次取出相邻的一对元素</li></ul><h3 id="有序集合"><a href="#有序集合" class="headerlink" title="有序集合"></a>有序集合</h3><p>添加/插入/删除单个元素复杂度为$O(log(n))$；添加k个可迭代对象复杂度为$O(k*log(n))$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sortedcontainers <span class="keyword">import</span> SortedList</span><br><span class="line">sl = SortedList([<span class="number">2</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>])  <span class="comment"># 初始化</span></span><br><span class="line">sl.add(<span class="number">6</span>)                   <span class="comment"># 添加元素</span></span><br><span class="line">sl.update([<span class="number">3</span>, <span class="number">6</span>, <span class="number">4</span>])        <span class="comment"># 添加可迭代对象</span></span><br><span class="line">sl.clear()                  <span class="comment"># 删除全部元素</span></span><br><span class="line">sl.discard(value)           <span class="comment"># 删除value，没有该值则不做操作</span></span><br><span class="line">sl.remove(value)            <span class="comment"># 删除value，没有该值则报错ValueError</span></span><br><span class="line">sl.pop(index=-<span class="number">1</span>)            <span class="comment"># 弹出index元素，默认最后一个元素</span></span><br><span class="line">idx = sl.bisect_left(value) <span class="comment"># 返回value插入的索引idx</span></span><br><span class="line">sl.count(value)             <span class="comment"># 返回value的元素数量</span></span><br><span class="line">sl.index(value)             <span class="comment"># 返回value的最小索引，没有该值则报错ValseError</span></span><br></pre></td></tr></table></figure><h3 id="力扣指南-1"><a href="#力扣指南-1" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">数组</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>         <td><a href=https://leetcode.cn/problems/rotate-image/description>✅48. 旋转图像</td>        <td>对角转换</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/spiral-matrix/description>✅54. 螺旋矩阵</td>        <td>设置边界模拟</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/spiral-matrix-ii/description>✅59. 螺旋矩阵 II</td>        <td>同上</td>         <td>🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/perfect-rectangle/description>✅391. 完美矩形</td>        <td></td>         <td>🌟🌟🌟</td>     </tr></table><h1 id="哈希"><a href="#哈希" class="headerlink" title="哈希"></a>哈希</h1><ul><li>特点：快速的数据存取：哈希表通过哈希函数将关键字映射到索引位置，因此可以在常数时间复杂度内存取数据，具有快速的存取速度;高效的查找和插入操作：通过哈希函数计算索引位置，可以快速定位数据的存储位置，从而实现高效的查找和插入操作。</li><li>哈希函数：哈希函数将关键字映射到索引位置，确保关键字的均匀分布。好的哈希函数应该尽可能减少冲突，即不同的关键字映射到相同的索引位置。</li><li>冲突解决：冲突是指不同的关键字经过哈希函数计算后映射到了相同的索引位置。<ul><li>链地址法（Chaining）：在每个哈希桶（哈希表的每个索引位置）上维护一个链表或其他数据结构，将哈希冲突的元素都存储在同一个桶中。当发生冲突时，新元素会被添加到桶中的链表末尾。链地址法可以解决大部分的哈希冲突，并且适用于大多数情况下的哈希表实现。但是在链表过长时，查找的效率可能会降低。</li><li>开放定址法（Open Addressing）：在开放定址法中，发生冲突时会尝试在哈希表中的其他位置寻找空槽来存储元素，而不是通过链表进行链接。开放定址法有几种常见的策略，如线性探测（Linear Probing）、二次探测（Quadratic Probing）、双重哈希（Double Hashing）等。这些策略决定了当冲突发生时如何寻找下一个空槽。开放定址法的优点是避免了链表的额外存储开销，但是当哈希表填充度较高时，可能会导致连续的冲突，进而降低查找效率。</li><li>再哈希法（Rehashing）：使用不同的哈希函数来处理冲突。当发生冲突时，再哈希法会应用另一个哈希函数，重新计算一个新的索引位置，并将元素存储到新的位置上。再哈希法可以在发生冲突时提供更好的分散性，从而减少冲突的发生。然而，选择合适的再哈希函数并不容易，因为它需要满足良好的分布性和计算效率。</li><li>其他方法：如建立公共溢出区（Public Overflow Area）。</li></ul></li><li>常用API：<ul><li><code>dict.get(key, 0)</code>：获取指定key的value，如果没有这个返回0</li><li>关于set的API：<code>union()</code> 取并集，<code>intersection()</code> 取交集，<code>difference()</code> 取差集等。</li></ul></li></ul><p>set是一种无序的不重复的哈希集合。特殊的「有序集合/映射」：红黑树（一种平衡二叉搜索树），特性是自动维护其中元素的顺序，操作效率是 O(logN)。</p><h3 id="力扣指南-2"><a href="#力扣指南-2" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">哈希</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>         <td><a href=https://leetcode.cn/problems/two-sum/description>✅1. 两数之和</td>        <td></td>         <td>🌟</td>     </tr></table><h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><ul><li><strong>简介</strong>：链表是一种数据结构，由一系列节点组成，每个节点包含两部分，一个是数据，另一个是指向下一个节点的指针。</li><li><strong>链表实现</strong>：在Python中，链表可以使用类和对象来实现。每个节点用一个类表示，节点之间的关系用指针来实现。</li><li><strong>复杂度</strong>：一般递归法和迭代解法的时间复杂度都是 $O(N)$，但是迭代解法的空间复杂度是 $O(1)$，⽽递归解法需要堆栈，空间复杂度是 $O(N)$</li><li><strong>优点</strong>：相比于数组，链表的优点是可以在任意位置插入和删除元素，不需要进行大量的数据搬移操作。</li><li><strong>缺点</strong>：访问节点时需要遍历整个链表，访问效率较低。</li><li><strong>分类</strong>：<ul><li>单向链表是一种链表，每个节点都只包含指向下一个节点的指针。链表的头节点指向第一个节点，最后一个节点的指针指向空值（null），表示链表结束。单向链表的访问只能从头节点开始，依次向后遍历，不能反向遍历。</li><li>单向循环链表：每个节点都只包含指向下一个节点的指针，最后一个节点的指针指向第一个节点，形成一个环形结构。和单向链表类似，单向循环链表也只能从头节点开始遍历，不能反向遍历。</li><li>双向链表：每个节点都包含指向前一个节点和后一个节点的指针。双向链表的访问可以从头节点或尾节点开始，可以向前或向后遍历。</li><li>双向循环链表：每个节点都包含指向前一个节点和后一个节点的指针，最后一个节点的指针指向头节点，形成一个环形结构。双向循环链表的访问可以从头节点或尾节点开始，可以向前或向后遍历，也可以在任意位置插入和删除节点。</li></ul></li></ul><p>当你需要创造一条新链表的时候，可以使用虚拟头结点dummy简化边界情况的处理。</p><p>数据结构的存储⽅式只有两种：数组（顺序存储）和链表（链式存储）。二者的优缺点：</p><ul><li>数组是紧凑连续存储,可以随机访问，通过索引快速找到对应元素，相对节约存储空间。但正因为连续存储，内存空间必须⼀次性分配够，所以说数组如果要扩容，需要重新分配⼀块更⼤的空间，再把数据全部复制过去，时间复杂度 O(N)；在数组中间进⾏插⼊和删除，每次必须搬移后⾯的所有数据以保持连续，时间复杂度 O(N)。</li><li>链表元素不连续，靠指针指向下⼀个元素的位置，所以不存在数组的扩容问题；如果知道某⼀元素的前驱和后驱，操作指针即可删除该元素或者插⼊新元素，时间复杂度 O(1)。但是正因为存储空间不连续，⽆法根据⼀个索引算出对应元素的地址，所以不能随机访问；⽽且由于每个元素必须存储指向前后元素位置的指针，会消耗相对更多的储存空间。</li></ul><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data=<span class="literal">None</span>, <span class="built_in">next</span>=<span class="literal">None</span>, prev=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.<span class="built_in">next</span> = <span class="built_in">next</span></span><br><span class="line">        <span class="comment"># self.prev = prev  # 循环链表需要添加前向指针</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinkedList</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.head = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加节点到链表尾部</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">append</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        new_node = Node(data)</span><br><span class="line">        <span class="keyword">if</span> self.head <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.head = new_node</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        last_node = self.head</span><br><span class="line">        <span class="keyword">while</span> last_node.<span class="built_in">next</span>:</span><br><span class="line">            last_node = last_node.<span class="built_in">next</span></span><br><span class="line">        last_node.<span class="built_in">next</span> = new_node</span><br><span class="line">        <span class="comment"># new_node.prev = last_node  # 循环链表</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 插入节点到指定位置</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span>(<span class="params">self, index, data</span>):</span></span><br><span class="line">        <span class="keyword">if</span> index == <span class="number">0</span>:</span><br><span class="line">            new_node = Node(data)</span><br><span class="line">            new_node.<span class="built_in">next</span> = self.head</span><br><span class="line">            <span class="comment"># self.head.prev = new_node</span></span><br><span class="line">            self.head = new_node</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        new_node = Node(data)</span><br><span class="line">        cur_node = self.head</span><br><span class="line">        cur_index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> cur_node <span class="keyword">and</span> cur_index &lt; index - <span class="number">1</span>:</span><br><span class="line">            cur_node = cur_node.<span class="built_in">next</span></span><br><span class="line">            cur_index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> cur_node <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;Index out of range&quot;</span>)</span><br><span class="line">        new_node.<span class="built_in">next</span> = cur_node.<span class="built_in">next</span></span><br><span class="line">        <span class="comment"># cur_node.next.prev = new_node</span></span><br><span class="line">        cur_node.<span class="built_in">next</span> = new_node</span><br><span class="line">        <span class="comment"># new_node.prev = cur_node</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除指定位置的节点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">delete</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.head <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;List is empty&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> index == <span class="number">0</span>:</span><br><span class="line">            self.head = self.head.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        cur_node = self.head</span><br><span class="line">        cur_index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> cur_node <span class="keyword">and</span> cur_index &lt; index - <span class="number">1</span>:</span><br><span class="line">            cur_node = cur_node.<span class="built_in">next</span></span><br><span class="line">            cur_index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> cur_node <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> cur_node.<span class="built_in">next</span> <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;Index out of range&quot;</span>)</span><br><span class="line">        cur_node.<span class="built_in">next</span> = cur_node.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取指定位置的节点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.head <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;List is empty&quot;</span>)</span><br><span class="line">        cur_node = self.head</span><br><span class="line">        cur_index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> cur_node <span class="keyword">and</span> cur_index &lt; index:</span><br><span class="line">            cur_node = cur_node.<span class="built_in">next</span></span><br><span class="line">            cur_index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> cur_node <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;Index out of range&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> cur_node.data</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回链表大小</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">size</span>(<span class="params">self</span>):</span></span><br><span class="line">        cur_node = self.head</span><br><span class="line">        size = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> cur_node:</span><br><span class="line">            size += <span class="number">1</span></span><br><span class="line">            cur_node = cur_node.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> size</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印链表</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span></span><br><span class="line">        cur_node = self.head</span><br><span class="line">        linked_list = []</span><br><span class="line">        <span class="keyword">while</span> cur_node:</span><br><span class="line">            linked_list.append(<span class="built_in">str</span>(cur_node.data))</span><br><span class="line">            cur_node = cur_node.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;-&gt;&quot;</span>.join(linked_list)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 清空链表</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clear</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.head = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建链表并添加节点</span></span><br><span class="line">linked_list = LinkedList()</span><br><span class="line">linked_list.append(<span class="number">1</span>)</span><br><span class="line">linked_list.append(<span class="number">2</span>)</span><br><span class="line">linked_list.append(<span class="number">3</span>)</span><br><span class="line">linked_list.append(<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(linked_list)  <span class="comment"># 1-&gt;2-&gt;3-&gt;4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在指定位置插入节点</span></span><br><span class="line">linked_list.insert(<span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(linked_list)  <span class="comment"># 1-&gt;2-&gt;5-&gt;3-&gt;4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除指定位置的节点</span></span><br><span class="line">linked_list.delete(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(linked_list)  <span class="comment"># 1-&gt;5-&gt;3-&gt;4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取指定位置的节点</span></span><br><span class="line"><span class="built_in">print</span>(linked_list.get(<span class="number">2</span>))  <span class="comment"># 3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回链表大小</span></span><br><span class="line"><span class="built_in">print</span>(linked_list.size())  <span class="comment"># 4</span></span><br></pre></td></tr></table></figure><h3 id="力扣指南-3"><a href="#力扣指南-3" class="headerlink" title="力扣指南"></a>力扣指南</h3><table>    <tr>        <th align='center', colspan="3">链表</th>    </tr>    <tr>        <th>题目</th>        <th>技巧</th>        <th>难度</th>    </tr>    <tr>        <td><a href=https://leetcode.cn/problems/remove-duplicates-from-sorted-list/description>✅83. 删除排序链表中的重复元素</td>        <td></td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/reverse-linked-list-ii/description>❌✅92. 反转链表 II</td>        <td>迭代法还没做</td>         <td>🌟🌟  </td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/reverse-linked-list/description>✅206. 反转链表</td>        <td>迭代和递归，双指针画个图</td>         <td>🌟</td>     </tr>    <tr>        <td><a href=https://leetcode.cn/problems/merge-k-sorted-lists/description>✅23. 合并 K 个升序链表</td>        <td>优先队列 / 归并排序</td>         <td>🌟🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/reverse-nodes-in-k-group/description>✅25. K 个一组翻转链表</td>        <td>迭代+递归</td>         <td>🌟🌟🌟</td>     </tr>    <tr>         <td><a href=https://leetcode.cn/problems/palindrome-linked-list/description>✅234. 回文链表</td>        <td></td>         <td>🌟</td>     </tr></table>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SfM &amp; SLAM</title>
      <link href="/2023/01/11/SfM-SLAM/"/>
      <url>/2023/01/11/SfM-SLAM/</url>
      
        <content type="html"><![CDATA[<p>根据北京邮电大学人工智能学院鲁鹏老师讲授的《计算机视觉之三维重建篇——深入浅出SfM系统与SLAM系统的核心算法》整理的笔记。</p><blockquote><ul><li><a href="https://www.bilibili.com/video/BV1mT4y1o7Q2/?spm_id_from=333.999.0.0&amp;vd_source=486265fa677326a8f53894f05277bfb9">b站视频链接</a></li><li><a href="https://cv-xueba.club/pages/courses/cv_sfm.html">课件链接</a></li></ul></blockquote><h1 id="摄像机几何"><a href="#摄像机几何" class="headerlink" title="摄像机几何"></a>摄像机几何</h1><h2 id="针孔模型-amp-透镜"><a href="#针孔模型-amp-透镜" class="headerlink" title="针孔模型&amp;透镜"></a>针孔模型&amp;透镜</h2><ol><li><strong>针孔摄像机</strong><br><div align="center"> <img src="1_针孔摄像机.png" width=70%></div><br>根据相似三角形，三维点 $P=[x, y, z]^T$ 到二维平面 $p’=[x’, y’]^T$ 的映射：<script type="math/tex">x'=f\frac{x}{z}; y'=f\frac{y}{z}</script></li><li><strong>透镜</strong><br>光圈减小，图像越清晰，但是越暗。透镜将多条光线汇聚到胶片上，可以增加照片亮度。所有平行于光轴的光线都会汇聚到焦点，焦点到透镜中心的距离为焦距。<br>透镜问题：<ul><li>失焦：物体聚焦有特定距离；景深</li><li>径向畸变：图像像素点以畸变中心为中心点，沿着径向产生位置偏差，导致图像成像发生形变</li></ul></li></ol><h2 id="摄像机几何-1"><a href="#摄像机几何-1" class="headerlink" title="摄像机几何"></a>摄像机几何</h2><ol><li><strong>像素坐标系</strong><br><div align="center"> <img src="1_像素坐标系.png" width=70%></div><br>单位：$k, l: pixel/m; f:m \space$  非方形像素 $\alpha, \beta: pixel$</li><li><strong>摄像机模型</strong><br>转换到齐次坐标，并加入摄像机偏斜 $\theta$ 、像机内外参数得到完整的摄像机模型：<br><div align="center"> <img src="1_摄像机模型.png" width=70%></div><br>当 $K$ 为单位矩阵时为规范化摄像机，摄像机模型包括$5$个内参数+$6$个外参数=$11$个自由度。<br>平面点转换成欧式坐标写法：<script type="math/tex">P'=MP_w=[m_1, m_2, m_3]^TP_w \rightarrow (\frac{m_1P_w}{m_3P_w}, \frac{m_2P_w}{m_3P_w})</script></li><li><strong>Faugeras1993定理</strong>：<div align="center"> <img src="1_定理.png" width=60%></div></li><li><strong>投影变换</strong><br>性质：点投影为点、线投影为线；近大远小；角度不再保持；平行线相交</li></ol><h2 id="其他摄像机模型"><a href="#其他摄像机模型" class="headerlink" title="其他摄像机模型"></a>其他摄像机模型</h2><ol><li><strong>透视投影和弱透视投影摄像机</strong><br>投影点 $P$ 到 $P\_$ 为从透视投影到弱透视投影<div align="center"> <img src="1_弱透视投影摄像机.png" width=60%></div>弱透视投影当物体较小且较远时准确，常用于图像识别任务；透视投影对3D到2D映射的建模更准确，用于运动恢复结构或SLAM。<div align="center"> <img src="1_透视与弱透视投影摄像机.png" width=60%></div></li><li><strong>正交投影摄像机</strong><br><div align="center"> <img src="1_正交投影摄像机.png" width=60%></div><br>正交投影更多应用在建筑设计或工业设计行业</li></ol><h2 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a>补充知识</h2><ol><li><strong>线性方程组的解</strong><div align="center"> <img src="1_线性方程组的解.png" width=70%></div></li><li><strong>线性方程组的最小二乘解</strong><div align="center"> <img src="1_线性方程组的最小二乘解.png" width=70%></div></li><li><strong>齐次线性方程组的解</strong><div align="center"> <img src="1_齐次线性方程组的解.png" width=70%></div></li><li><strong>齐次线性方程组的最小二乘解</strong><div align="center"> <img src="1_齐次线性方程组的最小二乘解.png" width=70%></div></li><li><strong>非线性方程组的最小二乘解</strong><div align="center"> <img src="1_非线性方程组的最小二乘解.png" width=70%></div></li></ol><h1 id="摄像机标定"><a href="#摄像机标定" class="headerlink" title="摄像机标定"></a>摄像机标定</h1><h2 id="针孔模型-amp-透镜摄像机标定问题"><a href="#针孔模型-amp-透镜摄像机标定问题" class="headerlink" title="针孔模型 &amp; 透镜摄像机标定问题"></a>针孔模型 &amp; 透镜摄像机标定问题</h2><ol><li><strong>摄像机标定问题</strong><br>摄像机标定即求解摄像机内、外参数矩阵，其内外参数矩阵描述了三维世界到二维像素的映射关系。<div align="center"> <img src="2_标定问题.png" width=50%></div></li><li><strong>求解投影矩阵</strong><div align="center"> <img src="2_求解投影矩阵.png" width=70%></div><div align="center"> <img src="2_转换为齐次方程组.png" width=70%></div><div align="center"> <img src="2_投影矩阵解法.png" width=70%></div></li><li><strong>提取摄像机参数</strong><br><div align="center"> <img src="2_提取摄像机参数.png" width=70%></div><br>注意： 世界坐标系的三维点不能位于同一平面！</li></ol><h2 id="径向畸变的摄像机标定"><a href="#径向畸变的摄像机标定" class="headerlink" title="径向畸变的摄像机标定"></a>径向畸变的摄像机标定</h2><ol><li><strong>问题建模</strong><div align="center"> <img src="2_径向畸变模型.png" width=60%></div><div align="center"> <img src="2_径向畸变相机标定.png" width=60%></div></li><li><strong>标定求解</strong><div align="center"> <img src="2_径向畸变相机标定求解.png" width=90%></div></li></ol><h2 id="补充知识-1"><a href="#补充知识-1" class="headerlink" title="补充知识"></a>补充知识</h2><ol><li><strong>2D平面上的变换</strong><ul><li>欧式变换<div align="center"><img src="2_2D欧式变换.png" width=70%></div></li><li>相似变换<div align="center"><img src="2_2D相似变换.png" width=70%></div></li><li>透视变换<div align="center"><img src="2_2D透视变换.png" width=70%></div></li><li>仿射变换<div align="center"><img src="2_2D仿射变换.png" width=70%></div></li></ul></li><li><strong>3D空间中的变换</strong><ul><li>欧式变换<div align="center"><img src="2_3D欧式变换.png" width=70%></div></li><li>透视变换<div align="center"><img src="2_3D透视变换.png" width=60%></div></li><li>仿射变换<div align="center"><img src="2_3D仿射变换.png" width=70%></div></li></ul></li></ol><h1 id="单视图重建"><a href="#单视图重建" class="headerlink" title="单视图重建"></a>单视图重建</h1><p>相机标定后，内外参数已知，也不能根据单视图测量值 $p$ 估算 $P$, 三维点可以位于视线中心和二维点定义的直线上的任何位置。</p><h2 id="无穷远点、线与平面"><a href="#无穷远点、线与平面" class="headerlink" title="无穷远点、线与平面"></a>无穷远点、线与平面</h2><ol><li><strong>2D平面上的直线</strong><br>二维点 $x=[x_1, x_2, 1]^T$ 在直线 $l=[a, b, c]^T$上可表示为 <script type="math/tex">l^Tx=0 或 x^Tl=0 或 ax_1+bx_2+c=0</script> </li><li><strong>两直线的交点</strong><script type="math/tex; mode=display">x=l \times l'</script></li><li><strong>2D平面上的无穷远点</strong><div align="center"> <img src="3_2D无穷远点.png" width=70%></div></li><li><strong>2D平面上的无穷远直线</strong><div align="center"> <img src="3_2D无穷远直线.png" width=50%></div></li><li><strong>3D平面上的直线</strong><br>三维点 $x=[x_1, x_2, x_3, 1]^T$ 在面 $\Pi=[a, b, c, d]^T$上可表示为 <script type="math/tex">\Pi^Tx=0 或 x^T\Pi=0</script> </li><li><strong>3D空间中的无穷远点</strong><br>空间中平行线的交点为无穷远点 $x_\infty=[a, b, c, 0]^T$</li><li><strong>3D空间中的无穷远平面</strong><br>平行平面在无穷远处交于一条公共线，即无穷远直线；<br>两条或多条无穷远直线的集合定义为无穷远平面 $\Pi_\infty=[0, 0, 0, 1]^T$</li></ol><h2 id="影消点和影消线"><a href="#影消点和影消线" class="headerlink" title="影消点和影消线"></a>影消点和影消线</h2><ol><li><strong>变换公式</strong><br>$H$ 为变换矩阵，点到点的变换公式：$p’=Hp$，直线到直线的变换公式：$l’=H^{-T}l$</li><li><strong>影消点与影消线</strong><br>影消点：三维空间中的无穷远点在图像平面上的投影点<br>影消线（视平线）：空间汇中的无穷远线<br>图像中两条直线的交点如果在影消线上；则这两条线是3D空间中的平行线<div align="center"> <img src="3_影消点与影消线.png" width=50%></div></li></ol><h2 id="单视重构"><a href="#单视重构" class="headerlink" title="单视重构"></a>单视重构</h2><ol><li><strong>两组平行线的夹角与影消点</strong><div align="center"> <img src="3_两组平行线的夹角与影消点.png" width=60%></div><div align="center"> <img src="3_w的性质.png" width=70%></div></li><li><strong>单视图标定</strong><div align="center"> <img src="3_单视图标定.png" width=70%></div></li><li><strong>单视图重构</strong><br>$K$ 已知，相机参考系中的场景平面方向 $n=K^Tl_h$<br>注意：场景的实际比例无法恢复<br>单视图重构弊端：需要手动选择影消点和影消线，需要知道场景先验信息（点对应关系，线、面几何信息等）</li></ol><h1 id="三维重建基础与极几何"><a href="#三维重建基础与极几何" class="headerlink" title="三维重建基础与极几何"></a>三维重建基础与极几何</h1><h2 id="三维重建基础"><a href="#三维重建基础" class="headerlink" title="三维重建基础"></a>三维重建基础</h2><ol><li><strong>摄像机标定与单视图重构</strong><div align="center"> <img src="4_摄像机标定与单视图重构.png" width=70%></div></li><li><p><strong>三角化</strong><br><div align="center"> <img src="4_三角化.png" width=70%></div><br>线性解法：<br><div align="center"> <img src="4_三角化线性解法.png" width=70%></div><br>非线性解法：<br><div align="center"> <img src="4_三角化非线性解法.png" width=60%></div><br>然而实际应用中，两条直线通常不相交。而线性和非线性解法都需要知道 $K、R、T$。多视图几何的关键问题包括：</p><ul><li>摄像机几何：从一张或多张图像中求解摄像机内外参数</li><li>场景几何：通过2-多幅图寻找3D场景坐标</li><li>对应关系：已知一个图像中的二维点，如何在另一个图像中找到对应的二维点</li></ul></li></ol><h2 id="极几何及基础矩阵"><a href="#极几何及基础矩阵" class="headerlink" title="极几何及基础矩阵"></a>极几何及基础矩阵</h2><ol><li><p><strong>极几何</strong><br>极几何描述了同一场景或物体的两个视点图像间的几何关系<br><div align="center"> <img src="4_极几何.png" width=70%></div><br>特例：</p><ul><li>平行视图<div align="center"> <img src="4_平行视图.png" width=70%></div></li><li>前向平移（无旋转）<br><div align="center"> <img src="4_前向平移.png" width=70%></div><br>极几何约束：可以将搜索范围缩小到对应的极线上</li></ul></li><li><strong>本质矩阵</strong><br>本质矩阵对<strong>规范化摄像机</strong>拍摄的两个视点图像间的极几何关系进行代数描述<div align="center"> <img src="4_本质矩阵.png" width=70%></div></li><li><strong>基础矩阵</strong><br>基础矩阵对一般的<strong>透视摄像机</strong>拍摄的两个视点的图像间的极几何关系进行代数描述，刻画了两个相同场景图像在不同视图中的对应关系<br><div align="center"> <img src="4_基础矩阵.png" width=60%></div><br>基础矩阵作用：已知 $F$，无需场景信息及摄像机内外参数即可建立两图像的对应关系；$F$ 包含摄像机内外参数信息，可应用于三维重构和多视图匹配</li></ol><h2 id="基础矩阵估计"><a href="#基础矩阵估计" class="headerlink" title="基础矩阵估计"></a>基础矩阵估计</h2><p>基础矩阵有$7$个自由度，理论上7个点即可求解，但估计方法较复杂</p><div align="center">  <img src="4_估计F.png" width=60%></div><ol><li><p><strong>八点算法</strong><br><div align="center"> <img src="4_八点算法.png" width=60%></div><br><div align="center"> <img src="4_八点算法存在问题.png" width=60%></div><br>存在问题：</p><ul><li>$W$ 中各个元素的数值差异过大</li><li>SVD分解有数值计算问题</li></ul></li><li><strong>归一化八点法</strong><br>归一化八点算法可以提高计算精度。对图像进行变换 $T$ (平移与缩放)，使得：原点 = 图像上点的重心;各个像点到坐标原点的均方根距离等于 $\sqrt{2}$ 。计算步骤：<ul><li>分别计算左图和右图的 $T$ 和 $T’$</li><li>坐标归一化：$q_i=Tp_i; q’_i=T’p’_i$</li><li>通过八点法计算矩阵 $F_q$</li><li>逆归一化 $F=T’^TF_qT$</li></ul></li></ol><h2 id="单应矩阵"><a href="#单应矩阵" class="headerlink" title="单应矩阵"></a>单应矩阵</h2><p>单应矩阵指空间平面在两个摄像机下的投影几何</p><ol><li><strong>单应矩阵推导</strong><div align="center"> <img src="4_单应矩阵推导.png" width=70%></div></li><li><strong>单应矩阵估计</strong><div align="center"> <img src="4_单应矩阵估计.png" width=70%></div></li><li><p><strong>单应矩阵性质</strong><br>场景结构：</p><ul><li>基础矩阵表示两视图间的对极约束与场景结构无关，其仅依赖相机内外参数及相机间的旋转和平移</li><li>单应矩阵要求场景中的点位于同一平面；或两个相机之间只有旋转无平移</li></ul><p>约束关系：</p><ul><li>基础矩阵建立点和极线的对应关系</li><li>单应矩阵建立点和点的对应</li></ul></li></ol><h1 id="双目立体视觉重建"><a href="#双目立体视觉重建" class="headerlink" title="双目立体视觉重建"></a>双目立体视觉重建</h1><h2 id="基于平行视图的双目立体视觉"><a href="#基于平行视图的双目立体视觉" class="headerlink" title="基于平行视图的双目立体视觉"></a>基于平行视图的双目立体视觉</h2><p>平行视图的三角测量：视差 $p<em>u-p_u’=\frac{B·f}{z}$，视差与深度$z$成反比<br>  <div align="center"><br>    &lt;img src=”5</em>平行视图的三角测量.png” width=70%&gt;<br>  &lt;/div&gt;</p><h2 id="图像校正"><a href="#图像校正" class="headerlink" title="图像校正"></a>图像校正</h2><p>图像校正步骤：<br>  <div align="center">    <img src="5_图像校正.png" width=70%>  </div></p><h2 id="对应点搜索"><a href="#对应点搜索" class="headerlink" title="对应点搜索"></a>对应点搜索</h2><ol><li>相关匹配算法<div align="center"> <img src="5_相关匹配算法.png" width=70%></div></li><li>归一化相关匹配算法<div align="center"> <img src="5_归一化相关匹配算法.png" width=80%></div></li><li>窗口大小的影响<br>窗口小：细节丰富但噪声多；窗口大视差图平滑噪声少但细节丢失</li><li><p>相关法存在问题<br>透视缩短：遮挡；基线选择；同质区域；重复性模式<br><div align="center"> <img src="5_透视缩短和遮挡问题.png" width=70%></div><br>以上需要引入更多约束解决对应点问题：</p><ul><li>唯一性约束：一张图像的任何点在另一张图像中最多只有一个匹配点</li><li>顺序约束（单调性约束）：左右视图中的对应点次序一致</li><li>平滑性约束：视差函数通常是平滑的（除了遮挡边界）</li></ul></li></ol><h1 id="多视图重建"><a href="#多视图重建" class="headerlink" title="多视图重建"></a>多视图重建</h1><h2 id="运动恢复结构问题"><a href="#运动恢复结构问题" class="headerlink" title="运动恢复结构问题"></a>运动恢复结构问题</h2><p>Structure from Motion(SfM)：通过三维场景的多张图像恢复出该场景的三维结构信息（如3D点云）以及每张图片对应的摄像机参数<br>  <div align="center">    <img src="6_运动恢复结构问题.png" width=80%>  </div></p><h2 id="三种典型的运动恢复结构任务"><a href="#三种典型的运动恢复结构任务" class="headerlink" title="三种典型的运动恢复结构任务"></a>三种典型的运动恢复结构任务</h2><h3 id="欧式结构恢复（摄像机内参已知，外参未知）"><a href="#欧式结构恢复（摄像机内参已知，外参未知）" class="headerlink" title="欧式结构恢复（摄像机内参已知，外参未知）"></a><strong>欧式结构恢复</strong>（摄像机内参已知，外参未知）</h3><p>  问题建模：<br>  <div align="center">    <img src="6_欧式结构恢复问题建模.png" width=70%>  </div><br>  2视图求解方法：<br>  <div align="center">    <img src="6_2视图欧式结构恢复求解方法.png" width=70%>  </div><br>  其中本质矩阵分解方法如下：<br>  <div align="center">    <img src="6_本质矩阵分解.png" width=60%>  </div><br>  欧式结构恢复歧义：恢复的机构与真实场景之间相差一个相似变换（旋转，平移，缩放）——度量重构（恢复的场景与真实场景之间存在相似变换的重构）</p><h3 id="仿射结构恢复（摄像机为仿射相机，内外参数均未知）"><a href="#仿射结构恢复（摄像机为仿射相机，内外参数均未知）" class="headerlink" title="仿射结构恢复（摄像机为仿射相机，内外参数均未知）"></a><strong>仿射结构恢复</strong>（摄像机为仿射相机，内外参数均未知）</h3><p>问题建模：</p><div align="center">  <img src="6_仿射结构恢复问题建模.png" width=70%></div><p><strong>基于因式分解的仿射结构恢复算法步骤</strong>：</p><ol><li>数据中心化：减去图像点的质心<div align="center"> <img src="6_数据中心化.png" width=70%></div></li><li>数据中心化的矩阵形式<div align="center"> <img src="6_数据中心化矩阵形式.png" width=70%></div></li><li>因式分解获得运动与结构<div align="center"> <img src="6_因式分解获得运动与结构.png" width=70%></div></li></ol><p>总结<br>  <div align="center">  <img src="6_仿射结构恢复问题总结.png" width=70%>  </div></p><p>仿射结构恢复歧义<br>  <div align="center">  <img src="6_仿射结构恢复歧义.png" width=70%>  </div><br>给定 $m$ 个相机，$n$ 个三维点，有 $2mn$ 个等式，$8m+3n-8$ 个未知量 </p><h3 id="透视结构恢复（摄像机为透视相机，内外参数均未知）"><a href="#透视结构恢复（摄像机为透视相机，内外参数均未知）" class="headerlink" title="透视结构恢复（摄像机为透视相机，内外参数均未知）"></a><strong>透视结构恢复</strong>（摄像机为透视相机，内外参数均未知）</h3><p>问题建模：</p><div align="center">  <img src="6_透视结构恢复问题建模.png" width=70%></div>透视结构恢复歧义<div align="center">  <img src="6_透视结构恢复歧义.png" width=70%></div>  给定 $m$ 个相机，$n$ 个三维点，有 $2mn$ 个等式，$11m+3n-15$ 个未知量 在相差一个 $4\times4$ 的可逆变换的情况下恢复摄像机运动与场景结构- **代数方法**（通过基础矩阵）  - 2视图代数方法    <div align="center">      <img src="6_2视图代数方法.png" width=70%>    </div>   - 利用F估计摄像机矩阵    <div align="center">      <img src="6_利用F估计摄像机矩阵.png" width=70%>    </div>   - n视图代数方法    <div align="center">      <img src="6_n视图代数方法.png" width=70%>    </div> - **捆绑调整**（Bundle Adjustment, BA）  因式分解法假定所有点均可见，存在遮挡和建立对应点关系失败时不可用；代数法应用于2视图重建，易出现误差累积。捆绑调整为非线性最小化问题，使用牛顿法与列文伯格——马夸尔特法（L-M）求解：    <div align="center">      <img src="6_捆绑调整.png" width=60%>    </div> <ul><li>捆绑调整法优势：可以同时处理大量视图，也可以处理丢失的数据</li><li>捆绑调整法局限性：大量参数的最小化问题，需要良好的初始条件</li><li>捆绑调整法实际操作：常用作SfM的最后一步，分解或代数方法可作为优化问题的初始解</li></ul><h1 id="运动恢复结构-SfM-系统设计"><a href="#运动恢复结构-SfM-系统设计" class="headerlink" title="运动恢复结构(SfM)系统设计"></a>运动恢复结构(SfM)系统设计</h1><h2 id="PnP问题"><a href="#PnP问题" class="headerlink" title="PnP问题"></a>PnP问题</h2><ol><li>PnP问题描述<div align="center"> <img src="7_PnP问题描述.png" width=70%></div> </li><li>P3P求解摄像机位姿<div align="center"> <img src="7_P3P求解摄像机位姿.png" width=70%></div> </li></ol><h2 id="两视图重构"><a href="#两视图重构" class="headerlink" title="两视图重构"></a>两视图重构</h2><p>2视图欧式结构恢复求解第一步为求解基础矩阵 $F$，一般在进行此步之前先进行特征提取+特征匹配，再进行基础矩阵估计</p><ol><li>特征提取<br>输入图片，输出尺度不变性的特征点（位置+每个特征的128维数据描述），SIFT特征提取过程如下：<div align="center"> <img src="7_SIFT特征提取.png" width=60%></div> </li><li>特征匹配<div align="center"> <img src="7_特征匹配.png" width=70%></div> </li><li>RANSAC估计基础矩阵<div align="center"> <img src="7_RANSAC估计基础矩阵.png" width=70%></div> </li></ol><h2 id="SfM系统：基于增量法的多视图欧式重构（以OpenMVG为例）"><a href="#SfM系统：基于增量法的多视图欧式重构（以OpenMVG为例）" class="headerlink" title="SfM系统：基于增量法的多视图欧式重构（以OpenMVG为例）"></a>SfM系统：基于增量法的多视图欧式重构（以OpenMVG为例）</h2><ol><li>预处理<br>图像特征点提取与匹配：输入图像集，输出几何校验后的特征点匹配结果<ol><li>计算潜在匹配对：提取特征点并计算特征描述符，利用近邻的特征点匹配方法进行特征点匹配</li><li>利用几何一致性过滤误匹配：估计基础矩阵 $F$ 和单应矩阵 $H$</li></ol></li><li><p>增量法求解SfM<br><div align="center"> <img src="7_增量法求解SfM.png" width=80%></div><br>注意：</p><ul><li>第1步 OpenMVG里只包含两张图的track会被剔除</li><li>第3步 选取的边 $e$ 要求射线夹角中位数最大，且夹角不大于60不小于3</li><li>第8步3) 图像1的选择需要射线夹角大于2度，且重投影误差小于某个值</li></ul></li></ol><h1 id="同时定位与建图-SLAM-系统设计"><a href="#同时定位与建图-SLAM-系统设计" class="headerlink" title="同时定位与建图(SLAM)系统设计"></a>同时定位与建图(SLAM)系统设计</h1><h2 id="补充知识-2"><a href="#补充知识-2" class="headerlink" title="补充知识"></a>补充知识</h2><ol><li>词袋模型<div align="center"> <img src="8_词袋模型.png" width=60%></div> </li><li>基于词袋模型的图像检索<div align="center"> <img src="8_基于词袋模型的图像检索.png" width=70%></div> </li></ol><h2 id="SLAM"><a href="#SLAM" class="headerlink" title="SLAM"></a>SLAM</h2><ol><li>SLAM介绍<br>同时定位和建图（Simultaneous Localization and Mapping, SLAM）中的定位指传感器的位置和姿态，SLAM应用于定位、导航、避障、重建、交互</li><li>传感器分类<br>传感器可分为携带于机器人本体上的（如相机、激光风）和安装于环境中的（如导轨、二维码标志等）。摄像机作为传感器的一种，按照工作方式可分为单目（Monocular）、双目（Stereo）和深度相机（RGB-D）</li><li>地图<br>地图指所有路标点的集合，地图是对环境的描述，但描述不固定，需要视SLAM的应用而定。</li><li>SLAM开源方案<div align="center"> <img src="8_SLAM开源方案.png" width=80%></div> </li></ol><h2 id="ORB-SLAM系统"><a href="#ORB-SLAM系统" class="headerlink" title="ORB-SLAM系统"></a>ORB-SLAM系统</h2><ol><li>系统组成<div align="center"> <img src="8_SLAM系统组成.png" width=70%></div> </li><li>具体步骤<ol><li>数据结构与数据库<div align="center"><img src="8_数据结构与数据库.png" width=90%></div> </li><li>跟踪<div align="center"><img src="8_跟踪.png" width=90%></div> </li><li>建图<div align="center"><img src="8_建图.png" width=90%></div> 局部Bundle Adjustment举例：<div align="center"><img src="8_局部Bundl_Adjustment.png" width=70%></div> </li><li>回环修正<div align="center"><img src="8_回环修正.png" width=90%></div> 回环候选帧检测：<div align="center"><img src="8_回环候选帧检测.png" width=90%></div> </li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> Computer Vision </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3D Construction</title>
      <link href="/2022/10/01/9-3D-Construction/"/>
      <url>/2022/10/01/9-3D-Construction/</url>
      
        <content type="html"><![CDATA[<h1 id="经典算法"><a href="#经典算法" class="headerlink" title="经典算法"></a>经典算法</h1><h2 id="ICP"><a href="#ICP" class="headerlink" title="ICP"></a>ICP</h2><p>迭代最近点算法（Iterative Closest Point, ICP）是一种点云配准算法，用来求解两堆点云之间的变换关系：旋转关系 $R$ 和平移关系 $t$。</p><ul><li>基本思路：找到两组点云集合中距离最近的点对，根据估计的变换关系（$R$ 和 $t$）来计算距离最近点对经过变换之后的误差，经过不断的迭代直至误差小于某一阈值或者达到迭代次数来确定最终的变换关系。</li><li>数学描述：给定两个点云集合：<script type="math/tex">X=(x_1,...,x_n)</script> <script type="math/tex">P=(p_1,...,p_m)</script> 求解$R$和$t$，能量最小化:<script type="math/tex; mode=display">E(R, t)=\frac{1}{n}\sum^n_{i=1}||x_i-(Rp_i+t)||^2</script></li><li><p>求解方法<br><strong>I. 已知对应点的情况</strong></p><ol><li>计算两组点云质心: <script type="math/tex">u_x=\frac{1}{n}\sum^n_{i=1}||x_i||^2</script> <script type="math/tex">u_p=\frac{1}{m}\sum^m_{i=1}||p_i||^2</script></li><li>计算两组点云中的点以质心为原点的坐标: <script type="math/tex">X'=(x_i-u_x)=(x_i')</script> <script type="math/tex">P'=(p_i-u_p)=(p_i')</script></li><li>计算 $w$ 并对其进行SVD分解: <script type="math/tex">w=\frac{1}{n}\sum^n_{i=1}x_i'p_i^T=U diag(\delta_1, \delta_2, \delta_3)V^T</script></li><li>ICP算法的解为：$R=VU^T, t=u_x-Ru_p$<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">icp</span>(<span class="params">X, P</span>):</span></span><br><span class="line">  u_x = np.mean(X, axis=<span class="number">0</span>)</span><br><span class="line">  u_p = np.mean(P, axis=<span class="number">0</span>)</span><br><span class="line">  H = (X - u_x).transpose() @ (P - u_p)</span><br><span class="line">  U, S, Vt = np.linalg.svd(H)</span><br><span class="line">  R = np.dot(Vt.T, U.T)</span><br><span class="line">  t = u_x - R @ u_p</span><br><span class="line">  <span class="keyword">return</span> R, t</span><br><span class="line">R, t = icp(X, P)</span><br><span class="line">X_trans = np.dot(X, R.transpose()) + t - X</span><br></pre></td></tr></table></figure></li></ol><p><strong>II. 未知对应点的情况</strong></p><ol><li>寻找两组点云中距离最近的点对</li><li>根据找到的距离最近点对求解两组点云之间的位姿关系</li><li>根据求解的位姿关系对点云进行变换，并计算误差</li><li>若误差没有达到要求，则重复1-3步直至误差满足要求或达到最大迭代次数</li></ol></li></ul><p>参考: <a href="https://blog.csdn.net/u014709760/article/details/99241393">ICP算法</a></p><h2 id="ARAP"><a href="#ARAP" class="headerlink" title="ARAP"></a>ARAP</h2><p>尽可能刚性变形算法（As Rigid As Possible, ARAP）要求模型变形前后保持局部细节不变，即只进行平移或旋转的刚体变形，形状不会发生扭曲。</p><ul><li>数学描述：设 $C$ 至 $C’$为刚体变换，其变形过程中存在旋转矩阵 $R$: <script type="math/tex">p_i'-p_j'=R_i(p_i-p_j), \forall j\in N(i)</script><br><img align='center' src='deform.png' height=70% width=70%><br>其中 $N(i)$ 表示顶点的1邻域点的索引，$p_j$ 和$p_j’$ 分别表示 $p_i$ 和 $p_i’$ 的1邻域顶点， $R_i$ 表示 $C_i$ 到 $C_i’$ 的最优旋转矩阵，最小化以下能量函数实现模型的尽可能刚性变形：<script type="math/tex; mode=display">E(C_i, C_i')=\sum_{j\in N(i)}w_{ij}||p_i'-p_j'-R_i(p_i-p_j)||^2</script>其中 $e$ 表示顶点之间的边，$w$ 表示其边上的权重</li><li>求解方法：<ol><li>R为变量，则不包含 $R$ 的部分可理解为常数，由此可得：<script type="math/tex; mode=display">E(C_i, C_i')=\sum_jw_{ij}(e_{ij}'-R_ie_{ij})^T(e_{ij}'-R_ie_{ij})=argmax_{R_i} Tr(R_i\sum_jw_{ij}e_{ij}e_{ij}')</script></li><li>协方差矩阵并进行SVD，根据中间变形结果 $P’$ 和初始模型坐标 $P$ 使用奇异值分解估算出变形单元的最优旋转矩阵 $R_i$ :<script type="math/tex; mode=display">\sum_{j\in N(i)}w_{ij}e_{ij}e_{ij}'=P_iD_iP_i'^T=U_i\sum_iV_i^T</script></li><li>在旋转矩阵已知的情况下令能量函数导数为0可得到函数取最小值时的 $P’$ ，下一次迭代将 $P’$ 作为已知求解 $R_i$， 迭代直至能量误差小于指定阈值<script type="math/tex; mode=display">\sum_{j\in N(i)}w_{ij}(p_i'-p_j')=\sum_{j\in N(i)}\frac{w_{ij}}{2}(R_i+R_j)(p_i-p_j)</script></li></ol></li></ul><p>参考：</p><ul><li><a href="https://blog.csdn.net/weixin_43236428/article/details/104669088">ARAP（As-Rigid-As-Possible）变形算法</a></li><li><a href="https://blog.csdn.net/penkgao/article/details/79631383">非固定边界网格参数化（ARAP）</a></li><li><a href="https://blog.csdn.net/why18767183086/article/details/108034725">ARAP参数化算法</a></li></ul><h2 id="Marching-Cubes"><a href="#Marching-Cubes" class="headerlink" title="Marching Cubes"></a>Marching Cubes</h2><p>Marching Cubes算法是三维离散数据场中提取等值面的经典算法。</p><ul><li>基本假设：沿六面体边的数据场呈连续性变化。即如果一条边的两个顶点分别大于或小于等值面的值，则在该条边上有且仅有一点是这条边与等值面的交点。</li><li>基本思想：逐个处理数据场中的立方体（体素），分离出与等值面相交的立方体，采用插值计算出等值面与立方体边的交点。根据立方体每一顶点与等值面的相对位置，将等值面与立方体边的交点按一定方式连接生成等值面，作为等值面在该立方体内的一个逼近表示。即用许多小正方体去对空间进行切分，用小正方体内部的平面来近似表示当前的等值面。小正方体的数量越多逼近效果越好但计算代价越大。</li><li>实现步骤：<ol><li>将原始数据经过预处理之后读入指定的数组中</li><li>从网格数据体中提取一个单元体成为当前单元体，同时获取该单元体的所有信息如8个顶点的值、坐标位置等</li><li>将当前单元体8个顶点的函数值与给定等值面值C进行比较得到该单元体的状态表(edgeTable、triTable)</li><li>根据当前单元体的状态表索引找出与等值面相交的单元体棱边，并采用线性插值的方法计算出各个交点的位置坐标</li><li>利用中心差分法求出当前单元体8个顶点的法向量，再采用线性插值的方法得到三角面片各个顶点的法向量</li><li>根据各个三角面片顶点的坐标、顶点法向量进行等值面图象的绘制</li></ol></li></ul><p>参考: </p><ul><li><a href="https://www.bilibili.com/video/BV1Ta4y1E7CT/?spm_id_from=333.337.search-card.all.click&amp;vd_source=486265fa677326a8f53894f05277bfb9">Coding Adventure: Marching Cubes</a></li><li><a href="https://blog.csdn.net/BXD1314/article/details/119324881?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166467987816782388075942%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=166467987816782388075942&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-119324881-null-null.142^v51^pc_rank_34_2,201^v3^control_2&amp;utm_term=Marching%20Cubes&amp;spm=1018.2226.3001.4187">Marching Cubes算法理解</a></li></ul><h2 id="TSDF"><a href="#TSDF" class="headerlink" title="TSDF"></a>TSDF</h2><p>基于截断的带符号距离函数（Truncated Signed Distance Function, TSDF）是一种计算隐势面的方法。通过求每个体素的值，再使用Marching Cube来提取等势面。在拥有大内存的显卡并行计算的情况下，使用TSDF可以做到实时的重建效果。</p><ul><li><p>实现步骤：</p><ol><li>准备工作<br>建立一个大的Volume能够完全包围要重建的物体，划分网格体素，体素的大小取决于Volume的大小和划分体素的数目。将整个空间的体素全部存入GPU运算，每个线程处理一条$(x,y)$。即对于$(x,y,z)$的晶格坐标，每个GPU进程扫描处理一个$(x,y)$坐标下的晶格柱。对于构造的立体中的每个体素转化为世界坐标系下的三维位置点 $p$。</li><li>计算当前帧的TSDF值以及权重<br>遍历所有体素，以一个体素在世界坐标系三维位置点 $p$ 为例，由深度数据的相机位姿矩阵求世界坐标系下点 $p$ 在相机坐标系下得映射点 $v$ 。并由相机内参矩阵反投影 $v$ 点求深度图像中的对应像素点 $x$ ，像素点 $x$ 的深度值为$value(x)$，点 $v$ 到相机坐标原点的距离为$distance(v)$。引入截断距离计算$tsdf(p)$, 限制大小在$[-1,1]$之间：<script type="math/tex; mode=display">sdf(p)=value(x)-distance(v)</script><script type="math/tex; mode=display">tsdf_i(x)=max(-1, min(1, \frac{sdf_i(x)}{t}))</script></li><li>当前帧与全局融合结果进行融合<br>如果当前帧是第一帧，则第一帧即是融合结果，否则需要当前帧与之前的融合结果进行融合。$TSDF_i(p)$为体素 $p$ 的融合$TSDF$值，$W_i(p)$ 为融合权重值，$tsdf_i(p)$为体素 $p$ 当前帧的$TSDF$值，$w_i(p)$为当前帧权重值，$θ$ 为投影光线与表面法向量的夹角。<script type="math/tex; mode=display">TSDF_i(p)=\frac{W_i(p)TSDF_{i-1}(p)+w_i(p)tsdf_i(p)}{W_{i-1}(p)+w_i(p)}</script><script type="math/tex; mode=display">W_i(p)=W_{i-1}(p)+w_i(p), w_i(p)=\frac{cos(θ)}{distance(v)}</script></li><li>每添加一帧深度数据，执行一遍2,3步的计算，直到最后输出结果给Marching Cube计算提取等势面</li></ol><p>参考：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/390276710">TSDF算法简述</a></li><li><a href="https://blog.csdn.net/zfjBIT/article/details/104648505">TSDF算法学习</a></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> Computer Vision </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Papers Reading about NLP</title>
      <link href="/2022/09/17/Papers-Reading-about-NLP/"/>
      <url>/2022/09/17/Papers-Reading-about-NLP/</url>
      
        <content type="html"><![CDATA[<p><strong>阅读大纲</strong><br><img src='index.png' height=100% width=100%></p><table>  <tr>      <td rowspan="1"><b>NLP</b></td>        <td>Adaptive input & DLCL</td>        <td>23-03-23</td>    </tr>    <tr>        <td rowspan="3"><b>NLP</b>: Language Model</td>        <td>HELM</td>        <td>23-02-06</td>    </tr>    <tr>        <td>InstructGPT, Anthropic_LLM</td>        <td>23-03-12</td>    </tr>  <tr>        <td>Visual ChatGPT</td>        <td>23-03-17</td>    </tr>    <tr>        <td rowspan="1"><b>NLP</b>: Retrieval</td>        <td>Neural Corpus Indexer</td>        <td>22-12-21</td>    </tr>    <tr>        <td rowspan="1"><b>NLP</b>: Audio</td>        <td>Whisper</td>        <td>22-11-17</td>    </tr></table><h1 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h1><h3>Learning Deep Transformer Models for Machine Translation</h3><ul><li>【ACL2019】 <a href="https://arxiv.org/abs/1906.01787">ArXiv</a> <a href="https://github.com/wangqiangneu/dlcl">Code</a></li><li>简介：原始的Transformer的encoder层&gt;12时很难训练。针对机器翻译任务，本文加入两个技巧（pre-LN和动态线性结合残差连接）训练更深层的Transformer，使模型参数更少训练更快</li><li>关键技术：<ol><li>相较于原始Transformer的Post-norm，使用Pre-norm可以减少梯度反传计算量，训练更高效</li><li>使用动态线性结合层（DLCL）代替传统的残差连接，用可学习的权值计算历史记忆的连接<ul><li>更早的层连接更稠密，层深越深连接变得稀疏</li><li>距离输出层最近的连接权值越高</li><li>不同层的权值动态变化</li></ul></li></ol></li><li>思考：不一定专注模型创新，把小的tricks灵活修改做足实验也是好work</li></ul><p><div align="center">  <img src="23-03-23DLCL.png"></div><br><br></p><hr><h3>Adaptive Input Representations for Neural Language Modeling</h3><ul><li>FAIR【ICLR2019】 <a href="https://arxiv.org/abs/1809.10853">ArXiv</a> <a href="http://github.com/pytorch/fairseq">Code</a></li><li>相关Paper:《Efficient softmax approximation for GPUs》FAIR【ICML2017】<a href="https://arxiv.org/abs/1609.04309v3">Arxiv</a> <a href="https://github.com/facebookresearch/adaptive-softmax">Code</a></li><li>简介：在自适应softmax基础上，提出了神经网络语言模型的自适应输入表示，使得网络参数更少且训练更快</li><li>关键技术：如果输出层使用与自适应输入表示相同参数(V, k, d)的自适应softmax，可以通过参数共享进一步减少参数，还可以共享减少容量的线性变化参数</li><li>参考：<a href="https://zhuanlan.zhihu.com/p/109125864">Adaptive Softmax</a>; <a href="https://zhuanlan.zhihu.com/p/67666803">Adaptive Input</a></li></ul><p><div align="center">  <img src="23-03-23Adaptive_input.png"></div><br><br></p><h1 id="NLP-Language-Model"><a href="#NLP-Language-Model" class="headerlink" title="NLP - Language Model"></a>NLP - Language Model</h1><h3>Holistic Evaluation of Language Models</h3><ul><li><a href="https://arxiv.org/abs/2211.09110">ArXiv</a></li><li>简介：全面的语言模型评测，针对现有语言模型的评测内容包括：核心场景、通用评价标准、针对性评估、模型、适用性等（要有钱有人力有人脉）</li><li>关键技术：<ol><li>先对语言模型分类，补充标准语言模型对各类模型的评价（准确率、校准、鲁棒性、公平性、偏见、有毒性、效率）</li><li>实验发现：InstructGPT davinci v2(175B*)综合表现最好；未开源的模型效果比开源模型效果好得多；所有模型对Prompting有很大的敏感性；模型越大效果越好</li></ol></li><li>Limitation：场景、评价标准、适用性不全等</li><li>参考：<a href="https://www.bilibili.com/video/BV1z24y1B7uX/?spm_id_from=444.41.list.card_archive.click&amp;vd_source=486265fa677326a8f53894f05277bfb9">沐神论文精读</a></li></ul><p><div align="center">  <img src="23-02-06HELM.png"></div><br><br></p><hr><h3>Training language models to follow instructions with human feedback</h3><ul><li><a href="https://arxiv.org/abs/2203.02155">ArXiv</a></li><li>参考：<a href="https://www.bilibili.com/video/BV1hd4y187CR/?spm_id_from=333.999.0.0&amp;vd_source=486265fa677326a8f53894f05277bfb9">沐神论文精读</a></li></ul><p><div align="center">  <img src="23-03-12InstructGPT.png">  <img src="23-03-12InstructGPT_c.png"></div><br><br></p><h3>Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback</h3><ul><li><a href="https://arxiv.org/abs/2204.05862">ArXiv</a></li><li>参考：<a href="https://www.bilibili.com/video/BV1XY411B7nM/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">沐神论文精读</a></li></ul><p><div align="center">  <img src="23-03-12Anthropic_LLM.png">  <img src="23-03-12Anthropic_LLM_c.png"></div><br><br></p><hr><h3>Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models</h3><ul><li>Microsoft <a href="https://arxiv.org/abs/2303.04671">ArXiv</a></li><li>简介：联合不同的视觉基础模型（VFM）使得ChatGPT可以处理复杂的视觉任务</li><li>关键技术：<ol><li>包含22个不同VFMs的Prompt Manager使得ChatGPT更好的交互和结合处理图像任务</li><li>复杂的Zero-shot实验验证了模型的优越性</li></ol></li><li>Limitation：依赖ChatGPT和VFMs的结合；需要大量大的Prompt工程；实时性不好；限制于ChatGPT的token的长度；安全和隐私</li></ul><p><div align="center">  <img src="23-03-17Visual_ChatGPT.png"></div><br><br></p><h1 id="NLP-Retrieval"><a href="#NLP-Retrieval" class="headerlink" title="NLP - Retrieval"></a>NLP - Retrieval</h1><h3>A Neural Corpus Indexer for Document Retrieval</h3><ul><li>【NeurlIPS2022】<a href="https://arxiv.org/abs/2206.02743v1">ArXiv</a></li><li>简介：基于Transformer的sequence-to-sequence架构，给定qurey生成相关文档id</li><li>关键技术：<ol><li>和DSI一样，是端到端的文档检索模型</li><li>prefix-aware weight-adaptive (PAWA) 解码器生成文档id</li><li>基于对比学习的一致性正则损失</li></ol></li><li>Limitation：模型过大不利于部署；检索速度有待提高；model-based难以进行新文档更新</li><li>参考：<a href="https://www.bilibili.com/video/BV1Se411w7Sn/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">沐神论文精读</a></li></ul><p><div align="center">  <img src="22-12-21NCI.png"></div><br><br></p><h1 id="NLP-Audio"><a href="#NLP-Audio" class="headerlink" title="NLP - Audio"></a>NLP - Audio</h1><h3>Robust Speech Recognition via Large-ScaleWeak Supervision</h3><ul><li>OpenAI <a href="https://cdn.openai.com/papers/whisper.pdf">Arxiv</a></li><li>简介：基于Transformer通过大尺度弱监督学习自动语音识别（ASR，Automatic Speech Recognition）模型，模型可以不微调直接进行zero-shot迁移。</li><li>关键技术：<ol><li>数据预处理：从网络上收集了68万小时的多语言（98 种语言）和多任务（multitask）监督数据对Whisper进行了训练。预处理使用了三种自动过滤方法：检测并删除机器生成的转录；使用语音检测器确保语言和转录匹配；识别并删除低质量数据。</li><li>模型：基于encoder-decoder的Transformer架构，其中解码器通过训练不同特殊的token识别单个任务，以此实现多任务统一训练。</li></ol></li><li>Limitation：由于使用现成的Transfomer架构并没有进行过多改进，会出现错误结果。可以对现有模型的解码策略、微调、正则化、数据增强、数据多样性、增加预训练等进行改进。</li><li>参考：<a href="https://www.bilibili.com/video/BV1VG4y1t74x/?spm_id_from=333.999.list.card_archive.click&amp;vd_source=486265fa677326a8f53894f05277bfb9">沐神论文精读</a> <a href="https://zhuanlan.zhihu.com/p/568173245">知乎</a></li></ul><p><div align="center">  <img src="22-11-17Whisper.png"></div><br><br></p><hr>]]></content>
      
      
      <categories>
          
          <category> Reading Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Papers Reading about CV</title>
      <link href="/2022/09/17/Papers-Reading-about-CV/"/>
      <url>/2022/09/17/Papers-Reading-about-CV/</url>
      
        <content type="html"><![CDATA[<p><strong>阅读大纲</strong><br><img src='index.png' height=100% width=100%></p><table>    <tr>        <th>Filed</th>        <th>Paper</th>        <th>Date</th>      </tr >    <tr >        <td rowspan="3"><b>CV</b>: Image</td>        <td>VTs-Drloc</td>        <td>22-11-24</td>    </tr>    <tr>        <td>SPT_LSA_ViT</td>        <td>22-11-25</td>    </tr>        <tr>        <td>SAM</td>        <td>23-11-17</td>    </tr>    <tr >        <td rowspan="6"><b>CV</b>: 3D Construction</td>        <td>TransformerFusion</td>        <td>22-11-08</td>    </tr>    <tr>        <td>Neural Deformation Graphs</td>        <td>22-11-09</td>    </tr>    <tr>        <td>Optimize Non-Rigid Tracking</td>        <td>22-11-10</td>    </tr>    <tr>        <td>Neural-DynamicReconstruction (NDR)</td>        <td>23-02-14</td>    </tr>    <tr>        <td>FlowNet3D</td>        <td>23-03-09</td>    </tr>    <tr>        <td>Bi-PointFlowNet</td>        <td>23-03-21</td>    </tr></table><h1 id="CV"><a href="#CV" class="headerlink" title="CV"></a>CV</h1><h2 id="Image"><a href="#Image" class="headerlink" title="Image"></a>Image</h2><h3>Efficient Training of Visual Transformers with Small-Size Datasets</h3><ul><li>【NeurlIPS2021】 <a href="https://arxiv.org/abs/2106.03746">ArXiv</a>  <a href="https://github.com/yhlleo/VTs-Drloc">Code</a></li><li>简介：使用小数据集优化训练Visual Transformer，训练加速，泛化能力增强。</li><li>关键技术：<ol><li>验证实验SOTA VTs(CvT、Swin、T2T)在小数据集上效果不好</li><li>VT由于缺少卷积归纳偏置，设计自监督代理任务，从图片中提取额外的信息学习空间关联，增加dense relative localization loss($L_{drloc}$)，即插即用。</li></ol></li><li>Limitation：fine-grained嵌入网格效果不好</li></ul><p><div align="center">  <img src="22-11-24VTs-Drloc.png"></div><br><br></p><hr><h3>Vision Transformer for Small-Size Datasets</h3><ul><li>【2021】 <a href="https://arxiv.org/abs/2112.13492">ArXiv</a>  <a href="https://github.com/aanna0701/SPT_LSA_ViT">Code</a></li><li>简介：使用SPT+LSA解决由于Vision Transformer缺少局部归纳偏置不能在小数据集上训练的问题</li><li>关键技术：<ol><li>Shifted Patch Tokenization：利用邻接像素空间关系，扩大感受野</li><li>Locality Self-Attention Mechanism：使用Diagonal Masking增加不同token之间的注意力分数 + 通过Learnable Temperature Scaling控制输出分布的平滑度</li></ol></li></ul><p><div align="center">  <img src="22-11-25SPT_LSA_ViT.png"></div><br><br></p><hr><h3>Segment Anything</h3><ul><li>【2023】 <a href="https://arxiv.org/abs/2304.02643">ArXiv</a> <a href="https://github.com/facebookresearch/segment-anything">Code</a></li><li>简介：使用三个组件建立图像分割的<strong>foundation model</strong>，解决一系列下游分割问题，可zero-shot生成</li><li>关键技术：<ol><li>promptable分割任务：使用prompt engineering，prompt不确定时输出多目标mask</li><li>分割模型：image encoder + prompt encoder -&gt; mask decoder</li><li>数据驱动：SA-1B（1B masks from 11M imgs）手工标注-&gt;半自动-&gt;全自动</li></ol></li><li>Limitation：存在不连贯不精细的mask结果；交互式实时mask生成但是img encoder耗时；text-to-mask任务效果不鲁棒</li></ul><p><div align="center">  <img src="23-11-17SAM_foundation.png"></div></p><p><div align="center">  <img src="23-11-17SAM.png"></div><br><br></p><h2 id="3D-Construction"><a href="#3D-Construction" class="headerlink" title="3D Construction"></a>3D Construction</h2><h3>TransformerFusion: Monocular RGB Scene Reconstruction using Transformers</h3><ul><li>【NeurlIPS2021】 <a href="https://arxiv.org/abs/2107.02191">ArXiv</a>  <a href="https://github.com/AljazBozic/TransformerFusion">Code</a></li><li>简介：Transformer在单RGB Video室内场景三维重建中的应用</li><li>关键技术：<ol><li>Coarse-to-fine融合：coarse重建全局场景，fine只重建接近表面处的精细特征，最后将特征融合解码为更高分辨率场景。</li><li>多视图特征融合：每次最多使用K张图片训练，加载超过K张图片时去除attention权值最小的图片，一直保持使用K张图片； </li></ol></li><li>Limitation: 遮挡、不完全场景、透明物体重建鲁棒性差。未来研究方向可以使用自监督损失，通过稀疏卷积和局部几何先验获得更高分辨率的几何保真。</li></ul><p><div align="center">  <img src="22-11-08TransformerFusion.png"></div><br><br></p><hr><h3>Neural Deformation Graphs for Globally-consistent Non-rigid Reconstruction</h3><ul><li>【CVPR2021】<a href="https://aljazbozic.github.io/neural_deformation_graphs/">Paper</a> <a href="https://github.com/AljazBozic/NeuralGraph">Code</a></li><li>简介：使用GNN进行非刚性4D重建</li><li>关键技术：<ol><li>全局+局部优化，损失分别计算；全局优化所有帧变形图，局部多MLP表示框</li><li>使用单帧图像多视图一致+变形表面一致来计算循迹和变形</li></ol></li><li>Limitation: 输入特定为64^3的SDF网格；纹理特征不鲁棒；未来可开展稀疏3D卷积和其他特征如颜色重建损失计算工作。</li></ul><p><div align="center">  <img src="22-11-09NDG.png"></div><br><br></p><hr><h3>Learning to Optimize Non-Rigid Tracking</h3><ul><li>【CVPR2020】<a href="https://arxiv.org/abs/2003.12230">ArXiv</a></li><li>简介：RGBD非刚性循迹图网络的收敛优化</li><li>关键技术：<ol><li>使用CNN端到端学习深度特征匹配，使得高斯牛顿求解器可以解决大非刚性变形场景</li><li>ConditionNet预处理求解器，增加PCG求解速度</li></ol></li><li>Limitation：3D场景遮挡问题建议直接从3D数据中提取特征；场景流真实数据难获取，建议在合成数据集上学习</li><li>Trick：数据增强；深度图滤波预处理</li></ul><p><div align="center">  <img src="22-11-10Optim_NRT.png"></div><br><br></p><hr><h3>Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera</h3><ul><li>【NeurlIPS Workshop 2021】<a href="https://arxiv.org/abs/2206.15258">ArXiv</a> <a href="https://github.com/USTC3DV/NDR-code">Code</a></li><li>简介：用单RGBD图像对动态场景进行神经表面重建</li><li>关键技术：<ol><li>NDR通过无模板先验的隐式形变场恢复运动信息并将观测帧的采样点变换到基准空间，<br>再通过基准空间中的符号距离场和神经辐射场分别恢复几何与颜色信息。</li><li>为了保证运动信息的周期一致性，在形变场中设计了一个符合非刚性运动的双射模块；<br>引入拓扑感知网络解决动态场景中常见的拓扑变化问题</li></ol></li><li>Limitation：输入是大而快的动作时重建效果不好，很难获得合理的相机位姿作为初始化；建模效率不高</li></ul><p><div align="center">  <img src="23-02-14NDR.png"></div><br><br></p><hr><h3>FlowNet3D: Learning Scene Flow in 3D Point Clouds</h3><ul><li>【CVPR2019】<a href="https://arxiv.org/abs/1806.01411">ArXiv</a> <a href="https://github.com/xingyul/flownet3d">Code</a></li><li>简介：通过深度混合架构直接对点云进行端到端的场景流估计</li><li>关键技术：<ol><li>提出一种端到端的估计连续点云对的场景流方法，做了充分的对比实验、消融、可视化、应用分析验证方法的优越性。</li><li>模型中的flow embedding层学习两片点云的相关特征，set upconv层学习点云到点云的传播特征。（这俩层结构差不多但输入不同学习的特征不同）</li></ol></li><li>思考：模型是UNet架构和PointNet++的abstraction layer的合体，并没有特别的创新。论文好在模型应用迁移、实验充分和会讲故事，尤其是场景流的meta-architecture总结的很好。</li></ul><p><div align="center">  <img src="23-03-09FlowNet3D.png"></div><br><br></p><hr><h3>Bi-PointFlowNet: Bidirectional Learning for Point Cloud Based Scene Flow Estimation</h3><ul><li>【ECCV2022】<a href="https://arxiv.org/abs/2207.07522">ArXiv</a> <a href="https://github.com/cwc1260/BiFlow">Code</a></li></ul><p><div align="center">  <img src="23-03-21Bi-PointFlowNet.png"></div><br><br></p>]]></content>
      
      
      <categories>
          
          <category> Reading Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> Computer Vision </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Papers Summary</title>
      <link href="/2022/09/17/Papers-Summary/"/>
      <url>/2022/09/17/Papers-Summary/</url>
      
        <content type="html"><![CDATA[<h1 id="对比学习论文总结"><a href="#对比学习论文总结" class="headerlink" title="对比学习论文总结"></a>对比学习论文总结</h1><p>学习视频：</p><ul><li><a href="https://www.bilibili.com/video/BV1C3411s7t9/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">李沐-MoCo论文逐段精读</a></li><li><a href="https://www.bilibili.com/video/BV19S4y1M7hm/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">李沐-对比学习论文综述</a></li></ul><table border="1" style="border-collapse: collapse;">  <tr>    <th>阶段</th>    <th  colspan="5">代表工作</th>  </tr>  <tr>    <td align='center'>百花齐放（18-19中）</td>    <td><b>Inst Disc</b>: memory Bank, 每张图都是一个类别（个体判别）</td>    <td><b>Inva Spread</b>: end-to-end, 在同一mini-batch中选正负样本</td>    <td><b>CPC V1</b>：用预测未来的代理任务做对比学习</td>      <td><b>CMC</b>：增大同一物体不同视角的互信息</td>     <td><b>Deep cluster</b></td>       </tr>  <tr>    <td align='center'>CV双雄（19-20中）</td>    <td><b>MoCo V1</b>: queue + momentum encoder</td>    <td><b>SimCLR V1</b>: MLP(projection head) + 数据增强</td>    <td><b>CPC V2</b></td>      <td><b>Infomin</b></td>       <td></td>      </tr>  <tr>    <td align='center'>不用负样本</td>    <td><b>MoCo V2</b>: V1 + MLP + aug + 增大epoch</td>    <td><b>SimCLR V2</b>: large, 2层MLP, momentum encoder</td>    <td></td>      <td></td>       <td><b>Swav</b>: multi-crop, 图片一个视角预测另一个视角，和聚类中心比</td>      </tr>  <tr>    <td align='center'>Transformer</td>    <td><b>MoCo V3</b>: V2 + SimSiam</td>    <td><b>BYOL</b>(匹配->预测) =》<b>BN Blog</b> =》<b>BYOL V2</b><br>        <b>BYOL</b> =》<b>Sim Siam</b>(stop gradient) =》<b>DINO</b></td>    <td></td>      <td></td>       <td></td>      </tr></table><h1 id="CLIP改进论文总结"><a href="#CLIP改进论文总结" class="headerlink" title="CLIP改进论文总结"></a>CLIP改进论文总结</h1><p>学习视频：</p><ul><li><a href="https://www.bilibili.com/video/BV1SL4y1s7LQ/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">李沐-CLIP论文逐段精读</a></li><li><a href="https://www.bilibili.com/video/BV1FV4y1p7Lm/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">李沐-CLIP改进工作串讲(上)</a></li><li><a href="https://www.bilibili.com/video/BV1gg411U7n4/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">李沐-CLIP改进工作串讲(下)</a></li></ul><table border="1" style="border-collapse: collapse;">  <tr>    <th>领域</th>    <th>代表工作</th>  </tr>  <tr>    <td align='center' rowspan='2'>语义分割</td>    <td><b>Lseg: Language Driven Semantic Segnatation</b>: zero-shot CLIP, dense feature, image encoder: DPT (ViT + decoder), supervise learning(依赖mask手工标注)目标函数非对比学习</td>    </tr>  <tr>    <td><b>GroupVit: Semantic Segmentation Energes from Text Supervision</b>: ViT + group block + group tokens(hpy聚类中心)</td>    </tr>  <tr>    <td align='center' rowspan='2'>目标检测</td>    <td><b>Open-Vocabulary ViLD</b>: CLIP的预训练image encoder作为teacher学习image embedding对比</td>    </tr>  <tr>    <td><b>GLIP：Grounded Language-Image Pre-traing</b>: 伪标签， phrase grounding</td>    </tr>  <tr>    <td align='center'>图形学</td>    <td><b>CLIPasso</b>: saliency initial, semantic loss + geometric loss</td>    </tr>  <tr>    <td align='center' rowspan='2'>视频</td>    <td>图文检索 <b>CLIP4Clip</b>: 时序图像文本融合：mean pooling效果最好; Transformer/LSTM; early fusion(tight)效果差</td>    </tr>  <tr>    <td>动作识别 <b>ActionCLIP</b>：temporal shift module</td>    </tr>  <tr>    <td align='center'>图像文本</td>    <td><b>CLIP-ViL</b> 用回图像文本下游任务</td>    </tr>  <tr>    <td align='center'>语音</td>    <td><b>AudioCLIP</b></td>    </tr>  <tr>    <td align='center'>三维</td>    <td><b>PointCLIP</b>  <b>depthCLIP</b></td>    </tr>  <tr>    <td colspan='2'><b>CLIP改进工作可以总结为三类：</b><br>      &nbsp &nbsp 1. 直接使用CLIP预训练模型得到更好的特征和现有框架得到特征进行融合(改动最小)<br>      &nbsp &nbsp 2. CLIP当做teacher，将其训练得到的特征用来蒸馏，加速现有模型训练(中间)<br>      &nbsp &nbsp 3. 借鉴多模态对比学习思想，定义自己任务的正负样本计算对比loss，实现zero-shot</td>  </tr></table><h1 id="视频理解论文总结"><a href="#视频理解论文总结" class="headerlink" title="视频理解论文总结"></a>视频理解论文总结</h1><p>学习视频：</p><ul><li><a href="https://www.bilibili.com/video/BV1mq4y1x7RU/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">李沐-双流网络论文逐段精读</a></li><li><a href="https://www.bilibili.com/video/BV1tY4y1p7hq/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">李沐-I3D论文精读</a></li><li><a href="https://www.bilibili.com/video/BV1fL4y157yA/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">李沐-视频理解论文串讲(上)</a></li><li><a href="https://www.bilibili.com/video/BV11Y411P7ep/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">李沐-视频理解论文串讲(下)</a></li></ul><p><strong>传统手工特征方法：</strong><br>(image) SIFT -&gt; (Video) STIP -&gt; (光流) DT/IDT -&gt; (全局特征) IDT + FV</p><p><strong>深度学习方法：</strong></p><table border="1" style="border-collapse: collapse;">  <tr>    <th>方法</th>    <th colspan='2'>代表工作</th>  </tr>  <tr>    <td align='center'><b>CNN</b></td>    <td colspan='2'><b>DeepVideo(CVPR2014)</b>: Sports 1M Datasets, 失败的尝试</td>    </tr>  <tr>    <td align='center' rowspan='9'><b>Two-Stream</b></td>    <td colspan='2'><b>Two-Stream(nureons2014)</b>: Spatial stream + Temporal stream late fusion</td>    </tr>  <tr>    <td colspan='2'><b>TDD(CVPR2015)</b>: 手工IDT+沿轨迹堆叠光流</td>    </tr>  <tr>    <td colspan='2'><b>Beyond Short Snippet(CVPR2015)</b>: 使用<font color='blue'>LSTM</font>增强特征，实际上最后一层+LSTM没那么有用（帧短抽到的特征差不多）</td>    </tr>  <tr>    <td colspan='2'><b>Conv Two-Stream(CVPR2016)</b>: <font color='blue'>early fusion</font>, Spatial fusion(max/concat/stack Conv(效果最好)/sum/bilinear), Temporal fusion(3D Pooling/3D Conv + 3D Pooling)</td>    </tr>  <tr>    <td colspan='2'><b>王利民TSN(ECCV2016)</b>:  <font color='blue'>长时间视频理解</font>, 给视频分段后结果求共识<br>    &nbsp &nbsp tips1: 使用ImageNet预训练光流, 复制参数为目标channel来初始化<br>    &nbsp &nbsp tips2: partial BN, 第一层使用BN, 其余层freeze BN<br>    &nbsp &nbsp tips3: 数据增强, conner cropping = scale jittering    </td>    </tr>  <tr>    <td align='center' rowspan='4'><b>TSN+全局建模</b></td>  </tr>  <tr>    <td><b>DOVF(CVPR2017)</b>: face rencting encoding</td>  </tr>  <tr>    <td><b>TLE(CVPR2017)</b>: end-to-end, bi-linearing encoding</td>    </tr>  <tr>    <td><b>ActionVLAN</b>: VLAN</td>    </tr>  <tr>    <td align='center' rowspan='8'><b>3D Conv</b></td>    <td colspan='2'><b>C3D(ICCV2015)</b>: 3D版VGG, 网络深, 提供一个好特征可以做下游任务</td>    </tr>  <tr>    <td colspan='2'><b>I3D(CVPR2017)</b>: 利用2D预训练模型, 同时使用光流刷爆UCF101, 证明2D向3D迁移的有效性</td>    </tr>  <tr>    <td colspan='2'><b>Non-local NN</b>: 使用plug and play(即插即用)的non-local block(self-attention)长时间建模，验证了多block效果更好/td>    </tr>  <tr>    <td colspan='2'><b>R(2+1)D(CVPR2018)</b>: 3D拆成空间2D+时间1D(二者利用特征投射融合), 训练简单效果好</td>    </tr>  <tr>    <td colspan='2'><b>SlowFast</b>: Slow(标准I3D)少帧小输入大网络 + Fast多帧大输入小网络 later connection, Fast时间维度不下采样</td>    </tr>  <tr>    <td colspan='2'><b>Hidden Two-Stream</b>: 将光流学习融入网络，不需要抽光流</td>    </tr>  <tr>    <td colspan='2'><b>TSM(ICCV2019)</b>: shift 2D网络</td>    </tr>  <tr>    <td colspan='2'><b>总结</b>: 由于抽光流耗时且占内存，兴起了3D Conv, 从C3D到I3D, 之后的演变主要为四方面:<br>        &nbsp &nbsp 1. 改进2D网络: R3D, MFNet, STC<br>        &nbsp &nbsp 2. 2D结合3D：S3D, R(2+1)D, ECO, D3D<br>        &nbsp &nbsp 3. 长时序处理：LTC, T3D, non-local, V4D<br>        &nbsp &nbsp 4. 高效率：CSN, SlowFast, X3D<br>            </td>    </tr>  <tr>    <td align='center' rowspan='2'><b>Vision Transformer</b></td>    <td colspan='2'><b>Timesformer</b>: Space-Time Attention降低复杂度: Divided ST A; Sparse Local Global A; Axial A(T+W+H)</td>    </tr>    <tr>    <td colspan='2'><b>ViViT, VidTr, MViT...</b></td>    </tr></table><h1 id="多模态论文总结"><a href="#多模态论文总结" class="headerlink" title="多模态论文总结"></a>多模态论文总结</h1><p>学习视频：</p><ul><li><a href="https://www.bilibili.com/video/BV1Vd4y1v77v/?spm_id_from=333.788&amp;vd_source=486265fa677326a8f53894f05277bfb9">李沐-多模态论文串讲·上</a></li><li><a href="https://www.bilibili.com/video/BV1fA411Z772/?spm_id_from=444.41.list.card_archive.click&amp;vd_source=486265fa677326a8f53894f05277bfb9">李沐-多模态论文串讲·下</a></li></ul><table border="1" style="border-collapse: collapse;">  <tr>    <th>方法</th>    <th colspan='2'>代表工作</th>  </tr>  <tr>    <td colspan='2'><b>多模态框架总结：其中图c的效果最好，即视觉模型要大于文本模型，Fusion模型也要大</b><img src="MultiModel.png"></td>    <tr>    <td align='center' rowspan='4'><b>encoder</b></td>    <td colspan='2'><b><a href='https://arxiv.org/abs/2102.03334'>ViLT</a></b>：效率较高，使用whole word masking + image augmentations<img src="ViLT.png"></td>   </tr>  <tr>    <td colspan='2'><b><a href="https://arxiv.org/abs/2103.00020">CLIP</a></b>：4亿数据集，大力出奇迹<img src="CLIP.png"></td>    </tr>  <tr>    <td colspan='2'><b><a href="https://arxiv.org/abs/2107.07651">ALBEF</a></b>：Fuse前使用对比学习loss对齐图像和文本；使用动量蒸馏学习伪标签<img src="ALBEF.png"></td>    </tr>  <tr>    <td colspan='2'><b><a href="http://arxiv-export-lb.library.cornell.edu/abs/2111.02358">VLMo</a></b>：每个block共享自注意力层并包含一个modality-specific experts池<img src="VLMo.png"></td>    </tr>  <tr>    <td align='center' rowspan='3'><b>encoder and decoder</b></td>    <td colspan='2'><b><a href='https://arxiv.org/abs/2201.12086'>BLIP</a></b>：模型加入Decoder使得可以做生成任务；加入CapFilt处理noisy数据<img src="BLIP_1.png"><img src="BLIP_2.png"></td>   </tr>  <tr>    <td colspan='2'><b><a href="https://arxiv.org/abs/2205.01917">CoCa</a></b>：结合contrastive和captioning objectives到一个encoder-decoder模型<img src="CoCa.png"></td>    </tr>  <tr>    <td colspan='2'><b><a href="https://arxiv.org/abs/2208.10442">BeiT V3</a></b>：scale模型；mask图像处理为图像语言，结合masked text为平行句子；统一模型，更适合做多任务<img src="BeiT_V3_1.png"><img src="BeiT_V3_2.png"></td>    </tr>  <tr>    <td colspan='2'><b>总结</b><img src="总结.png"></td>    <tr></table><h1 id="扩散模型综述"><a href="#扩散模型综述" class="headerlink" title="扩散模型综述"></a>扩散模型综述</h1><h3>Diffusion Models: A Comprehensive Survey of Methods and Applications</h3><ul><li><a href="https://arxiv.org/abs/2209.00796">Arxiv</a></li><li>简介：扩散模型的综述：介绍三种基础公式DDPMs、SGMs、Score SDEs；从采样效率、最大似然和用特殊结构处理数据三方面优化扩散模型；扩散模型和其他生成模型的联系；多领域的应用</li><li>主要内容：<ul><li>基础：深度生成模型的目标是为了学习X的分布$p(X)$，Denoising diffusion probabilistic models (DDPMs), Score-based generative models (SGMs)和Stochastic differential equations (Score SDEs)<br>的关键都是用随机噪声渐进式扰动数据然后再逐渐删除噪声生成新的数据。</li><li>优化：原始扩散模型的三个主要缺点，采样速度慢，最大化似然差、数据泛化能力弱。<ol><li>Discretization Optimization、Non-Markovian Process、Partial Sampling优化采样效率；</li><li>由于对数似然难以直接计算，最大化似然差的优化研究主要集中在优化和分析变分下界（VLB）；</li><li>扩散模型假设数据存在于欧几里得空间，即具有平面几何形状的流形，并添加高斯噪声将不可避免地将数据转换为连续状态空间。使用Feature Space Unification和Data-Dependent Transition Kernels优化将扩散模型推广到适用于其他数据类型的模型。</li></ol></li><li>应用：计算机视觉、自然语言处理、波形信号处理、多模态学习、分子图生成、时间序列以及对抗学习等七大应用方向</li><li>未来方向：检验应用假设；理论理解指导；在隐空间更好的表示数据；更多泛化场景</li></ul></li><li>参考：<a href="https://zhuanlan.zhihu.com/p/565043915">「扩散模型」首篇综述+论文分类汇总，谷歌&amp;北大最新研究</a></li></ul><p><div align="center">  <img src="23-03-30Generate_model.png"  height="80%" width="80%"></div><br><br></p>]]></content>
      
      
      <categories>
          
          <category> Reading Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Daily</title>
      <link href="/2022/08/30/Daily/"/>
      <url>/2022/08/30/Daily/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="3d450346d5662ca8d10e7d7dcb34a0ca635a7deb95c55bac10fca1c8eda97a44">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> Daily </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Work &amp; Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pyspark &amp; Pandas</title>
      <link href="/2022/03/18/8-pyspark&amp;pandas/"/>
      <url>/2022/03/18/8-pyspark&amp;pandas/</url>
      
        <content type="html"><![CDATA[<h1 id="pyspark常用操作"><a href="#pyspark常用操作" class="headerlink" title="pyspark常用操作"></a>pyspark常用操作</h1><p><strong>spark连接</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.shell <span class="keyword">import</span> sc</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> udf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> ArrayType</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparkUtils</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.spark = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_spark</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.spark <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.spark = SparkSession.builder.appName(<span class="string">&quot;username&quot;</span>) \</span><br><span class="line">                .enableHiveSupport().config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="string">&quot;500&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.sql.broadcastTimeout&quot;</span>, <span class="string">&quot;3600&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.driver.memory&quot;</span>, <span class="string">&quot;200g&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.executor.memory&quot;</span>, <span class="string">&quot;40g&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.yarn.appMasterEnv.yarn.nodemanager.container-executor.class&quot;</span>, <span class="string">&quot;DockerLinuxContainer&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.executorEnv.yarn.nodemanager.container-executor.class&quot;</span>, <span class="string">&quot;DockerLinuxContainer&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.yarn.appMasterEnv.yarn.nodemanager.docker-container-executor.image-name&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;bdp-docker.jd.com:5000/wise_mart_bag:latest&quot;</span>) \</span><br><span class="line">                .config(<span class="string">&quot;spark.executorEnv.yarn.nodemanager.docker-container-executor.image-name&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;bdp-docker.jd.com:5000/wise_mart_bag:latest&quot;</span>) \</span><br><span class="line">                .getOrCreate()</span><br><span class="line">        <span class="keyword">return</span> self.spark</span><br><span class="line"></span><br><span class="line">spark = SparkUtils()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成dataframe</span></span><br><span class="line">spark_data = spark.sql(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    select </span></span><br><span class="line"><span class="string">      id, </span></span><br><span class="line"><span class="string">      username,</span></span><br><span class="line"><span class="string">      num</span></span><br><span class="line"><span class="string">    from </span></span><br><span class="line"><span class="string">      table1</span></span><br><span class="line"><span class="string">    where </span></span><br><span class="line"><span class="string">      status in (1, 2, 3)</span></span><br><span class="line"><span class="string">      and dt = &#x27;&#123;&#125;&#x27;</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span>.<span class="built_in">format</span>(date))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建sql数据表</span></span><br><span class="line">sp_test.createOrReplaceTempView(<span class="string">&#x27;data&#x27;</span>)</span><br></pre></td></tr></table></figure></p><p><strong>常用命令</strong><br>参考：</p><ul><li><a href="https://bobokele.blog.csdn.net/article/details/52802150">Spark-SQL之DataFrame操作大全</a></li><li><a href="https://blog.csdn.net/htbeker/article/details/86233819">pyspark.sql.functions详解</a></li><li><a href="https://blog.csdn.net/weixin_40548136/article/details/102622977">Hadoop和Spark笔记目录</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建第一个dataframe</span></span><br><span class="line">rdd = sc.parallelize([(<span class="number">1</span>, <span class="string">&#x27;Alice&#x27;</span>, <span class="number">18</span>), (<span class="number">2</span>, <span class="string">&#x27;Andy&#x27;</span>, <span class="number">19</span>), (<span class="number">3</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="number">17</span>)])</span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;id&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;name&quot;</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;age&quot;</span>, IntegerType(), <span class="literal">True</span>)</span><br><span class="line">])</span><br><span class="line">sp_test = spark.createDataFrame(rdd, schema)</span><br><span class="line">sp_test.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据缓存</span></span><br><span class="line">sp_test.cache()</span><br><span class="line">sp_test.persist()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新增一列</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line">sp_test.withColumn(<span class="string">&quot;price_detail&quot;</span>, F.udf(func, IntegerType())(sp_test.a, sp_test.b))</span><br><span class="line">sp_test.withColumn(<span class="string">&quot;price_detail&quot;</span>, F.udf(func, IntegerType())(sp_test[<span class="string">&#x27;a&#x27;</span>], sp_test[<span class="string">&#x27;b&#x27;</span>]))</span><br><span class="line">sp_test.withColumn(<span class="string">&quot;price_detail&quot;</span>, F.udf(func, IntegerType())(F.col(<span class="string">&quot;a&quot;</span>), F.col(<span class="string">&quot;b&quot;</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改名字</span></span><br><span class="line">sp_test.withColumnRenamed(<span class="string">&quot;old_name&quot;</span>, <span class="string">&quot;new_name&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保持关联</span></span><br><span class="line">sp_data_join = sp_data_new.join(sp_data_old,</span><br><span class="line">                                sp_data_new_filter.begin_org_name_new == sp_data_old_filter.begin_org_name_old) &amp;</span><br><span class="line">                                (sp_data_new_filter.real_vehicle_type_new == sp_data_old_filter.vehicle_type_old),</span><br><span class="line">                                how=<span class="string">&quot;left&quot;</span>)     <span class="comment"># 默认为inner</span></span><br><span class="line"><span class="comment"># 通过一个字段关联</span></span><br><span class="line">sp_data_join = sp_data_new.join(sp_data_old, [<span class="string">&#x27;id&#x27;</span>], <span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用udf函数过滤数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filter_milage</span>(<span class="params">milage_old, milage_new</span>):</span></span><br><span class="line">    <span class="comment"># print(type(milage_old), type(milage_new))</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">abs</span>(milage_old - milage_new) &lt;= <span class="number">5</span></span><br><span class="line">sp_data_join = sp_data_new.<span class="built_in">filter</span>(</span><br><span class="line">    F.udf(filter_milage, BooleanType())(sp_data_new[<span class="string">&quot;milage_old&quot;</span>], sp_data_new[<span class="string">&quot;milage_new&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择两列</span></span><br><span class="line">sp_test_filter = sp_test.select(<span class="string">&#x27;code&#x27;</span>, <span class="string">&#x27;name&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除列</span></span><br><span class="line">sp_test = sp_test.drop(<span class="string">&#x27;name&#x27;</span>, <span class="string">&quot;code&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置列值</span></span><br><span class="line">sp_test = sp_test.withColumn(<span class="string">&#x27;name&#x27;</span>,F.lit(<span class="string">&#x27;&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 过滤非空符号</span></span><br><span class="line">sp_test = sp_test.<span class="built_in">filter</span>(~(F.isnull(sp_test.d)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断不为空（字符串）</span></span><br><span class="line">sp_test = sp_test.<span class="built_in">filter</span>(~((sp_test.code.isNull()) | (sp_test.code == <span class="string">&quot;&quot;</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去重</span></span><br><span class="line">sp_test.select(<span class="string">&#x27;code&#x27;</span>).distinct()</span><br><span class="line">sp_test_filter = sp_test.drop_duplicates([<span class="string">&quot;code&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 赋值为0或者&quot;&quot;</span></span><br><span class="line">sp_test = sp_test.withColumn(<span class="string">&#x27;code&#x27;</span>, F.when(F.isnull(sp_test.code), <span class="number">0</span>).otherwise(sp_test.code))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚合</span></span><br><span class="line">sp_test_collect = sp_test.groupBy(<span class="string">&#x27;number&#x27;</span>).agg(</span><br><span class="line">    F.collect_set(<span class="string">&#x27;province&#x27;</span>).alias(<span class="string">&#x27;set_province&#x27;</span>),</span><br><span class="line">    F.first(<span class="string">&#x27;city&#x27;</span>).alias(<span class="string">&#x27;set_city&#x27;</span>),</span><br><span class="line">    F.collect_list(<span class="string">&#x27;district&#x27;</span>).alias(<span class="string">&#x27;set_district&#x27;</span>),</span><br><span class="line">    F.<span class="built_in">max</span>(<span class="string">&#x27;report_user&#x27;</span>).alias(<span class="string">&#x27;set_report_user&#x27;</span>),</span><br><span class="line">    F.<span class="built_in">min</span>(<span class="string">&#x27;first_type&#x27;</span>).alias(<span class="string">&#x27;set_first_type&#x27;</span>))</span><br><span class="line">sp_test_collect = sp_test.groupby().agg(&#123;<span class="string">&#x27;code&#x27;</span>: <span class="string">&#x27;sum&#x27;</span>&#125;).collect()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 字段占比数量</span></span><br><span class="line">sp_test.groupBy(sp_test.code).count().show()</span><br></pre></td></tr></table></figure><h1 id="pandas常用操作"><a href="#pandas常用操作" class="headerlink" title="pandas常用操作"></a>pandas常用操作</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_rows&#x27;</span>, <span class="number">100</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.width&#x27;</span>,<span class="number">1000</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_colwidth&#x27;</span>,<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据</span></span><br><span class="line">df = pd.read_excel(<span class="string">&quot;file_name&quot;</span>)</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;file_name&quot;</span>, sep=<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">df.to_csv(<span class="string">&quot;data.csv&quot;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建空表</span></span><br><span class="line">df_empty = pd.DataFrame()</span><br><span class="line">df_empty.append([<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="string">&quot;哈哈&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 过滤数据</span></span><br><span class="line">df_new = df[df[<span class="string">&quot;code&quot;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">len</span>(x) == <span class="number">11</span>)]</span><br><span class="line">df_new2 = df[df[<span class="string">&quot;code&quot;</span>] == <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除列，更改列名</span></span><br><span class="line">df.drop([<span class="string">&#x27;column1&#x27;</span>, <span class="string">&quot;column2&quot;</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.rename(columns=&#123;<span class="string">&quot;column1&quot;</span>: <span class="string">&quot;new_name1&quot;</span>, <span class="string">&quot;column2&quot;</span>: <span class="string">&quot;new_name2&quot;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改表</span></span><br><span class="line">df[<span class="string">&quot;电话&quot;</span>] = df[<span class="string">&quot;电话&quot;</span>].apply(<span class="keyword">lambda</span> x: x == <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改表2</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x[<span class="string">&quot;所属市&quot;</span>] == <span class="string">&quot;赣州市&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;宁都县&quot;</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line">df[<span class="string">&quot;所属县&quot;</span>] = df.apply(func, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上下合并表</span></span><br><span class="line">df_rule = pd.concat([df_rule_1, df_rule_2], axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 左右表合并</span></span><br><span class="line">pd.merge(df_left, df_right, left_on=<span class="string">&quot;a&quot;</span>, right_on=<span class="string">&quot;b&quot;</span>, how=<span class="string">&quot;left|right|inner|outer&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分组聚合</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func1</span>(<span class="params">gg</span>):</span></span><br><span class="line">    <span class="keyword">return</span> pd.DataFrame(&#123;</span><br><span class="line">        <span class="string">&quot;上游客户电话号码&quot;</span>: gg[<span class="string">&quot;上游电话号码修改&quot;</span>].tolist()[<span class="number">0</span>],</span><br><span class="line">        <span class="string">&quot;上游商家单量&quot;</span>: <span class="built_in">sum</span>(gg[<span class="string">&quot;上游商家单量&quot;</span>])&#125;, index=[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">df_result = df_new.groupby([<span class="string">&quot;上游电话号码修改&quot;</span>]).apply(func1)</span><br><span class="line">df_result2 = df.groupby(<span class="string">&quot;tag&quot;</span>).apply(func1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 索引变列</span></span><br><span class="line">df_result.reset_index()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历iterrows</span></span><br><span class="line"><span class="keyword">for</span> i, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    <span class="built_in">print</span>(row[<span class="string">&quot;c1&quot;</span>], row[<span class="string">&quot;c2&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 补零操作</span></span><br><span class="line">num = <span class="number">233</span></span><br><span class="line">str_num = <span class="built_in">str</span>(num).zfill(<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(str_num)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去重</span></span><br><span class="line">df.drop_duplicates([<span class="string">&quot;列名&quot;</span>], keep=<span class="string">&#x27;first&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 排序</span></span><br><span class="line">df.sort_values(by=[<span class="string">&quot;A&quot;</span>, <span class="string">&quot;D&quot;</span>], axis=<span class="number">0</span>, ascending=[<span class="literal">True</span>, <span class="literal">False</span>], inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除空值</span></span><br><span class="line">df.dropna(subset=[<span class="string">&#x27;trader_province_name&#x27;</span>, <span class="string">&quot;trader_county_name&quot;</span>], how=<span class="string">&quot;any&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换数据类型</span></span><br><span class="line">df[<span class="string">&quot;Customer&quot;</span>] = df[<span class="string">&#x27;Customer&#x27;</span>].astype(<span class="string">&quot;int&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建sql数据表</span></span><br><span class="line">df_data = spark.createDataFrame(df[[<span class="string">&quot;Customer&quot;</span>]])</span><br><span class="line">df_data.registerTempTable(<span class="string">&#x27;df_data&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Data Analysis and Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FM / FFM / Wide&amp;Deep / DeepFFM</title>
      <link href="/2022/03/17/7-FM-FFM-Wide&amp;Deep-DeepFFM/"/>
      <url>/2022/03/17/7-FM-FFM-Wide&amp;Deep-DeepFFM/</url>
      
        <content type="html"><![CDATA[<h1 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h1><p>LR + 特征交叉项：进行特征组合增强模型泛化能力。</p><script type="math/tex; mode=display">y=w_{0}+\sum_{i=1}^{n}{w_{i}x_{i}}+\sum_{i=1}^{n}{\sum_{i+1}^{n}{<v_{i},v_{j}>x_{i}x_{j}}}</script><p>式中$v_i$为特征的embedding向量</p><h1 id="FFM"><a href="#FFM" class="headerlink" title="FFM"></a>FFM</h1><p>FM + Field：将特征按照事先规则分多个场。每个特征将被映射为多个隐向量，每个隐向量对应一个场。当两个特征组合时，用对方对应的场对应的隐向量做内积。FM可看做只有一个场的FFM。</p><script type="math/tex; mode=display">y=w_{0}+\sum_{i=1}^{n}{w_{i}x_{i}}+\sum_{i=1}^{n}{\sum_{i+1}^{n}{<v_{i,f_j}, v_{j,f_i}>x_{i}x_{j}}}</script><h1 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide &amp; Deep"></a>Wide &amp; Deep</h1><p>Wide + Deep：由浅层（或单层）的Wide部分神经网络和深层的Deep部分多层神经网络组成，输出层采用softmax或logistics regression综合Wide和Deep部分的输出。Wide部分有利于增强模型的“记忆能力”，Deep部分有利于增强模型的“泛化能力”。</p><script type="math/tex; mode=display">P(Y=1|x)=\sigma(W^T_{wide}[x, \phi (x)] + W^T_{deep}a^{l_f} + b)</script><center>  <img align='center' src='Wide&Deep.png' alt='Wide & Deep' height=100% width=100%>  <div>Wide & Deep 网络架构</div></center><h1 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h1><p>Deep + FM：用FM做特征间低阶组合，用Deep NN部分做特征间高阶组合，并行方式组合。DeepFM不需要预训练和人工特征工程。</p><script type="math/tex; mode=display">\hat y=sigmoid(y_{FM}+y_{DNN})</script><center>  <img align='center' src='DeepFM.png' alt='DeepFM' height=70% width=70%>  <div>DeepFM 网络架构</div></center><p><code>tf.nn.embedding_lookup_sparse()</code> 多值离散特征的embedding处理</p><h1 id="DCN"><a href="#DCN" class="headerlink" title="DCN"></a>DCN</h1><p>Deep + Cross: 深度神经网络+应用显式特征交叉。特征交叉部分公式为：</p><script type="math/tex; mode=display">x_{l+1}=x_0x^T_lw_l+b_l+x_l=f(x_l, w_l, b_l)+x_l</script><center>  <img align='center' src='Deep&Cross.png' alt='Deep&Cross' height=70% width=70%>  <div>Deep & Cross 网络架构</div></center><h1 id="面试问题"><a href="#面试问题" class="headerlink" title="面试问题"></a>面试问题</h1><ol><li>DeepFM和Wide&amp;Deep的deep部分有什么不同？<br>原生的wide&amp;deep里面的deep输入是onehot，数值特征和标签特征都有；DeepFM中的deep是连续数值的embedding输入，且与FM的embedding共享，训练更快更准确。</li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://zhuanlan.zhihu.com/p/268776484">推荐系统学习笔记-4.FM,FFM,Wide &amp; Deep,DeepFM</a></li><li><a href="https://blog.csdn.net/maqunfi/article/details/99635620?spm=1001.2014.3001.5506">推荐系统 - DeepFM架构详解</a></li><li><a href="https://mp.weixin.qq.com/s/Mp1eYfxbhUTZcJs_3cwQNg">FFM解析 + tf代码实现</a></li><li><a href="https://mp.weixin.qq.com/s/4bw9GxQ10iyC08H0zYbSmw">DeepFM解析 + tf代码实现</a></li><li><a href="https://mp.weixin.qq.com/s/WF-Ivm-wE-Kjp2bXnropJw">多值离散特征的embedding解决方案</a></li><li><a href="https://mp.weixin.qq.com/s/XK0doAhDfyzxzJVgMlnc1g">Deep&amp;Cross解析 + tf代码实现</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Search / Advertisement / Recommendation / Causal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GBDT / XGBoost / LightGBM</title>
      <link href="/2022/03/17/6.2-GBDT-XGBoost-LightGBM/"/>
      <url>/2022/03/17/6.2-GBDT-XGBoost-LightGBM/</url>
      
        <content type="html"><![CDATA[<p><strong>系列笔记</strong></p><ol><li><a href="https://xfliu1998.github.io/2022/03/16/6.1-Decision-Tree/">Decision Tree</a></li><li><a href="https://xfliu1998.github.io/2021/10/27/1-Ensemble-Learning/">Ensemble Learning</a></li><li><a href="https://xfliu1998.github.io/2022/03/17/6.2-GBDT-XGBoost-LightGBM/">GBDT / XGBoost / LightGBM</a></li></ol><blockquote><p>如果说我看得比别人更远些，那是因为我站在巨人的肩膀上。</p></blockquote><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble">sklearn.ensemble官方文档</a></li><li><a href="https://blog.csdn.net/zpalyq110/article/details/79527653?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164748939316780269840201%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=164748939316780269840201&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-79527653.142^v2^pc_search_result_control_group,143^v4^control&amp;utm_term=GBDT&amp;spm=1018.2226.3001.4187">GBDT算法原理以及实例理解</a></li><li><a href="https://zhuanlan.zhihu.com/p/86354141">梯度提升（Gradient Boosting）算法</a></li><li><a href="https://zhuanlan.zhihu.com/p/81016622">深入理解GBDT回归算法</a></li><li><a href="https://zhuanlan.zhihu.com/p/89549390">深入理解GBDT二分类算法</a></li><li><a href="https://zhuanlan.zhihu.com/p/91652813">深入理解GBDT多分类算法</a></li><li><a href="https://zhuanlan.zhihu.com/p/83901304">深入理解XGBoost</a></li><li><a href="https://blog.csdn.net/lamusique/article/details/96478351?spm=1001.2014.3001.5506">Xgboost算法之原理+代码</a></li><li><a href="https://zhuanlan.zhihu.com/p/99069186">深入理解LightGBM</a></li><li><a href="https://zhuanlan.zhihu.com/p/33700459">GBDT、XGBoost、LightGBM 的使用及参数调优</a></li></ul><h2 id="GBDT代码实现"><a href="#GBDT代码实现" class="headerlink" title="GBDT代码实现"></a>GBDT代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets, ensemble</span><br><span class="line"><span class="keyword">from</span> sklearn.inspection <span class="keyword">import</span> permutation_importance</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">diabetes = datasets.load_diabetes()</span><br><span class="line">X, y = diabetes.data, diabetes.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># data preprocessing</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">    X, y, test_size=<span class="number">0.1</span>, random_state=<span class="number">13</span></span><br><span class="line">)</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&quot;n_estimators&quot;</span>: <span class="number">500</span>,      <span class="comment"># 迭代次数</span></span><br><span class="line">    <span class="string">&quot;max_depth&quot;</span>: <span class="number">4</span>,           <span class="comment"># 树中结点的最大深度</span></span><br><span class="line">    <span class="string">&quot;min_samples_split&quot;</span>: <span class="number">5</span>,   <span class="comment"># 拆分内部结点所需的最小样本数</span></span><br><span class="line">    <span class="string">&quot;learning_rate&quot;</span>: <span class="number">0.01</span>,    <span class="comment"># 每棵树的贡献会减少多少</span></span><br><span class="line">    <span class="string">&quot;loss&quot;</span>: <span class="string">&quot;squared_error&quot;</span>,  <span class="comment"># 优化损失函数</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit regression model</span></span><br><span class="line">reg = ensemble.GradientBoostingRegressor(**params)</span><br><span class="line">reg.fit(X_train, y_train)</span><br><span class="line">mse = mean_squared_error(y_test, reg.predict(X_test))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The mean squared error (MSE) on test set: &#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(mse))   <span class="comment"># 3009.1324</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># polt training deviance</span></span><br><span class="line">test_score = np.zeros((params[<span class="string">&quot;n_estimators&quot;</span>],), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(reg.staged_predict(X_test)):</span><br><span class="line">    test_score[i] = reg.loss_(y_test, y_pred)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Deviance&quot;</span>)</span><br><span class="line">plt.plot(</span><br><span class="line">    np.arange(params[<span class="string">&quot;n_estimators&quot;</span>]) + <span class="number">1</span>,</span><br><span class="line">    reg.train_score_,</span><br><span class="line">    <span class="string">&quot;b-&quot;</span>,</span><br><span class="line">    label=<span class="string">&quot;Training Set Deviance&quot;</span>,</span><br><span class="line">)</span><br><span class="line">plt.plot(</span><br><span class="line">    np.arange(params[<span class="string">&quot;n_estimators&quot;</span>]) + <span class="number">1</span>, test_score, <span class="string">&quot;r-&quot;</span>, label=<span class="string">&quot;Test Set Deviance&quot;</span></span><br><span class="line">)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;upper right&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Boosting Iterations&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Deviance&quot;</span>)</span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><center>  <img align='center' src='GBDT_result.png' alt='运行结果'>  <dev>GBDT regression运行结果</dev></center><h2 id="XGBoost代码实现"><a href="#XGBoost代码实现" class="headerlink" title="XGBoost代码实现"></a>XGBoost代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="comment"># read in data</span></span><br><span class="line">dtrain = xgb.DMatrix(<span class="string">&#x27;demo/data/agaricus.txt.train&#x27;</span>)</span><br><span class="line">dtest = xgb.DMatrix(<span class="string">&#x27;demo/data/agaricus.txt.test&#x27;</span>)</span><br><span class="line"><span class="comment"># specify parameters via map</span></span><br><span class="line">param = &#123;<span class="string">&#x27;max_depth&#x27;</span>:<span class="number">2</span>, <span class="string">&#x27;eta&#x27;</span>:<span class="number">1</span>, <span class="string">&#x27;objective&#x27;</span>:<span class="string">&#x27;binary:logistic&#x27;</span> &#125;</span><br><span class="line">num_round = <span class="number">2</span></span><br><span class="line">bst = xgb.train(param, dtrain, num_round)</span><br><span class="line"><span class="comment"># make prediction</span></span><br><span class="line">preds = bst.predict(dtest)</span><br></pre></td></tr></table></figure><h2 id="LightGBM代码实现"><a href="#LightGBM代码实现" class="headerlink" title="LightGBM代码实现"></a>LightGBM代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data Interface</span></span><br><span class="line">train_data = lgb.Dataset(<span class="string">&#x27;train.svm.bin&#x27;</span>)</span><br><span class="line">data = np.random.rand(<span class="number">500</span>, <span class="number">10</span>)  <span class="comment"># 500 entities, each contains 10 features</span></span><br><span class="line">label = np.random.randint(<span class="number">2</span>, size=<span class="number">500</span>)  <span class="comment"># binary target</span></span><br><span class="line">train_data = lgb.Dataset(data, label=label)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"># 创建数据集的其他方式</span></span><br><span class="line"><span class="string">csr = scipy.sparse.csr_matrix((dat, (row, col)))</span></span><br><span class="line"><span class="string">train_data = lgb.Dataset(csr)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">class HDFSequence(lgb.Sequence):</span></span><br><span class="line"><span class="string">    def __init__(self, hdf_dataset, batch_size):</span></span><br><span class="line"><span class="string">        self.data = hdf_dataset</span></span><br><span class="line"><span class="string">        self.batch_size = batch_size</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def __getitem__(self, idx):</span></span><br><span class="line"><span class="string">        return self.data[idx]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def __len__(self):</span></span><br><span class="line"><span class="string">        return len(self.data)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">f = h5py.File(&#x27;train.hdf5&#x27;, &#x27;r&#x27;)</span></span><br><span class="line"><span class="string">train_data = lgb.Dataset(HDFSequence(f[&#x27;X&#x27;], 8192), label=f[&#x27;Y&#x27;][:])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">train_data = lgb.Dataset(&#x27;train.svm.txt&#x27;)</span></span><br><span class="line"><span class="string">train_data.save_binary(&#x27;train.bin&#x27;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">validation_data = train_data.create_valid(&#x27;validation.svm&#x27;)</span></span><br><span class="line"><span class="string"># validation_data = lgb.Dataset(&#x27;validation.svm&#x27;, reference=train_data)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">train_data = lgb.Dataset(data, label=label, feature_name=[&#x27;c1&#x27;, &#x27;c2&#x27;, &#x27;c3&#x27;], categorical_feature=[&#x27;c3&#x27;])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">w = np.random.rand(500, )</span></span><br><span class="line"><span class="string">train_data = lgb.Dataset(data, label=label, weight=w)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setting Parameters</span></span><br><span class="line">param = &#123;<span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">31</span>, <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary&#x27;</span>&#125;</span><br><span class="line">param[<span class="string">&#x27;metric&#x27;</span>] = <span class="string">&#x27;auc&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Traing</span></span><br><span class="line">num_round = <span class="number">10</span></span><br><span class="line">bst = lgb.train(param, train_data, num_round, valid_sets=[validation_data])</span><br><span class="line">bst.save_model(<span class="string">&#x27;model.txt&#x27;</span>)</span><br><span class="line">json_model = bst.dump_model()</span><br><span class="line">bst = lgb.Booster(model_file=<span class="string">&#x27;model.txt&#x27;</span>)  <span class="comment"># init model</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># CV</span></span><br><span class="line">lgb.cv(param, train_data, num_round, nfold=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Early Stopping</span></span><br><span class="line">bst = lgb.train(param, train_data, num_round, valid_sets=valid_sets, callbacks=[lgb.early_stopping(stopping_rounds=<span class="number">5</span>)])</span><br><span class="line">bst.save_model(<span class="string">&#x27;model.txt&#x27;</span>, num_iteration=bst.best_iteration)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prediction</span></span><br><span class="line"><span class="comment"># 7 entities, each contains 10 features</span></span><br><span class="line">data = np.random.rand(<span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line">ypred = bst.predict(data)</span><br><span class="line"><span class="comment"># ypred = bst.predict(data, num_iteration=bst.best_iteration)   # if early stopping</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Machine Learning and Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Decision Tree</title>
      <link href="/2022/03/16/6.1-Decision-Tree/"/>
      <url>/2022/03/16/6.1-Decision-Tree/</url>
      
        <content type="html"><![CDATA[<p><strong>系列笔记</strong></p><ol><li><a href="https://xfliu1998.github.io/2022/03/16/6.1-Decision-Tree/">Decision Tree</a></li><li><a href="https://xfliu1998.github.io/2021/10/27/1-Ensemble-Learning/">Ensemble Learning</a></li><li><a href="https://xfliu1998.github.io/2022/03/17/6.2-GBDT-XGBoost-LightGBM/">GBDT / XGBoost / LightGBM</a></li></ol><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>决策树由结点和有向边组成。结点有两种类型：内部节点和叶结点，内部结点表示一个特征或属性，叶结点表示一个类。棵树仅有一层划分的决策树，亦称“决策树桩”（decision stump）</p><p>二叉树的几何解释：向量空间中特征不相关的矩阵划分，经过一系列的决策划分，得到相应类别区域。</p><p>决策树是一个递归过程，有三种情形会导致递归返回：<br>（1）当前结点包含的样本全属于同一类别，无需划分<br>（2）当前属性集为空，或所有样本在所有属性上的取值相同，无法划分<br>（3）当前节点包含的样本集合为空，不能划分</p><center>  <img align='center' src='决策树学习的基本算法.jpg' alt='决策树学习的基本算法'>  <div>决策树学习的基本算法</div></center><h1 id="决策树的关键问题"><a href="#决策树的关键问题" class="headerlink" title="决策树的关键问题"></a>决策树的关键问题</h1><ul><li>问题数：<ul><li>离散值情况：以特征或特征的可能离散值作为问题</li><li>连续值情况：以每个维度的样本特征值作为问题</li></ul></li><li>划分（问题）选择<ol><li>非纯度（Impurity Measure）：IM最大时各类别概率相等；IM最小时只有一类<ul><li>非纯度的熵度量<script type="math/tex; mode=display">I(D)=Entropy(D)=-sum^k_{i=1}p_ilog p_i</script></li><li>非纯度的基尼度量<script type="math/tex; mode=display">I(D)=Gini(D)=1-\sum^k_{i=1}p_i^2</script></li></ul></li><li>划分选择目标：选择最大减少类别非纯度的问题作为划分点<ul><li>非纯度的减少量：<script type="math/tex; mode=display">\Delta I(t)=I(t)-\frac{N_{tY}}{N_t}I(tY)-\frac{N_{tN}}{N_t}I(tN)</script></li></ul></li><li>基于非纯度变化量的三个指标：<ol><li>信息增益（熵度量）：越大越好<br>对于样本集合$D$，类别数为$K$，数据集$D$的经验熵表示为：<script type="math/tex; mode=display">H(D)=-\sum^K_{k=1}\frac{|C_k|}{|D|}log_2\frac{|C_k|}{|D|}</script>其中$C_k$是样本集合$D$中属于第$k$类的样本子集，$|C_k|$表示该子集的元素个数，$|D|$表示样本集合的元素个数，计算某个特征$A$对于数据集$D$的经验条件熵$H(D|A)$为：<script type="math/tex; mode=display">H(D|A)=\sum^n_{i=1}\frac{|D_i|}{|D|}H(D_i)=\sum^n_{i=1}\frac{|D_i|}{|D|}(-\sum^k_{k=1}\frac{|D_{ik}|}{|D_i|}log_2\frac{|D_{ik}|}{|D_i|})</script>其中$D<em>i$表示$D$中特征$A$取第$i$个值的样本子集，$D</em>{ik}$表示$D_i$中属于第$k$类的样本子集，于是信息增益可以表示为二者的差：<script type="math/tex; mode=display">Gain(D,a)=H(D)-H(D|A)</script>存在的问题：$Gain(D,a)$倾向于具有大量值的属性</li><li>增益率（信息增益与数据集$D$关于问题$a$的熵值之比）：越大越好，特征$A$对于数据集$D$的信息增益比定义为：<script type="math/tex; mode=display">Gini\_ratio(D,A)=\frac{Gain(D,A)}{H_A(D)}</script><script type="math/tex; mode=display">H_A(D)=-\sum^n_{i=1}\frac{｜D_i｜}{｜D｜}log_2\frac{｜D_i｜}{｜D｜}</script></li><li>基尼指数（基尼度量）：越小越好，描述数据的纯度，与信息熵含义类似<script type="math/tex; mode=display">Gini(D)=1-\sum^n_{k=1}(\frac{|C_k|}{|D|})^2</script>特征$A$的基尼指数定义为：<script type="math/tex; mode=display">Gini(D｜A)=\sum^n_{i=1}\frac{|D_i|}{|D|}Gini(D_i)</script></li></ol></li><li>节点类别设置：叶子结点纯度达到预设阈值后停止划分，并对叶子结点进行类别设置。按概率最大的类别设定：<script type="math/tex; mode=display">j=argmax_i p_i</script></li></ol></li><li>决策树生成<br>从顶向下（不断增加一个节点）<ul><li>准则：所有划分中选择一个使$\Delta I$(非纯度减少量)最大的划分为节点，加入决策树</li><li>贪婪学习：根据划分准则，在问题集上进行划分，直到Impurity不能再改善或达到较小的改善</li><li>停止规则：设定阈值</li></ul></li><li>剪枝处理（防止过拟合）<ol><li>预剪枝（prepruning）：在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点</li><li>后剪枝（postpruning）：先从训练集生成一颗完整的决策树，然后自底向上对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。后剪枝决策树的欠拟合风险很小，训练时间开销比未剪枝决策树和预剪枝决策树都要大得多</li></ol></li></ul><h1 id="经典决策树模型"><a href="#经典决策树模型" class="headerlink" title="经典决策树模型"></a>经典决策树模型</h1><h2 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h2><ul><li>属性特征作为结点问题，划分选择实际是特征选择的过程</li><li>划分选择依据：最大化信息增益</li><li>ID3相当于用极大似然法进行概率模型的选择</li><li>算法流程：<center><img align='center' src='ID3.jpg' alt='ID3' height=80% width=80%><div>ID3决策树</div></center></li></ul><h2 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h2><ul><li>属性特征作为结点问题，划分选择实际是特征选择的过程</li><li>划分选择依据：最大化信息增益率</li><li>算法流程：<center><img align='center' src='C4.5.jpg' alt='C4.5' height=80% width=80%><div>C4.5决策树</div></center></li></ul><p>对ID3的改进：</p><ul><li>用信息增益率选择属性，克服了信息增益选择属性时偏向选择取值多的属性的不足</li><li>在树构造的过程中进行剪枝</li><li>能完成对连续属性的离散化处理</li><li>能够对不完整数据进行处理</li></ul><h2 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h2><ul><li>属性特征离散值作为节点问题，本质是<strong>二叉树</strong></li><li>划分选择依据：最小化基尼指数</li><li>预测结果为概率分布，即在输入给定的条件下输出条件概率分布</li><li>ID3、C4.5只能分类，CART既能分类也能回归，回归时采用均方误差做评价；ID3、C4.5特征只使用一次，CART的特征可重复利用</li><li>算法流程<center><img align='center' src='CART.jpg' alt='CART' height=80% width=80%><div>CART决策树</div></center></li></ul><h1 id="决策树计算实例"><a href="#决策树计算实例" class="headerlink" title="决策树计算实例"></a>决策树计算实例</h1><p>分别利用三种决策树计算最有划分特征</p><center>  <img align='center' src='eg.jpg' alt='eg' height=70% width=70%></center><ol><li><p>ID3（最大化信息增益）</p><script type="math/tex; mode=display">H(D)=-\frac{3}{5}log_2\frac{3}{5}-\frac{2}{5}log_2\frac{2}{5}=0.971</script><script type="math/tex; mode=display">\begin{aligned} H(D|年龄)&=\frac{1}{5}H(老)+\frac{4}{5}H(年轻)=\frac{1}{5}(-0)+\frac{4}{5}(-\frac{2}{4}log_2\frac{2}{4}-\frac{2}{4}log_2\frac{2}{4})=0.8\end{aligned}</script><script type="math/tex; mode=display">g(D,年龄)=H(D)-H(D|年龄)=0.171</script><p>同理：<br>$g(D,长相)=0.42$<br>$g(D,工资)=0.42$<br>$g(D,写代码)=0.971$<br>写代码为最优划分特征</p></li><li><p>C4.5（最大化信息增益率）</p><script type="math/tex; mode=display">H_{年龄}(D)=-\frac{1}{5}log_2\frac{1}{5}-\frac{4}{5}log_2\frac{4}{5}=0.722</script><script type="math/tex; mode=display">g_R(D,年龄)=\frac{g(D,年龄)}{H_{年龄}(D)}=\frac{0.171}{0.722}=0.236</script><p>同理：<br>$g_R(D,长相)=0.306$<br>$g_R(D,工资)=0.306$<br>$g_R(D,写代码)=1$<br>写代码为最优划分特征</p></li><li><p>CART（最小基尼指数）</p><script type="math/tex; mode=display">\begin{aligned} Gini(D|年龄=老)=\frac{1}{5}\times(1-1)+\frac{4}{5}\times(1-(\frac{1}{2})^2-(\frac{1}{2})^2)=0.4=Gini(D|年龄=年轻)=Gini(D|年龄)\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned} Gini(D|长相=帅)=\frac{4}{5}\times(1-(\frac{1}{2})^2-(\frac{1}{2})^2)=0.4=Gini(D|长相=丑)\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned} Gini(D|写代码)&=\frac{3}{5}\times(1-1)+\frac{2}{5}\times(1-1)=0\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned} Gini(D|工资=高)&=\frac{3}{5}\times(1-(\frac{1}{3})^2-(\frac{2}{3})^2)+\frac{2}{5}\times(1-(\frac{1}{2})^2-(\frac{1}{2})^2)=0.47\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned} Gini(D|工资=中等)&=\frac{4}{5}\times(1-(\frac{3}{4})^2-(\frac{1}{4})^2)=0.3\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned} Gini(D|工资=低)&=\frac{4}{5}\times(1-(\frac{1}{2})^2-(\frac{1}{2})^2)=0.4\end{aligned}</script><p>写代码为最优划分特征</p></li></ol><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>sklearn默认使用的是CART决策树，既可以分类也可以回归<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import the necessary modules and libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a random dataset</span></span><br><span class="line">rng = np.random.RandomState(<span class="number">1</span>)</span><br><span class="line">X = np.sort(<span class="number">5</span> * rng.rand(<span class="number">80</span>, <span class="number">1</span>), axis=<span class="number">0</span>)</span><br><span class="line">y = np.sin(X).ravel()</span><br><span class="line">y[::<span class="number">5</span>] += <span class="number">3</span> * (<span class="number">0.5</span> - rng.rand(<span class="number">16</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit regression model</span></span><br><span class="line">regr_1 = DecisionTreeRegressor(max_depth=<span class="number">2</span>)</span><br><span class="line">regr_2 = DecisionTreeRegressor(max_depth=<span class="number">5</span>)</span><br><span class="line">regr_1.fit(X, y)</span><br><span class="line">regr_2.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predict</span></span><br><span class="line">X_test = np.arange(<span class="number">0.0</span>, <span class="number">5.0</span>, <span class="number">0.01</span>)[:, np.newaxis]</span><br><span class="line">y_1 = regr_1.predict(X_test)</span><br><span class="line">y_2 = regr_2.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the results</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(X, y, s=<span class="number">20</span>, edgecolor=<span class="string">&quot;black&quot;</span>, c=<span class="string">&quot;darkorange&quot;</span>, label=<span class="string">&quot;data&quot;</span>)</span><br><span class="line">plt.plot(X_test, y_1, color=<span class="string">&quot;cornflowerblue&quot;</span>, label=<span class="string">&quot;max_depth=2&quot;</span>, linewidth=<span class="number">2</span>)</span><br><span class="line">plt.plot(X_test, y_2, color=<span class="string">&quot;yellowgreen&quot;</span>, label=<span class="string">&quot;max_depth=5&quot;</span>, linewidth=<span class="number">2</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;data&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;target&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Decision Tree Regression&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><br>运行结果：</p><center>  <img align='center' src='decision_tree_regression.png' alt='decision tree regression'></center><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://scikit-learn.org/stable/auto_examples/index.html#decision-trees">官方文档sklearn-decision-trees</a></li><li>机器学习，周志华，清华大学，2016.</li><li>统计学习方法，李航，清华大学，2012.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning and Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning Framework</title>
      <link href="/2022/01/21/Learning-Framework/"/>
      <url>/2022/01/21/Learning-Framework/</url>
      
        <content type="html"><![CDATA[<table>  <tr>        <th colspan="3">Learning Framework</th></tr>  <tr>    <th>大类</th>    <th>小类</th>    <th>具体链接</th>  </tr>  <tr>    <td rowspan="13">数据结构与算法</td>    <td rowspan="3">数据结构</td>    <td><a href=https://xfliu1998.github.io/2023/02/06/Basic-Data-Structures>字符串、数组、哈希、链表</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/02/07/Stack-Queue-and-Heap>栈、队列、堆</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2021/11/01/3-Tree>树</td>  </tr>  <tr>    <td rowspan="10">算法</td>    <td><a href=https://xfliu1998.github.io/2023/06/13/Sort-Algorithm>排序算法</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/03/27/Bit-Arithmetic>位运算</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/03/19/Double-Pointer-and-Binary-Search-Algorithm>双指针、滑动窗口、二分查找</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/03/22/Prefix-Sum-and-Difference-Array>前缀和、差分数组</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/04/12/Search-and-Backstrack>递归、搜索（DFS/BFS）和回溯</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/04/19/Dynamic-Programming>动态规划</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/05/21/Greedy-Algorithm>贪心算法</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/05/29/Divide-and-Conquer>分治算法</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/06/04/Graph-Theory>图论</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/07/05/Number-Theory-and-Geometry>数论与几何</td>  </tr>  <tr>    <td rowspan="5">经典论文</td>    <td rowspan="4">论文阅读</td>    <td><a href=https://xfliu1998.github.io/2022/09/17/Papers-Summary>Papers Summary</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/03/25/Papers-Ideas>Papers Ideas</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2022/09/17/Papers-Reading-about-CV>Papers Reading about CV</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2022/09/17/Papers-Reading-about-NLP>Papers Reading about NLP</td>  </tr>  <tr>    <td rowspan="1">项目实战</td>    <td><a href=https://xfliu1998.github.io/2024/07/01/Get-Mask>Get Target Mask for Zero-shot Learning</td>  </tr>  <tr>    <td rowspan="6">机器学习与深度学习</td>    <td rowspan="3">机器学习</td>    <td><a href=https://xfliu1998.github.io/2022/03/16/6.1-Decision-Tree>Decision Tree</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2021/10/27/1-Ensemble-Learning>Ensemble Learning</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2022/03/17/6.2-GBDT-XGBoost-LightGBM>GBDT / XGBoost / LightGBM</td>  </tr>  <tr>    <td rowspan="2">深度学习</td>    <td><a href=https://xfliu1998.github.io/2023/05/19/Experimental-Technique>Experimental Technique</td>  </tr>  <tr>    <td>\</td>  </tr>  <tr>    <td>机器学习与深度学习总结</td>    <td><a href=https://xfliu1998.github.io/2023/05/19/Summary-NG>吴恩达机器学习与深度学习笔记总结</td>  </tr>  <tr>    <td rowspan="4">图像算法与三维重建</td>    <td rowspan="1">图像处理</td>    <td>\</td>  </tr>  <tr>    <td rowspan="3">三维重建</td>    <td><a href=https://xfliu1998.github.io/2022/10/01/9-3D-Construction>3D Construction</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2024/03/24/Construction-Based-KinectV2>Construction Based KinectV2</td>  </tr>  <tr>    <td><a href=https://xfliu1998.github.io/2023/01/11/SfM-SLAM>SfM & SLAM</td>  </tr>  <tr>    <td rowspan="5">搜索/广告/推荐/因果</td>    <td rowspan="1">搜索</td>    <td><a href=https://xfliu1998.github.io/2021/12/03/4-Smart-Search-and-Recommendation-System-Principles-Algorithm-and-Application>Smart Search and Recommendation System Principles, Algorithm and Application</td>  </tr>  <tr>    <td rowspan="1">广告</td>    <td></td>  </tr>  <tr>    <td rowspan="2">推荐系统</td>    <td><a href=https://xfliu1998.github.io/2022/03/17/7-FM-FFM-Wide&Deep-DeepFFM>FM / FFM / Wide&Deep / DeepFFM</td>  </tr>  <tr>    <td>      <a href=https://xfliu1998.github.io/2022/01/18/5.1-Recommendation-System-Introduction>推荐系统介绍<br>      <a href=https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm>推荐算法<br>      <a href=https://xfliu1998.github.io/2022/01/18/5.3-Hadoop>Hadoop<br>      <a href=https://xfliu1998.github.io/2022/01/18/5.4-Hive>Hive & HBase<br>      <a href=https://xfliu1998.github.io/2022/01/18/5.5-Spark-core>Spark core<br>      <a href=https://xfliu1998.github.io/2022/01/18/5.6-Spark-SQL>Spark SQL & Spark streaming<br>      <a href=https://xfliu1998.github.io/2022/01/18/5.7-RS-case>推荐系统案例<br>    </td>  </tr>  <tr>    <td rowspan="1">因果</td>    <td><a href=https://xfliu1998.github.io/2024/03/31/Causal-Inference>Causal Inference</td>  </tr>  <tr>    <td rowspan="1">编程语言</td>    <td rowspan="1">Python</td>    <td>\</td>  </tr>  <tr>    <td rowspan="2">编程框架</td>    <td rowspan="1">Pytorch</td>    <td><a href=https://xfliu1998.github.io/2023/05/19/Pytorch>Pytorch笔记</td>  </tr>  <tr>    <td rowspan="1">Tensorflow</td>    <td>\</td>  </tr>  <tr>    <td rowspan="2">数据处理</td>    <td rowspan="1">Pyspark</td>    <td><a href=https://xfliu1998.github.io/2022/03/18/8-pyspark&pandas>pyspark & pandas</td>  </tr>  <tr>    <td rowspan="1">数据库</td>    <td><a href=https://xfliu1998.github.io/2023/05/20/Database>Hive / MySQL / MongoDB</td>  </tr>  <tr>    <td rowspan="2">操作系统与编程工具</td>    <td rowspan="1">Linux</td>    <td><a href=https://xfliu1998.github.io/2023/05/20/Linux>Linux (包含Vim)</td>  </tr>  <tr>    <td rowspan="1">Git</td>    <td><a href=https://xfliu1998.github.io/2023/05/20/Git>Git及Python环境部署</td>  </tr>  <tr>    <td rowspan="2">算法工程师</td>    <td rowspan="1">面试笔试</td>    <td><a href=https://xfliu1998.github.io/2023/06/05/Interview-Experience>八股</td>  </tr>  <tr>    <td rowspan="1">每日刷题</td>    <td><a href=https://xfliu1998.github.io/2024/07/09/Daily-Leetcode>一天一道Leetcode</td>  </tr>  <tr>    <td rowspan="5">小小宝典</td>    <td rowspan="1">数据库常用</td>    <td><a href=https://xfliu1998.github.io/2024/04/07/Technical-Summary-Database>MySQL, Hive SQL, Spark SQL</td>  <tr>  <tr>    <td rowspan="1">深度学习常用 </td>    <td><a href=https://xfliu1998.github.io/2024/07/09/Technical-Summary-Deep-Learning>Pytorch, Numpy</td>  </tr>  <tr>    <td rowspan="1">大数据处理常用</td>    <td><a href=https://xfliu1998.github.io/2024/04/15/Technical-Summary-BigData>Pyspark & Pandas</td>  </tr>  <tr>    <td rowspan="1">常用命令</td>    <td><a href=https://xfliu1998.github.io/2024/07/02/Technical-Summary-Necessary>Shell, Git, Vim</td>  </tr>  <tr>    <td rowspan="1"> </td>    <td><a href=></td>  </tr></table>]]></content>
      
      
      <categories>
          
          <category> Reading Notes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Recommendation System case</title>
      <link href="/2022/01/18/5.7-RS-case/"/>
      <url>/2022/01/18/5.7-RS-case/</url>
      
        <content type="html"><![CDATA[<p><strong>推荐系统学习笔记目录</strong></p><ol><li><a href="https://xfliu1998.github.io/2022/01/18/5.1-Recommendation-System-Introduction/">推荐系统介绍</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/">推荐算法</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.3-Hadoop/">Hadoop</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.4-Hive/">Hive &amp; HBase</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.5-Spark-core/">Spark core</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.6-Spark-SQL/">Spark SQL &amp; Spark streaming</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.7-RS-case/">推荐系统案例</a></li></ol><h2 id="个性化电商广告推荐系统介绍"><a href="#个性化电商广告推荐系统介绍" class="headerlink" title="个性化电商广告推荐系统介绍"></a>个性化电商广告推荐系统介绍</h2><h3 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h3><ul><li><p>Ali_Display_Ad_Click是阿里巴巴提供的一个淘宝展示广告点击率预估数据集</p><p>数据集来源：天池竞赛</p></li><li><p>原始样本骨架raw_sample</p><p>淘宝网站中随机抽样了114万用户8天内的广告展示/点击日志（2600万条记录），构成原始的样本骨架。 字段说明如下：</p><ol><li>user_id：脱敏过的用户ID；</li><li>adgroup_id：脱敏过的广告单元ID；</li><li>time_stamp：时间戳；</li><li>pid：资源位；</li><li>noclk：为1代表没有点击；为0代表点击；</li><li>clk：为0代表没有点击；为1代表点击；</li></ol><p>用前面7天的做训练样本（20170506-20170512），用第8天的做测试样本（20170513）</p></li><li><p>广告基本信息表ad_feature</p><p>本数据集涵盖了raw_sample中全部广告的基本信息(约80万条目)。字段说明如下：</p><ol><li>adgroup_id：脱敏过的广告ID；</li><li>cate_id：脱敏过的商品类目ID；</li><li>campaign_id：脱敏过的广告计划ID；</li><li>customer_id: 脱敏过的广告主ID；</li><li>brand_id：脱敏过的品牌ID；</li><li>price: 宝贝的价格</li></ol><p>其中一个广告ID对应一个商品（宝贝），一个宝贝属于一个类目，一个宝贝属于一个品牌。</p></li><li><p>用户基本信息表user_profile</p><p>本数据集涵盖了raw_sample中全部用户的基本信息(约100多万用户)。字段说明如下：</p><ol><li>userid：脱敏过的用户ID；</li><li>cms_segid：微群ID；</li><li>cms_group_id：cms_group_id；</li><li>final_gender_code：性别 1:男,2:女；</li><li>age_level：年龄层次； 1234</li><li>pvalue_level：消费档次，1:低档，2:中档，3:高档；</li><li>shopping_level：购物深度，1:浅层用户,2:中度用户,3:深度用户</li><li>occupation：是否大学生 ，1:是,0:否</li><li>new_user_class_level：城市层级</li></ol></li><li><p>用户的行为日志behavior_log</p><p>本数据集涵盖了raw_sample中全部用户22天内的购物行为(共七亿条记录)。字段说明如下：</p><p>user：脱敏过的用户ID；<br>time_stamp：时间戳；<br>btag：行为类型, 包括以下四种：<br>​    类型 | 说明<br>​    pv | 浏览<br>​    cart | 加入购物车<br>​    fav | 喜欢<br>​    buy | 购买<br>cate_id：脱敏过的商品类目id；<br>brand_id: 脱敏过的品牌id；<br>这里以user + time_stamp为key，会有很多重复的记录；这是因为我们的不同的类型的行为数据是不同部门记录的，在打包到一起的时候，实际上会有小的偏差（即两个一样的time_stamp实际上是差异比较小的两个时间）</p></li></ul><h3 id="项目效果展示"><a href="#项目效果展示" class="headerlink" title="项目效果展示"></a>项目效果展示</h3><p><img src="1545049355235.png" alt=""></p><h3 id="项目实现分析"><a href="#项目实现分析" class="headerlink" title="项目实现分析"></a>项目实现分析</h3><ul><li><p>主要包括</p><ul><li>一份广告点击的样本数据raw_sample.csv：体现的是用户对不同位置广告点击、没点击的情况</li><li>一份广告基本信息数据ad_feature.csv：体现的是每个广告的类目(id)、品牌(id)、价格特征</li><li>一份用户基本信息数据user_profile.csv：体现的是用户群组、性别、年龄、消费购物档次、所在城市级别等特征</li><li>一份用户行为日志数据behavior_log.csv：体现用户对商品类目(id)、品牌(id)的浏览、加购物车、收藏、购买等信息</li></ul><p>我们是在对非搜索类型的广告进行点击率预测和推荐(没有搜索词、没有广告的内容特征信息)</p><ol><li>推荐业务处理主要流程： 召回 ===&gt; 排序 ===&gt; 过滤<ul><li>离线处理业务流<ul><li>raw_sample.csv ==&gt; 历史样本数据</li><li>ad_feature.csv ==&gt; 广告特征数据</li><li>user_profile.csv ==&gt; 用户特征数据</li><li>raw_sample.csv + ad_feature.csv + user_profile.csv ==&gt; CTR点击率预测模型</li><li>behavior_log.csv ==&gt; 评分数据 ==&gt; user-cate/brand评分数据 ==&gt; 协同过滤 ==&gt; top-N cate/brand ==&gt; 关联广告</li><li>协同过滤召回 ==&gt; top-N cate/brand ==&gt; 关联对应的广告完成召回</li></ul></li><li>在线处理业务流<ul><li>数据处理部分：<ul><li>实时行为日志 ==&gt; 实时特征 ==&gt; 缓存</li><li>实时行为日志 ==&gt; 实时商品类别/品牌 ==&gt; 实时广告召回集 ==&gt; 缓存</li></ul></li><li>推荐任务部分：<ul><li>CTR点击率预测模型 + 广告/用户特征(缓存) + 对应的召回集(缓存) ==&gt; 点击率排序 ==&gt; top-N 广告推荐结果</li></ul></li></ul></li></ul></li><li>涉及技术：Flume、Kafka、Spark-streming\HDFS、Spark SQL、Spark ML、Redis<ul><li>Flume：日志数据收集</li><li>Kafka：实时日志数据处理队列</li><li>HDFS：存储数据</li><li>Spark SQL：离线处理</li><li>Spark ML：模型训练</li><li>Redis：缓存</li></ul></li></ol></li></ul><h3 id="点击率预测-CTR—Click-Through-Rate-概念"><a href="#点击率预测-CTR—Click-Through-Rate-概念" class="headerlink" title="点击率预测(CTR—Click-Through-Rate)概念"></a>点击率预测(CTR—Click-Through-Rate)概念</h3><ul><li><p>电商广告推荐通常使用广告点击率(CTR—Click-Through-Rate)预测来实现</p><p><strong>点击率预测 VS 推荐算法</strong></p><p>点击率预测需要给出精准的点击概率，比如广告A点击率0.5%、广告B的点击率0.12%等；而推荐算法很多时候只需要得出一个最优的次序A&gt;B&gt;C即可。</p><p>点击率预测使用的算法通常是如逻辑回归(Logic Regression)这样的机器学习算法，而推荐算法则是一些基于协同过滤推荐、基于内容的推荐等思想实现的算法</p><p><strong>点击率 VS 转化率</strong></p><p>点击率预测是对每次广告的点击情况做出预测，可以判定这次为点击或不点击，也可以给出点击或不点击的概率</p><p>转化率指的是从状态A进入到状态B的概率，电商的转化率通常是指到达网站后，进而有成交记录的用户比率，如用户成交量/用户访问量</p><p><strong>搜索和非搜索广告点击率预测的区别</strong></p><p>搜索中有很强的搜索信号-“查询词(Query)”，查询词和广告内容的匹配程度很大程度影响了点击概率，搜索广告的点击率普遍较高</p><p>非搜索广告（例如展示广告，信息流广告）的点击率的计算很多就来源于用户的兴趣和广告自身的特征，以及上下文环境。通常好位置能达到百分之几的点击率。对于很多底部的广告，点击率非常低，常常是千分之几，甚至更低</p></li></ul><h2 id="根据用户行为数据创建ALS模型并召回商品"><a href="#根据用户行为数据创建ALS模型并召回商品" class="headerlink" title="根据用户行为数据创建ALS模型并召回商品"></a>根据用户行为数据创建ALS模型并召回商品</h2><h3 id="用户行为数据拆分"><a href="#用户行为数据拆分" class="headerlink" title="用户行为数据拆分"></a>用户行为数据拆分</h3><ul><li><p>方便练习可以对数据做拆分处理</p><ul><li>pandas的数据分批读取  chunk 厚厚的一块 相当大的数量或部分</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">reader = pd.read_csv(<span class="string">&#x27;behavior_log.csv&#x27;</span>,chunksize=<span class="number">100</span>,iterator=<span class="literal">True</span>)</span><br><span class="line">count = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> reader:</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> count ==<span class="number">1</span>:</span><br><span class="line">        chunk.to_csv(<span class="string">&#x27;test4.csv&#x27;</span>,index = <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">elif</span> count&gt;<span class="number">1</span> <span class="keyword">and</span> count&lt;<span class="number">1000</span>:</span><br><span class="line">        chunk.to_csv(<span class="string">&#x27;test4.csv&#x27;</span>,index = <span class="literal">False</span>, mode = <span class="string">&#x27;a&#x27;</span>,header = <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">pd.read_csv(<span class="string">&#x27;test4.csv&#x27;</span>)</span><br></pre></td></tr></table></figure></li></ul><h3 id="预处理behavior-log数据集"><a href="#预处理behavior-log数据集" class="headerlink" title="预处理behavior_log数据集"></a>预处理behavior_log数据集</h3><ul><li>创建spark session</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line"><span class="comment"># spark配置信息</span></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">SPARK_APP_NAME = <span class="string">&quot;preprocessingBehaviorLog&quot;</span></span><br><span class="line">SPARK_URL = <span class="string">&quot;spark://192.168.199.188:7077&quot;</span></span><br><span class="line"></span><br><span class="line">conf = SparkConf()    <span class="comment"># 创建spark config对象</span></span><br><span class="line">config = (</span><br><span class="line">(<span class="string">&quot;spark.app.name&quot;</span>, SPARK_APP_NAME),    <span class="comment"># 设置启动的spark的app名称，没有提供，将随机产生一个名称</span></span><br><span class="line">(<span class="string">&quot;spark.executor.memory&quot;</span>, <span class="string">&quot;6g&quot;</span>),    <span class="comment"># 设置该app启动时占用的内存用量，默认1g</span></span><br><span class="line">(<span class="string">&quot;spark.master&quot;</span>, SPARK_URL),    <span class="comment"># spark master的地址</span></span><br><span class="line">    (<span class="string">&quot;spark.executor.cores&quot;</span>, <span class="string">&quot;4&quot;</span>),    <span class="comment"># 设置spark executor使用的CPU核心数</span></span><br><span class="line">    <span class="comment"># 以下三项配置，可以控制执行器数量</span></span><br><span class="line"><span class="comment">#     (&quot;spark.dynamicAllocation.enabled&quot;, True),</span></span><br><span class="line"><span class="comment">#     (&quot;spark.dynamicAllocation.initialExecutors&quot;, 1),    # 1个执行器</span></span><br><span class="line"><span class="comment">#     (&quot;spark.shuffle.service.enabled&quot;, True)</span></span><br><span class="line"><span class="comment"># (&#x27;spark.sql.pivotMaxValues&#x27;, &#x27;99999&#x27;),  # 当需要pivot DF，且值很多时，需要修改，默认是10000</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 查看更详细配置及说明：https://spark.apache.org/docs/latest/configuration.html</span></span><br><span class="line"></span><br><span class="line">conf.setAll(config)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用config对象，创建spark session</span></span><br><span class="line">spark = SparkSession.builder.config(conf=conf).getOrCreate()</span><br></pre></td></tr></table></figure><ul><li>从hdfs中加载csv文件为DataFrame</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从hdfs加载CSV文件为DataFrame</span></span><br><span class="line">df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/behavior_log.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line">df.show()    <span class="comment"># 查看dataframe，默认显示前20条</span></span><br><span class="line"><span class="comment"># 大致查看一下数据类型</span></span><br><span class="line">df.printSchema()    <span class="comment"># 打印当前dataframe的结构</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+----+-----+------+</span><br><span class="line">|  user|time_stamp|btag| cate| brand|</span><br><span class="line">+------+----------+----+-----+------+</span><br><span class="line">|558157|1493741625|  pv| 6250| 91286|</span><br><span class="line">|558157|1493741626|  pv| 6250| 91286|</span><br><span class="line">|558157|1493741627|  pv| 6250| 91286|</span><br><span class="line">|728690|1493776998|  pv|11800| 62353|</span><br><span class="line">|332634|1493809895|  pv| 1101|365477|</span><br><span class="line">|857237|1493816945|  pv| 1043|110616|</span><br><span class="line">|619381|1493774638|  pv|  385|428950|</span><br><span class="line">|467042|1493772641|  pv| 8237|301299|</span><br><span class="line">|467042|1493772644|  pv| 8237|301299|</span><br><span class="line">|991528|1493780710|  pv| 7270|274795|</span><br><span class="line">|991528|1493780712|  pv| 7270|274795|</span><br><span class="line">|991528|1493780712|  pv| 7270|274795|</span><br><span class="line">|991528|1493780712|  pv| 7270|274795|</span><br><span class="line">|991528|1493780714|  pv| 7270|274795|</span><br><span class="line">|991528|1493780765|  pv| 7270|274795|</span><br><span class="line">|991528|1493780714|  pv| 7270|274795|</span><br><span class="line">|991528|1493780765|  pv| 7270|274795|</span><br><span class="line">|991528|1493780764|  pv| 7270|274795|</span><br><span class="line">|991528|1493780633|  pv| 7270|274795|</span><br><span class="line">|991528|1493780764|  pv| 7270|274795|</span><br><span class="line">+------+----------+----+-----+------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- user: string (nullable = true)</span><br><span class="line"> |-- time_stamp: string (nullable = true)</span><br><span class="line"> |-- btag: string (nullable = true)</span><br><span class="line"> |-- cate: string (nullable = true)</span><br><span class="line"> |-- brand: string (nullable = true)</span><br></pre></td></tr></table></figure><ul><li>从hdfs加载数据为dataframe，并设置结构</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType</span><br><span class="line"><span class="comment"># 构建结构对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;timestamp&quot;</span>, LongType()),</span><br><span class="line">    StructField(<span class="string">&quot;btag&quot;</span>, StringType()),</span><br><span class="line">    StructField(<span class="string">&quot;cateId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;brandId&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 从hdfs加载数据为dataframe，并设置结构</span></span><br><span class="line">behavior_log_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/datasets/behavior_log.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line">behavior_log_df.show()</span><br><span class="line">behavior_log_df.count() </span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+----+------+-------+</span><br><span class="line">|userId| timestamp|btag|cateId|brandId|</span><br><span class="line">+------+----------+----+------+-------+</span><br><span class="line">|558157|1493741625|  pv|  6250|  91286|</span><br><span class="line">|558157|1493741626|  pv|  6250|  91286|</span><br><span class="line">|558157|1493741627|  pv|  6250|  91286|</span><br><span class="line">|728690|1493776998|  pv| 11800|  62353|</span><br><span class="line">|332634|1493809895|  pv|  1101| 365477|</span><br><span class="line">|857237|1493816945|  pv|  1043| 110616|</span><br><span class="line">|619381|1493774638|  pv|   385| 428950|</span><br><span class="line">|467042|1493772641|  pv|  8237| 301299|</span><br><span class="line">|467042|1493772644|  pv|  8237| 301299|</span><br><span class="line">|991528|1493780710|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780712|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780712|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780712|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780714|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780765|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780714|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780765|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780764|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780633|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780764|  pv|  7270| 274795|</span><br><span class="line">+------+----------+----+------+-------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- timestamp: long (nullable = true)</span><br><span class="line"> |-- btag: string (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- brandId: integer (nullable = true)</span><br></pre></td></tr></table></figure><ul><li>分析数据集字段的类型和格式<ul><li>查看是否有空值</li><li>查看每列数据的类型</li><li>查看每列数据的类别情况</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看userId的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;userId&quot;</span>).count().count())</span><br><span class="line"><span class="comment"># 约113w用户</span></span><br><span class="line"><span class="comment">#注意：behavior_log_df.groupBy(&quot;userId&quot;).count()  返回的是一个dataframe，这里的count计算的是每一个分组的个数，但当前还没有进行计算</span></span><br><span class="line"><span class="comment"># 当调用df.count()时才开始进行计算，这里的count计算的是dataframe的条目数，也就是共有多少个分组</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看user的数据情况： 1136340</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看btag的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;btag&quot;</span>).count().collect())    <span class="comment"># collect会把计算结果全部加载到内存，谨慎使用</span></span><br><span class="line"><span class="comment"># 只有四种类型数据：pv、fav、cart、buy</span></span><br><span class="line"><span class="comment"># 这里由于类型只有四个，所以直接使用collect，把数据全部加载出来</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看btag的数据情况： [Row(btag=&#x27;buy&#x27;, count=9115919), Row(btag=&#x27;fav&#x27;, count=9301837), Row(btag=&#x27;cart&#x27;, count=15946033), Row(btag=&#x27;pv&#x27;, count=688904345)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看cateId的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;cateId&quot;</span>).count().count())</span><br><span class="line"><span class="comment"># 约12968类别id</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看cateId的数据情况： 12968</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看brandId的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;brandId&quot;</span>).count().count())</span><br><span class="line"><span class="comment"># 约460561品牌id</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看brandId的数据情况： 460561</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;判断数据是否有空值：&quot;</span>, behavior_log_df.count(), behavior_log_df.dropna().count())</span><br><span class="line"><span class="comment"># 约7亿条目723268134 723268134</span></span><br><span class="line"><span class="comment"># 本数据集无空值条目，可放心处理</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">判断数据是否有空值： 723268134 723268134</span><br></pre></td></tr></table></figure><ul><li>pivot透视操作，把某列里的字段值转换成行并进行聚合运算(pyspark.sql.GroupedData.pivot)<ul><li>如果透视的字段中的不同属性值超过10000个，则需要设置spark.sql.pivotMaxValues，否则计算过程中会出现错误。<a href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=pivot#pyspark.sql.GroupedData.pivot">文档介绍</a>。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计每个用户对各类商品的pv、fav、cart、buy数量</span></span><br><span class="line">cate_count_df = behavior_log_df.groupBy(behavior_log_df.userId, behavior_log_df.cateId).pivot(<span class="string">&quot;btag&quot;</span>,[<span class="string">&quot;pv&quot;</span>,<span class="string">&quot;fav&quot;</span>,<span class="string">&quot;cart&quot;</span>,<span class="string">&quot;buy&quot;</span>]).count()</span><br><span class="line">cate_count_df.printSchema()    <span class="comment"># 此时还没有开始计算</span></span><br></pre></td></tr></table></figure><p>显示效果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- pv: long (nullable = true)</span><br><span class="line"> |-- fav: long (nullable = true)</span><br><span class="line"> |-- cart: long (nullable = true)</span><br><span class="line"> |-- buy: long (nullable = true)</span><br></pre></td></tr></table></figure><ul><li>统计每个用户对各个品牌的pv、fav、cart、buy数量并保存结果</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计每个用户对各个品牌的pv、fav、cart、buy数量</span></span><br><span class="line">brand_count_df = behavior_log_df.groupBy(behavior_log_df.userId, behavior_log_df.brandId).pivot(<span class="string">&quot;btag&quot;</span>,[<span class="string">&quot;pv&quot;</span>,<span class="string">&quot;fav&quot;</span>,<span class="string">&quot;cart&quot;</span>,<span class="string">&quot;buy&quot;</span>]).count()</span><br><span class="line"><span class="comment"># brand_count_df.show()    # 同上</span></span><br><span class="line"><span class="comment"># 113w * 46w</span></span><br><span class="line"><span class="comment"># 由于运算时间比较长，所以这里先将结果存储起来，供后续其他操作使用</span></span><br><span class="line"><span class="comment"># 写入数据时才开始计算</span></span><br><span class="line">cate_count_df.write.csv(<span class="string">&quot;hdfs://localhost:9000/preprocessing_dataset/cate_count.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line">brand_count_df.write.csv(<span class="string">&quot;hdfs://localhost:9000/preprocessing_dataset/brand_count.csv&quot;</span>, header=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="根据用户对类目偏好打分训练ALS模型"><a href="#根据用户对类目偏好打分训练ALS模型" class="headerlink" title="根据用户对类目偏好打分训练ALS模型"></a>根据用户对类目偏好打分训练ALS模型</h3><ul><li>根据您统计的次数 + 打分规则 ==&gt; 偏好打分数据集 ==&gt; ALS模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># spark ml的模型训练是基于内存的，如果数据过大，内存空间小，迭代次数过多的化，可能会造成内存溢出，报错</span></span><br><span class="line"><span class="comment"># 设置Checkpoint的话，会把所有数据落盘，这样如果异常退出，下次重启后，可以接着上次的训练节点继续运行</span></span><br><span class="line"><span class="comment"># 但该方法其实指标不治本，因为无法防止内存溢出，所以还是会报错</span></span><br><span class="line"><span class="comment"># 如果数据量大，应考虑的是增加内存、或限制迭代次数和训练数据量级等</span></span><br><span class="line">spark.sparkContext.setCheckpointDir(<span class="string">&quot;hdfs://localhost:8020/checkPoint/&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建结构对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cateId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;pv&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;fav&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cart&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;buy&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从hdfs加载CSV文件</span></span><br><span class="line">cate_count_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/preprocessing_dataset/cate_count.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line">cate_count_df.printSchema()</span><br><span class="line">cate_count_df.first()    <span class="comment"># 第一行数据</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- pv: integer (nullable = true)</span><br><span class="line"> |-- fav: integer (nullable = true)</span><br><span class="line"> |-- cart: integer (nullable = true)</span><br><span class="line"> |-- buy: integer (nullable = true)</span><br><span class="line"></span><br><span class="line">Row(userId=1061650, cateId=4520, pv=2326, fav=None, cart=53, buy=None)</span><br></pre></td></tr></table></figure><ul><li>处理每一行数据：r表示row对象</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_row</span>(<span class="params">r</span>):</span></span><br><span class="line">    <span class="comment"># 处理每一行数据：r表示row对象</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 偏好评分规则：</span></span><br><span class="line"><span class="comment">#     m: 用户对应的行为次数</span></span><br><span class="line">    <span class="comment">#     该偏好权重比例，次数上限仅供参考，具体数值应根据产品业务场景权衡</span></span><br><span class="line"><span class="comment">#     pv: if m&lt;=20: score=0.2*m; else score=4</span></span><br><span class="line"><span class="comment">#     fav: if m&lt;=20: score=0.4*m; else score=8</span></span><br><span class="line"><span class="comment">#     cart: if m&lt;=20: score=0.6*m; else score=12</span></span><br><span class="line"><span class="comment">#     buy: if m&lt;=20: score=1*m; else score=20</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 注意这里要全部设为浮点数，spark运算时对类型比较敏感，要保持数据类型都一致</span></span><br><span class="line">pv_count = r.pv <span class="keyword">if</span> r.pv <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">fav_count = r.fav <span class="keyword">if</span> r.fav <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">cart_count = r.cart <span class="keyword">if</span> r.cart <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">buy_count = r.buy <span class="keyword">if</span> r.buy <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">pv_score = <span class="number">0.2</span>*pv_count <span class="keyword">if</span> pv_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">4.0</span></span><br><span class="line">fav_score = <span class="number">0.4</span>*fav_count <span class="keyword">if</span> fav_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">8.0</span></span><br><span class="line">cart_score = <span class="number">0.6</span>*cart_count <span class="keyword">if</span> cart_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">12.0</span></span><br><span class="line">buy_score = <span class="number">1.0</span>*buy_count <span class="keyword">if</span> buy_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">20.0</span></span><br><span class="line"></span><br><span class="line">rating = pv_score + fav_score + cart_score + buy_score</span><br><span class="line"><span class="comment"># 返回用户ID、分类ID、用户对分类的偏好打分</span></span><br><span class="line"><span class="keyword">return</span> r.userId, r.cateId, rating</span><br></pre></td></tr></table></figure><ul><li>返回一个PythonRDD类型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回一个PythonRDD类型，此时还没开始计算</span></span><br><span class="line">cate_count_df.rdd.<span class="built_in">map</span>(process_row).toDF([<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;cateId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[userId: bigint, cateId: bigint, rating: double]</span><br></pre></td></tr></table></figure><ul><li>用户对商品类别的打分数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户对商品类别的打分数据</span></span><br><span class="line"><span class="comment"># map返回的结果是rdd类型，需要调用toDF方法转换为Dataframe</span></span><br><span class="line">cate_rating_df = cate_count_df.rdd.<span class="built_in">map</span>(process_row).toDF([<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;cateId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line"><span class="comment"># 注意：toDF不是每个rdd都有的方法，仅局限于此处的rdd</span></span><br><span class="line"><span class="comment"># 可通过该方法获得 user-cate-matrix</span></span><br><span class="line"><span class="comment"># 但由于cateId字段过多，这里运算量比很大，机器内存要求很高才能执行，否则无法完成任务</span></span><br><span class="line"><span class="comment"># 请谨慎使用</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 但好在我们训练ALS模型时，不需要转换为user-cate-matrix，所以这里可以不用运行</span></span><br><span class="line"><span class="comment"># cate_rating_df.groupBy(&quot;userId&quot;).povit(&quot;cateId&quot;).min(&quot;rating&quot;)</span></span><br><span class="line"><span class="comment"># 用户对类别的偏好打分数据</span></span><br><span class="line">cate_rating_df</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[userId: bigint, cateId: bigint, rating: double]</span><br></pre></td></tr></table></figure><ul><li>通常如果USER-ITEM打分数据应该是通过一下方式进行处理转换为USER-ITEM-MATRIX</li></ul><p><img src="CF%E4%BB%8B%E7%BB%8D.png" alt=""></p><p>但这里我们将使用的Spark的ALS模型进行CF推荐，因此注意这里数据输入不需要提前转换为矩阵，直接是 USER-ITEM-RATE的数据</p><ul><li><p>基于Spark的ALS隐因子模型进行CF评分预测</p><ul><li><p>ALS的意思是交替最小二乘法（Alternating Least Squares），是Spark2.*中加入的进行基于模型的协同过滤（model-based CF）的推荐系统算法。</p><p>同SVD，它也是一种矩阵分解技术，对数据进行降维处理。</p></li><li><p>详细使用方法：<a href="https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation">pyspark.ml.recommendation.ALS</a></p></li><li><p>注意：由于数据量巨大，因此这里也不考虑基于内存的CF算法</p><p>参考：<a href="https://www.cnblogs.com/mooba/p/6539142.html">为什么Spark中只有ALS</a></p></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用pyspark中的ALS矩阵分解方法实现CF评分预测</span></span><br><span class="line"><span class="comment"># 文档地址：https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALS   <span class="comment"># ml：dataframe， mllib：rdd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用打分数据，训练ALS模型</span></span><br><span class="line">als = ALS(userCol=<span class="string">&#x27;userId&#x27;</span>, itemCol=<span class="string">&#x27;cateId&#x27;</span>, ratingCol=<span class="string">&#x27;rating&#x27;</span>, checkpointInterval=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处训练时间较长</span></span><br><span class="line">model = als.fit(cate_rating_df)</span><br></pre></td></tr></table></figure><ul><li>模型训练好后，调用方法进行使用，<a href="https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=alsmodel#pyspark.ml.recommendation.ALSModel">具体API查看</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给所有用户推荐TOP-N个物品</span></span><br><span class="line">ret = model.recommendForAllUsers(<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 由于是给所有用户进行推荐，此处运算时间也较长</span></span><br><span class="line">ret.show()</span><br><span class="line"><span class="comment"># 推荐结果存放在recommendations列中，</span></span><br><span class="line">ret.select(<span class="string">&quot;recommendations&quot;</span>).show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|   148|[[3347, 12.547271...|</span><br><span class="line">|   463|[[1610, 9.250818]...|</span><br><span class="line">|   471|[[1610, 10.246621...|</span><br><span class="line">|   496|[[1610, 5.162216]...|</span><br><span class="line">|   833|[[5607, 9.065482]...|</span><br><span class="line">|  1088|[[104, 6.886987],...|</span><br><span class="line">|  1238|[[5631, 14.51981]...|</span><br><span class="line">|  1342|[[5720, 10.89842]...|</span><br><span class="line">|  1580|[[5731, 8.466453]...|</span><br><span class="line">|  1591|[[1610, 12.835257...|</span><br><span class="line">|  1645|[[1610, 11.968531...|</span><br><span class="line">|  1829|[[1610, 17.576496...|</span><br><span class="line">|  1959|[[1610, 8.353473]...|</span><br><span class="line">|  2122|[[1610, 12.652732...|</span><br><span class="line">|  2142|[[1610, 12.48068]...|</span><br><span class="line">|  2366|[[1610, 11.904813...|</span><br><span class="line">|  2659|[[5607, 11.699315...|</span><br><span class="line">|  2866|[[1610, 7.752719]...|</span><br><span class="line">|  3175|[[3347, 2.3429515...|</span><br><span class="line">|  3749|[[1610, 3.641833]...|</span><br><span class="line">+------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">+--------------------+</span><br><span class="line">|     recommendations|</span><br><span class="line">+--------------------+</span><br><span class="line">|[[3347, 12.547271...|</span><br><span class="line">|[[1610, 9.250818]...|</span><br><span class="line">|[[1610, 10.246621...|</span><br><span class="line">|[[1610, 5.162216]...|</span><br><span class="line">|[[5607, 9.065482]...|</span><br><span class="line">|[[104, 6.886987],...|</span><br><span class="line">|[[5631, 14.51981]...|</span><br><span class="line">|[[5720, 10.89842]...|</span><br><span class="line">|[[5731, 8.466453]...|</span><br><span class="line">|[[1610, 12.835257...|</span><br><span class="line">|[[1610, 11.968531...|</span><br><span class="line">|[[1610, 17.576496...|</span><br><span class="line">|[[1610, 8.353473]...|</span><br><span class="line">|[[1610, 12.652732...|</span><br><span class="line">|[[1610, 12.48068]...|</span><br><span class="line">|[[1610, 11.904813...|</span><br><span class="line">|[[5607, 11.699315...|</span><br><span class="line">|[[1610, 7.752719]...|</span><br><span class="line">|[[3347, 2.3429515...|</span><br><span class="line">|[[1610, 3.641833]...|</span><br><span class="line">+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>model.recommendForUserSubset 给部分用户推荐TOP-N个物品</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意：recommendForUserSubset API，2.2.2版本中无法使用</span></span><br><span class="line">dataset = spark.createDataFrame([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]])</span><br><span class="line">dataset = dataset.withColumnRenamed(<span class="string">&quot;_1&quot;</span>, <span class="string">&quot;userId&quot;</span>)</span><br><span class="line">ret = model.recommendForUserSubset(dataset, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只给部分用推荐，运算时间短</span></span><br><span class="line">ret.show()</span><br><span class="line">ret.collect()    <span class="comment"># 注意： collect会将所有数据加载到内存，慎用</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|     1|[[1610, 25.4989],...|</span><br><span class="line">|     3|[[5607, 13.665942...|</span><br><span class="line">|     2|[[5579, 5.9051886...|</span><br><span class="line">+------+--------------------+</span><br><span class="line"></span><br><span class="line">[Row(userId=1, recommendations=[Row(cateId=1610, rating=25.498899459838867), Row(cateId=5737, rating=24.901548385620117), Row(cateId=3347, rating=20.736785888671875)]),</span><br><span class="line"> Row(userId=3, recommendations=[Row(cateId=5607, rating=13.665942192077637), Row(cateId=1610, rating=11.770171165466309), Row(cateId=3347, rating=10.35690689086914)]),</span><br><span class="line"> Row(userId=2, recommendations=[Row(cateId=5579, rating=5.90518856048584), Row(cateId=2447, rating=5.624575138092041), Row(cateId=5690, rating=5.2555742263793945)])]</span><br></pre></td></tr></table></figure><ul><li>transform中提供userId和cateId可以对打分进行预测，利用打分结果排序后</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># transform中提供userId和cateId可以对打分进行预测，利用打分结果排序后，同样可以实现TOP-N的推荐</span></span><br><span class="line">model.transform</span><br><span class="line"><span class="comment"># 将模型进行存储</span></span><br><span class="line">model.save(<span class="string">&quot;hdfs://localhost:8020/models/userCateRatingALSModel.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 测试存储的模型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALSModel</span><br><span class="line"><span class="comment"># 从hdfs加载之前存储的模型</span></span><br><span class="line">als_model = ALSModel.load(<span class="string">&quot;hdfs://localhost:8020/models/userCateRatingALSModel.obj&quot;</span>)</span><br><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给用户推荐TOP-N个物品</span></span><br><span class="line">result = als_model.recommendForAllUsers(<span class="number">3</span>)</span><br><span class="line">result.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|   148|[[3347, 12.547271...|</span><br><span class="line">|   463|[[1610, 9.250818]...|</span><br><span class="line">|   471|[[1610, 10.246621...|</span><br><span class="line">|   496|[[1610, 5.162216]...|</span><br><span class="line">|   833|[[5607, 9.065482]...|</span><br><span class="line">|  1088|[[104, 6.886987],...|</span><br><span class="line">|  1238|[[5631, 14.51981]...|</span><br><span class="line">|  1342|[[5720, 10.89842]...|</span><br><span class="line">|  1580|[[5731, 8.466453]...|</span><br><span class="line">|  1591|[[1610, 12.835257...|</span><br><span class="line">|  1645|[[1610, 11.968531...|</span><br><span class="line">|  1829|[[1610, 17.576496...|</span><br><span class="line">|  1959|[[1610, 8.353473]...|</span><br><span class="line">|  2122|[[1610, 12.652732...|</span><br><span class="line">|  2142|[[1610, 12.48068]...|</span><br><span class="line">|  2366|[[1610, 11.904813...|</span><br><span class="line">|  2659|[[5607, 11.699315...|</span><br><span class="line">|  2866|[[1610, 7.752719]...|</span><br><span class="line">|  3175|[[3347, 2.3429515...|</span><br><span class="line">|  3749|[[1610, 3.641833]...|</span><br><span class="line">+------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>召回到redis</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis</span><br><span class="line">host = <span class="string">&quot;192.168.19.8&quot;</span></span><br><span class="line">port = <span class="number">6379</span>    </span><br><span class="line"><span class="comment"># 召回到redis</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recall_cate_by_cf</span>(<span class="params">partition</span>):</span></span><br><span class="line">    <span class="comment"># 建立redis 连接池</span></span><br><span class="line">    pool = redis.ConnectionPool(host=host, port=port)</span><br><span class="line">    <span class="comment"># 建立redis客户端</span></span><br><span class="line">    client = redis.Redis(connection_pool=pool)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> partition:</span><br><span class="line">        client.hset(<span class="string">&quot;recall_cate&quot;</span>, row.userId, [i.cateId <span class="keyword">for</span> i <span class="keyword">in</span> row.recommendations])</span><br><span class="line"><span class="comment"># 对每个分片的数据进行处理 #mapPartition Transformation   map</span></span><br><span class="line"><span class="comment"># foreachPartition Action操作             foreachRDD</span></span><br><span class="line">result.foreachPartition(recall_cate_by_cf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：这里这是召回的是用户最感兴趣的n个类别</span></span><br><span class="line"><span class="comment"># 总的条目数，查看redis中总的条目数是否一致</span></span><br><span class="line">result.count()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1136340</span><br></pre></td></tr></table></figure><h3 id="根据用户对品牌偏好打分训练ALS模型"><a href="#根据用户对品牌偏好打分训练ALS模型" class="headerlink" title="根据用户对品牌偏好打分训练ALS模型"></a>根据用户对品牌偏好打分训练ALS模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType</span><br><span class="line"></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;brandId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;pv&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;fav&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cart&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;buy&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 从hdfs加载预处理好的品牌的统计数据</span></span><br><span class="line">brand_count_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/preprocessing_dataset/brand_count.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line"><span class="comment"># brand_count_df.show()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_row</span>(<span class="params">r</span>):</span></span><br><span class="line">    <span class="comment"># 处理每一行数据：r表示row对象</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 偏好评分规则：</span></span><br><span class="line"><span class="comment">#     m: 用户对应的行为次数</span></span><br><span class="line">    <span class="comment">#     该偏好权重比例，次数上限仅供参考，具体数值应根据产品业务场景权衡</span></span><br><span class="line"><span class="comment">#     pv: if m&lt;=20: score=0.2*m; else score=4</span></span><br><span class="line"><span class="comment">#     fav: if m&lt;=20: score=0.4*m; else score=8</span></span><br><span class="line"><span class="comment">#     cart: if m&lt;=20: score=0.6*m; else score=12</span></span><br><span class="line"><span class="comment">#     buy: if m&lt;=20: score=1*m; else score=20</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 注意这里要全部设为浮点数，spark运算时对类型比较敏感，要保持数据类型都一致</span></span><br><span class="line">pv_count = r.pv <span class="keyword">if</span> r.pv <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">fav_count = r.fav <span class="keyword">if</span> r.fav <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">cart_count = r.cart <span class="keyword">if</span> r.cart <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">buy_count = r.buy <span class="keyword">if</span> r.buy <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">pv_score = <span class="number">0.2</span>*pv_count <span class="keyword">if</span> pv_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">4.0</span></span><br><span class="line">fav_score = <span class="number">0.4</span>*fav_count <span class="keyword">if</span> fav_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">8.0</span></span><br><span class="line">cart_score = <span class="number">0.6</span>*cart_count <span class="keyword">if</span> cart_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">12.0</span></span><br><span class="line">buy_score = <span class="number">1.0</span>*buy_count <span class="keyword">if</span> buy_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">20.0</span></span><br><span class="line"></span><br><span class="line">rating = pv_score + fav_score + cart_score + buy_score</span><br><span class="line"><span class="comment"># 返回用户ID、品牌ID、用户对品牌的偏好打分</span></span><br><span class="line"><span class="keyword">return</span> r.userId, r.brandId, rating</span><br><span class="line"><span class="comment"># 用户对品牌的打分数据</span></span><br><span class="line">brand_rating_df = brand_count_df.rdd.<span class="built_in">map</span>(process_row).toDF([<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;brandId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line"><span class="comment"># brand_rating_df.show()</span></span><br></pre></td></tr></table></figure><ul><li><p>基于Spark的ALS隐因子模型进行CF评分预测</p><ul><li><p>ALS的意思是交替最小二乘法（Alternating Least Squares），是Spark中进行基于模型的协同过滤（model-based CF）的推荐系统算法，也是目前Spark内唯一一个推荐算法。</p><p>同SVD，它也是一种矩阵分解技术，但理论上，ALS在海量数据的处理上要优于SVD。</p><p>更多了解：<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation">pyspark.ml.recommendation.ALS</a></p><p>注意：由于数据量巨大，因此这里不考虑基于内存的CF算法</p><p>参考：<a href="https://www.cnblogs.com/mooba/p/6539142.html">为什么Spark中只有ALS</a></p></li></ul></li><li><p>使用pyspark中的ALS矩阵分解方法实现CF评分预测</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用pyspark中的ALS矩阵分解方法实现CF评分预测</span></span><br><span class="line"><span class="comment"># 文档地址：https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALS</span><br><span class="line"></span><br><span class="line">als = ALS(userCol=<span class="string">&#x27;userId&#x27;</span>, itemCol=<span class="string">&#x27;brandId&#x27;</span>, ratingCol=<span class="string">&#x27;rating&#x27;</span>, checkpointInterval=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 利用打分数据，训练ALS模型</span></span><br><span class="line"><span class="comment"># 此处训练时间较长</span></span><br><span class="line">model = als.fit(brand_rating_df)</span><br><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给用户推荐TOP-N个物品</span></span><br><span class="line">model.recommendForAllUsers(<span class="number">3</span>).show()</span><br><span class="line"><span class="comment"># 将模型进行存储</span></span><br><span class="line">model.save(<span class="string">&quot;hdfs://localhost:9000/models/userBrandRatingModel.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 测试存储的模型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALSModel</span><br><span class="line"><span class="comment"># 从hdfs加载模型</span></span><br><span class="line">my_model = ALSModel.load(<span class="string">&quot;hdfs://localhost:9000/models/userBrandRatingModel.obj&quot;</span>)</span><br><span class="line">my_model</span><br><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给用户推荐TOP-N个物品</span></span><br><span class="line">my_model.recommendForAllUsers(<span class="number">3</span>).first()</span><br></pre></td></tr></table></figure><h2 id="CTR预估数据准备"><a href="#CTR预估数据准备" class="headerlink" title="CTR预估数据准备"></a>CTR预估数据准备</h2><h3 id="分析并预处理raw-sample数据集"><a href="#分析并预处理raw-sample数据集" class="headerlink" title="分析并预处理raw_sample数据集"></a>分析并预处理raw_sample数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从HDFS中加载样本数据信息</span></span><br><span class="line">df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/raw_sample.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line">df.show()    <span class="comment"># 展示数据，默认前20条</span></span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+----------+-----------+------+---+</span><br><span class="line">|  user|time_stamp|adgroup_id|        pid|nonclk|clk|</span><br><span class="line">+------+----------+----------+-----------+------+---+</span><br><span class="line">|581738|1494137644|         1|430548_1007|     1|  0|</span><br><span class="line">|449818|1494638778|         3|430548_1007|     1|  0|</span><br><span class="line">|914836|1494650879|         4|430548_1007|     1|  0|</span><br><span class="line">|914836|1494651029|         5|430548_1007|     1|  0|</span><br><span class="line">|399907|1494302958|         8|430548_1007|     1|  0|</span><br><span class="line">|628137|1494524935|         9|430548_1007|     1|  0|</span><br><span class="line">|298139|1494462593|         9|430539_1007|     1|  0|</span><br><span class="line">|775475|1494561036|         9|430548_1007|     1|  0|</span><br><span class="line">|555266|1494307136|        11|430539_1007|     1|  0|</span><br><span class="line">|117840|1494036743|        11|430548_1007|     1|  0|</span><br><span class="line">|739815|1494115387|        11|430539_1007|     1|  0|</span><br><span class="line">|623911|1494625301|        11|430548_1007|     1|  0|</span><br><span class="line">|623911|1494451608|        11|430548_1007|     1|  0|</span><br><span class="line">|421590|1494034144|        11|430548_1007|     1|  0|</span><br><span class="line">|976358|1494156949|        13|430548_1007|     1|  0|</span><br><span class="line">|286630|1494218579|        13|430539_1007|     1|  0|</span><br><span class="line">|286630|1494289247|        13|430539_1007|     1|  0|</span><br><span class="line">|771431|1494153867|        13|430548_1007|     1|  0|</span><br><span class="line">|707120|1494220810|        13|430548_1007|     1|  0|</span><br><span class="line">|530454|1494293746|        13|430548_1007|     1|  0|</span><br><span class="line">+------+----------+----------+-----------+------+---+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- user: string (nullable = true)</span><br><span class="line"> |-- time_stamp: string (nullable = true)</span><br><span class="line"> |-- adgroup_id: string (nullable = true)</span><br><span class="line"> |-- pid: string (nullable = true)</span><br><span class="line"> |-- nonclk: string (nullable = true)</span><br><span class="line"> |-- clk: string (nullable = true)</span><br></pre></td></tr></table></figure><ul><li>分析数据集字段的类型和格式<ul><li>查看是否有空值</li><li>查看每列数据的类型</li><li>查看每列数据的类别情况</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;样本数据集总条目数：&quot;</span>, df.count())</span><br><span class="line"><span class="comment"># 约2600w</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;用户user总数：&quot;</span>, df.groupBy(<span class="string">&quot;user&quot;</span>).count().count())</span><br><span class="line"><span class="comment"># 约 114w，略多余日志数据中用户数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;广告id adgroup_id总数：&quot;</span>, df.groupBy(<span class="string">&quot;adgroup_id&quot;</span>).count().count())</span><br><span class="line"><span class="comment"># 约85w</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;广告展示位pid情况：&quot;</span>, df.groupBy(<span class="string">&quot;pid&quot;</span>).count().collect())</span><br><span class="line"><span class="comment"># 只有两种广告展示位，占比约为六比四</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;广告点击数据情况clk：&quot;</span>, df.groupBy(<span class="string">&quot;clk&quot;</span>).count().collect())</span><br><span class="line"><span class="comment"># 点和不点比率约： 1:20</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">样本数据集总条目数： 26557961</span><br><span class="line">用户user总数： 1141729</span><br><span class="line">广告id adgroup_id总数： 846811</span><br><span class="line">广告展示位pid情况： [Row(pid=&#x27;430548_1007&#x27;, count=16472898), Row(pid=&#x27;430539_1007&#x27;, count=10085063)]</span><br><span class="line">广告点击数据情况clk： [Row(clk=&#x27;0&#x27;, count=25191905), Row(clk=&#x27;1&#x27;, count=1366056)]</span><br></pre></td></tr></table></figure><ul><li>使用dataframe.withColumn更改df列数据结构；使用dataframe.withColumnRenamed更改列名称</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更改表结构，转换为对应的数据类型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType, LongType, StringType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印df结构信息</span></span><br><span class="line">df.printSchema()   </span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">raw_sample_df = df.\</span><br><span class="line">    withColumn(<span class="string">&quot;user&quot;</span>, df.user.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;userId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;time_stamp&quot;</span>, df.time_stamp.cast(LongType())).withColumnRenamed(<span class="string">&quot;time_stamp&quot;</span>, <span class="string">&quot;timestamp&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, df.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;pid&quot;</span>, df.pid.cast(StringType())).\</span><br><span class="line">    withColumn(<span class="string">&quot;nonclk&quot;</span>, df.nonclk.cast(IntegerType())).\</span><br><span class="line">    withColumn(<span class="string">&quot;clk&quot;</span>, df.clk.cast(IntegerType()))</span><br><span class="line">raw_sample_df.printSchema()</span><br><span class="line">raw_sample_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- user: string (nullable = true)</span><br><span class="line"> |-- time_stamp: string (nullable = true)</span><br><span class="line"> |-- adgroup_id: string (nullable = true)</span><br><span class="line"> |-- pid: string (nullable = true)</span><br><span class="line"> |-- nonclk: string (nullable = true)</span><br><span class="line"> |-- clk: string (nullable = true)</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- timestamp: long (nullable = true)</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- pid: string (nullable = true)</span><br><span class="line"> |-- nonclk: integer (nullable = true)</span><br><span class="line"> |-- clk: integer (nullable = true)</span><br><span class="line"></span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">|userId| timestamp|adgroupId|        pid|nonclk|clk|</span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">|581738|1494137644|        1|430548_1007|     1|  0|</span><br><span class="line">|449818|1494638778|        3|430548_1007|     1|  0|</span><br><span class="line">|914836|1494650879|        4|430548_1007|     1|  0|</span><br><span class="line">|914836|1494651029|        5|430548_1007|     1|  0|</span><br><span class="line">|399907|1494302958|        8|430548_1007|     1|  0|</span><br><span class="line">|628137|1494524935|        9|430548_1007|     1|  0|</span><br><span class="line">|298139|1494462593|        9|430539_1007|     1|  0|</span><br><span class="line">|775475|1494561036|        9|430548_1007|     1|  0|</span><br><span class="line">|555266|1494307136|       11|430539_1007|     1|  0|</span><br><span class="line">|117840|1494036743|       11|430548_1007|     1|  0|</span><br><span class="line">|739815|1494115387|       11|430539_1007|     1|  0|</span><br><span class="line">|623911|1494625301|       11|430548_1007|     1|  0|</span><br><span class="line">|623911|1494451608|       11|430548_1007|     1|  0|</span><br><span class="line">|421590|1494034144|       11|430548_1007|     1|  0|</span><br><span class="line">|976358|1494156949|       13|430548_1007|     1|  0|</span><br><span class="line">|286630|1494218579|       13|430539_1007|     1|  0|</span><br><span class="line">|286630|1494289247|       13|430539_1007|     1|  0|</span><br><span class="line">|771431|1494153867|       13|430548_1007|     1|  0|</span><br><span class="line">|707120|1494220810|       13|430548_1007|     1|  0|</span><br><span class="line">|530454|1494293746|       13|430548_1007|     1|  0|</span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li><p>特征选取（Feature Selection）</p><ul><li><p>特征选择就是选择那些靠谱的Feature，去掉冗余的Feature，对于搜索广告，Query关键词和广告的匹配程度很重要；但对于展示广告，广告本身的历史表现，往往是最重要的Feature。</p><p>根据经验，该数据集中，只有广告展示位pid对比较重要，且数据不同数据之间的占比约为6:4，因此pid可以作为一个关键特征</p><p>nonclk和clk在这里是作为目标值，不做为特征</p></li></ul></li><li><p>热独编码 OneHotEncode</p><ul><li><p>热独编码是一种经典编码，是使用N位状态寄存器(如0和1)来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候，其中只有一位有效。</p><p>假设有三组特征，分别表示年龄，城市，设备；</p><p>[“男”, “女”][0,1]</p><p>[“北京”, “上海”, “广州”][0,1,2]</p><p>[“苹果”, “小米”, “华为”, “微软”][0,1,2,3]</p><p>传统变化： 对每一组特征，使用枚举类型，从0开始；</p><p>[“男“，”上海“，”小米“]=[ 0,1,1]</p><p>[“女“，”北京“，”苹果“] =[1,0,0]</p><p>传统变化后的数据不是连续的，而是随机分配的，不容易应用在分类器中</p><p>而经过热独编码，数据会变成稀疏的，方便分类器处理：</p><p>[“男“，”上海“，”小米“]=[ 1,0,0,1,0,0,1,0,0]</p><p>[“女“，”北京“，”苹果“] =[0,1,1,0,0,1,0,0,0]</p><p>这样做保留了特征的多样性，但是也要注意如果数据过于稀疏(样本较少、维度过高)，其效果反而会变差</p></li></ul></li><li><p>Spark中使用热独编码</p><ul><li><p>注意：热编码只能对字符串类型的列数据进行处理</p><p><a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=stringindexer#pyspark.ml.feature.StringIndexer">StringIndexer</a>：对指定字符串列数据进行特征处理，如将性别数据“男”、“女”转化为0和1</p><p><a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=onehotencoder#pyspark.ml.feature.OneHotEncoder">OneHotEncoder</a>：对特征列数据，进行热编码，通常需结合StringIndexer一起使用</p><p><a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=pipeline#pyspark.ml.Pipeline">Pipeline</a>：让数据按顺序依次被处理，将前一次的处理结果作为下一次的输入</p></li></ul></li><li><p>特征处理</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;特征处理&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">pid 资源位。该特征属于分类特征，只有两类取值，因此考虑进行热编码处理即可，分为是否在资源位1、是否在资源位2 两个特征</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># StringIndexer对指定字符串列进行特征处理</span></span><br><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;pid&#x27;</span>, outputCol=<span class="string">&#x27;pid_feature&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对处理出来的特征处理列进行，热独编码</span></span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;pid_feature&#x27;</span>, outputCol=<span class="string">&#x27;pid_value&#x27;</span>)</span><br><span class="line"><span class="comment"># 利用管道对每一个数据进行热独编码处理</span></span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_model = pipeline.fit(raw_sample_df)</span><br><span class="line">new_df = pipeline_model.transform(raw_sample_df)</span><br><span class="line">new_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|userId| timestamp|adgroupId|        pid|nonclk|clk|pid_feature|    pid_value|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|581738|1494137644|        1|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|449818|1494638778|        3|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|914836|1494650879|        4|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|914836|1494651029|        5|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|399907|1494302958|        8|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|628137|1494524935|        9|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|298139|1494462593|        9|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|775475|1494561036|        9|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|555266|1494307136|       11|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|117840|1494036743|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|739815|1494115387|       11|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|623911|1494625301|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|623911|1494451608|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|421590|1494034144|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|976358|1494156949|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|286630|1494218579|       13|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|286630|1494289247|       13|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|771431|1494153867|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|707120|1494220810|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|530454|1494293746|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>返回字段pid_value是一个稀疏向量类型数据 <a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=sparse#pyspark.ml.linalg.SparseVector">pyspark.ml.linalg.SparseVector</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> SparseVector</span><br><span class="line"><span class="comment"># 参数：维度、索引列表、值列表</span></span><br><span class="line"><span class="built_in">print</span>(SparseVector(<span class="number">4</span>, [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>]))</span><br><span class="line"><span class="built_in">print</span>(SparseVector(<span class="number">4</span>, [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>]).toArray())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*********&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(new_df.select(<span class="string">&quot;pid_value&quot;</span>).first())</span><br><span class="line"><span class="built_in">print</span>(new_df.select(<span class="string">&quot;pid_value&quot;</span>).first().pid_value.toArray())</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(4,[1,3],[3.0,4.0])</span><br><span class="line">[0. 3. 0. 4.]</span><br><span class="line">*********</span><br><span class="line">Row(pid_value=SparseVector(2, &#123;0: 1.0&#125;))</span><br><span class="line">[1. 0.]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>查看最大时间</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_df.sort(<span class="string">&quot;timestamp&quot;</span>, ascending=<span class="literal">False</span>).show()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|userId| timestamp|adgroupId|        pid|nonclk|clk|pid_feature|    pid_value|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|177002|1494691186|   593001|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|243671|1494691186|   600195|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|488527|1494691184|   494312|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|488527|1494691184|   431082|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">| 17054|1494691184|   742741|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">| 17054|1494691184|   756665|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|488527|1494691184|   687854|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|839493|1494691183|   561681|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|704223|1494691183|   624504|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|839493|1494691183|   582235|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|704223|1494691183|   675674|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|628998|1494691180|   618965|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|674444|1494691179|   427579|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|627200|1494691179|   782038|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|627200|1494691179|   420769|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|674444|1494691179|   588664|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|738335|1494691179|   451004|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|627200|1494691179|   817569|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|322244|1494691179|   820018|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|322244|1494691179|   735220|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 本样本数据集共计8天数据</span></span><br><span class="line"><span class="comment"># 前七天为训练数据、最后一天为测试数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line">datetime.fromtimestamp(<span class="number">1494691186</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;该时间之前的数据为训练样本，该时间以后的数据为测试样本：&quot;</span>, datetime.fromtimestamp(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">该时间之前的数据为训练样本，该时间以后的数据为测试样本： 2017-05-12 23:59:46</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>训练样本</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练样本：</span></span><br><span class="line">train_sample = raw_sample_df.<span class="built_in">filter</span>(raw_sample_df.timestamp&lt;=(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练样本个数：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(train_sample.count())</span><br><span class="line"><span class="comment"># 测试样本</span></span><br><span class="line">test_sample = raw_sample_df.<span class="built_in">filter</span>(raw_sample_df.timestamp&gt;(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试样本个数：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(test_sample.count())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：还需要加入广告基本特征和用户基本特征才能做程一份完整的样本数据集</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">训练样本个数：</span><br><span class="line">23249291</span><br><span class="line">测试样本个数：</span><br><span class="line">3308670</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="分析并预处理ad-feature数据集"><a href="#分析并预处理ad-feature数据集" class="headerlink" title="分析并预处理ad_feature数据集"></a>分析并预处理ad_feature数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从HDFS中加载广告基本信息数据，返回spark dafaframe对象</span></span><br><span class="line">df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/ad_feature.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line">df.show()    <span class="comment"># 展示数据，默认前20条</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+----------+-------+-----------+--------+------+-----+</span><br><span class="line">|adgroup_id|cate_id|campaign_id|customer| brand|price|</span><br><span class="line">+----------+-------+-----------+--------+------+-----+</span><br><span class="line">|     63133|   6406|      83237|       1| 95471|170.0|</span><br><span class="line">|    313401|   6406|      83237|       1| 87331|199.0|</span><br><span class="line">|    248909|    392|      83237|       1| 32233| 38.0|</span><br><span class="line">|    208458|    392|      83237|       1|174374|139.0|</span><br><span class="line">|    110847|   7211|     135256|       2|145952|32.99|</span><br><span class="line">|    607788|   6261|     387991|       6|207800|199.0|</span><br><span class="line">|    375706|   4520|     387991|       6|  NULL| 99.0|</span><br><span class="line">|     11115|   7213|     139747|       9|186847| 33.0|</span><br><span class="line">|     24484|   7207|     139744|       9|186847| 19.0|</span><br><span class="line">|     28589|   5953|     395195|      13|  NULL|428.0|</span><br><span class="line">|     23236|   5953|     395195|      13|  NULL|368.0|</span><br><span class="line">|    300556|   5953|     395195|      13|  NULL|639.0|</span><br><span class="line">|     92560|   5953|     395195|      13|  NULL|368.0|</span><br><span class="line">|    590965|   4284|      28145|      14|454237|249.0|</span><br><span class="line">|    529913|   4284|      70206|      14|  NULL|249.0|</span><br><span class="line">|    546930|   4284|      28145|      14|  NULL|249.0|</span><br><span class="line">|    639794|   6261|      70206|      14| 37004| 89.9|</span><br><span class="line">|    335413|   4284|      28145|      14|  NULL|249.0|</span><br><span class="line">|    794890|   4284|      70206|      14|454237|249.0|</span><br><span class="line">|    684020|   6261|      70206|      14| 37004| 99.0|</span><br><span class="line">+----------+-------+-----------+--------+------+-----+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意：由于本数据集中存在NULL字样的数据，无法直接设置schema，只能先将NULL类型的数据处理掉，然后进行类型转换</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换掉NULL字符串，替换掉</span></span><br><span class="line">df = df.replace(<span class="string">&quot;NULL&quot;</span>, <span class="string">&quot;-1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印df结构信息</span></span><br><span class="line">df.printSchema()   </span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">ad_feature_df = df.\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, df.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;cate_id&quot;</span>, df.cate_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;cate_id&quot;</span>, <span class="string">&quot;cateId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;campaign_id&quot;</span>, df.campaign_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;campaign_id&quot;</span>, <span class="string">&quot;campaignId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;customer&quot;</span>, df.customer.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;customer&quot;</span>, <span class="string">&quot;customerId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;brand&quot;</span>, df.brand.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;brand&quot;</span>, <span class="string">&quot;brandId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;price&quot;</span>, df.price.cast(FloatType()))</span><br><span class="line">ad_feature_df.printSchema()</span><br><span class="line">ad_feature_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- adgroup_id: string (nullable = true)</span><br><span class="line"> |-- cate_id: string (nullable = true)</span><br><span class="line"> |-- campaign_id: string (nullable = true)</span><br><span class="line"> |-- customer: string (nullable = true)</span><br><span class="line"> |-- brand: string (nullable = true)</span><br><span class="line"> |-- price: string (nullable = true)</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- campaignId: integer (nullable = true)</span><br><span class="line"> |-- customerId: integer (nullable = true)</span><br><span class="line"> |-- brandId: integer (nullable = true)</span><br><span class="line"> |-- price: float (nullable = true)</span><br><span class="line"></span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|adgroupId|cateId|campaignId|customerId|brandId|price|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|    63133|  6406|     83237|         1|  95471|170.0|</span><br><span class="line">|   313401|  6406|     83237|         1|  87331|199.0|</span><br><span class="line">|   248909|   392|     83237|         1|  32233| 38.0|</span><br><span class="line">|   208458|   392|     83237|         1| 174374|139.0|</span><br><span class="line">|   110847|  7211|    135256|         2| 145952|32.99|</span><br><span class="line">|   607788|  6261|    387991|         6| 207800|199.0|</span><br><span class="line">|   375706|  4520|    387991|         6|     -1| 99.0|</span><br><span class="line">|    11115|  7213|    139747|         9| 186847| 33.0|</span><br><span class="line">|    24484|  7207|    139744|         9| 186847| 19.0|</span><br><span class="line">|    28589|  5953|    395195|        13|     -1|428.0|</span><br><span class="line">|    23236|  5953|    395195|        13|     -1|368.0|</span><br><span class="line">|   300556|  5953|    395195|        13|     -1|639.0|</span><br><span class="line">|    92560|  5953|    395195|        13|     -1|368.0|</span><br><span class="line">|   590965|  4284|     28145|        14| 454237|249.0|</span><br><span class="line">|   529913|  4284|     70206|        14|     -1|249.0|</span><br><span class="line">|   546930|  4284|     28145|        14|     -1|249.0|</span><br><span class="line">|   639794|  6261|     70206|        14|  37004| 89.9|</span><br><span class="line">|   335413|  4284|     28145|        14|     -1|249.0|</span><br><span class="line">|   794890|  4284|     70206|        14| 454237|249.0|</span><br><span class="line">|   684020|  6261|     70206|        14|  37004| 99.0|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>查看各项数据的特征</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;总广告条数：&quot;</span>,df.count())   <span class="comment"># 数据条数</span></span><br><span class="line">_1 = ad_feature_df.groupBy(<span class="string">&quot;cateId&quot;</span>).count().count()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;cateId数值个数：&quot;</span>, _1)</span><br><span class="line">_2 = ad_feature_df.groupBy(<span class="string">&quot;campaignId&quot;</span>).count().count()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;campaignId数值个数：&quot;</span>, _2)</span><br><span class="line">_3 = ad_feature_df.groupBy(<span class="string">&quot;customerId&quot;</span>).count().count()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;customerId数值个数：&quot;</span>, _3)</span><br><span class="line">_4 = ad_feature_df.groupBy(<span class="string">&quot;brandId&quot;</span>).count().count()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;brandId数值个数：&quot;</span>, _4)</span><br><span class="line">ad_feature_df.sort(<span class="string">&quot;price&quot;</span>).show()</span><br><span class="line">ad_feature_df.sort(<span class="string">&quot;price&quot;</span>, ascending=<span class="literal">False</span>).show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;价格高于1w的条目个数：&quot;</span>, ad_feature_df.select(<span class="string">&quot;price&quot;</span>).<span class="built_in">filter</span>(<span class="string">&quot;price&gt;10000&quot;</span>).count())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;价格低于1的条目个数&quot;</span>, ad_feature_df.select(<span class="string">&quot;price&quot;</span>).<span class="built_in">filter</span>(<span class="string">&quot;price&lt;1&quot;</span>).count())</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">总广告条数： 846811</span><br><span class="line">cateId数值个数： 6769</span><br><span class="line">campaignId数值个数： 423436</span><br><span class="line">customerId数值个数： 255875</span><br><span class="line">brandId数值个数： 99815</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|adgroupId|cateId|campaignId|customerId|brandId|price|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|   485749|  9970|    352666|    140520|     -1| 0.01|</span><br><span class="line">|    88975|  9996|    198424|    182415|     -1| 0.01|</span><br><span class="line">|   109704| 10539|     59774|     90351| 202710| 0.01|</span><br><span class="line">|    49911|  7032|    129079|    172334|     -1| 0.01|</span><br><span class="line">|   339334|  9994|    310408|    211292| 383023| 0.01|</span><br><span class="line">|     6636|  6703|    392038|     46239| 406713| 0.01|</span><br><span class="line">|    92241|  6130|     72781|    149714|     -1| 0.01|</span><br><span class="line">|    20397| 10539|    410958|     65726|  79971| 0.01|</span><br><span class="line">|   345870|  9995|    179595|    191036|  79971| 0.01|</span><br><span class="line">|    77797|  9086|    218276|     31183|     -1| 0.01|</span><br><span class="line">|    14435|  1136|    135610|     17788|     -1| 0.01|</span><br><span class="line">|    42055|  9994|     43866|    113068| 123242| 0.01|</span><br><span class="line">|    41925|  7032|     85373|    114532|     -1| 0.01|</span><br><span class="line">|    67558|  9995|     90141|     83948|     -1| 0.01|</span><br><span class="line">|   149570|  7043|    126746|    176076|     -1| 0.01|</span><br><span class="line">|   518883|  7185|    403318|     58013|     -1| 0.01|</span><br><span class="line">|     2246|  9996|    413653|     60214| 182966| 0.01|</span><br><span class="line">|   290675|  4824|    315371|    240984|     -1| 0.01|</span><br><span class="line">|   552638| 10305|    403318|     58013|     -1| 0.01|</span><br><span class="line">|    89831| 10539|     90141|     83948| 211816| 0.01|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">+---------+------+----------+----------+-------+-----------+</span><br><span class="line">|adgroupId|cateId|campaignId|customerId|brandId|      price|</span><br><span class="line">+---------+------+----------+----------+-------+-----------+</span><br><span class="line">|   658722|  1093|    218101|    207754|     -1|      1.0E8|</span><br><span class="line">|   468220|  1093|    270719|    207754|     -1|      1.0E8|</span><br><span class="line">|   179746|  1093|    270027|    102509| 405447|      1.0E8|</span><br><span class="line">|   443295|  1093|     44251|    102509| 300681|      1.0E8|</span><br><span class="line">|    31899|   685|    218918|     31239| 278301|      1.0E8|</span><br><span class="line">|   243384|   685|    218918|     31239| 278301|      1.0E8|</span><br><span class="line">|   554311|  1093|    266086|    207754|     -1|      1.0E8|</span><br><span class="line">|   513942|   745|      8401|     86243|     -1|8.8888888E7|</span><br><span class="line">|   201060|   745|      8401|     86243|     -1|5.5555556E7|</span><br><span class="line">|   289563|   685|     37665|    120847| 278301|      1.5E7|</span><br><span class="line">|    35156|   527|    417722|     72273| 278301|      1.0E7|</span><br><span class="line">|    33756|   527|    416333|     70894|     -1|  9900000.0|</span><br><span class="line">|   335495|   739|    170121|    148946| 326126|  9600000.0|</span><br><span class="line">|   218306|   206|    162394|      4339| 221720|  8888888.0|</span><br><span class="line">|   213567|  7213|    239302|    205612| 406125|  5888888.0|</span><br><span class="line">|   375920|   527|    217512|    148946| 326126|  4760000.0|</span><br><span class="line">|   262215|   527|    132721|     11947| 417898|  3980000.0|</span><br><span class="line">|   154623|   739|    170121|    148946| 326126|  3900000.0|</span><br><span class="line">|   152414|   739|    170121|    148946| 326126|  3900000.0|</span><br><span class="line">|   448651|   527|    422260|     41289| 209959|  3800000.0|</span><br><span class="line">+---------+------+----------+----------+-------+-----------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">价格高于1w的条目个数： 6527</span><br><span class="line">价格低于1的条目个数 5762</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>特征选择</p><ul><li>cateId：脱敏过的商品类目ID；</li><li>campaignId：脱敏过的广告计划ID；</li><li>customerId:脱敏过的广告主ID；</li><li>brandId：脱敏过的品牌ID；</li></ul><p>以上四个特征均属于分类特征，但由于分类值个数均过于庞大，如果去做热独编码处理，会导致数据过于稀疏 且当前我们缺少对这些特征更加具体的信息，（如商品类目具体信息、品牌具体信息等），从而无法对这些特征的数据做聚类、降维处理 因此这里不选取它们作为特征</p><p>而只选取price作为特征数据，因为价格本身是一个统计类型连续数值型数据，且能很好的体现广告的价值属性特征，通常也不需要做其他处理(离散化、归一化、标准化等)，所以这里直接将当做特征数据来使用</p></li></ul><h3 id="分析并预处理user-profile数据集"><a href="#分析并预处理user-profile数据集" class="headerlink" title="分析并预处理user_profile数据集"></a>分析并预处理user_profile数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从HDFS加载用户基本信息数据</span></span><br><span class="line">df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/csv/user_profile.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 发现pvalue_level和new_user_class_level存在空值：（注意此处的null表示空值，而如果是NULL，则往往表示是一个字符串）</span></span><br><span class="line"><span class="comment"># 因此直接利用schema就可以加载进该数据，无需替换null值</span></span><br><span class="line">df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+---------------------+</span><br><span class="line">|userid|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level |</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+---------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|        null|             3|         0|                    3|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                    2|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                 null|</span><br><span class="line">|  1670|        0|           4|                2|        4|        null|             1|         0|                 null|</span><br><span class="line">|  2545|        0|          10|                1|        4|        null|             3|         0|                 null|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                    2|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                    2|</span><br><span class="line">|  6211|        0|           9|                1|        3|        null|             3|         0|                    2|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                    4|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                    1|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                    2|</span><br><span class="line">|  9293|        0|           5|                2|        5|        null|             3|         0|                    4|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                    2|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                    2|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                 null|</span><br><span class="line">| 10812|        0|           4|                2|        4|        null|             2|         0|                 null|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                 null|</span><br><span class="line">| 10996|        0|           5|                2|        5|        null|             3|         0|                    4|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                    3|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                    4|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+---------------------+</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意：这里的null会直接被pyspark识别为None数据，也就是na数据，所以这里可以直接利用schema导入数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建表结构schema对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cms_segid&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cms_group_id&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;final_gender_code&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;age_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;pvalue_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;shopping_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;occupation&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;new_user_class_level&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 利用schema从hdfs加载</span></span><br><span class="line">user_profile_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/csv/user_profile.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line">user_profile_df.printSchema()</span><br><span class="line">user_profile_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cms_segid: integer (nullable = true)</span><br><span class="line"> |-- cms_group_id: integer (nullable = true)</span><br><span class="line"> |-- final_gender_code: integer (nullable = true)</span><br><span class="line"> |-- age_level: integer (nullable = true)</span><br><span class="line"> |-- pvalue_level: integer (nullable = true)</span><br><span class="line"> |-- shopping_level: integer (nullable = true)</span><br><span class="line"> |-- occupation: integer (nullable = true)</span><br><span class="line"> |-- new_user_class_level: integer (nullable = true)</span><br><span class="line"></span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|        null|             3|         0|                   3|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                null|</span><br><span class="line">|  1670|        0|           4|                2|        4|        null|             1|         0|                null|</span><br><span class="line">|  2545|        0|          10|                1|        4|        null|             3|         0|                null|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|</span><br><span class="line">|  6211|        0|           9|                1|        3|        null|             3|         0|                   2|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|</span><br><span class="line">|  9293|        0|           5|                2|        5|        null|             3|         0|                   4|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                null|</span><br><span class="line">| 10812|        0|           4|                2|        4|        null|             2|         0|                null|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                null|</span><br><span class="line">| 10996|        0|           5|                2|        5|        null|             3|         0|                   4|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>显示特征情况</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;分类特征值个数情况: &quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;cms_segid: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;cms_segid&quot;</span>).count().count())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;cms_group_id: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;cms_group_id&quot;</span>).count().count())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;final_gender_code: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;final_gender_code&quot;</span>).count().count())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;age_level: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;age_level&quot;</span>).count().count())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;shopping_level: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;shopping_level&quot;</span>).count().count())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;occupation: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;occupation&quot;</span>).count().count())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;含缺失值的特征情况: &quot;</span>)</span><br><span class="line">user_profile_df.groupBy(<span class="string">&quot;pvalue_level&quot;</span>).count().show()</span><br><span class="line">user_profile_df.groupBy(<span class="string">&quot;new_user_class_level&quot;</span>).count().show()</span><br><span class="line"></span><br><span class="line">t_count = user_profile_df.count()</span><br><span class="line">pl_na_count = t_count - user_profile_df.dropna(subset=[<span class="string">&quot;pvalue_level&quot;</span>]).count()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pvalue_level的空值情况：&quot;</span>, pl_na_count, <span class="string">&quot;空值占比：%0.2f%%&quot;</span>%(pl_na_count/t_count*<span class="number">100</span>))</span><br><span class="line">nul_na_count = t_count - user_profile_df.dropna(subset=[<span class="string">&quot;new_user_class_level&quot;</span>]).count()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;new_user_class_level的空值情况：&quot;</span>, nul_na_count, <span class="string">&quot;空值占比：%0.2f%%&quot;</span>%(nul_na_count/t_count*<span class="number">100</span>))</span><br></pre></td></tr></table></figure><p>显示内容:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">分类特征值个数情况: </span><br><span class="line">cms_segid:  97</span><br><span class="line">cms_group_id:  13</span><br><span class="line">final_gender_code:  2</span><br><span class="line">age_level:  7</span><br><span class="line">shopping_level:  3</span><br><span class="line">occupation:  2</span><br><span class="line">含缺失值的特征情况: </span><br><span class="line">+------------+------+</span><br><span class="line">|pvalue_level| count|</span><br><span class="line">+------------+------+</span><br><span class="line">|        null|575917|</span><br><span class="line">|           1|154436|</span><br><span class="line">|           3| 37759|</span><br><span class="line">|           2|293656|</span><br><span class="line">+------------+------+</span><br><span class="line"></span><br><span class="line">+--------------------+------+</span><br><span class="line">|new_user_class_level| count|</span><br><span class="line">+--------------------+------+</span><br><span class="line">|                null|344920|</span><br><span class="line">|                   1| 80548|</span><br><span class="line">|                   3|173047|</span><br><span class="line">|                   4|138833|</span><br><span class="line">|                   2|324420|</span><br><span class="line">+--------------------+------+</span><br><span class="line"></span><br><span class="line">pvalue_level的空值情况： 575917 空值占比：54.24%</span><br><span class="line">new_user_class_level的空值情况： 344920 空值占比：32.49%</span><br></pre></td></tr></table></figure><ul><li><p>缺失值处理</p><ul><li><p>注意，一般情况下：</p><ul><li>缺失率低于10%：可直接进行相应的填充，如默认值、均值、算法拟合等等；</li><li>高于10%：往往会考虑舍弃该特征</li><li>特征处理，如1维转多维</li></ul><p>但根据我们的经验，我们的广告推荐其实和用户的消费水平、用户所在城市等级都有比较大的关联，因此在这里pvalue_level、new_user_class_level都是比较重要的特征，我们不考虑舍弃</p></li></ul></li><li><p>缺失值处理方案：</p><ul><li>填充方案：结合用户的其他特征值，利用随机森林算法进行预测；但产生了大量人为构建的数据，一定程度上增加了数据的噪音</li><li>把变量映射到高维空间：如pvalue_level的1维数据，转换成是否1、是否2、是否3、是否缺失的4维数据；这样保证了所有原始数据不变，同时能提高精确度，但这样会导致数据变得比较稀疏，如果样本量很小，反而会导致样本效果较差，因此也不能滥用</li></ul></li><li><p>填充方案</p><ul><li>利用随机森林对pvalue_level的缺失值进行预测</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</span><br><span class="line"></span><br><span class="line"><span class="comment"># 剔除掉缺失值数据，将余下的数据作为训练数据</span></span><br><span class="line"><span class="comment"># user_profile_df.dropna(subset=[&quot;pvalue_level&quot;])： 将pvalue_level中的空值所在行数据剔除后的数据，作为训练样本</span></span><br><span class="line">train_data = user_profile_df.dropna(subset=[<span class="string">&quot;pvalue_level&quot;</span>]).rdd.<span class="built_in">map</span>(</span><br><span class="line">    <span class="keyword">lambda</span> r:LabeledPoint(r.pvalue_level-<span class="number">1</span>, [r.cms_segid, r.cms_group_id, r.final_gender_code, r.age_level, r.shopping_level, r.occupation])</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意随机森林输入数据时，由于label的分类数是从0开始的，但pvalue_level的目前只分别是1，2，3，所以需要对应分别-1来作为目标值</span></span><br><span class="line"><span class="comment"># 自然那么最终得出预测值后，需要对应+1才能还原回来</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们使用cms_segid, cms_group_id, final_gender_code, age_level, shopping_level, occupation作为特征值，pvalue_level作为目标值</span></span><br></pre></td></tr></table></figure><ul><li>Labeled point</li></ul><p>A labeled point is a local vector, either dense or sparse, associated with a label/response. In MLlib, labeled points are used in supervised learning algorithms. We use a double to store a label, so we can use labeled points in both regression and classification. For binary classification, a label should be either 0 (negative) or 1 (positive). For multiclass classification, labels should be class indices starting from zero: 0, 1, 2, ….<br>标记点是与标签/响应相关联的密集或稀疏的局部矢量。在MLlib中，标记点用于监督学习算法。我们使用double来存储标签，因此我们可以在回归和分类中使用标记点。对于二进制分类，标签应为0（负）或1（正）。对于多类分类，标签应该是从零开始的类索引：0, 1, 2, …。</p><p><strong>Python</strong><br>A labeled point is represented by LabeledPoint.<br>标记点表示为 LabeledPoint。<br>Refer to the LabeledPoint Python docs for more details on the API.<br>有关API的更多详细信息，请参阅LabeledPointPython文档。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.linalg <span class="keyword">import</span> SparseVector</span><br><span class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a labeled point with a positive label and a dense feature vector.</span></span><br><span class="line">pos = LabeledPoint(<span class="number">1.0</span>, [<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a labeled point with a negative label and a sparse feature vector.</span></span><br><span class="line">neg = LabeledPoint(<span class="number">0.0</span>, SparseVector(<span class="number">3</span>, [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">1.0</span>, <span class="number">3.0</span>]))</span><br></pre></td></tr></table></figure><ul><li>随机森林：<a href="https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=randomforest#pyspark.mllib.tree.RandomForest">pyspark.mllib.tree.RandomForest</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.tree <span class="keyword">import</span> RandomForest</span><br><span class="line"><span class="comment"># 训练分类模型</span></span><br><span class="line"><span class="comment"># 参数1 训练的数据</span></span><br><span class="line"><span class="comment">#参数2 目标值的分类个数 0,1,2</span></span><br><span class="line"><span class="comment">#参数3 特征中是否包含分类的特征 &#123;2:2,3:7&#125; &#123;2:2&#125; 表示 在特征中 第二个特征是分类的: 有两个分类</span></span><br><span class="line"><span class="comment">#参数4 随机森林中 树的棵数</span></span><br><span class="line">model = RandomForest.trainClassifier(train_data, <span class="number">3</span>, &#123;&#125;, <span class="number">5</span>)</span><br></pre></td></tr></table></figure><ul><li>随机森林模型：<a href="https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=randomforest#pyspark.mllib.tree.RandomForestModel">pyspark.mllib.tree.RandomForestModel</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测单个数据</span></span><br><span class="line"><span class="comment"># 注意用法：https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=tree%20random#pyspark.mllib.tree.RandomForestModel.predict</span></span><br><span class="line">model.predict([<span class="number">0.0</span>, <span class="number">4.0</span> ,<span class="number">2.0</span> , <span class="number">4.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>])</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.0</span><br></pre></td></tr></table></figure><ul><li>筛选出缺失值条目</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">pl_na_df = user_profile_df.na.fill(-<span class="number">1</span>).where(<span class="string">&quot;pvalue_level=-1&quot;</span>)</span><br><span class="line">pl_na_df.show(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">row</span>(<span class="params">r</span>):</span></span><br><span class="line">    <span class="keyword">return</span> r.cms_segid, r.cms_group_id, r.final_gender_code, r.age_level, r.shopping_level, r.occupation</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为普通的rdd类型</span></span><br><span class="line">rdd = pl_na_df.rdd.<span class="built_in">map</span>(row)</span><br><span class="line"><span class="comment"># 预测全部的pvalue_level值:</span></span><br><span class="line">predicts = model.predict(rdd)</span><br><span class="line"><span class="comment"># 查看前20条</span></span><br><span class="line"><span class="built_in">print</span>(predicts.take(<span class="number">20</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测值总数&quot;</span>, predicts.count())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里注意predict参数，如果是预测多个，那么参数必须是直接有列表构成的rdd参数，而不能是dataframe.rdd类型</span></span><br><span class="line"><span class="comment"># 因此这里经过map函数处理，将每一行数据转换为普通的列表数据</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">| 11602|        0|           5|                2|        5|          -1|             3|         0|                   2|</span><br><span class="line">| 11727|        0|           3|                2|        3|          -1|             3|         0|                   1|</span><br><span class="line">| 12195|        0|          10|                1|        4|          -1|             3|         0|                   2|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 10 rows</span><br><span class="line"></span><br><span class="line">[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]</span><br><span class="line">预测值总数 575917</span><br></pre></td></tr></table></figure><ul><li>转换为pandas dataframe</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里数据量比较小，直接转换为pandas dataframe来处理，因为方便，但注意如果数据量较大不推荐，因为这样会把全部数据加载到内存中</span></span><br><span class="line">temp = predicts.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:<span class="built_in">int</span>(x)).collect()</span><br><span class="line">pdf = pl_na_df.toPandas()</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> <span class="comment"># 在pandas df的基础上直接替换掉列数据</span></span><br><span class="line">pdf[<span class="string">&quot;pvalue_level&quot;</span>] = np.array(temp) + <span class="number">1</span>  <span class="comment"># 注意+1 还原预测值</span></span><br><span class="line">pdf</span><br></pre></td></tr></table></figure><ul><li>与非缺失数据进行拼接，完成pvalue_level的缺失值预测</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">new_user_profile_df = user_profile_df.dropna(subset=[<span class="string">&quot;pvalue_level&quot;</span>]).unionAll(spark.createDataFrame(pdf, schema=schema))</span><br><span class="line">new_user_profile_df.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：unionAll的使用，两个df的表结构必须完全一样</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                null|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                null|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                null|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|</span><br><span class="line">| 11739|       20|           3|                2|        3|           2|             3|         0|                   4|</span><br><span class="line">| 12549|       33|           4|                2|        4|           2|             3|         0|                   2|</span><br><span class="line">| 15155|       36|           5|                2|        5|           2|             1|         0|                null|</span><br><span class="line">| 15347|       20|           3|                2|        3|           2|             3|         0|                   3|</span><br><span class="line">| 15455|        8|           2|                2|        2|           2|             3|         0|                   3|</span><br><span class="line">| 15783|        0|           4|                2|        4|           2|             3|         0|                null|</span><br><span class="line">| 16749|        5|           2|                2|        2|           1|             3|         1|                   4|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>利用随机森林对new_user_class_level的缺失值进行预测</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选出new_user_class_level全部的</span></span><br><span class="line">train_data2 = user_profile_df.dropna(subset=[<span class="string">&quot;new_user_class_level&quot;</span>]).rdd.<span class="built_in">map</span>(</span><br><span class="line">    <span class="keyword">lambda</span> r:LabeledPoint(r.new_user_class_level - <span class="number">1</span>, [r.cms_segid, r.cms_group_id, r.final_gender_code, r.age_level, r.shopping_level, r.occupation])</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> pyspark.mllib.tree <span class="keyword">import</span> RandomForest</span><br><span class="line">model2 = RandomForest.trainClassifier(train_data2, <span class="number">4</span>, &#123;&#125;, <span class="number">5</span>)</span><br><span class="line">model2.predict([<span class="number">0.0</span>, <span class="number">4.0</span> ,<span class="number">2.0</span> , <span class="number">4.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>])</span><br><span class="line"><span class="comment"># 预测值实际应该为2</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.0</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">nul_na_df = user_profile_df.na.fill(-<span class="number">1</span>).where(<span class="string">&quot;new_user_class_level=-1&quot;</span>)</span><br><span class="line">nul_na_df.show(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">row</span>(<span class="params">r</span>):</span></span><br><span class="line">    <span class="keyword">return</span> r.cms_segid, r.cms_group_id, r.final_gender_code, r.age_level, r.shopping_level, r.occupation</span><br><span class="line"></span><br><span class="line">rdd2 = nul_na_df.rdd.<span class="built_in">map</span>(row)</span><br><span class="line">predicts2 = model.predict(rdd2)</span><br><span class="line">predicts2.take(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><ul><li>显示结果:</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 12620|        0|           4|                2|        4|          -1|             2|         0|                  -1|</span><br><span class="line">| 14437|        0|           5|                2|        5|          -1|             3|         0|                  -1|</span><br><span class="line">| 14574|        0|           1|                2|        1|          -1|             2|         0|                  -1|</span><br><span class="line">| 14985|        0|          11|                1|        5|          -1|             2|         0|                  -1|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 10 rows</span><br><span class="line"></span><br><span class="line">[1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 0.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 0.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 0.0,</span><br><span class="line"> 0.0,</span><br><span class="line"> 1.0]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>总结：可以发现由于这两个字段的缺失过多，所以预测出来的值已经大大失真，但如果缺失率在10%以下，这种方法是比较有效的一种</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">user_profile_df = user_profile_df.na.fill(-<span class="number">1</span>)</span><br><span class="line">user_profile_df.show()</span><br><span class="line"><span class="comment"># new_df = new_df.withColumn(&quot;pvalue_level&quot;, new_df.pvalue_level.cast(StringType()))\</span></span><br><span class="line"><span class="comment">#     .withColumn(&quot;new_user_class_level&quot;, new_df.new_user_class_level.cast(StringType()))</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>低维转高维方式<ul><li>我们接下来采用将变量映射到高维空间的方法来处理数据，即将缺失项也当做一个单独的特征来对待，保证数据的原始性<br>由于该思想正好和热独编码实现方法一样，因此这里直接使用热独编码方式处理数据</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用热独编码转换pvalue_level的一维数据为多维，其中缺失值单独作为一个特征值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要先将缺失值全部替换为数值，与原有特征一起处理</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line">user_profile_df = user_profile_df.na.fill(-<span class="number">1</span>)</span><br><span class="line">user_profile_df.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 热独编码时，必须先将待处理字段转为字符串类型才可处理</span></span><br><span class="line">user_profile_df = user_profile_df.withColumn(<span class="string">&quot;pvalue_level&quot;</span>, user_profile_df.pvalue_level.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;new_user_class_level&quot;</span>, user_profile_df.new_user_class_level.cast(StringType()))</span><br><span class="line">user_profile_df.printSchema()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对pvalue_level进行热独编码，求值</span></span><br><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;pvalue_level&#x27;</span>, outputCol=<span class="string">&#x27;pl_onehot_feature&#x27;</span>)</span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;pl_onehot_feature&#x27;</span>, outputCol=<span class="string">&#x27;pl_onehot_value&#x27;</span>)</span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_fit = pipeline.fit(user_profile_df)</span><br><span class="line">user_profile_df2 = pipeline_fit.transform(user_profile_df)</span><br><span class="line"><span class="comment"># pl_onehot_value列的值为稀疏向量，存储热独编码的结果</span></span><br><span class="line">user_profile_df2.printSchema()</span><br><span class="line">user_profile_df2.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cms_segid: integer (nullable = true)</span><br><span class="line"> |-- cms_group_id: integer (nullable = true)</span><br><span class="line"> |-- final_gender_code: integer (nullable = true)</span><br><span class="line"> |-- age_level: integer (nullable = true)</span><br><span class="line"> |-- pvalue_level: string (nullable = true)</span><br><span class="line"> |-- shopping_level: integer (nullable = true)</span><br><span class="line"> |-- occupation: integer (nullable = true)</span><br><span class="line"> |-- new_user_class_level: string (nullable = true)</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cms_segid: integer (nullable = true)</span><br><span class="line"> |-- cms_group_id: integer (nullable = true)</span><br><span class="line"> |-- final_gender_code: integer (nullable = true)</span><br><span class="line"> |-- age_level: integer (nullable = true)</span><br><span class="line"> |-- pvalue_level: string (nullable = true)</span><br><span class="line"> |-- shopping_level: integer (nullable = true)</span><br><span class="line"> |-- occupation: integer (nullable = true)</span><br><span class="line"> |-- new_user_class_level: string (nullable = true)</span><br><span class="line"> |-- pl_onehot_feature: double (nullable = false)</span><br><span class="line"> |-- pl_onehot_value: vector (nullable = true)</span><br><span class="line"></span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|pl_onehot_feature|pl_onehot_value|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|              0.0|  (4,[0],[1.0])|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|              2.0|  (4,[2],[1.0])|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|              0.0|  (4,[0],[1.0])|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|              0.0|  (4,[0],[1.0])|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|              0.0|  (4,[0],[1.0])|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|              1.0|  (4,[1],[1.0])|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|              1.0|  (4,[1],[1.0])|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|              1.0|  (4,[1],[1.0])|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|              0.0|  (4,[0],[1.0])|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|              2.0|  (4,[2],[1.0])|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>使用热编码转换new_user_class_level的一维数据为多维</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;new_user_class_level&#x27;</span>, outputCol=<span class="string">&#x27;nucl_onehot_feature&#x27;</span>)</span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;nucl_onehot_feature&#x27;</span>, outputCol=<span class="string">&#x27;nucl_onehot_value&#x27;</span>)</span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_fit = pipeline.fit(user_profile_df2)</span><br><span class="line">user_profile_df3 = pipeline_fit.transform(user_profile_df2)</span><br><span class="line">user_profile_df3.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|pl_onehot_feature|pl_onehot_value|nucl_onehot_feature|nucl_onehot_value|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|              0.0|  (4,[0],[1.0])|                2.0|    (5,[2],[1.0])|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|              2.0|  (4,[2],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|              0.0|  (4,[0],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|              1.0|  (4,[1],[1.0])|                4.0|    (5,[4],[1.0])|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|              2.0|  (4,[2],[1.0])|                2.0|    (5,[2],[1.0])|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>用户特征合并</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line">feature_df = VectorAssembler().setInputCols([<span class="string">&quot;age_level&quot;</span>, <span class="string">&quot;pl_onehot_value&quot;</span>, <span class="string">&quot;nucl_onehot_value&quot;</span>]).setOutputCol(<span class="string">&quot;features&quot;</span>).transform(user_profile_df3)</span><br><span class="line">feature_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|pl_onehot_feature|pl_onehot_value|nucl_onehot_feature|nucl_onehot_value|            features|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+--------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|              0.0|  (4,[0],[1.0])|                2.0|    (5,[2],[1.0])|(10,[0,1,7],[5.0,...|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|              2.0|  (4,[2],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,3,6],[2.0,...|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,2,5],[2.0,...|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,1,5],[4.0,...|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,1,5],[4.0,...|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,2,6],[6.0,...|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,2,6],[5.0,...|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|              0.0|  (4,[0],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,1,6],[3.0,...|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|(10,[0,3,8],[1.0,...|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|              1.0|  (4,[1],[1.0])|                4.0|    (5,[4],[1.0])|(10,[0,2,9],[5.0,...|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,2,6],[2.0,...|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|(10,[0,1,8],[5.0,...|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,2,6],[2.0,...|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,2,6],[4.0,...|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,2,5],[4.0,...|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,1,5],[4.0,...|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,2,5],[4.0,...|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|(10,[0,1,8],[5.0,...|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|              2.0|  (4,[2],[1.0])|                2.0|    (5,[2],[1.0])|(10,[0,3,7],[2.0,...|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|(10,[0,3,8],[4.0,...|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">feature_df.select(<span class="string">&quot;features&quot;</span>).show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+</span><br><span class="line">|            features|</span><br><span class="line">+--------------------+</span><br><span class="line">|(10,[0,1,7],[5.0,...|</span><br><span class="line">|(10,[0,3,6],[2.0,...|</span><br><span class="line">|(10,[0,2,5],[2.0,...|</span><br><span class="line">|(10,[0,1,5],[4.0,...|</span><br><span class="line">|(10,[0,1,5],[4.0,...|</span><br><span class="line">|(10,[0,2,6],[6.0,...|</span><br><span class="line">|(10,[0,2,6],[5.0,...|</span><br><span class="line">|(10,[0,1,6],[3.0,...|</span><br><span class="line">|(10,[0,3,8],[1.0,...|</span><br><span class="line">|(10,[0,2,9],[5.0,...|</span><br><span class="line">|(10,[0,2,6],[2.0,...|</span><br><span class="line">|(10,[0,1,8],[5.0,...|</span><br><span class="line">|(10,[0,2,6],[2.0,...|</span><br><span class="line">|(10,[0,2,6],[4.0,...|</span><br><span class="line">|(10,[0,2,5],[4.0,...|</span><br><span class="line">|(10,[0,1,5],[4.0,...|</span><br><span class="line">|(10,[0,2,5],[4.0,...|</span><br><span class="line">|(10,[0,1,8],[5.0,...|</span><br><span class="line">|(10,[0,3,7],[2.0,...|</span><br><span class="line">|(10,[0,3,8],[4.0,...|</span><br><span class="line">+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>特征选取</li></ul><p>除了前面处理的pvalue_level和new_user_class_level需要作为特征以外，(能体现出用户的购买力特征)，还有：</p><p>前面分析的以下几个分类特征值个数情况:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- cms_segid:  97</span><br><span class="line">- cms_group_id:  13</span><br><span class="line">- final_gender_code:  2</span><br><span class="line">- age_level:  7</span><br><span class="line">- shopping_level:  3</span><br><span class="line">- occupation:  2</span><br><span class="line">-pvalue_level</span><br><span class="line">-new_user_class_level</span><br><span class="line">-price</span><br></pre></td></tr></table></figure><p>根据经验，以上几个分类特征都一定程度能体现用户在购物方面的特征，且类别都较少，都可以用来作为用户特征</p><h2 id="LR实现CTR预估"><a href="#LR实现CTR预估" class="headerlink" title="LR实现CTR预估"></a>LR实现CTR预估</h2><h3 id="Spark逻辑回归-LR-模型使用介绍"><a href="#Spark逻辑回归-LR-模型使用介绍" class="headerlink" title="Spark逻辑回归(LR)模型使用介绍"></a>Spark逻辑回归(LR)模型使用介绍</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本数据集</span></span><br><span class="line">sample_dataset = [</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">37</span>, <span class="number">10</span>, <span class="string">&quot;no&quot;</span>, <span class="number">3</span>, <span class="number">18</span>, <span class="number">7</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">27</span>, <span class="number">4</span>, <span class="string">&quot;no&quot;</span>, <span class="number">4</span>, <span class="number">14</span>, <span class="number">6</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">32</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">1</span>, <span class="number">12</span>, <span class="number">1</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">57</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">5</span>, <span class="number">18</span>, <span class="number">6</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">22</span>, <span class="number">0.75</span>, <span class="string">&quot;no&quot;</span>, <span class="number">2</span>, <span class="number">17</span>, <span class="number">6</span>, <span class="number">3</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">32</span>, <span class="number">1.5</span>, <span class="string">&quot;no&quot;</span>, <span class="number">2</span>, <span class="number">17</span>, <span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>, <span class="number">0.75</span>, <span class="string">&quot;no&quot;</span>, <span class="number">2</span>, <span class="number">12</span>, <span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">57</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">14</span>, <span class="number">4</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">32</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">4</span>, <span class="number">16</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">22</span>, <span class="number">1.5</span>, <span class="string">&quot;no&quot;</span>, <span class="number">4</span>, <span class="number">14</span>, <span class="number">4</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">37</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">20</span>, <span class="number">7</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">27</span>, <span class="number">4</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">4</span>, <span class="number">18</span>, <span class="number">6</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">47</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">5</span>, <span class="number">17</span>, <span class="number">6</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>, <span class="number">1.5</span>, <span class="string">&quot;no&quot;</span>, <span class="number">2</span>, <span class="number">17</span>, <span class="number">5</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">27</span>, <span class="number">4</span>, <span class="string">&quot;no&quot;</span>, <span class="number">4</span>, <span class="number">14</span>, <span class="number">5</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">37</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">1</span>, <span class="number">17</span>, <span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">37</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">4</span>, <span class="number">3</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>, <span class="number">0.75</span>, <span class="string">&quot;no&quot;</span>, <span class="number">3</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>, <span class="number">1.5</span>, <span class="string">&quot;no&quot;</span>, <span class="number">2</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">27</span>, <span class="number">10</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">14</span>, <span class="number">1</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;female&quot;</span>, <span class="number">32</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">3</span>, <span class="number">14</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;female&quot;</span>, <span class="number">27</span>, <span class="number">7</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">4</span>, <span class="number">16</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;male&quot;</span>, <span class="number">42</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">3</span>, <span class="number">18</span>, <span class="number">6</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;female&quot;</span>, <span class="number">42</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">14</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;male&quot;</span>, <span class="number">27</span>, <span class="number">7</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">17</span>, <span class="number">5</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;male&quot;</span>, <span class="number">32</span>, <span class="number">10</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">4</span>, <span class="number">14</span>, <span class="number">4</span>, <span class="number">3</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;male&quot;</span>, <span class="number">47</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">3</span>, <span class="number">16</span>, <span class="number">4</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">37</span>, <span class="number">4</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">20</span>, <span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">columns = [<span class="string">&quot;affairs&quot;</span>, <span class="string">&quot;gender&quot;</span>, <span class="string">&quot;age&quot;</span>, <span class="string">&quot;label&quot;</span>, <span class="string">&quot;children&quot;</span>, <span class="string">&quot;religiousness&quot;</span>, <span class="string">&quot;education&quot;</span>, <span class="string">&quot;occupation&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># pandas构建dataframe，方便</span></span><br><span class="line">pdf = pd.DataFrame(sample_dataset, columns=columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换成spark的dataframe</span></span><br><span class="line">df = spark.createDataFrame(pdf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征选取：affairs为目标值，其余为特征值</span></span><br><span class="line">df2 = df.select(<span class="string">&quot;affairs&quot;</span>,<span class="string">&quot;age&quot;</span>, <span class="string">&quot;religiousness&quot;</span>, <span class="string">&quot;education&quot;</span>, <span class="string">&quot;occupation&quot;</span>, <span class="string">&quot;rating&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用于计算特征向量的字段</span></span><br><span class="line">colArray2 = [<span class="string">&quot;age&quot;</span>, <span class="string">&quot;religiousness&quot;</span>, <span class="string">&quot;education&quot;</span>, <span class="string">&quot;occupation&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算出特征向量</span></span><br><span class="line">df3 = VectorAssembler().setInputCols(colArray2).setOutputCol(<span class="string">&quot;features&quot;</span>).transform(df2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;数据集：&quot;</span>)</span><br><span class="line">df3.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#  随机切分为训练集和测试集</span></span><br><span class="line">trainDF, testDF = df3.randomSplit([<span class="number">0.8</span>,<span class="number">0.2</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集：&quot;</span>)</span><br><span class="line">trainDF.show(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集：&quot;</span>)</span><br><span class="line">testDF.show(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">数据集：</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|affairs|age|religiousness|education|occupation|rating|            features|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|      0| 37|            3|       18|         7|     4|[37.0,3.0,18.0,7....|</span><br><span class="line">|      0| 27|            4|       14|         6|     4|[27.0,4.0,14.0,6....|</span><br><span class="line">|      0| 32|            1|       12|         1|     4|[32.0,1.0,12.0,1....|</span><br><span class="line">|      0| 57|            5|       18|         6|     5|[57.0,5.0,18.0,6....|</span><br><span class="line">|      0| 22|            2|       17|         6|     3|[22.0,2.0,17.0,6....|</span><br><span class="line">|      0| 32|            2|       17|         5|     5|[32.0,2.0,17.0,5....|</span><br><span class="line">|      0| 22|            2|       12|         1|     3|[22.0,2.0,12.0,1....|</span><br><span class="line">|      0| 57|            2|       14|         4|     4|[57.0,2.0,14.0,4....|</span><br><span class="line">|      0| 32|            4|       16|         1|     2|[32.0,4.0,16.0,1....|</span><br><span class="line">|      0| 22|            4|       14|         4|     5|[22.0,4.0,14.0,4....|</span><br><span class="line">|      0| 37|            2|       20|         7|     2|[37.0,2.0,20.0,7....|</span><br><span class="line">|      0| 27|            4|       18|         6|     4|[27.0,4.0,18.0,6....|</span><br><span class="line">|      0| 47|            5|       17|         6|     4|[47.0,5.0,17.0,6....|</span><br><span class="line">|      0| 22|            2|       17|         5|     4|[22.0,2.0,17.0,5....|</span><br><span class="line">|      0| 27|            4|       14|         5|     4|[27.0,4.0,14.0,5....|</span><br><span class="line">|      0| 37|            1|       17|         5|     5|[37.0,1.0,17.0,5....|</span><br><span class="line">|      0| 37|            2|       18|         4|     3|[37.0,2.0,18.0,4....|</span><br><span class="line">|      0| 22|            3|       16|         5|     4|[22.0,3.0,16.0,5....|</span><br><span class="line">|      0| 22|            2|       16|         5|     5|[22.0,2.0,16.0,5....|</span><br><span class="line">|      0| 27|            2|       14|         1|     5|[27.0,2.0,14.0,1....|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">训练集：</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|affairs|age|religiousness|education|occupation|rating|            features|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|      0| 32|            1|       12|         1|     4|[32.0,1.0,12.0,1....|</span><br><span class="line">|      0| 37|            3|       18|         7|     4|[37.0,3.0,18.0,7....|</span><br><span class="line">|      0| 22|            2|       17|         6|     3|[22.0,2.0,17.0,6....|</span><br><span class="line">|      0| 32|            2|       17|         5|     5|[32.0,2.0,17.0,5....|</span><br><span class="line">|      0| 57|            5|       18|         6|     5|[57.0,5.0,18.0,6....|</span><br><span class="line">|      0| 57|            2|       14|         4|     4|[57.0,2.0,14.0,4....|</span><br><span class="line">|      0| 22|            2|       17|         5|     4|[22.0,2.0,17.0,5....|</span><br><span class="line">|      0| 22|            4|       14|         4|     5|[22.0,4.0,14.0,4....|</span><br><span class="line">|      0| 27|            4|       18|         6|     4|[27.0,4.0,18.0,6....|</span><br><span class="line">|      0| 37|            2|       20|         7|     2|[37.0,2.0,20.0,7....|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">only showing top 10 rows</span><br><span class="line"></span><br><span class="line">测试集：</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|affairs|age|religiousness|education|occupation|rating|            features|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|      0| 27|            4|       14|         6|     4|[27.0,4.0,14.0,6....|</span><br><span class="line">|      0| 22|            2|       12|         1|     3|[22.0,2.0,12.0,1....|</span><br><span class="line">|      0| 32|            4|       16|         1|     2|[32.0,4.0,16.0,1....|</span><br><span class="line">|      0| 27|            4|       14|         5|     4|[27.0,4.0,14.0,5....|</span><br><span class="line">|      0| 22|            3|       16|         5|     4|[22.0,3.0,16.0,5....|</span><br><span class="line">|      1| 27|            4|       16|         1|     2|[27.0,4.0,16.0,1....|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br></pre></td></tr></table></figure><ul><li>逻辑回归训练模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment"># 创建逻辑回归训练器</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model = lr.setLabelCol(<span class="string">&quot;affairs&quot;</span>).setFeaturesCol(<span class="string">&quot;features&quot;</span>).fit(trainDF)</span><br><span class="line"><span class="comment"># 预测数据</span></span><br><span class="line">model.transform(testDF).show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-------+---+-------------+---------+----------+------+--------------------+--------------------+--------------------+----------+</span><br><span class="line">|affairs|age|religiousness|education|occupation|rating|            features|       rawPrediction|         probability|prediction|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+--------------------+--------------------+----------+</span><br><span class="line">|      0| 27|            4|       14|         6|     4|[27.0,4.0,14.0,6....|[0.39067871041193...|[0.59644607432863...|       0.0|</span><br><span class="line">|      0| 22|            2|       12|         1|     3|[22.0,2.0,12.0,1....|[-2.6754687573263...|[0.06443650129497...|       1.0|</span><br><span class="line">|      0| 32|            4|       16|         1|     2|[32.0,4.0,16.0,1....|[-4.5240336812732...|[0.01072883305878...|       1.0|</span><br><span class="line">|      0| 27|            4|       14|         5|     4|[27.0,4.0,14.0,5....|[0.16206512668426...|[0.54042783360658...|       0.0|</span><br><span class="line">|      0| 22|            3|       16|         5|     4|[22.0,3.0,16.0,5....|[1.69102697292197...|[0.84435916906682...|       0.0|</span><br><span class="line">|      1| 27|            4|       16|         1|     2|[27.0,4.0,16.0,1....|[-4.7969907272012...|[0.00818697014985...|       1.0|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+--------------------+--------------------+----------+</span><br></pre></td></tr></table></figure><h3 id="基于LR的点击率预测模型训练"><a href="#基于LR的点击率预测模型训练" class="headerlink" title="基于LR的点击率预测模型训练"></a>基于LR的点击率预测模型训练</h3><ul><li><p>本小节主要根据广告点击样本数据集(raw_sample)、广告基本特征数据集(ad_feature)、用户基本信息数据集(user_profile)构建出了一个完整的样本数据集，并按日期划分为了训练集(前七天)和测试集(最后一天)，利用逻辑回归进行训练。</p><p>训练模型时，通过对类别特征数据进行处理，一定程度达到提高了模型的效果</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;从HDFS中加载样本数据信息&#x27;&#x27;&#x27;</span></span><br><span class="line">_raw_sample_df1 = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/csv/raw_sample.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># _raw_sample_df1.show()    # 展示数据，默认前20条</span></span><br><span class="line"><span class="comment"># 更改表结构，转换为对应的数据类型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType, LongType, StringType</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">_raw_sample_df2 = _raw_sample_df1.\</span><br><span class="line">    withColumn(<span class="string">&quot;user&quot;</span>, _raw_sample_df1.user.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;userId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;time_stamp&quot;</span>, _raw_sample_df1.time_stamp.cast(LongType())).withColumnRenamed(<span class="string">&quot;time_stamp&quot;</span>, <span class="string">&quot;timestamp&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, _raw_sample_df1.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;pid&quot;</span>, _raw_sample_df1.pid.cast(StringType())).\</span><br><span class="line">    withColumn(<span class="string">&quot;nonclk&quot;</span>, _raw_sample_df1.nonclk.cast(IntegerType())).\</span><br><span class="line">    withColumn(<span class="string">&quot;clk&quot;</span>, _raw_sample_df1.clk.cast(IntegerType()))</span><br><span class="line">_raw_sample_df2.printSchema()</span><br><span class="line">_raw_sample_df2.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本数据pid特征处理</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;pid&#x27;</span>, outputCol=<span class="string">&#x27;pid_feature&#x27;</span>)</span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;pid_feature&#x27;</span>, outputCol=<span class="string">&#x27;pid_value&#x27;</span>)</span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_fit = pipeline.fit(_raw_sample_df2)</span><br><span class="line">raw_sample_df = pipeline_fit.transform(_raw_sample_df2)</span><br><span class="line">raw_sample_df.show()</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;pid和特征的对应关系</span></span><br><span class="line"><span class="string">430548_1007：0</span></span><br><span class="line"><span class="string">430549_1007：1</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- timestamp: long (nullable = true)</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- pid: string (nullable = true)</span><br><span class="line"> |-- nonclk: integer (nullable = true)</span><br><span class="line"> |-- clk: integer (nullable = true)</span><br><span class="line"></span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">|userId| timestamp|adgroupId|        pid|nonclk|clk|</span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">|581738|1494137644|        1|430548_1007|     1|  0|</span><br><span class="line">|449818|1494638778|        3|430548_1007|     1|  0|</span><br><span class="line">|914836|1494650879|        4|430548_1007|     1|  0|</span><br><span class="line">|914836|1494651029|        5|430548_1007|     1|  0|</span><br><span class="line">|399907|1494302958|        8|430548_1007|     1|  0|</span><br><span class="line">|628137|1494524935|        9|430548_1007|     1|  0|</span><br><span class="line">|298139|1494462593|        9|430539_1007|     1|  0|</span><br><span class="line">|775475|1494561036|        9|430548_1007|     1|  0|</span><br><span class="line">|555266|1494307136|       11|430539_1007|     1|  0|</span><br><span class="line">|117840|1494036743|       11|430548_1007|     1|  0|</span><br><span class="line">|739815|1494115387|       11|430539_1007|     1|  0|</span><br><span class="line">|623911|1494625301|       11|430548_1007|     1|  0|</span><br><span class="line">|623911|1494451608|       11|430548_1007|     1|  0|</span><br><span class="line">|421590|1494034144|       11|430548_1007|     1|  0|</span><br><span class="line">|976358|1494156949|       13|430548_1007|     1|  0|</span><br><span class="line">|286630|1494218579|       13|430539_1007|     1|  0|</span><br><span class="line">|286630|1494289247|       13|430539_1007|     1|  0|</span><br><span class="line">|771431|1494153867|       13|430548_1007|     1|  0|</span><br><span class="line">|707120|1494220810|       13|430548_1007|     1|  0|</span><br><span class="line">|530454|1494293746|       13|430548_1007|     1|  0|</span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|userId| timestamp|adgroupId|        pid|nonclk|clk|pid_feature|    pid_value|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|581738|1494137644|        1|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|449818|1494638778|        3|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|914836|1494650879|        4|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|914836|1494651029|        5|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|399907|1494302958|        8|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|628137|1494524935|        9|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|298139|1494462593|        9|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|775475|1494561036|        9|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|555266|1494307136|       11|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|117840|1494036743|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|739815|1494115387|       11|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|623911|1494625301|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|623911|1494451608|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|421590|1494034144|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|976358|1494156949|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|286630|1494218579|       13|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|286630|1494289247|       13|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|771431|1494153867|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|707120|1494220810|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|530454|1494293746|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">&#x27;pid和特征的对应关系\n430548_1007：0\n430549_1007：1\n&#x27;</span><br></pre></td></tr></table></figure><ul><li>从HDFS中加载广告基本信息数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">_ad_feature_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/ad_feature.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改表结构，转换为对应的数据类型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换掉NULL字符串</span></span><br><span class="line">_ad_feature_df = _ad_feature_df.replace(<span class="string">&quot;NULL&quot;</span>, <span class="string">&quot;-1&quot;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">ad_feature_df = _ad_feature_df.\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, _ad_feature_df.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;cate_id&quot;</span>, _ad_feature_df.cate_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;cate_id&quot;</span>, <span class="string">&quot;cateId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;campaign_id&quot;</span>, _ad_feature_df.campaign_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;campaign_id&quot;</span>, <span class="string">&quot;campaignId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;customer&quot;</span>, _ad_feature_df.customer.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;customer&quot;</span>, <span class="string">&quot;customerId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;brand&quot;</span>, _ad_feature_df.brand.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;brand&quot;</span>, <span class="string">&quot;brandId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;price&quot;</span>, _ad_feature_df.price.cast(FloatType()))</span><br><span class="line">ad_feature_df.printSchema()</span><br><span class="line">ad_feature_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- campaignId: integer (nullable = true)</span><br><span class="line"> |-- customerId: integer (nullable = true)</span><br><span class="line"> |-- brandId: integer (nullable = true)</span><br><span class="line"> |-- price: float (nullable = true)</span><br><span class="line"></span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|adgroupId|cateId|campaignId|customerId|brandId|price|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|    63133|  6406|     83237|         1|  95471|170.0|</span><br><span class="line">|   313401|  6406|     83237|         1|  87331|199.0|</span><br><span class="line">|   248909|   392|     83237|         1|  32233| 38.0|</span><br><span class="line">|   208458|   392|     83237|         1| 174374|139.0|</span><br><span class="line">|   110847|  7211|    135256|         2| 145952|32.99|</span><br><span class="line">|   607788|  6261|    387991|         6| 207800|199.0|</span><br><span class="line">|   375706|  4520|    387991|         6|     -1| 99.0|</span><br><span class="line">|    11115|  7213|    139747|         9| 186847| 33.0|</span><br><span class="line">|    24484|  7207|    139744|         9| 186847| 19.0|</span><br><span class="line">|    28589|  5953|    395195|        13|     -1|428.0|</span><br><span class="line">|    23236|  5953|    395195|        13|     -1|368.0|</span><br><span class="line">|   300556|  5953|    395195|        13|     -1|639.0|</span><br><span class="line">|    92560|  5953|    395195|        13|     -1|368.0|</span><br><span class="line">|   590965|  4284|     28145|        14| 454237|249.0|</span><br><span class="line">|   529913|  4284|     70206|        14|     -1|249.0|</span><br><span class="line">|   546930|  4284|     28145|        14|     -1|249.0|</span><br><span class="line">|   639794|  6261|     70206|        14|  37004| 89.9|</span><br><span class="line">|   335413|  4284|     28145|        14|     -1|249.0|</span><br><span class="line">|   794890|  4284|     70206|        14| 454237|249.0|</span><br><span class="line">|   684020|  6261|     70206|        14|  37004| 99.0|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>从HDFS加载用户基本信息数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建表结构schema对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cms_segid&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cms_group_id&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;final_gender_code&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;age_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;pvalue_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;shopping_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;occupation&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;new_user_class_level&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 利用schema从hdfs加载</span></span><br><span class="line">_user_profile_df1 = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/user_profile.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line"><span class="comment"># user_profile_df.printSchema()</span></span><br><span class="line"><span class="comment"># user_profile_df.show()</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;对缺失数据进行特征热编码&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用热编码转换pvalue_level的一维数据为多维，增加n-1个虚拟变量，n为pvalue_level的取值范围</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要先将缺失值全部替换为数值，便于处理，否则会抛出异常</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line">_user_profile_df2 = _user_profile_df1.na.fill(-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># _user_profile_df2.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 热编码时，必须先将待处理字段转为字符串类型才可处理</span></span><br><span class="line">_user_profile_df3 = _user_profile_df2.withColumn(<span class="string">&quot;pvalue_level&quot;</span>, _user_profile_df2.pvalue_level.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;new_user_class_level&quot;</span>, _user_profile_df2.new_user_class_level.cast(StringType()))</span><br><span class="line"><span class="comment"># _user_profile_df3.printSchema()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对pvalue_level进行热编码，求值</span></span><br><span class="line"><span class="comment"># 运行过程是先将pvalue_level转换为一列新的特征数据，然后对该特征数据求出的热编码值，存在了新的一列数据中，类型为一个稀疏矩阵</span></span><br><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;pvalue_level&#x27;</span>, outputCol=<span class="string">&#x27;pl_onehot_feature&#x27;</span>)</span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;pl_onehot_feature&#x27;</span>, outputCol=<span class="string">&#x27;pl_onehot_value&#x27;</span>)</span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_fit = pipeline.fit(_user_profile_df3)</span><br><span class="line">_user_profile_df4 = pipeline_fit.transform(_user_profile_df3)</span><br><span class="line"><span class="comment"># pl_onehot_value列的值为稀疏矩阵，存储热编码的结果</span></span><br><span class="line"><span class="comment"># _user_profile_df4.printSchema()</span></span><br><span class="line"><span class="comment"># _user_profile_df4.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用热编码转换new_user_class_level的一维数据为多维</span></span><br><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;new_user_class_level&#x27;</span>, outputCol=<span class="string">&#x27;nucl_onehot_feature&#x27;</span>)</span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;nucl_onehot_feature&#x27;</span>, outputCol=<span class="string">&#x27;nucl_onehot_value&#x27;</span>)</span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_fit = pipeline.fit(_user_profile_df4)</span><br><span class="line">user_profile_df = pipeline_fit.transform(_user_profile_df4)</span><br><span class="line">user_profile_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|pl_onehot_feature|pl_onehot_value|nucl_onehot_feature|nucl_onehot_value|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|              0.0|  (4,[0],[1.0])|                2.0|    (5,[2],[1.0])|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|              2.0|  (4,[2],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|              0.0|  (4,[0],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|              1.0|  (4,[1],[1.0])|                4.0|    (5,[4],[1.0])|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|              2.0|  (4,[2],[1.0])|                2.0|    (5,[2],[1.0])|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>热编码中：”pvalue_level”特征对应关系:</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+------------+----------------------+</span><br><span class="line">|pvalue_level|pl_onehot_feature     |</span><br><span class="line">+------------+----------------------+</span><br><span class="line">|          -1|                   0.0|</span><br><span class="line">|           3|                   3.0|</span><br><span class="line">|           1|                   2.0|</span><br><span class="line">|           2|                   1.0|</span><br><span class="line">+------------+----------------------+</span><br></pre></td></tr></table></figure><ul><li>“new_user_class_level”的特征对应关系</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------------------------+</span><br><span class="line">|new_user_class_level|nucl_onehot_feature     |</span><br><span class="line">+--------------------+------------------------+</span><br><span class="line">|                  -1|                     0.0|</span><br><span class="line">|                   3|                     2.0|</span><br><span class="line">|                   1|                     4.0|</span><br><span class="line">|                   4|                     3.0|</span><br><span class="line">|                   2|                     1.0|</span><br><span class="line">+--------------------+------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">user_profile_df.groupBy(<span class="string">&quot;pvalue_level&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;pl_onehot_feature&quot;</span>).show()</span><br><span class="line">user_profile_df.groupBy(<span class="string">&quot;new_user_class_level&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;nucl_onehot_feature&quot;</span>).show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">+------------+----------------------+</span><br><span class="line">|pvalue_level|min(pl_onehot_feature)|</span><br><span class="line">+------------+----------------------+</span><br><span class="line">|          -1|                   0.0|</span><br><span class="line">|           3|                   3.0|</span><br><span class="line">|           1|                   2.0|</span><br><span class="line">|           2|                   1.0|</span><br><span class="line">+------------+----------------------+</span><br><span class="line"></span><br><span class="line">+--------------------+------------------------+</span><br><span class="line">|new_user_class_level|min(nucl_onehot_feature)|</span><br><span class="line">+--------------------+------------------------+</span><br><span class="line">|                  -1|                     0.0|</span><br><span class="line">|                   3|                     2.0|</span><br><span class="line">|                   1|                     4.0|</span><br><span class="line">|                   4|                     3.0|</span><br><span class="line">|                   2|                     1.0|</span><br><span class="line">+--------------------+------------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>Dataframe数据合并：<a href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=join#pyspark.sql.DataFrame.join">pyspark.sql.DataFrame.join</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># raw_sample_df和ad_feature_df合并条件</span></span><br><span class="line">condition = [raw_sample_df.adgroupId==ad_feature_df.adgroupId]</span><br><span class="line">_ = raw_sample_df.join(ad_feature_df, condition, <span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># _和user_profile_df合并条件</span></span><br><span class="line">condition2 = [_.userId==user_profile_df.userId]</span><br><span class="line">datasets = _.join(user_profile_df, condition2, <span class="string">&quot;outer&quot;</span>)</span><br><span class="line"><span class="comment"># 查看datasets的结构</span></span><br><span class="line">datasets.printSchema()</span><br><span class="line"><span class="comment"># 查看datasets条目数</span></span><br><span class="line"><span class="built_in">print</span>(datasets.count())</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- timestamp: long (nullable = true)</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- pid: string (nullable = true)</span><br><span class="line"> |-- nonclk: integer (nullable = true)</span><br><span class="line"> |-- clk: integer (nullable = true)</span><br><span class="line"> |-- pid_feature: double (nullable = true)</span><br><span class="line"> |-- pid_value: vector (nullable = true)</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- campaignId: integer (nullable = true)</span><br><span class="line"> |-- customerId: integer (nullable = true)</span><br><span class="line"> |-- brandId: integer (nullable = true)</span><br><span class="line"> |-- price: float (nullable = true)</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cms_segid: integer (nullable = true)</span><br><span class="line"> |-- cms_group_id: integer (nullable = true)</span><br><span class="line"> |-- final_gender_code: integer (nullable = true)</span><br><span class="line"> |-- age_level: integer (nullable = true)</span><br><span class="line"> |-- pvalue_level: string (nullable = true)</span><br><span class="line"> |-- shopping_level: integer (nullable = true)</span><br><span class="line"> |-- occupation: integer (nullable = true)</span><br><span class="line"> |-- new_user_class_level: string (nullable = true)</span><br><span class="line"> |-- pl_onehot_feature: double (nullable = true)</span><br><span class="line"> |-- pl_onehot_value: vector (nullable = true)</span><br><span class="line"> |-- nucl_onehot_feature: double (nullable = true)</span><br><span class="line"> |-- nucl_onehot_value: vector (nullable = true)</span><br><span class="line"></span><br><span class="line">26557961</span><br></pre></td></tr></table></figure><ul><li>训练CTRModel_Normal：直接将对应的特征的特征值组合成对应的特征向量进行训练</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 剔除冗余、不需要的字段</span></span><br><span class="line">useful_cols = [</span><br><span class="line">    <span class="comment"># </span></span><br><span class="line">    <span class="comment"># 时间字段，划分训练集和测试集</span></span><br><span class="line">    <span class="string">&quot;timestamp&quot;</span>,</span><br><span class="line">    <span class="comment"># label目标值字段</span></span><br><span class="line">    <span class="string">&quot;clk&quot;</span>,  </span><br><span class="line">    <span class="comment"># 特征值字段</span></span><br><span class="line">    <span class="string">&quot;pid_value&quot;</span>,       <span class="comment"># 资源位的特征向量</span></span><br><span class="line">    <span class="string">&quot;price&quot;</span>,    <span class="comment"># 广告价格</span></span><br><span class="line">    <span class="string">&quot;cms_segid&quot;</span>,    <span class="comment"># 用户微群ID</span></span><br><span class="line">    <span class="string">&quot;cms_group_id&quot;</span>,    <span class="comment"># 用户组ID</span></span><br><span class="line">    <span class="string">&quot;final_gender_code&quot;</span>,    <span class="comment"># 用户性别特征，[1,2]</span></span><br><span class="line">    <span class="string">&quot;age_level&quot;</span>,    <span class="comment"># 年龄等级，1-</span></span><br><span class="line">    <span class="string">&quot;shopping_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;occupation&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pl_onehot_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;nucl_onehot_value&quot;</span></span><br><span class="line">]</span><br><span class="line"><span class="comment"># 筛选指定字段数据，构建新的数据集</span></span><br><span class="line">datasets_1 = datasets.select(*useful_cols)</span><br><span class="line"><span class="comment"># 由于前面使用的是outer方式合并的数据，产生了部分空值数据，这里必须先剔除掉</span></span><br><span class="line">datasets_1 = datasets_1.dropna()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;剔除空值数据后，还剩：&quot;</span>, datasets_1.count())</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">剔除空值数据后，还剩： 25029435</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>根据特征字段计算出特征向量，并划分出训练数据集和测试数据集</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="comment"># 根据特征字段计算特征向量</span></span><br><span class="line">datasets_1 = VectorAssembler().setInputCols(useful_cols[<span class="number">2</span>:]).setOutputCol(<span class="string">&quot;features&quot;</span>).transform(datasets_1)</span><br><span class="line"><span class="comment"># 训练数据集: 约7天的数据</span></span><br><span class="line">train_datasets_1 = datasets_1.<span class="built_in">filter</span>(datasets_1.timestamp&lt;=(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line"><span class="comment"># 测试数据集：约1天的数据量</span></span><br><span class="line">test_datasets_1 = datasets_1.<span class="built_in">filter</span>(datasets_1.timestamp&gt;(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line"><span class="comment"># 所有的特征的特征向量已经汇总到在features字段中</span></span><br><span class="line">train_datasets_1.show(<span class="number">5</span>)</span><br><span class="line">test_datasets_1.show(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">+----------+---+-------------+------+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">| timestamp|clk|    pid_value| price|cms_segid|cms_group_id|final_gender_code|age_level|shopping_level|occupation|pl_onehot_value|nucl_onehot_value|            features|</span><br><span class="line">+----------+---+-------------+------+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">|1494261938|  0|(2,[1],[1.0])| 108.0|        0|          11|                1|        5|             3|         0|  (4,[0],[1.0])|    (5,[1],[1.0])|(18,[1,2,4,5,6,7,...|</span><br><span class="line">|1494261938|  0|(2,[1],[1.0])|1880.0|        0|          11|                1|        5|             3|         0|  (4,[0],[1.0])|    (5,[1],[1.0])|(18,[1,2,4,5,6,7,...|</span><br><span class="line">|1494553913|  0|(2,[1],[1.0])|2360.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494553913|  0|(2,[1],[1.0])|2200.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494436784|  0|(2,[1],[1.0])|5649.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">+----------+---+-------------+------+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+----------+---+-------------+-----+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">| timestamp|clk|    pid_value|price|cms_segid|cms_group_id|final_gender_code|age_level|shopping_level|occupation|pl_onehot_value|nucl_onehot_value|            features|</span><br><span class="line">+----------+---+-------------+-----+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">|1494677292|  0|(2,[1],[1.0])|176.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494677292|  0|(2,[1],[1.0])|698.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494677292|  0|(2,[1],[1.0])|697.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494684007|  0|(2,[1],[1.0])|247.0|       18|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[4],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494684007|  0|(2,[1],[1.0])|109.0|       18|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[4],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">+----------+---+-------------+-----+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>创建逻辑回归训练器，并训练模型：<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=logisticregression#pyspark.ml.classification.LogisticRegression">LogisticRegression</a>、 <a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=logisticregression#pyspark.ml.classification.LogisticRegressionModel">LogisticRegressionModel</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"><span class="comment"># 设置目标字段、特征值字段并训练</span></span><br><span class="line">model = lr.setLabelCol(<span class="string">&quot;clk&quot;</span>).setFeaturesCol(<span class="string">&quot;features&quot;</span>).fit(train_datasets_1)</span><br><span class="line"><span class="comment"># 对模型进行存储</span></span><br><span class="line">model.save(<span class="string">&quot;hdfs://localhost:9000/models/CTRModel_Normal.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 载入训练好的模型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegressionModel</span><br><span class="line">model = LogisticRegressionModel.load(<span class="string">&quot;hdfs://localhost:9000/models/CTRModel_Normal.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 根据测试数据进行预测</span></span><br><span class="line">result_1 = model.transform(test_datasets_1)</span><br><span class="line"><span class="comment"># 按probability升序排列数据，probability表示预测结果的概率</span></span><br><span class="line"><span class="comment"># 如果预测值是0，其概率是0.9248，那么反之可推出1的可能性就是1-0.9248=0.0752，即点击概率约为7.52%</span></span><br><span class="line"><span class="comment"># 因为前面提到广告的点击率一般都比较低，所以预测值通常都是0，因此通常需要反减得出点击的概率</span></span><br><span class="line">result_1.select(<span class="string">&quot;clk&quot;</span>, <span class="string">&quot;price&quot;</span>, <span class="string">&quot;probability&quot;</span>, <span class="string">&quot;prediction&quot;</span>).sort(<span class="string">&quot;probability&quot;</span>).show(<span class="number">100</span>)</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|clk|      price|         probability|prediction|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|  0|      1.0E8|[0.86822033939259...|       0.0|</span><br><span class="line">|  0|      1.0E8|[0.88410457194969...|       0.0|</span><br><span class="line">|  0|      1.0E8|[0.89175497837562...|       0.0|</span><br><span class="line">|  1|5.5555556E7|[0.92481456486873...|       0.0|</span><br><span class="line">|  0|      1.5E7|[0.93741450446939...|       0.0|</span><br><span class="line">|  0|      1.5E7|[0.93757135079959...|       0.0|</span><br><span class="line">|  0|      1.5E7|[0.93834723093801...|       0.0|</span><br><span class="line">|  0|     1099.0|[0.93972095713786...|       0.0|</span><br><span class="line">|  0|      338.0|[0.93972134993018...|       0.0|</span><br><span class="line">|  0|      311.0|[0.93972136386626...|       0.0|</span><br><span class="line">|  0|      300.0|[0.93972136954393...|       0.0|</span><br><span class="line">|  0|      278.0|[0.93972138089925...|       0.0|</span><br><span class="line">|  0|      188.0|[0.93972142735283...|       0.0|</span><br><span class="line">|  0|      176.0|[0.93972143354663...|       0.0|</span><br><span class="line">|  0|      168.0|[0.93972143767584...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93972144283734...|       0.0|</span><br><span class="line">|  1|      138.0|[0.93972145316035...|       0.0|</span><br><span class="line">|  0|      125.0|[0.93972145987031...|       0.0|</span><br><span class="line">|  0|      119.0|[0.93972146296721...|       0.0|</span><br><span class="line">|  0|       78.0|[0.93972148412937...|       0.0|</span><br><span class="line">|  0|      59.98|[0.93972149343040...|       0.0|</span><br><span class="line">|  0|       58.0|[0.93972149445238...|       0.0|</span><br><span class="line">|  0|       56.0|[0.93972149548468...|       0.0|</span><br><span class="line">|  0|       38.0|[0.93972150477538...|       0.0|</span><br><span class="line">|  1|       35.0|[0.93972150632383...|       0.0|</span><br><span class="line">|  0|       33.0|[0.93972150735613...|       0.0|</span><br><span class="line">|  0|       30.0|[0.93972150890458...|       0.0|</span><br><span class="line">|  0|       27.6|[0.93972151014334...|       0.0|</span><br><span class="line">|  0|       18.0|[0.93972151509838...|       0.0|</span><br><span class="line">|  0|       30.0|[0.93980311191464...|       0.0|</span><br><span class="line">|  0|       28.0|[0.93980311294563...|       0.0|</span><br><span class="line">|  0|       25.0|[0.93980311449212...|       0.0|</span><br><span class="line">|  0|      688.0|[0.93999362023323...|       0.0|</span><br><span class="line">|  0|      339.0|[0.93999379960808...|       0.0|</span><br><span class="line">|  0|      335.0|[0.93999380166395...|       0.0|</span><br><span class="line">|  0|      220.0|[0.93999386077017...|       0.0|</span><br><span class="line">|  0|      176.0|[0.93999388338470...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93999389263610...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93999389263610...|       0.0|</span><br><span class="line">|  1|      149.0|[0.93999389726180...|       0.0|</span><br><span class="line">|  0|      122.5|[0.93999391088191...|       0.0|</span><br><span class="line">|  0|       99.0|[0.93999392296012...|       0.0|</span><br><span class="line">|  0|       88.0|[0.93999392861375...|       0.0|</span><br><span class="line">|  0|       79.0|[0.93999393323945...|       0.0|</span><br><span class="line">|  0|       75.0|[0.93999393529532...|       0.0|</span><br><span class="line">|  0|       68.0|[0.93999393889308...|       0.0|</span><br><span class="line">|  0|       68.0|[0.93999393889308...|       0.0|</span><br><span class="line">|  0|       59.9|[0.93999394305620...|       0.0|</span><br><span class="line">|  0|      44.98|[0.93999395072458...|       0.0|</span><br><span class="line">|  0|       35.5|[0.93999395559698...|       0.0|</span><br><span class="line">|  0|       33.0|[0.93999395688189...|       0.0|</span><br><span class="line">|  0|       32.8|[0.93999395698469...|       0.0|</span><br><span class="line">|  0|       30.0|[0.93999395842379...|       0.0|</span><br><span class="line">|  0|       28.0|[0.93999395945172...|       0.0|</span><br><span class="line">|  0|       19.9|[0.93999396361485...|       0.0|</span><br><span class="line">|  0|       19.8|[0.93999396366625...|       0.0|</span><br><span class="line">|  0|       19.8|[0.93999396366625...|       0.0|</span><br><span class="line">|  0|       12.0|[0.93999396767518...|       0.0|</span><br><span class="line">|  0|        6.7|[0.93999397039920...|       0.0|</span><br><span class="line">|  0|      568.0|[0.94000369247841...|       0.0|</span><br><span class="line">|  0|      398.0|[0.94000377983931...|       0.0|</span><br><span class="line">|  0|      158.0|[0.94000390317214...|       0.0|</span><br><span class="line">|  0|     5718.0|[0.94001886593718...|       0.0|</span><br><span class="line">|  0|     5718.0|[0.94001886593718...|       0.0|</span><br><span class="line">|  1|     5608.0|[0.94001892245145...|       0.0|</span><br><span class="line">|  0|     4120.0|[0.94001968693052...|       0.0|</span><br><span class="line">|  0|     1027.5|[0.94002127571285...|       0.0|</span><br><span class="line">|  0|     1027.5|[0.94002127571285...|       0.0|</span><br><span class="line">|  0|      989.0|[0.94002129549211...|       0.0|</span><br><span class="line">|  0|      672.0|[0.94002145834965...|       0.0|</span><br><span class="line">|  0|      660.0|[0.94002146451460...|       0.0|</span><br><span class="line">|  0|      598.0|[0.94002149636681...|       0.0|</span><br><span class="line">|  0|      598.0|[0.94002149636681...|       0.0|</span><br><span class="line">|  0|      563.0|[0.94002151434789...|       0.0|</span><br><span class="line">|  0|      509.0|[0.94002154209012...|       0.0|</span><br><span class="line">|  0|      509.0|[0.94002154209012...|       0.0|</span><br><span class="line">|  0|      500.0|[0.94002154671382...|       0.0|</span><br><span class="line">|  0|      498.0|[0.94002154774131...|       0.0|</span><br><span class="line">|  0|      440.0|[0.94002157753851...|       0.0|</span><br><span class="line">|  0|      430.0|[0.94002158267595...|       0.0|</span><br><span class="line">|  0|      388.0|[0.94002160425322...|       0.0|</span><br><span class="line">|  0|      369.0|[0.94002161401436...|       0.0|</span><br><span class="line">|  0|      368.0|[0.94002161452811...|       0.0|</span><br><span class="line">|  0|      368.0|[0.94002161452811...|       0.0|</span><br><span class="line">|  0|      368.0|[0.94002161452811...|       0.0|</span><br><span class="line">|  0|      368.0|[0.94002161452811...|       0.0|</span><br><span class="line">|  0|      366.0|[0.94002161555560...|       0.0|</span><br><span class="line">|  0|      366.0|[0.94002161555560...|       0.0|</span><br><span class="line">|  0|      348.0|[0.94002162480299...|       0.0|</span><br><span class="line">|  0|      299.0|[0.94002164997645...|       0.0|</span><br><span class="line">|  0|      299.0|[0.94002164997645...|       0.0|</span><br><span class="line">|  0|      299.0|[0.94002164997645...|       0.0|</span><br><span class="line">|  0|      298.0|[0.94002165049020...|       0.0|</span><br><span class="line">|  0|      297.0|[0.94002165100394...|       0.0|</span><br><span class="line">|  0|      278.0|[0.94002166076508...|       0.0|</span><br><span class="line">|  1|      275.0|[0.94002166230631...|       0.0|</span><br><span class="line">|  0|      275.0|[0.94002166230631...|       0.0|</span><br><span class="line">|  0|      273.0|[0.94002166333380...|       0.0|</span><br><span class="line">|  0|      258.0|[0.94002167103995...|       0.0|</span><br><span class="line">|  0|      256.0|[0.94002167206744...|       0.0|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">only showing top 100 rows</span><br></pre></td></tr></table></figure><ul><li>查看样本中点击的被实际点击的条目的预测情况</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result_1.<span class="built_in">filter</span>(result_1.clk==<span class="number">1</span>).select(<span class="string">&quot;clk&quot;</span>, <span class="string">&quot;price&quot;</span>, <span class="string">&quot;probability&quot;</span>, <span class="string">&quot;prediction&quot;</span>).sort(<span class="string">&quot;probability&quot;</span>).show(<span class="number">100</span>)</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|clk|      price|         probability|prediction|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|  1|5.5555556E7|[0.92481456486873...|       0.0|</span><br><span class="line">|  1|      138.0|[0.93972145316035...|       0.0|</span><br><span class="line">|  1|       35.0|[0.93972150632383...|       0.0|</span><br><span class="line">|  1|      149.0|[0.93999389726180...|       0.0|</span><br><span class="line">|  1|     5608.0|[0.94001892245145...|       0.0|</span><br><span class="line">|  1|      275.0|[0.94002166230631...|       0.0|</span><br><span class="line">|  1|       35.0|[0.94002178560473...|       0.0|</span><br><span class="line">|  1|       49.0|[0.94004219516957...|       0.0|</span><br><span class="line">|  1|      915.0|[0.94021082858784...|       0.0|</span><br><span class="line">|  1|      598.0|[0.94021099096349...|       0.0|</span><br><span class="line">|  1|      568.0|[0.94021100633025...|       0.0|</span><br><span class="line">|  1|      398.0|[0.94021109340848...|       0.0|</span><br><span class="line">|  1|      368.0|[0.94021110877521...|       0.0|</span><br><span class="line">|  1|      299.0|[0.94021114411869...|       0.0|</span><br><span class="line">|  1|      278.0|[0.94021115487539...|       0.0|</span><br><span class="line">|  1|      259.0|[0.94021116460765...|       0.0|</span><br><span class="line">|  1|      258.0|[0.94021116511987...|       0.0|</span><br><span class="line">|  1|      258.0|[0.94021116511987...|       0.0|</span><br><span class="line">|  1|      258.0|[0.94021116511987...|       0.0|</span><br><span class="line">|  1|      195.0|[0.94021119738998...|       0.0|</span><br><span class="line">|  1|      188.0|[0.94021120097554...|       0.0|</span><br><span class="line">|  1|      178.0|[0.94021120609778...|       0.0|</span><br><span class="line">|  1|      159.0|[0.94021121583003...|       0.0|</span><br><span class="line">|  1|      149.0|[0.94021122095226...|       0.0|</span><br><span class="line">|  1|      138.0|[0.94021122658672...|       0.0|</span><br><span class="line">|  1|       58.0|[0.94021126756458...|       0.0|</span><br><span class="line">|  1|       49.0|[0.94021127217459...|       0.0|</span><br><span class="line">|  1|       35.0|[0.94021127934572...|       0.0|</span><br><span class="line">|  1|       25.0|[0.94021128446795...|       0.0|</span><br><span class="line">|  1|     2890.0|[0.94028789742257...|       0.0|</span><br><span class="line">|  1|      220.0|[0.94028926340218...|       0.0|</span><br><span class="line">|  1|      188.0|[0.94031410659516...|       0.0|</span><br><span class="line">|  1|       68.0|[0.94031416796289...|       0.0|</span><br><span class="line">|  1|       58.0|[0.94031417307687...|       0.0|</span><br><span class="line">|  1|      198.0|[0.94035413548387...|       0.0|</span><br><span class="line">|  1|      208.0|[0.94039204931181...|       0.0|</span><br><span class="line">|  1|     8888.0|[0.94045237642030...|       0.0|</span><br><span class="line">|  1|      519.0|[0.94045664687995...|       0.0|</span><br><span class="line">|  1|      478.0|[0.94045666780037...|       0.0|</span><br><span class="line">|  1|      349.0|[0.94045673362308...|       0.0|</span><br><span class="line">|  1|      348.0|[0.94045673413334...|       0.0|</span><br><span class="line">|  1|      316.0|[0.94045675046144...|       0.0|</span><br><span class="line">|  1|      298.0|[0.94045675964600...|       0.0|</span><br><span class="line">|  1|      298.0|[0.94045675964600...|       0.0|</span><br><span class="line">|  1|      199.0|[0.94045681016104...|       0.0|</span><br><span class="line">|  1|      199.0|[0.94045681016104...|       0.0|</span><br><span class="line">|  1|      198.0|[0.94045681067129...|       0.0|</span><br><span class="line">|  1|      187.1|[0.94045681623305...|       0.0|</span><br><span class="line">|  1|      176.0|[0.94045682189685...|       0.0|</span><br><span class="line">|  1|      168.0|[0.94045682597887...|       0.0|</span><br><span class="line">|  1|      160.0|[0.94045683006090...|       0.0|</span><br><span class="line">|  1|      158.0|[0.94045683108140...|       0.0|</span><br><span class="line">|  1|      158.0|[0.94045683108140...|       0.0|</span><br><span class="line">|  1|      135.0|[0.94045684281721...|       0.0|</span><br><span class="line">|  1|      129.0|[0.94045684587872...|       0.0|</span><br><span class="line">|  1|      127.0|[0.94045684689923...|       0.0|</span><br><span class="line">|  1|      125.0|[0.94045684791973...|       0.0|</span><br><span class="line">|  1|      124.0|[0.94045684842999...|       0.0|</span><br><span class="line">|  1|      118.0|[0.94045685149150...|       0.0|</span><br><span class="line">|  1|      109.0|[0.94045685608377...|       0.0|</span><br><span class="line">|  1|      108.0|[0.94045685659402...|       0.0|</span><br><span class="line">|  1|       99.0|[0.94045686118630...|       0.0|</span><br><span class="line">|  1|       98.0|[0.94045686169655...|       0.0|</span><br><span class="line">|  1|       79.8|[0.94045687098314...|       0.0|</span><br><span class="line">|  1|       79.0|[0.94045687139134...|       0.0|</span><br><span class="line">|  1|       77.0|[0.94045687241185...|       0.0|</span><br><span class="line">|  1|       72.5|[0.94045687470798...|       0.0|</span><br><span class="line">|  1|       69.0|[0.94045687649386...|       0.0|</span><br><span class="line">|  1|       68.0|[0.94045687700412...|       0.0|</span><br><span class="line">|  1|       60.0|[0.94045688108613...|       0.0|</span><br><span class="line">|  1|      43.98|[0.94045688926037...|       0.0|</span><br><span class="line">|  1|       40.0|[0.94045689129118...|       0.0|</span><br><span class="line">|  1|       39.9|[0.94045689134220...|       0.0|</span><br><span class="line">|  1|       39.6|[0.94045689149528...|       0.0|</span><br><span class="line">|  1|       32.0|[0.94045689537319...|       0.0|</span><br><span class="line">|  1|       31.0|[0.94045689588345...|       0.0|</span><br><span class="line">|  1|      25.98|[0.94045689844491...|       0.0|</span><br><span class="line">|  1|       23.0|[0.94045689996546...|       0.0|</span><br><span class="line">|  1|       19.0|[0.94045690200647...|       0.0|</span><br><span class="line">|  1|       16.9|[0.94045690307800...|       0.0|</span><br><span class="line">|  1|       10.0|[0.94045690659874...|       0.0|</span><br><span class="line">|  1|        3.5|[0.94045690991538...|       0.0|</span><br><span class="line">|  1|        3.5|[0.94045690991538...|       0.0|</span><br><span class="line">|  1|        0.4|[0.94045691149716...|       0.0|</span><br><span class="line">|  1|     3960.0|[0.94055740378069...|       0.0|</span><br><span class="line">|  1|     3088.0|[0.94055784801535...|       0.0|</span><br><span class="line">|  1|     1689.0|[0.94055856072019...|       0.0|</span><br><span class="line">|  1|      998.0|[0.94055891273943...|       0.0|</span><br><span class="line">|  1|      888.0|[0.94055896877705...|       0.0|</span><br><span class="line">|  1|      788.0|[0.94055901972029...|       0.0|</span><br><span class="line">|  1|      737.0|[0.94055904570133...|       0.0|</span><br><span class="line">|  1|      629.0|[0.94055910071996...|       0.0|</span><br><span class="line">|  1|      599.0|[0.94055911600291...|       0.0|</span><br><span class="line">|  1|      599.0|[0.94055911600291...|       0.0|</span><br><span class="line">|  1|      599.0|[0.94055911600291...|       0.0|</span><br><span class="line">|  1|      499.0|[0.94055916694603...|       0.0|</span><br><span class="line">|  1|      468.0|[0.94055918273839...|       0.0|</span><br><span class="line">|  1|      459.0|[0.94055918732327...|       0.0|</span><br><span class="line">|  1|      399.0|[0.94055921788912...|       0.0|</span><br><span class="line">|  1|      399.0|[0.94055921788912...|       0.0|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">only showing top 100 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>训练CTRModel_AllOneHot</p><ul><li>“pid_value”, 类别型特征，已被转换为多维特征==&gt; 2维</li><li>“price”, 统计型特征 ===&gt; 1维</li><li>“cms_segid”, 类别型特征，约97个分类 ===&gt; 1维</li><li>“cms_group_id”, 类别型特征，约13个分类 ==&gt; 1维</li><li>“final_gender_code”, 类别型特征，2个分类 ==&gt; 1维</li><li>“age_level”, 类别型特征，7个分类 ==&gt; 1维</li><li>“shopping_level”, 类别型特征，3个分类 ==&gt; 1维</li><li>“occupation”, 类别型特征，2个分类 ==&gt; 1维</li><li>“pl_onehot_value”, 类别型特征，已被转换为多维特征 ==&gt; 4维</li><li>“nucl_onehot_value” 类别型特征，已被转换为多维特征 ==&gt; 5维</li></ul><p>类别性特征都可以考虑进行热独编码，将单一变量变为多变量，相当于增加了相关特征的数量</p><ul><li>“cms_segid”, 类别型特征，约97个分类 ===&gt; 97维 舍弃</li><li>“cms_group_id”, 类别型特征，约13个分类 ==&gt; 13维</li><li>“final_gender_code”, 类别型特征，2个分类 ==&gt; 2维</li><li>“age_level”, 类别型特征，7个分类 ==&gt;7维</li><li>“shopping_level”, 类别型特征，3个分类 ==&gt; 3维</li><li>“occupation”, 类别型特征，2个分类 ==&gt; 2维</li></ul><p>但由于cms_segid分类过多，这里考虑舍弃，避免数据过于稀疏</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datasets_1.first()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">datasets_1.first()</span><br><span class="line">datasets_1.first()</span><br><span class="line">Row(timestamp=1494261938, clk=0, pid_value=SparseVector(2, &#123;1: 1.0&#125;), price=1880.0, cms_segid=0, cms_group_id=11, final_gender_code=1, age_level=5, shopping_level=3, occupation=0, pl_onehot_value=SparseVector(4, &#123;0: 1.0&#125;), nucl_onehot_value=SparseVector(5, &#123;1: 1.0&#125;), features=SparseVector(18, &#123;1: 1.0, 2: 1880.0, 4: 11.0, 5: 1.0, 6: 5.0, 7: 3.0, 9: 1.0, 14: 1.0&#125;))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先将下列五列数据转为字符串类型，以便于进行热独编码</span></span><br><span class="line"><span class="comment"># - &quot;cms_group_id&quot;,   类别型特征，约13个分类 ==&gt; 13</span></span><br><span class="line"><span class="comment"># - &quot;final_gender_code&quot;, 类别型特征，2个分类 ==&gt; 2</span></span><br><span class="line"><span class="comment"># - &quot;age_level&quot;,    类别型特征，7个分类 ==&gt;7</span></span><br><span class="line"><span class="comment"># - &quot;shopping_level&quot;,    类别型特征，3个分类 ==&gt; 3</span></span><br><span class="line"><span class="comment"># - &quot;occupation&quot;,    类别型特征，2个分类 ==&gt; 2</span></span><br><span class="line"></span><br><span class="line">datasets_2 = datasets.withColumn(<span class="string">&quot;cms_group_id&quot;</span>, datasets.cms_group_id.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;final_gender_code&quot;</span>, datasets.final_gender_code.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;age_level&quot;</span>, datasets.age_level.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;shopping_level&quot;</span>, datasets.shopping_level.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;occupation&quot;</span>, datasets.occupation.cast(StringType()))</span><br><span class="line">useful_cols_2 = [</span><br><span class="line">    <span class="comment"># 时间值，划分训练集和测试集</span></span><br><span class="line">    <span class="string">&quot;timestamp&quot;</span>,</span><br><span class="line">    <span class="comment"># label目标值</span></span><br><span class="line">    <span class="string">&quot;clk&quot;</span>,  </span><br><span class="line">    <span class="comment"># 特征值</span></span><br><span class="line">    <span class="string">&quot;price&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cms_group_id&quot;</span>,</span><br><span class="line">    <span class="string">&quot;final_gender_code&quot;</span>,</span><br><span class="line">    <span class="string">&quot;age_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;shopping_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;occupation&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pid_value&quot;</span>, </span><br><span class="line">    <span class="string">&quot;pl_onehot_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;nucl_onehot_value&quot;</span></span><br><span class="line">]</span><br><span class="line"><span class="comment"># 筛选指定字段数据</span></span><br><span class="line">datasets_2 = datasets_2.select(*useful_cols_2)</span><br><span class="line"><span class="comment"># 由于前面使用的是outer方式合并的数据，产生了部分空值数据，这里必须先剔除掉</span></span><br><span class="line">datasets_2 = datasets_2.dropna()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="comment"># 热编码处理函数封装</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">oneHotEncoder</span>(<span class="params">col1, col2, col3, data</span>):</span></span><br><span class="line">    stringindexer = StringIndexer(inputCol=col1, outputCol=col2)</span><br><span class="line">    encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=col2, outputCol=col3)</span><br><span class="line">    pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">    pipeline_fit = pipeline.fit(data)</span><br><span class="line">    <span class="keyword">return</span> pipeline_fit.transform(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对这五个字段进行热独编码</span></span><br><span class="line"><span class="comment">#     &quot;cms_group_id&quot;,</span></span><br><span class="line"><span class="comment">#     &quot;final_gender_code&quot;,</span></span><br><span class="line"><span class="comment">#     &quot;age_level&quot;,</span></span><br><span class="line"><span class="comment">#     &quot;shopping_level&quot;,</span></span><br><span class="line"><span class="comment">#     &quot;occupation&quot;,</span></span><br><span class="line">datasets_2 = oneHotEncoder(<span class="string">&quot;cms_group_id&quot;</span>, <span class="string">&quot;cms_group_id_feature&quot;</span>, <span class="string">&quot;cms_group_id_value&quot;</span>, datasets_2)</span><br><span class="line">datasets_2 = oneHotEncoder(<span class="string">&quot;final_gender_code&quot;</span>, <span class="string">&quot;final_gender_code_feature&quot;</span>, <span class="string">&quot;final_gender_code_value&quot;</span>, datasets_2)</span><br><span class="line">datasets_2 = oneHotEncoder(<span class="string">&quot;age_level&quot;</span>, <span class="string">&quot;age_level_feature&quot;</span>, <span class="string">&quot;age_level_value&quot;</span>, datasets_2)</span><br><span class="line">datasets_2 = oneHotEncoder(<span class="string">&quot;shopping_level&quot;</span>, <span class="string">&quot;shopping_level_feature&quot;</span>, <span class="string">&quot;shopping_level_value&quot;</span>, datasets_2)</span><br><span class="line">datasets_2 = oneHotEncoder(<span class="string">&quot;occupation&quot;</span>, <span class="string">&quot;occupation_feature&quot;</span>, <span class="string">&quot;occupation_value&quot;</span>, datasets_2)</span><br></pre></td></tr></table></figure><ul><li>“cms_group_id”特征对应关系：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">+------------+-------------------------+</span><br><span class="line">|cms_group_id|min(cms_group_id_feature)|</span><br><span class="line">+------------+-------------------------+</span><br><span class="line">|           7|                      9.0|</span><br><span class="line">|          11|                      6.0|</span><br><span class="line">|           3|                      0.0|</span><br><span class="line">|           8|                      8.0|</span><br><span class="line">|           0|                     12.0|</span><br><span class="line">|           5|                      3.0|</span><br><span class="line">|           6|                     10.0|</span><br><span class="line">|           9|                      5.0|</span><br><span class="line">|           1|                      7.0|</span><br><span class="line">|          10|                      4.0|</span><br><span class="line">|           4|                      1.0|</span><br><span class="line">|          12|                     11.0|</span><br><span class="line">|           2|                      2.0|</span><br><span class="line">+------------+-------------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>“final_gender_code”特征对应关系：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+------------------------------+</span><br><span class="line">|final_gender_code|min(final_gender_code_feature)|</span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line">|                1|                           1.0|</span><br><span class="line">|                2|                           0.0|</span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>“age_level”特征对应关系：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">+---------+----------------------+</span><br><span class="line">|age_level|min(age_level_feature)|</span><br><span class="line">+---------+----------------------+</span><br><span class="line">|        3|                   0.0|</span><br><span class="line">|        0|                   6.0|</span><br><span class="line">|        5|                   2.0|</span><br><span class="line">|        6|                   5.0|</span><br><span class="line">|        1|                   4.0|</span><br><span class="line">|        4|                   1.0|</span><br><span class="line">|        2|                   3.0|</span><br><span class="line">+---------+----------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>“shopping_level”特征对应关系：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">|shopping_level|min(shopping_level_feature)|</span><br><span class="line">+--------------+---------------------------+</span><br><span class="line">|             3|                        0.0|</span><br><span class="line">|             1|                        2.0|</span><br><span class="line">|             2|                        1.0|</span><br><span class="line">+--------------+---------------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>“occupation”特征对应关系：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+----------+-----------------------+</span><br><span class="line">|occupation|min(occupation_feature)|</span><br><span class="line">+----------+-----------------------+</span><br><span class="line">|         0|                    0.0|</span><br><span class="line">|         1|                    1.0|</span><br><span class="line">+----------+-----------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">datasets_2.groupBy(<span class="string">&quot;cms_group_id&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;cms_group_id_feature&quot;</span>).show()</span><br><span class="line">datasets_2.groupBy(<span class="string">&quot;final_gender_code&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;final_gender_code_feature&quot;</span>).show()</span><br><span class="line">datasets_2.groupBy(<span class="string">&quot;age_level&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;age_level_feature&quot;</span>).show()</span><br><span class="line">datasets_2.groupBy(<span class="string">&quot;shopping_level&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;shopping_level_feature&quot;</span>).show()</span><br><span class="line">datasets_2.groupBy(<span class="string">&quot;occupation&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;occupation_feature&quot;</span>).show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">+------------+-------------------------+</span><br><span class="line">|cms_group_id|min(cms_group_id_feature)|</span><br><span class="line">+------------+-------------------------+</span><br><span class="line">|           7|                      9.0|</span><br><span class="line">|          11|                      6.0|</span><br><span class="line">|           3|                      0.0|</span><br><span class="line">|           8|                      8.0|</span><br><span class="line">|           0|                     12.0|</span><br><span class="line">|           5|                      3.0|</span><br><span class="line">|           6|                     10.0|</span><br><span class="line">|           9|                      5.0|</span><br><span class="line">|           1|                      7.0|</span><br><span class="line">|          10|                      4.0|</span><br><span class="line">|           4|                      1.0|</span><br><span class="line">|          12|                     11.0|</span><br><span class="line">|           2|                      2.0|</span><br><span class="line">+------------+-------------------------+</span><br><span class="line"></span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line">|final_gender_code|min(final_gender_code_feature)|</span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line">|                1|                           1.0|</span><br><span class="line">|                2|                           0.0|</span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line"></span><br><span class="line">+---------+----------------------+</span><br><span class="line">|age_level|min(age_level_feature)|</span><br><span class="line">+---------+----------------------+</span><br><span class="line">|        3|                   0.0|</span><br><span class="line">|        0|                   6.0|</span><br><span class="line">|        5|                   2.0|</span><br><span class="line">|        6|                   5.0|</span><br><span class="line">|        1|                   4.0|</span><br><span class="line">|        4|                   1.0|</span><br><span class="line">|        2|                   3.0|</span><br><span class="line">+---------+----------------------+</span><br><span class="line"></span><br><span class="line">+--------------+---------------------------+</span><br><span class="line">|shopping_level|min(shopping_level_feature)|</span><br><span class="line">+--------------+---------------------------+</span><br><span class="line">|             3|                        0.0|</span><br><span class="line">|             1|                        2.0|</span><br><span class="line">|             2|                        1.0|</span><br><span class="line">+--------------+---------------------------+</span><br><span class="line"></span><br><span class="line">+----------+-----------------------+</span><br><span class="line">|occupation|min(occupation_feature)|</span><br><span class="line">+----------+-----------------------+</span><br><span class="line">|         0|                    0.0|</span><br><span class="line">|         1|                    1.0|</span><br><span class="line">+----------+-----------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由于热独编码后，特征字段不再是之前的字段，重新定义特征值字段</span></span><br><span class="line">feature_cols = [</span><br><span class="line">    <span class="comment"># 特征值</span></span><br><span class="line">    <span class="string">&quot;price&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cms_group_id_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;final_gender_code_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;age_level_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;shopping_level_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;occupation_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pid_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pl_onehot_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;nucl_onehot_value&quot;</span></span><br><span class="line">]</span><br><span class="line"><span class="comment"># 根据特征字段计算出特征向量，并划分出训练数据集和测试数据集</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line">datasets_2 = VectorAssembler().setInputCols(feature_cols).setOutputCol(<span class="string">&quot;features&quot;</span>).transform(datasets_2)</span><br><span class="line">train_datasets_2 = datasets_2.<span class="built_in">filter</span>(datasets_2.timestamp&lt;=(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line">test_datasets_2 = datasets_2.<span class="built_in">filter</span>(datasets_2.timestamp&gt;(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line">train_datasets_2.printSchema()</span><br><span class="line">train_datasets_2.first()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- timestamp: long (nullable = true)</span><br><span class="line"> |-- clk: integer (nullable = true)</span><br><span class="line"> |-- price: float (nullable = true)</span><br><span class="line"> |-- cms_group_id: string (nullable = true)</span><br><span class="line"> |-- final_gender_code: string (nullable = true)</span><br><span class="line"> |-- age_level: string (nullable = true)</span><br><span class="line"> |-- shopping_level: string (nullable = true)</span><br><span class="line"> |-- occupation: string (nullable = true)</span><br><span class="line"> |-- pid_value: vector (nullable = true)</span><br><span class="line"> |-- pl_onehot_value: vector (nullable = true)</span><br><span class="line"> |-- nucl_onehot_value: vector (nullable = true)</span><br><span class="line"> |-- cms_group_id_feature: double (nullable = false)</span><br><span class="line"> |-- cms_group_id_value: vector (nullable = true)</span><br><span class="line"> |-- final_gender_code_feature: double (nullable = false)</span><br><span class="line"> |-- final_gender_code_value: vector (nullable = true)</span><br><span class="line"> |-- age_level_feature: double (nullable = false)</span><br><span class="line"> |-- age_level_value: vector (nullable = true)</span><br><span class="line"> |-- shopping_level_feature: double (nullable = false)</span><br><span class="line"> |-- shopping_level_value: vector (nullable = true)</span><br><span class="line"> |-- occupation_feature: double (nullable = false)</span><br><span class="line"> |-- occupation_value: vector (nullable = true)</span><br><span class="line"> |-- features: vector (nullable = true)</span><br><span class="line"></span><br><span class="line">Row(timestamp=1494261938, clk=0, price=108.0, cms_group_id=&#x27;11&#x27;, final_gender_code=&#x27;1&#x27;, age_level=&#x27;5&#x27;, shopping_level=&#x27;3&#x27;, occupation=&#x27;0&#x27;, pid_value=SparseVector(2, &#123;1: 1.0&#125;), pl_onehot_value=SparseVector(4, &#123;0: 1.0&#125;), nucl_onehot_value=SparseVector(5, &#123;1: 1.0&#125;), cms_group_id_feature=6.0, cms_group_id_value=SparseVector(13, &#123;6: 1.0&#125;), final_gender_code_feature=1.0, final_gender_code_value=SparseVector(2, &#123;1: 1.0&#125;), age_level_feature=2.0, age_level_value=SparseVector(7, &#123;2: 1.0&#125;), shopping_level_feature=0.0, shopping_level_value=SparseVector(3, &#123;0: 1.0&#125;), occupation_feature=0.0, occupation_value=SparseVector(2, &#123;0: 1.0&#125;), features=SparseVector(39, &#123;0: 108.0, 7: 1.0, 15: 1.0, 18: 1.0, 23: 1.0, 26: 1.0, 29: 1.0, 30: 1.0, 35: 1.0&#125;))</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>创建逻辑回归训练器，并训练模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr2 = LogisticRegression()</span><br><span class="line"><span class="comment">#设置目标值对应的列   setFeaturesCol 设置特征值对应的列名</span></span><br><span class="line">model2 = lr2.setLabelCol(<span class="string">&quot;clk&quot;</span>).setFeaturesCol(<span class="string">&quot;features&quot;</span>).fit(train_datasets_2)</span><br><span class="line"><span class="comment"># 存储模型</span></span><br><span class="line">model2.save(<span class="string">&quot;hdfs://localhost:9000/models/CTRModel_AllOneHot.obj&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegressionModel</span><br><span class="line"><span class="comment"># 载入训练好的模型</span></span><br><span class="line">model2 = LogisticRegressionModel.load(<span class="string">&quot;hdfs://localhost:9000/models/CTRModel_AllOneHot.obj&quot;</span>)</span><br><span class="line">result_2 = model2.transform(test_datasets_2)</span><br><span class="line"><span class="comment"># 按probability升序排列数据，probability表示预测结果的概率</span></span><br><span class="line">result_2.select(<span class="string">&quot;clk&quot;</span>, <span class="string">&quot;price&quot;</span>, <span class="string">&quot;probability&quot;</span>, <span class="string">&quot;prediction&quot;</span>).sort(<span class="string">&quot;probability&quot;</span>).show(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对比前面的result_1的预测结果，能发现这里的预测率稍微准确了一点，这里top20里出现了3个点击的，但前面的只出现了1个</span></span><br><span class="line"><span class="comment"># 因此可见对特征的细化处理，已经帮助我们提高模型的效果的</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|clk|      price|         probability|prediction|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|  0|      1.0E8|[0.85524418892857...|       0.0|</span><br><span class="line">|  0|      1.0E8|[0.88353143762124...|       0.0|</span><br><span class="line">|  0|      1.0E8|[0.89169808985616...|       0.0|</span><br><span class="line">|  1|5.5555556E7|[0.92511743960350...|       0.0|</span><br><span class="line">|  0|     179.01|[0.93239951738307...|       0.0|</span><br><span class="line">|  1|      159.0|[0.93239952905659...|       0.0|</span><br><span class="line">|  0|      118.0|[0.93239955297535...|       0.0|</span><br><span class="line">|  0|      688.0|[0.93451506165953...|       0.0|</span><br><span class="line">|  0|      339.0|[0.93451525933626...|       0.0|</span><br><span class="line">|  0|      335.0|[0.93451526160190...|       0.0|</span><br><span class="line">|  0|      220.0|[0.93451532673881...|       0.0|</span><br><span class="line">|  0|      176.0|[0.93451535166074...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93451536185607...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93451536185607...|       0.0|</span><br><span class="line">|  1|      149.0|[0.93451536695374...|       0.0|</span><br><span class="line">|  0|      122.5|[0.93451538196353...|       0.0|</span><br><span class="line">|  0|       99.0|[0.93451539527410...|       0.0|</span><br><span class="line">|  0|       88.0|[0.93451540150458...|       0.0|</span><br><span class="line">|  0|       79.0|[0.93451540660224...|       0.0|</span><br><span class="line">|  0|       75.0|[0.93451540886787...|       0.0|</span><br><span class="line">|  0|       68.0|[0.93451541283272...|       0.0|</span><br><span class="line">|  0|       68.0|[0.93451541283272...|       0.0|</span><br><span class="line">|  0|       59.9|[0.93451541742061...|       0.0|</span><br><span class="line">|  0|      44.98|[0.93451542587140...|       0.0|</span><br><span class="line">|  0|       35.5|[0.93451543124094...|       0.0|</span><br><span class="line">|  0|       33.0|[0.93451543265696...|       0.0|</span><br><span class="line">|  0|       32.8|[0.93451543277024...|       0.0|</span><br><span class="line">|  0|       30.0|[0.93451543435618...|       0.0|</span><br><span class="line">|  0|       28.0|[0.93451543548899...|       0.0|</span><br><span class="line">|  0|       19.9|[0.93451544007688...|       0.0|</span><br><span class="line">|  0|       19.8|[0.93451544013353...|       0.0|</span><br><span class="line">|  0|       19.8|[0.93451544013353...|       0.0|</span><br><span class="line">|  0|       12.0|[0.93451544455150...|       0.0|</span><br><span class="line">|  0|        6.7|[0.93451544755345...|       0.0|</span><br><span class="line">|  0|      568.0|[0.93458159339238...|       0.0|</span><br><span class="line">|  0|      398.0|[0.93458168959099...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93458182540058...|       0.0|</span><br><span class="line">|  0|      245.0|[0.93471518526899...|       0.0|</span><br><span class="line">|  0|       99.0|[0.93471526772971...|       0.0|</span><br><span class="line">|  0|       88.0|[0.93471527394249...|       0.0|</span><br><span class="line">|  0|     1288.0|[0.93474589600376...|       0.0|</span><br><span class="line">|  0|      688.0|[0.93474623473450...|       0.0|</span><br><span class="line">|  0|      656.0|[0.93474625280009...|       0.0|</span><br><span class="line">|  0|      568.0|[0.93474630248045...|       0.0|</span><br><span class="line">|  0|      498.0|[0.93474634199889...|       0.0|</span><br><span class="line">|  0|      399.0|[0.93474639788922...|       0.0|</span><br><span class="line">|  0|      396.0|[0.93474639958287...|       0.0|</span><br><span class="line">|  0|      298.0|[0.93474645490860...|       0.0|</span><br><span class="line">|  0|      293.0|[0.93474645773134...|       0.0|</span><br><span class="line">|  0|      209.0|[0.93474650515337...|       0.0|</span><br><span class="line">|  0|      198.0|[0.93474651136339...|       0.0|</span><br><span class="line">|  0|      198.0|[0.93474651136339...|       0.0|</span><br><span class="line">|  0|      169.0|[0.93474652773527...|       0.0|</span><br><span class="line">|  0|      168.0|[0.93474652829982...|       0.0|</span><br><span class="line">|  0|      159.0|[0.93474653338074...|       0.0|</span><br><span class="line">|  0|      155.0|[0.93474653563893...|       0.0|</span><br><span class="line">|  0|      139.0|[0.93474654467169...|       0.0|</span><br><span class="line">|  0|      138.0|[0.93474654523624...|       0.0|</span><br><span class="line">|  0|      119.0|[0.93474655596264...|       0.0|</span><br><span class="line">|  0|       99.0|[0.93474656725358...|       0.0|</span><br><span class="line">|  0|       99.0|[0.93474656725358...|       0.0|</span><br><span class="line">|  0|       88.0|[0.93474657346360...|       0.0|</span><br><span class="line">|  0|       88.0|[0.93474657346360...|       0.0|</span><br><span class="line">|  0|       79.0|[0.93474657854453...|       0.0|</span><br><span class="line">|  0|       59.0|[0.93474658983547...|       0.0|</span><br><span class="line">|  0|       59.0|[0.93474658983547...|       0.0|</span><br><span class="line">|  0|       59.0|[0.93474658983547...|       0.0|</span><br><span class="line">|  0|       58.0|[0.93474659040002...|       0.0|</span><br><span class="line">|  0|       57.0|[0.93474659096456...|       0.0|</span><br><span class="line">|  0|       49.8|[0.93474659502930...|       0.0|</span><br><span class="line">|  0|      39.98|[0.93474660057315...|       0.0|</span><br><span class="line">|  0|       36.8|[0.93474660236841...|       0.0|</span><br><span class="line">|  0|       34.0|[0.93474660394914...|       0.0|</span><br><span class="line">|  0|     6520.0|[0.93480919087761...|       0.0|</span><br><span class="line">|  0|     3699.0|[0.93481078202537...|       0.0|</span><br><span class="line">|  0|     1980.0|[0.93481175158689...|       0.0|</span><br><span class="line">|  0|      660.0|[0.93481249609274...|       0.0|</span><br><span class="line">|  0|      660.0|[0.93481249609274...|       0.0|</span><br><span class="line">|  0|      398.0|[0.93481264386492...|       0.0|</span><br><span class="line">|  0|      369.0|[0.93481266022137...|       0.0|</span><br><span class="line">|  0|      299.0|[0.93481269970243...|       0.0|</span><br><span class="line">|  0|      295.0|[0.93481270195849...|       0.0|</span><br><span class="line">|  0|      278.0|[0.93481271154674...|       0.0|</span><br><span class="line">|  0|      270.0|[0.93481271605886...|       0.0|</span><br><span class="line">|  0|      228.0|[0.93481273974748...|       0.0|</span><br><span class="line">|  0|      228.0|[0.93481273974748...|       0.0|</span><br><span class="line">|  0|    11368.0|[0.93494253131370...|       0.0|</span><br><span class="line">|  0|     9999.0|[0.93494330201510...|       0.0|</span><br><span class="line">|  0|     1099.0|[0.93494360670448...|       0.0|</span><br><span class="line">|  1|     8888.0|[0.93494392746484...|       0.0|</span><br><span class="line">|  0|      338.0|[0.93494403511659...|       0.0|</span><br><span class="line">|  0|      311.0|[0.93494405031645...|       0.0|</span><br><span class="line">|  0|      300.0|[0.93494405650898...|       0.0|</span><br><span class="line">|  0|      278.0|[0.93494406889404...|       0.0|</span><br><span class="line">|  0|      188.0|[0.93494411956019...|       0.0|</span><br><span class="line">|  0|      176.0|[0.93494412631568...|       0.0|</span><br><span class="line">|  0|      168.0|[0.93494413081933...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93494413644890...|       0.0|</span><br><span class="line">|  1|      138.0|[0.93494414770804...|       0.0|</span><br><span class="line">|  0|      125.0|[0.93494415502647...|       0.0|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">only showing top 100 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result_2.<span class="built_in">filter</span>(result_2.clk==<span class="number">1</span>).select(<span class="string">&quot;clk&quot;</span>, <span class="string">&quot;price&quot;</span>, <span class="string">&quot;probability&quot;</span>, <span class="string">&quot;prediction&quot;</span>).sort(<span class="string">&quot;probability&quot;</span>).show(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 从该结果也可以看出，result_2的点击率预测率普遍要比result_1高出一点点</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|clk|      price|         probability|prediction|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|  1|5.5555556E7|[0.92511743960350...|       0.0|</span><br><span class="line">|  1|      159.0|[0.93239952905659...|       0.0|</span><br><span class="line">|  1|      149.0|[0.93451536695374...|       0.0|</span><br><span class="line">|  1|     8888.0|[0.93494392746484...|       0.0|</span><br><span class="line">|  1|      138.0|[0.93494414770804...|       0.0|</span><br><span class="line">|  1|       35.0|[0.93494420569256...|       0.0|</span><br><span class="line">|  1|      519.0|[0.93494863870621...|       0.0|</span><br><span class="line">|  1|      478.0|[0.93494866178596...|       0.0|</span><br><span class="line">|  1|      349.0|[0.93494873440265...|       0.0|</span><br><span class="line">|  1|      348.0|[0.93494873496557...|       0.0|</span><br><span class="line">|  1|      316.0|[0.93494875297901...|       0.0|</span><br><span class="line">|  1|      298.0|[0.93494876311156...|       0.0|</span><br><span class="line">|  1|      298.0|[0.93494876311156...|       0.0|</span><br><span class="line">|  1|      199.0|[0.93494881884058...|       0.0|</span><br><span class="line">|  1|      199.0|[0.93494881884058...|       0.0|</span><br><span class="line">|  1|      198.0|[0.93494881940350...|       0.0|</span><br><span class="line">|  1|      187.1|[0.93494882553931...|       0.0|</span><br><span class="line">|  1|      176.0|[0.93494883178772...|       0.0|</span><br><span class="line">|  1|      168.0|[0.93494883629107...|       0.0|</span><br><span class="line">|  1|      160.0|[0.93494884079442...|       0.0|</span><br><span class="line">|  1|      158.0|[0.93494884192026...|       0.0|</span><br><span class="line">|  1|      158.0|[0.93494884192026...|       0.0|</span><br><span class="line">|  1|      135.0|[0.93494885486740...|       0.0|</span><br><span class="line">|  1|      129.0|[0.93494885824491...|       0.0|</span><br><span class="line">|  1|      127.0|[0.93494885937075...|       0.0|</span><br><span class="line">|  1|      125.0|[0.93494886049659...|       0.0|</span><br><span class="line">|  1|      124.0|[0.93494886105951...|       0.0|</span><br><span class="line">|  1|      118.0|[0.93494886443702...|       0.0|</span><br><span class="line">|  1|      109.0|[0.93494886950329...|       0.0|</span><br><span class="line">|  1|      108.0|[0.93494887006621...|       0.0|</span><br><span class="line">|  1|       99.0|[0.93494887513247...|       0.0|</span><br><span class="line">|  1|       98.0|[0.93494887569539...|       0.0|</span><br><span class="line">|  1|       79.8|[0.93494888594051...|       0.0|</span><br><span class="line">|  1|       79.0|[0.93494888639085...|       0.0|</span><br><span class="line">|  1|       77.0|[0.93494888751668...|       0.0|</span><br><span class="line">|  1|       72.5|[0.93494889004982...|       0.0|</span><br><span class="line">|  1|       69.0|[0.93494889202003...|       0.0|</span><br><span class="line">|  1|       68.0|[0.93494889258295...|       0.0|</span><br><span class="line">|  1|       60.0|[0.93494889708630...|       0.0|</span><br><span class="line">|  1|      43.98|[0.93494890610426...|       0.0|</span><br><span class="line">|  1|       40.0|[0.93494890834467...|       0.0|</span><br><span class="line">|  1|       39.9|[0.93494890840096...|       0.0|</span><br><span class="line">|  1|       39.6|[0.93494890856984...|       0.0|</span><br><span class="line">|  1|       32.0|[0.93494891284802...|       0.0|</span><br><span class="line">|  1|       31.0|[0.93494891341094...|       0.0|</span><br><span class="line">|  1|      25.98|[0.93494891623679...|       0.0|</span><br><span class="line">|  1|       23.0|[0.93494891791428...|       0.0|</span><br><span class="line">|  1|       19.0|[0.93494892016596...|       0.0|</span><br><span class="line">|  1|       16.9|[0.93494892134809...|       0.0|</span><br><span class="line">|  1|       10.0|[0.93494892523222...|       0.0|</span><br><span class="line">|  1|        3.5|[0.93494892889119...|       0.0|</span><br><span class="line">|  1|        3.5|[0.93494892889119...|       0.0|</span><br><span class="line">|  1|        0.4|[0.93494893063624...|       0.0|</span><br><span class="line">|  1|     1288.0|[0.93501426059874...|       0.0|</span><br><span class="line">|  1|      980.0|[0.93501443381533...|       0.0|</span><br><span class="line">|  1|      788.0|[0.93501454179429...|       0.0|</span><br><span class="line">|  1|      698.0|[0.93501459240937...|       0.0|</span><br><span class="line">|  1|      695.0|[0.93501459409654...|       0.0|</span><br><span class="line">|  1|      688.0|[0.93501459803326...|       0.0|</span><br><span class="line">|  1|      599.0|[0.93501464808591...|       0.0|</span><br><span class="line">|  1|      588.0|[0.93501465427219...|       0.0|</span><br><span class="line">|  1|      516.0|[0.93501469476419...|       0.0|</span><br><span class="line">|  1|      495.0|[0.93501470657436...|       0.0|</span><br><span class="line">|  1|      398.0|[0.93501476112603...|       0.0|</span><br><span class="line">|  1|      368.0|[0.93501477799768...|       0.0|</span><br><span class="line">|  1|      339.0|[0.93501479430693...|       0.0|</span><br><span class="line">|  1|      335.0|[0.93501479655648...|       0.0|</span><br><span class="line">|  1|      324.0|[0.93501480274275...|       0.0|</span><br><span class="line">|  1|      316.0|[0.93501480724185...|       0.0|</span><br><span class="line">|  1|      299.0|[0.93501481680244...|       0.0|</span><br><span class="line">|  1|      295.0|[0.93501481905199...|       0.0|</span><br><span class="line">|  1|      279.0|[0.93501482805020...|       0.0|</span><br><span class="line">|  1|      268.0|[0.93501483423646...|       0.0|</span><br><span class="line">|  1|      259.0|[0.93501483929795...|       0.0|</span><br><span class="line">|  1|      259.0|[0.93501483929795...|       0.0|</span><br><span class="line">|  1|      249.0|[0.93501484492182...|       0.0|</span><br><span class="line">|  1|      238.0|[0.93501485110809...|       0.0|</span><br><span class="line">|  1|      199.0|[0.93501487304119...|       0.0|</span><br><span class="line">|  1|      198.0|[0.93501487360358...|       0.0|</span><br><span class="line">|  1|      179.0|[0.93501488428894...|       0.0|</span><br><span class="line">|  1|      175.0|[0.93501488653849...|       0.0|</span><br><span class="line">|  1|      129.0|[0.93501491240829...|       0.0|</span><br><span class="line">|  1|      128.0|[0.93501491297068...|       0.0|</span><br><span class="line">|  1|      118.0|[0.93501491859455...|       0.0|</span><br><span class="line">|  1|      109.0|[0.93501492365603...|       0.0|</span><br><span class="line">|  1|       98.0|[0.93501492984229...|       0.0|</span><br><span class="line">|  1|       89.0|[0.93501493490377...|       0.0|</span><br><span class="line">|  1|       79.0|[0.93501494052764...|       0.0|</span><br><span class="line">|  1|       75.0|[0.93501494277718...|       0.0|</span><br><span class="line">|  1|       69.8|[0.93501494570159...|       0.0|</span><br><span class="line">|  1|       30.0|[0.93501496808458...|       0.0|</span><br><span class="line">|  1|       15.0|[0.93501497652038...|       0.0|</span><br><span class="line">|  1|      368.0|[0.93665387743951...|       0.0|</span><br><span class="line">|  1|      198.0|[0.93665397079735...|       0.0|</span><br><span class="line">|  1|      178.0|[0.93665398178062...|       0.0|</span><br><span class="line">|  1|      158.0|[0.93665399276388...|       0.0|</span><br><span class="line">|  1|      158.0|[0.93665399276388...|       0.0|</span><br><span class="line">|  1|      149.0|[0.93665399770635...|       0.0|</span><br><span class="line">|  1|       68.0|[0.93665404218855...|       0.0|</span><br><span class="line">|  1|       36.0|[0.93665405976176...|       0.0|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">only showing top 100 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="离线推荐数据缓存"><a href="#离线推荐数据缓存" class="headerlink" title="离线推荐数据缓存"></a>离线推荐数据缓存</h2><h3 id="离线数据缓存之离线召回集"><a href="#离线数据缓存之离线召回集" class="headerlink" title="离线数据缓存之离线召回集"></a>离线数据缓存之离线召回集</h3><ul><li><p>这里主要是利用我们前面训练的ALS模型进行协同过滤召回，但是注意，我们ALS模型召回的是用户最感兴趣的类别，而我们需要的是用户可能感兴趣的广告的集合，因此我们还需要根据召回的类别匹配出对应的广告。</p><p>所以这里我们除了需要我们训练的ALS模型以外，还需要有一个广告和类别的对应关系。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从HDFS中加载广告基本信息数据，返回spark dafaframe对象</span></span><br><span class="line">df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/csv/ad_feature.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：由于本数据集中存在NULL字样的数据，无法直接设置schema，只能先将NULL类型的数据处理掉，然后进行类型转换</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换掉NULL字符串，替换掉</span></span><br><span class="line">df = df.replace(<span class="string">&quot;NULL&quot;</span>, <span class="string">&quot;-1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">ad_feature_df = df.\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, df.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;cate_id&quot;</span>, df.cate_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;cate_id&quot;</span>, <span class="string">&quot;cateId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;campaign_id&quot;</span>, df.campaign_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;campaign_id&quot;</span>, <span class="string">&quot;campaignId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;customer&quot;</span>, df.customer.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;customer&quot;</span>, <span class="string">&quot;customerId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;brand&quot;</span>, df.brand.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;brand&quot;</span>, <span class="string">&quot;brandId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;price&quot;</span>, df.price.cast(FloatType()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里我们只需要adgroupId、和cateId</span></span><br><span class="line">_ = ad_feature_df.select(<span class="string">&quot;adgroupId&quot;</span>, <span class="string">&quot;cateId&quot;</span>)</span><br><span class="line"><span class="comment"># 由于这里数据集其实很少，所以我们再直接转成Pandas dataframe来处理，把数据载入内存</span></span><br><span class="line">pdf = _.toPandas()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动释放一些内存</span></span><br><span class="line"><span class="keyword">del</span> df</span><br><span class="line"><span class="keyword">del</span> ad_feature_df</span><br><span class="line"><span class="keyword">del</span> _</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line">gc.collect()</span><br></pre></td></tr></table></figure><ul><li>根据指定的类别找到对应的广告</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">pdf.where(pdf.cateId==<span class="number">11156</span>).dropna().adgroupId</span><br><span class="line"></span><br><span class="line">np.random.choice(pdf.where(pdf.cateId==<span class="number">11156</span>).dropna().adgroupId.astype(np.int64), <span class="number">200</span>)</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">313       138953.0</span><br><span class="line">314       467512.0</span><br><span class="line">1661      140008.0</span><br><span class="line">1666      238772.0</span><br><span class="line">1669      237471.0</span><br><span class="line">1670      238761.0</span><br><span class="line">...   </span><br><span class="line">843456    352273.0</span><br><span class="line">846728    818681.0</span><br><span class="line">846729    838953.0</span><br><span class="line">846810    845337.0</span><br><span class="line">Name: adgroupId, Length: 731, dtype: float64</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>利用ALS模型进行类别的召回</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载als模型，注意必须先有spark上下文管理器，即sparkContext，但这里sparkSession创建后，自动创建了sparkContext</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALSModel</span><br><span class="line"><span class="comment"># 从hdfs加载之前存储的模型</span></span><br><span class="line">als_model = ALSModel.load(<span class="string">&quot;hdfs://localhost:8020/models/userCateRatingALSModel.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 返回模型中关于用户的所有属性   df:   id   features</span></span><br><span class="line">als_model.userFactors</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[id: int, features: array&lt;float&gt;]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">cateId_df = pd.DataFrame(pdf.cateId.unique(),columns=[<span class="string">&quot;cateId&quot;</span>])</span><br><span class="line">cateId_df</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cateId</span><br><span class="line">01</span><br><span class="line">12</span><br><span class="line">23</span><br><span class="line">34</span><br><span class="line">45</span><br><span class="line">56</span><br><span class="line">67</span><br><span class="line">......</span><br><span class="line">676612948</span><br><span class="line">676712955</span><br><span class="line">676812960</span><br><span class="line">6769 rows × 1 columns</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cateId_df.insert(<span class="number">0</span>, <span class="string">&quot;userId&quot;</span>, np.array([<span class="number">8</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6769</span>)]))</span><br><span class="line">cateId_df</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> userId cateId</span><br><span class="line">081</span><br><span class="line">182</span><br><span class="line">283</span><br><span class="line">384</span><br><span class="line">485</span><br><span class="line">.........</span><br><span class="line">6766812948</span><br><span class="line">6767812955</span><br><span class="line">6768812960</span><br><span class="line">6769 rows × 2 columns</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>传入 userid、cataId的df，对应预测值进行排序</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">als_model.transform(spark.createDataFrame(cateId_df)).sort(<span class="string">&quot;prediction&quot;</span>, ascending=<span class="literal">False</span>).na.drop().show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+------+----------+</span><br><span class="line">|userId|cateId|prediction|</span><br><span class="line">+------+------+----------+</span><br><span class="line">|     8|  7214|  9.917084|</span><br><span class="line">|     8|   877|  7.479664|</span><br><span class="line">|     8|  7266| 7.4762917|</span><br><span class="line">|     8| 10856| 7.3395424|</span><br><span class="line">|     8|  4766|  7.149538|</span><br><span class="line">|     8|  7282| 6.6835284|</span><br><span class="line">|     8|  7270| 6.2145095|</span><br><span class="line">|     8|   201| 6.0623236|</span><br><span class="line">|     8|  4267| 5.9155636|</span><br><span class="line">|     8|  7267|  5.838009|</span><br><span class="line">|     8|  5392| 5.6882005|</span><br><span class="line">|     8|  6261| 5.6804466|</span><br><span class="line">|     8|  6306| 5.2992325|</span><br><span class="line">|     8| 11050|  5.245261|</span><br><span class="line">|     8|  8655| 5.1701374|</span><br><span class="line">|     8|  4610|  5.139578|</span><br><span class="line">|     8|   932|   5.12694|</span><br><span class="line">|     8| 12276| 5.0776596|</span><br><span class="line">|     8|  8071|  4.979195|</span><br><span class="line">|     8|  6580| 4.8523283|</span><br><span class="line">+------+------+----------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存储用户召回，使用redis第9号数据库，类型：sets类型</span></span><br><span class="line">client = redis.StrictRedis(host=<span class="string">&quot;192.168.199.188&quot;</span>, port=<span class="number">6379</span>, db=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> als_model.userFactors.select(<span class="string">&quot;id&quot;</span>).collect():</span><br><span class="line">    </span><br><span class="line">    userId = r.<span class="built_in">id</span></span><br><span class="line">    </span><br><span class="line">    cateId_df = pd.DataFrame(pdf.cateId.unique(),columns=[<span class="string">&quot;cateId&quot;</span>])</span><br><span class="line">    cateId_df.insert(<span class="number">0</span>, <span class="string">&quot;userId&quot;</span>, np.array([userId <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6769</span>)]))</span><br><span class="line">    ret = <span class="built_in">set</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 利用模型，传入datasets(userId, cateId)，这里控制了userId一样，所以相当于是在求某用户对所有分类的兴趣程度</span></span><br><span class="line">    cateId_list = als_model.transform(spark.createDataFrame(cateId_df)).sort(<span class="string">&quot;prediction&quot;</span>, ascending=<span class="literal">False</span>).na.drop()</span><br><span class="line">    <span class="comment"># 从前20个分类中选出500个进行召回</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> cateId_list.head(<span class="number">20</span>):</span><br><span class="line">        need = <span class="number">500</span> - <span class="built_in">len</span>(ret)    <span class="comment"># 如果不足500个，那么随机选出need个广告</span></span><br><span class="line">        ret = ret.union(np.random.choice(pdf.where(pdf.cateId==i.cateId).adgroupId.dropna().astype(np.int64), need))</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(ret) &gt;= <span class="number">500</span>:    <span class="comment"># 如果达到500个则退出</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    client.sadd(userId, *ret)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 如果redis所在机器，内存不足，会抛出异常</span></span><br></pre></td></tr></table></figure><h3 id="离线数据缓存之离线特征"><a href="#离线数据缓存之离线特征" class="headerlink" title="离线数据缓存之离线特征"></a>离线数据缓存之离线特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &quot;pid&quot;, 广告资源位，属于场景特征，也就是说，每一种广告通常是可以防止在多种资源外下的</span></span><br><span class="line"><span class="comment"># 因此这里对于pid，应该是由广告系统发起推荐请求时，向推荐系统明确要推荐的用户是谁，以及对应的资源位，或者说有哪些</span></span><br><span class="line"><span class="comment"># 这样如果有多个资源位，那么每个资源位都会对应相应的一个推荐列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要进行缓存的特征值</span></span><br><span class="line">    </span><br><span class="line">feature_cols_from_ad = [</span><br><span class="line">    <span class="string">&quot;price&quot;</span>    <span class="comment"># 来自广告基本信息中</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户特征</span></span><br><span class="line">feature_cols_from_user = [</span><br><span class="line">    <span class="string">&quot;cms_group_id&quot;</span>,</span><br><span class="line">    <span class="string">&quot;final_gender_code&quot;</span>,</span><br><span class="line">    <span class="string">&quot;age_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;shopping_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;occupation&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pvalue_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;new_user_class_level&quot;</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><ul><li>从HDFS中加载广告基本信息数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">_ad_feature_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/ad_feature.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改表结构，转换为对应的数据类型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换掉NULL字符串</span></span><br><span class="line">_ad_feature_df = _ad_feature_df.replace(<span class="string">&quot;NULL&quot;</span>, <span class="string">&quot;-1&quot;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">ad_feature_df = _ad_feature_df.\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, _ad_feature_df.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;cate_id&quot;</span>, _ad_feature_df.cate_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;cate_id&quot;</span>, <span class="string">&quot;cateId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;campaign_id&quot;</span>, _ad_feature_df.campaign_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;campaign_id&quot;</span>, <span class="string">&quot;campaignId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;customer&quot;</span>, _ad_feature_df.customer.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;customer&quot;</span>, <span class="string">&quot;customerId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;brand&quot;</span>, _ad_feature_df.brand.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;brand&quot;</span>, <span class="string">&quot;brandId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;price&quot;</span>, _ad_feature_df.price.cast(FloatType()))</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreachPartition</span>(<span class="params">partition</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">import</span> redis</span><br><span class="line">    <span class="keyword">import</span> json</span><br><span class="line">    client = redis.StrictRedis(host=<span class="string">&quot;192.168.199.188&quot;</span>, port=<span class="number">6379</span>, db=<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> partition:</span><br><span class="line">        data = &#123;</span><br><span class="line">            <span class="string">&quot;price&quot;</span>: r.price</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 转成json字符串再保存，能保证数据再次倒出来时，能有效的转换成python类型</span></span><br><span class="line">        client.hset(<span class="string">&quot;ad_features&quot;</span>, r.adgroupId, json.dumps(data))</span><br><span class="line">        </span><br><span class="line">ad_feature_df.foreachPartition(foreachPartition)</span><br></pre></td></tr></table></figure><ul><li>从HDFS加载用户基本信息数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建表结构schema对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cms_segid&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cms_group_id&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;final_gender_code&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;age_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;pvalue_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;shopping_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;occupation&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;new_user_class_level&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 利用schema从hdfs加载</span></span><br><span class="line">user_profile_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/csv/user_profile.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line">user_profile_df</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[userId: int, cms_segid: int, cms_group_id: int, final_gender_code: int, age_level: int, pvalue_level: int, shopping_level: int, occupation: int, new_user_class_level: int]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreachPartition2</span>(<span class="params">partition</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">import</span> redis</span><br><span class="line">    <span class="keyword">import</span> json</span><br><span class="line">    client = redis.StrictRedis(host=<span class="string">&quot;192.168.199.188&quot;</span>, port=<span class="number">6379</span>, db=<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> partition:</span><br><span class="line">        data = &#123;</span><br><span class="line">            <span class="string">&quot;cms_group_id&quot;</span>: r.cms_group_id,</span><br><span class="line">            <span class="string">&quot;final_gender_code&quot;</span>: r.final_gender_code,</span><br><span class="line">            <span class="string">&quot;age_level&quot;</span>: r.age_level,</span><br><span class="line">            <span class="string">&quot;shopping_level&quot;</span>: r.shopping_level,</span><br><span class="line">            <span class="string">&quot;occupation&quot;</span>: r.occupation,</span><br><span class="line">            <span class="string">&quot;pvalue_level&quot;</span>: r.pvalue_level,</span><br><span class="line">            <span class="string">&quot;new_user_class_level&quot;</span>: r.new_user_class_level</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 转成json字符串再保存，能保证数据再次倒出来时，能有效的转换成python类型</span></span><br><span class="line">        client.hset(<span class="string">&quot;user_features1&quot;</span>, r.userId, json.dumps(data))</span><br><span class="line">        </span><br><span class="line">user_profile_df.foreachPartition(foreachPartition2)</span><br></pre></td></tr></table></figure><h2 id="实时产生推荐结果"><a href="#实时产生推荐结果" class="headerlink" title="实时产生推荐结果"></a>实时产生推荐结果</h2><h3 id="推荐任务处理"><a href="#推荐任务处理" class="headerlink" title="推荐任务处理"></a>推荐任务处理</h3><ul><li><p>CTR预测模型 + 特征 ==&gt; 预测结果 ==&gt; TOP-N列表</p></li><li><p>热编码中：”pvalue_level”特征对应关系:</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+------------+----------------------+</span><br><span class="line">|pvalue_level|pl_onehot_feature     |</span><br><span class="line">+------------+----------------------+</span><br><span class="line">|          -1|                   0.0|</span><br><span class="line">|           3|                   3.0|</span><br><span class="line">|           1|                   2.0|</span><br><span class="line">|           2|                   1.0|</span><br><span class="line">+------------+----------------------+</span><br></pre></td></tr></table></figure><ul><li>“new_user_class_level”的特征对应关系：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------------------------+</span><br><span class="line">|new_user_class_level|nucl_onehot_feature     |</span><br><span class="line">+--------------------+------------------------+</span><br><span class="line">|                  -1|                     0.0|</span><br><span class="line">|                   3|                     2.0|</span><br><span class="line">|                   1|                     4.0|</span><br><span class="line">|                   4|                     3.0|</span><br><span class="line">|                   2|                     1.0|</span><br><span class="line">+--------------------+------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pvalue_level_rela = &#123;-<span class="number">1</span>: <span class="number">0</span>, <span class="number">3</span>:<span class="number">3</span>, <span class="number">1</span>:<span class="number">2</span>, <span class="number">2</span>:<span class="number">1</span>&#125;</span><br><span class="line">new_user_class_level_rela = &#123;-<span class="number">1</span>:<span class="number">0</span>, <span class="number">3</span>:<span class="number">2</span>, <span class="number">1</span>:<span class="number">4</span>, <span class="number">4</span>:<span class="number">3</span>, <span class="number">2</span>:<span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure><ul><li>“cms_group_id”特征对应关系：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">+------------+-------------------------+</span><br><span class="line">|cms_group_id|min(cms_group_id_feature)|</span><br><span class="line">+------------+-------------------------+</span><br><span class="line">|           7|                      9.0|</span><br><span class="line">|          11|                      6.0|</span><br><span class="line">|           3|                      0.0|</span><br><span class="line">|           8|                      8.0|</span><br><span class="line">|           0|                     12.0|</span><br><span class="line">|           5|                      3.0|</span><br><span class="line">|           6|                     10.0|</span><br><span class="line">|           9|                      5.0|</span><br><span class="line">|           1|                      7.0|</span><br><span class="line">|          10|                      4.0|</span><br><span class="line">|           4|                      1.0|</span><br><span class="line">|          12|                     11.0|</span><br><span class="line">|           2|                      2.0|</span><br><span class="line">+------------+-------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cms_group_id_rela = &#123;</span><br><span class="line">    7: 9,</span><br><span class="line">    11: 6,</span><br><span class="line">    3: 0,</span><br><span class="line">    8: 8,</span><br><span class="line">    0: 12,</span><br><span class="line">    5: 3,</span><br><span class="line">    6: 10,</span><br><span class="line">    9: 5,</span><br><span class="line">    1: 7,</span><br><span class="line">    10: 4,</span><br><span class="line">    4: 1,</span><br><span class="line">    12: 11,</span><br><span class="line">    2: 2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>“final_gender_code”特征对应关系：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+------------------------------+</span><br><span class="line">|final_gender_code|min(final_gender_code_feature)|</span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line">|                1|                           1.0|</span><br><span class="line">|                2|                           0.0|</span><br><span class="line">+-----------------+------------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final_gender_code_rela = &#123;1:1, 2:0&#125;</span><br></pre></td></tr></table></figure><ul><li>“age_level”特征对应关系：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+---------+----------------------+</span><br><span class="line">|age_level|min(age_level_feature)|</span><br><span class="line">+---------+----------------------+</span><br><span class="line">|        3|                   0.0|</span><br><span class="line">|        0|                   6.0|</span><br><span class="line">|        5|                   2.0|</span><br><span class="line">|        6|                   5.0|</span><br><span class="line">|        1|                   4.0|</span><br><span class="line">|        4|                   1.0|</span><br><span class="line">|        2|                   3.0|</span><br><span class="line">+---------+----------------------+</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">age_level_rela = &#123;3:0, 0:6, 5:2, 6:5, 1:4, 4:1, 2:3&#125;</span><br></pre></td></tr></table></figure><ul><li>“shopping_level”特征对应关系：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">|shopping_level|min(shopping_level_feature)|</span><br><span class="line">+--------------+---------------------------+</span><br><span class="line">|             3|                        0.0|</span><br><span class="line">|             1|                        2.0|</span><br><span class="line">|             2|                        1.0|</span><br><span class="line">+--------------+---------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shopping_level_rela = &#123;3:0, 1:2, 2:1&#125;</span><br></pre></td></tr></table></figure><ul><li>“occupation”特征对应关系：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+----------+-----------------------+</span><br><span class="line">|occupation|min(occupation_feature)|</span><br><span class="line">+----------+-----------------------+</span><br><span class="line">|         0|                    0.0|</span><br><span class="line">|         1|                    1.0|</span><br><span class="line">+----------+-----------------------+</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">occupation_rela = &#123;0:0, 1:1&#125;</span><br><span class="line"></span><br><span class="line">pid_rela = &#123;</span><br><span class="line">    &quot;430548_1007&quot;: 0, </span><br><span class="line">    &quot;430549_1007&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>特征获取</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> DenseVector</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_datasets</span>(<span class="params">userId, pid</span>):</span></span><br><span class="line">    client_of_recall = redis.StrictRedis(host=<span class="string">&quot;192.168.199.88&quot;</span>, port=<span class="number">6379</span>, db=<span class="number">9</span>)</span><br><span class="line">    client_of_features = redis.StrictRedis(host=<span class="string">&quot;192.168.199.88&quot;</span>, port=<span class="number">6379</span>, db=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 获取用户特征</span></span><br><span class="line">    user_feature = json.loads(client_of_features.hget(<span class="string">&quot;user_features&quot;</span>, userId))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取用户召回集</span></span><br><span class="line">    recall_sets = client_of_recall.smembers(userId)</span><br><span class="line">    </span><br><span class="line">    result = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历召回集</span></span><br><span class="line">    <span class="keyword">for</span> adgroupId <span class="keyword">in</span> recall_sets:</span><br><span class="line">        adgroupId = <span class="built_in">int</span>(adgroupId)</span><br><span class="line">        <span class="comment"># 获取该广告的特征值</span></span><br><span class="line">        ad_feature = json.loads(client_of_features.hget(<span class="string">&quot;ad_features&quot;</span>, adgroupId))</span><br><span class="line">        </span><br><span class="line">        features = &#123;&#125;</span><br><span class="line">        features.update(user_feature)</span><br><span class="line">        features.update(ad_feature)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> k,v <span class="keyword">in</span> features.items():</span><br><span class="line">            <span class="keyword">if</span> v <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                features[k] = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        features_col = [</span><br><span class="line">            <span class="comment"># 特征值</span></span><br><span class="line">            <span class="string">&quot;price&quot;</span>,</span><br><span class="line">            <span class="string">&quot;cms_group_id&quot;</span>,</span><br><span class="line">            <span class="string">&quot;final_gender_code&quot;</span>,</span><br><span class="line">            <span class="string">&quot;age_level&quot;</span>,</span><br><span class="line">            <span class="string">&quot;shopping_level&quot;</span>,</span><br><span class="line">            <span class="string">&quot;occupation&quot;</span>,</span><br><span class="line">            <span class="string">&quot;pid&quot;</span>, </span><br><span class="line">            <span class="string">&quot;pvalue_level&quot;</span>,</span><br><span class="line">            <span class="string">&quot;new_user_class_level&quot;</span></span><br><span class="line">        ]</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        &quot;cms_group_id&quot;, 类别型特征，约13个分类 ==&gt; 13维</span></span><br><span class="line"><span class="string">        &quot;final_gender_code&quot;, 类别型特征，2个分类 ==&gt; 2维</span></span><br><span class="line"><span class="string">        &quot;age_level&quot;, 类别型特征，7个分类 ==&gt;7维</span></span><br><span class="line"><span class="string">        &quot;shopping_level&quot;, 类别型特征，3个分类 ==&gt; 3维</span></span><br><span class="line"><span class="string">        &quot;occupation&quot;, 类别型特征，2个分类 ==&gt; 2维</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        price = <span class="built_in">float</span>(features[<span class="string">&quot;price&quot;</span>])</span><br><span class="line"></span><br><span class="line">        pid_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]<span class="comment">#[0,0]</span></span><br><span class="line">        cms_group_id_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>)]</span><br><span class="line">        final_gender_code_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]</span><br><span class="line">        age_level_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span>)]</span><br><span class="line">        shopping_level_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)]</span><br><span class="line">        occupation_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]</span><br><span class="line">        pvalue_level_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)]</span><br><span class="line">        new_user_class_level_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]</span><br><span class="line"></span><br><span class="line">        pid_value[pid_rela[pid]] = <span class="number">1</span></span><br><span class="line">        cms_group_id_value[cms_group_id_rela[<span class="built_in">int</span>(features[<span class="string">&quot;cms_group_id&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        final_gender_code_value[final_gender_code_rela[<span class="built_in">int</span>(features[<span class="string">&quot;final_gender_code&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        age_level_value[age_level_rela[<span class="built_in">int</span>(features[<span class="string">&quot;age_level&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        shopping_level_value[shopping_level_rela[<span class="built_in">int</span>(features[<span class="string">&quot;shopping_level&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        occupation_value[occupation_rela[<span class="built_in">int</span>(features[<span class="string">&quot;occupation&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        pvalue_level_value[pvalue_level_rela[<span class="built_in">int</span>(features[<span class="string">&quot;pvalue_level&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        new_user_class_level_value[new_user_class_level_rela[<span class="built_in">int</span>(features[<span class="string">&quot;new_user_class_level&quot;</span>])]] = <span class="number">1</span></span><br><span class="line"> <span class="comment">#         print(pid_value)</span></span><br><span class="line"><span class="comment">#         print(cms_group_id_value)</span></span><br><span class="line"><span class="comment">#         print(final_gender_code_value)</span></span><br><span class="line"><span class="comment">#         print(age_level_value)</span></span><br><span class="line"><span class="comment">#         print(shopping_level_value)</span></span><br><span class="line"><span class="comment">#         print(occupation_value)</span></span><br><span class="line"><span class="comment">#         print(pvalue_level_value)</span></span><br><span class="line"><span class="comment">#         print(new_user_class_level_value)</span></span><br><span class="line">        </span><br><span class="line">        vector = DenseVector([price] + pid_value + cms_group_id_value + final_gender_code_value\</span><br><span class="line">        + age_level_value + shopping_level_value + occupation_value + pvalue_level_value + new_user_class_level_value)</span><br><span class="line">        </span><br><span class="line">        result.append((userId, adgroupId, vector))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># create_datasets(88, &quot;430548_1007&quot;)</span></span><br></pre></td></tr></table></figure><ul><li>载入训练好的模型</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.classification import LogisticRegressionModel</span><br><span class="line">CTR_model = LogisticRegressionModel.load(&quot;hdfs://localhost:9000/models/CTRModel_AllOneHot.obj&quot;)</span><br><span class="line">pdf = pd.DataFrame(create_datasets(8, &quot;430548_1007&quot;), columns=[&quot;userId&quot;, &quot;adgroupId&quot;, &quot;features&quot;])</span><br><span class="line">datasets = spark.createDataFrame(pdf)</span><br><span class="line">datasets.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+--------------------+</span><br><span class="line">|userId|adgroupId|            features|</span><br><span class="line">+------+---------+--------------------+</span><br><span class="line">|     8|   445914|[9.89999961853027...|</span><br><span class="line">|     8|   258252|[7.59999990463256...|</span><br><span class="line">|     8|   129682|[8.5,1.0,0.0,1.0,...|</span><br><span class="line">|     8|   763027|[68.0,1.0,0.0,1.0...|</span><br><span class="line">|     8|   292027|[16.0,1.0,0.0,1.0...|</span><br><span class="line">|     8|   430023|[34.2000007629394...|</span><br><span class="line">|     8|   133457|[169.0,1.0,0.0,1....|</span><br><span class="line">|     8|   816999|[5.0,1.0,0.0,1.0,...|</span><br><span class="line">|     8|   221714|[4.80000019073486...|</span><br><span class="line">|     8|   186334|[106.0,1.0,0.0,1....|</span><br><span class="line">|     8|   169717|[2.20000004768371...|</span><br><span class="line">|     8|    31314|[15.8000001907348...|</span><br><span class="line">|     8|   815312|[2.29999995231628...|</span><br><span class="line">|     8|   199445|[5.0,1.0,0.0,1.0,...|</span><br><span class="line">|     8|   746178|[16.7999992370605...|</span><br><span class="line">|     8|   290950|[6.5,1.0,0.0,1.0,...|</span><br><span class="line">|     8|   221585|[18.5,1.0,0.0,1.0...|</span><br><span class="line">|     8|   692672|[47.0,1.0,0.0,1.0...|</span><br><span class="line">|     8|   797982|[33.0,1.0,0.0,1.0...|</span><br><span class="line">|     8|   815219|[2.40000009536743...|</span><br><span class="line">+------+---------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">prediction = CTR_model.transform(datasets).sort(&quot;probability&quot;)</span><br><span class="line">prediction.show()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+--------------------+--------------------+--------------------+----------+</span><br><span class="line">|userId|adgroupId|            features|       rawPrediction|         probability|prediction|</span><br><span class="line">+------+---------+--------------------+--------------------+--------------------+----------+</span><br><span class="line">|     8|   631204|[19888.0,1.0,0.0,...|[2.69001234046578...|[0.93643471623189...|       0.0|</span><br><span class="line">|     8|   583215|[3750.0,1.0,0.0,1...|[2.69016170680037...|[0.93644360664433...|       0.0|</span><br><span class="line">|     8|   275819|[3280.0,1.0,0.0,1...|[2.69016605691669...|[0.93644386554961...|       0.0|</span><br><span class="line">|     8|   401433|[1200.0,1.0,0.0,1...|[2.69018530849532...|[0.93644501133142...|       0.0|</span><br><span class="line">|     8|    29466|[640.0,1.0,0.0,1....|[2.69019049161265...|[0.93644531980785...|       0.0|</span><br><span class="line">|     8|   173327|[356.0,1.0,0.0,1....|[2.69019312019358...|[0.93644547624893...|       0.0|</span><br><span class="line">|     8|   241402|[269.0,1.0,0.0,1....|[2.69019392542787...|[0.93644552417271...|       0.0|</span><br><span class="line">|     8|   351366|[246.0,1.0,0.0,1....|[2.69019413830591...|[0.93644553684221...|       0.0|</span><br><span class="line">|     8|   229827|[238.0,1.0,0.0,1....|[2.69019421235044...|[0.93644554124900...|       0.0|</span><br><span class="line">|     8|   164807|[228.0,1.0,0.0,1....|[2.69019430490611...|[0.93644554675747...|       0.0|</span><br><span class="line">|     8|   227731|[199.0,1.0,0.0,1....|[2.69019457331754...|[0.93644556273205...|       0.0|</span><br><span class="line">|     8|   265403|[198.0,1.0,0.0,1....|[2.69019458257311...|[0.93644556328290...|       0.0|</span><br><span class="line">|     8|   569939|[188.0,1.0,0.0,1....|[2.69019467512877...|[0.93644556879138...|       0.0|</span><br><span class="line">|     8|   277335|[181.5,1.0,0.0,1....|[2.69019473528996...|[0.93644557237189...|       0.0|</span><br><span class="line">|     8|   575633|[180.0,1.0,0.0,1....|[2.69019474917331...|[0.93644557319816...|       0.0|</span><br><span class="line">|     8|   201867|[179.0,1.0,0.0,1....|[2.69019475842887...|[0.93644557374900...|       0.0|</span><br><span class="line">|     8|    25542|[176.0,1.0,0.0,1....|[2.69019478619557...|[0.93644557540155...|       0.0|</span><br><span class="line">|     8|   133457|[169.0,1.0,0.0,1....|[2.69019485098454...|[0.93644557925748...|       0.0|</span><br><span class="line">|     8|   494224|[169.0,1.0,0.0,1....|[2.69019485098454...|[0.93644557925748...|       0.0|</span><br><span class="line">|     8|   339382|[163.0,1.0,0.0,1....|[2.69019490651794...|[0.93644558256256...|       0.0|</span><br><span class="line">+------+---------+--------------------+--------------------+--------------------+----------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>TOP-20</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TOP-20</span></span><br><span class="line">prediction.select(<span class="string">&quot;adgroupId&quot;</span>).head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[Row(adgroupId=631204),</span><br><span class="line"> Row(adgroupId=583215),</span><br><span class="line"> Row(adgroupId=275819),</span><br><span class="line"> Row(adgroupId=401433),</span><br><span class="line"> Row(adgroupId=29466),</span><br><span class="line"> Row(adgroupId=173327),</span><br><span class="line"> Row(adgroupId=241402),</span><br><span class="line"> Row(adgroupId=351366),</span><br><span class="line"> Row(adgroupId=229827),</span><br><span class="line"> Row(adgroupId=164807),</span><br><span class="line"> Row(adgroupId=227731),</span><br><span class="line"> Row(adgroupId=265403),</span><br><span class="line"> Row(adgroupId=569939),</span><br><span class="line"> Row(adgroupId=277335),</span><br><span class="line"> Row(adgroupId=575633),</span><br><span class="line"> Row(adgroupId=201867),</span><br><span class="line"> Row(adgroupId=25542),</span><br><span class="line"> Row(adgroupId=133457),</span><br><span class="line"> Row(adgroupId=494224),</span><br><span class="line"> Row(adgroupId=339382)]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[i.adgroupId for i in prediction.select(&quot;adgroupId&quot;).head(20)]</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[631204,</span><br><span class="line"> 583215,</span><br><span class="line"> 275819,</span><br><span class="line"> 401433,</span><br><span class="line"> 29466,</span><br><span class="line"> 173327,</span><br><span class="line"> 241402,</span><br><span class="line"> 351366,</span><br><span class="line"> 229827,</span><br><span class="line"> 164807,</span><br><span class="line"> 227731,</span><br><span class="line"> 265403,</span><br><span class="line"> 569939,</span><br><span class="line"> 277335,</span><br><span class="line"> 575633,</span><br><span class="line"> 201867,</span><br><span class="line"> 25542,</span><br><span class="line"> 133457,</span><br><span class="line"> 494224,</span><br><span class="line"> 339382]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Search / Advertisement / Recommendation / Causal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark SQL &amp; Spark streaming</title>
      <link href="/2022/01/18/5.6-Spark-SQL/"/>
      <url>/2022/01/18/5.6-Spark-SQL/</url>
      
        <content type="html"><![CDATA[<p><strong>推荐系统学习笔记目录</strong></p><ol><li><a href="https://xfliu1998.github.io/2022/01/18/5.1-Recommendation-System-Introduction/">推荐系统介绍</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/">推荐算法</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.3-Hadoop/">Hadoop</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.4-Hive/">Hive &amp; HBase</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.5-Spark-core/">Spark core</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.6-Spark-SQL/">Spark SQL &amp; Spark streaming</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.7-RS-case/">推荐系统案例</a></li></ol><h1 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark SQL"></a>Spark SQL</h1><p><strong>Spark SQL概念</strong></p><ul><li>Spark SQL is Apache Spark’s module for working with structured data.<ul><li>它是spark中用于处理结构化数据的一个模块</li></ul></li></ul><p><strong>Spark SQL历史</strong></p><ul><li>Hive是目前大数据领域，事实上的数据仓库标准。</li></ul><p><img src="s9.PNG" alt="s9"></p><ul><li>Shark：shark底层使用spark的基于内存的计算模型，从而让性能比Hive提升了数倍到上百倍。</li><li>底层很多东西还是依赖于Hive，修改了内存管理、物理计划、执行三个模块</li><li>2014年6月1日的时候，Spark宣布了不再开发Shark，全面转向Spark SQL的开发</li></ul><p><strong>Spark SQL优势</strong></p><ul><li>Write Less Code<br><img src="s10.PNG" alt="s10"></li></ul><ul><li>Performance<br><img src="s11.PNG" alt="s11"></li></ul><p>python操作RDD，转换为可执行代码，运行在java虚拟机，涉及两个不同语言引擎之间的切换，进行进程间        通信很耗费性能。</p><p>DataFrame</p><ul><li>是RDD为基础的分布式数据集，类似于传统关系型数据库的二维表，dataframe记录了对应列的名称和类型</li><li>dataFrame引入schema和off-heap(使用操作系统层面上的内存)<ul><li>1、解决了RDD的缺点</li><li>序列化和反序列化开销大</li><li>频繁的创建和销毁对象造成大量的GC</li><li>2、丢失了RDD的优点</li><li>RDD编译时进行类型检查</li><li>RDD具有面向对象编程的特性</li></ul></li></ul><p>用scala/python编写的RDD比Spark SQL编写转换的RDD慢，涉及到执行计划</p><ul><li>CatalystOptimizer：Catalyst优化器</li><li>ProjectTungsten：钨丝计划，为了提高RDD的效率而制定的计划</li><li>Code gen：代码生成器</li></ul><p><img src="s12.PNG" alt="s12"></p><p>直接编写RDD也可以自实现优化代码，但是远不及SparkSQL前面的优化操作后转换的RDD效率高，快1倍左右</p><p>优化引擎：类似mysql等关系型数据库基于成本的优化器</p><p>首先执行逻辑执行计划，然后转换为物理执行计划(选择成本最小的)，通过Code Generation最终生成为RDD</p><ul><li><p>Language-independent API</p><p>用任何语言编写生成的RDD都一样，而使用spark-core编写的RDD，不同的语言生成不同的RDD</p></li></ul><ul><li><p>Schema</p><p>结构化数据，可以直接看出数据的详情</p><p>在RDD中无法看出，解释性不强，无法告诉引擎信息，没法详细优化。</p></li></ul><p><strong>为什么要学习sparksql </strong></p><p>sparksql特性</p><ul><li>1、易整合</li><li>2、统一的数据源访问</li><li>3、兼容hive</li><li>4、提供了标准的数据库连接（jdbc/odbc）</li></ul><h1 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>在Spark语义中，DataFrame是一个分布式的<strong>行集合</strong>，可以想象为一个关系型数据库的表，或者一个带有列名的Excel表格。它和RDD一样，有这样一些特点：</p><ul><li>Immuatable：一旦RDD、DataFrame被创建，就不能更改，只能通过transformation生成新的RDD、DataFrame</li><li>Lazy Evaluations：只有action才会触发Transformation的执行</li><li>Distributed：DataFrame和RDD一样都是分布式的</li><li>dataframe和dataset统一，dataframe只是dataset[ROW]的类型别名。由于Python是弱类型语言，只能使用DataFrame</li></ul><p><strong>DataFrame vs RDD</strong></p><ul><li>RDD：分布式的对象的集合，Spark并不知道对象的详细模式信息</li><li>DataFrame：分布式的Row对象的集合，其提供了由列组成的详细模式信息，使得Spark SQL可以进行某些形式的执行优化。</li><li>DataFrame和普通的RDD的逻辑框架区别如下所示：</li></ul><p><img src="s13.PNG" alt="s13"></p><ul><li><p>左侧的RDD Spark框架本身不了解 Person类的内部结构。</p></li><li><p>右侧的DataFrame提供了详细的结构信息（schema——每列的名称，类型）</p></li><li>DataFrame还配套了新的操作数据的方法，DataFrame API（如df.select())和SQL(select id, name from xx_table where …)。</li><li><p>DataFrame还引入了off-heap,意味着JVM堆以外的内存, 这些内存直接受操作系统管理（而不是JVM）。</p></li><li><p>RDD是分布式的Java对象的集合。DataFrame是分布式的Row对象的集合。DataFrame除了提供了比RDD更丰富的算子以外，更重要的特点是提升执行效率、减少数据读取以及执行计划的优化。</p></li><li>DataFrame的抽象后，我们处理数据更加简单了，甚至可以用SQL来处理数据了</li><li>通过DataFrame API或SQL处理数据，会自动经过Spark 优化器（Catalyst）的优化，即使你写的程序或SQL不仅高效，也可以运行的很快。</li><li>DataFrame相当于是一个带着schema的RDD</li></ul><p><strong>Pandas DataFrame vs Spark DataFrame</strong></p><ul><li>Cluster Parallel：集群并行执行</li><li>Lazy Evaluations: 只有action才会触发Transformation的执行</li><li>Immutable：不可更改</li><li>Pandas rich API：比Spark SQL api丰富</li></ul><h2 id="创建DataFrame"><a href="#创建DataFrame" class="headerlink" title="创建DataFrame"></a>创建DataFrame</h2><ol><li><p>创建dataFrame的步骤<br>调用方法例如：spark.read.xxx方法</p></li><li><p>其他方式创建dataframe</p></li></ol><ul><li><p>createDataFrame：pandas dataframe、list、RDD</p></li><li><p>数据源：RDD、csv、json、parquet、orc、jdbc</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">  jsonDF = spark.read.json(<span class="string">&quot;xxx.json&quot;</span>)</span><br><span class="line">  </span><br><span class="line">  jsonDF = spark.read.<span class="built_in">format</span>(<span class="string">&#x27;json&#x27;</span>).load(<span class="string">&#x27;xxx.json&#x27;</span>)</span><br><span class="line">  </span><br><span class="line">  parquetDF = spark.read.parquet(<span class="string">&quot;xxx.parquet&quot;</span>)</span><br><span class="line">  </span><br><span class="line">  jdbcDF = spark.read.<span class="built_in">format</span>(<span class="string">&quot;jdbc&quot;</span>).option(<span class="string">&quot;url&quot;</span>,<span class="string">&quot;jdbc:mysql://localhost:3306/db_name&quot;</span>).option(<span class="string">&quot;dbtable&quot;</span>,<span class="string">&quot;table_name&quot;</span>).option(<span class="string">&quot;user&quot;</span>,<span class="string">&quot;xxx&quot;</span>).option(<span class="string">&quot;password&quot;</span>,<span class="string">&quot;xxx&quot;</span>).load()</span><br><span class="line">  PNG</span><br><span class="line"></span><br><span class="line">- Transformation:延迟性操作</span><br><span class="line"></span><br><span class="line">- action：立即操作</span><br><span class="line"></span><br><span class="line">  ![s14](s14.PNG)</span><br><span class="line"></span><br><span class="line"><span class="comment">## DataFrame API实现</span></span><br><span class="line"></span><br><span class="line">**基于RDD创建**</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&#x27;test&#x27;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"><span class="comment"># spark.conf.set(&quot;spark.sql.shuffle.partitions&quot;, 6)</span></span><br><span class="line"><span class="comment"># ================直接创建==========================</span></span><br><span class="line">l = [(<span class="string">&#x27;Ankit&#x27;</span>,<span class="number">25</span>),(<span class="string">&#x27;Jalfaizy&#x27;</span>,<span class="number">22</span>),(<span class="string">&#x27;saurabh&#x27;</span>,<span class="number">20</span>),(<span class="string">&#x27;Bala&#x27;</span>,<span class="number">26</span>)]</span><br><span class="line">rdd = sc.parallelize(l)</span><br><span class="line"><span class="comment">#为数据添加列名</span></span><br><span class="line">people = rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: Row(name=x[<span class="number">0</span>], age=<span class="built_in">int</span>(x[<span class="number">1</span>])))</span><br><span class="line"><span class="comment">#创建DataFrame</span></span><br><span class="line">schemaPeople = spark.createDataFrame(people)</span><br></pre></td></tr></table></figure></li></ul><p><strong>从csv中读取数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==================从csv读取======================</span></span><br><span class="line"><span class="comment">#加载csv类型的数据并转换为DataFrame</span></span><br><span class="line">df = spark.read.<span class="built_in">format</span>(<span class="string">&quot;csv&quot;</span>). \</span><br><span class="line">    option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>) \</span><br><span class="line">    .load(<span class="string">&quot;iris.csv&quot;</span>)</span><br><span class="line"><span class="comment">#显示数据结构</span></span><br><span class="line">df.printSchema()</span><br><span class="line"><span class="comment">#显示前10条数据</span></span><br><span class="line">df.show(<span class="number">10</span>)</span><br><span class="line"><span class="comment">#统计总量</span></span><br><span class="line">df.count()</span><br><span class="line"><span class="comment">#列名</span></span><br><span class="line">df.columns</span><br></pre></td></tr></table></figure><p><strong>增加一列</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ===============增加一列(或者替换) withColumn===========</span></span><br><span class="line"><span class="comment">#定义一个新的列，数据为其他某列数据的两倍</span></span><br><span class="line"><span class="comment">#如果操作的是原有列，可以替换原有列的数据</span></span><br><span class="line">df.withColumn(<span class="string">&#x27;newWidth&#x27;</span>,df.SepalWidth * <span class="number">2</span>).show()</span><br></pre></td></tr></table></figure><p><strong>删除一列</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==========删除一列  drop=========================</span></span><br><span class="line"><span class="comment">#删除一列</span></span><br><span class="line">df.drop(<span class="string">&#x27;cls&#x27;</span>).show()</span><br></pre></td></tr></table></figure><p><strong>统计信息</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#================ 统计信息 describe================</span></span><br><span class="line">df.describe().show()</span><br><span class="line"><span class="comment">#计算某一列的描述信息</span></span><br><span class="line">df.describe(<span class="string">&#x27;cls&#x27;</span>).show()   </span><br></pre></td></tr></table></figure><p><strong>提取部分列</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ===============提取部分列 select==============</span></span><br><span class="line">df.select(<span class="string">&#x27;SepalLength&#x27;</span>,<span class="string">&#x27;SepalWidth&#x27;</span>).show()</span><br></pre></td></tr></table></figure><p><strong>基本统计功能</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==================基本统计功能 distinct count=====</span></span><br><span class="line">df.select(<span class="string">&#x27;cls&#x27;</span>).distinct().count()</span><br></pre></td></tr></table></figure><p><strong>分组统计</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分组统计 groupby(colname).agg(&#123;&#x27;col&#x27;:&#x27;fun&#x27;,&#x27;col2&#x27;:&#x27;fun2&#x27;&#125;)</span></span><br><span class="line">df.groupby(<span class="string">&#x27;cls&#x27;</span>).agg(&#123;<span class="string">&#x27;SepalWidth&#x27;</span>:<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;SepalLength&#x27;</span>:<span class="string">&#x27;max&#x27;</span>&#125;).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># avg(), count(), countDistinct(), first(), kurtosis(),</span></span><br><span class="line"><span class="comment"># max(), mean(), min(), skewness(), stddev(), stddev_pop(),</span></span><br><span class="line"><span class="comment"># stddev_samp(), sum(), sumDistinct(), var_pop(), var_samp() and variance()</span></span><br></pre></td></tr></table></figure><p><strong>自定义的汇总方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义的汇总方法</span></span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> fn</span><br><span class="line"><span class="comment">#调用函数并起一个别名</span></span><br><span class="line">df.agg(fn.count(<span class="string">&#x27;SepalWidth&#x27;</span>).alias(<span class="string">&#x27;width_count&#x27;</span>),fn.countDistinct(<span class="string">&#x27;cls&#x27;</span>).alias(<span class="string">&#x27;distinct_cls_count&#x27;</span>)).show()</span><br></pre></td></tr></table></figure><p><strong>拆分数据集</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#====================数据集拆成两部分 randomSplit ===========</span></span><br><span class="line"><span class="comment">#设置数据比例将数据划分为两部分</span></span><br><span class="line">trainDF, testDF = df.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>])</span><br></pre></td></tr></table></figure><p><strong>采样数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ================采样数据 sample===========</span></span><br><span class="line"><span class="comment">#withReplacement：是否有放回的采样</span></span><br><span class="line"><span class="comment">#fraction：采样比例</span></span><br><span class="line"><span class="comment">#seed：随机种子</span></span><br><span class="line">sdf = df.sample(<span class="literal">False</span>,<span class="number">0.2</span>,<span class="number">100</span>)</span><br></pre></td></tr></table></figure><p><strong>查看两个数据集在类别上的差异</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看两个数据集在类别上的差异 subtract，确保训练数据集覆盖了所有分类</span></span><br><span class="line">diff_in_train_test = testDF.select(<span class="string">&#x27;cls&#x27;</span>).subtract(trainDF.select(<span class="string">&#x27;cls&#x27;</span>))</span><br><span class="line">diff_in_train_test.distinct().count()</span><br></pre></td></tr></table></figure><p><strong>交叉表</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ================交叉表 crosstab=============</span></span><br><span class="line">df.crosstab(<span class="string">&#x27;cls&#x27;</span>,<span class="string">&#x27;SepalLength&#x27;</span>).show()</span><br></pre></td></tr></table></figure><p><strong>udf</strong></p><p>udf：自定义函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#================== 综合案例 + udf================</span></span><br><span class="line"><span class="comment"># 测试数据集中有些类别在训练集中是不存在的，找到这些数据集做后续处理</span></span><br><span class="line">trainDF,testDF = df.randomSplit([<span class="number">0.99</span>,<span class="number">0.01</span>])</span><br><span class="line"></span><br><span class="line">diff_in_train_test = trainDF.select(<span class="string">&#x27;cls&#x27;</span>).subtract(testDF.select(<span class="string">&#x27;cls&#x27;</span>)).distinct().show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#首先找到这些类，整理到一个列表</span></span><br><span class="line">not_exist_cls = trainDF.select(<span class="string">&#x27;cls&#x27;</span>).subtract(testDF.select(<span class="string">&#x27;cls&#x27;</span>)).distinct().rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x :x[<span class="number">0</span>]).collect()</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个方法，用于检测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">should_remove</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x <span class="keyword">in</span> not_exist_cls:</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建udf，udf函数需要两个参数：</span></span><br><span class="line"><span class="comment"># Function</span></span><br><span class="line"><span class="comment"># Return type (in my case StringType())</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#在RDD中可以直接定义函数，交给rdd的transformatioins方法进行执行</span></span><br><span class="line"><span class="comment">#在DataFrame中需要通过udf将自定义函数封装成udf函数再交给DataFrame进行调用执行</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> udf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">check = udf(should_remove,StringType())</span><br><span class="line"></span><br><span class="line">resultDF = trainDF.withColumn(<span class="string">&#x27;New_cls&#x27;</span>,check(trainDF[<span class="string">&#x27;cls&#x27;</span>])).<span class="built_in">filter</span>(<span class="string">&#x27;New_cls &lt;&gt; -1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">resultDF.show()</span><br></pre></td></tr></table></figure><h1 id="JSON数据的处理"><a href="#JSON数据的处理" class="headerlink" title="JSON数据的处理"></a>JSON数据的处理</h1><h2 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h2><p><strong>JSON数据</strong></p><ul><li><p>Spark SQL can automatically infer the schema of a JSON dataset and load it as a DataFrame</p><p>Spark SQL能够自动将JSON数据集以结构化的形式加载为一个DataFrame</p></li><li><p>This conversion can be done using SparkSession.read.json on a JSON file</p><p>读取一个JSON文件可以用SparkSession.read.json方法</p></li></ul><p><strong>从JSON到DataFrame</strong></p><ul><li><p>指定DataFrame的schema</p><ol><li>通过反射自动推断，适合静态数据</li><li>程序指定，适合程序运行中动态生成的数据</li></ol></li></ul><p><strong>加载json数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用内部的schema</span></span><br><span class="line">jsonDF = spark.read.json(<span class="string">&quot;xxx.json&quot;</span>)</span><br><span class="line">jsonDF = spark.read.<span class="built_in">format</span>(<span class="string">&#x27;json&#x27;</span>).load(<span class="string">&#x27;xxx.json&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#指定schema</span></span><br><span class="line">jsonDF = spark.read.schema(jsonSchema).json(<span class="string">&#x27;xxx.json&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>嵌套结构的JSON</strong></p><ul><li><p>重要的方法</p><ol><li>get_json_object</li><li>get_json</li><li>explode</li></ol></li></ul><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><h3 id="静态json数据的读取和操作"><a href="#静态json数据的读取和操作" class="headerlink" title="静态json数据的读取和操作"></a>静态json数据的读取和操作</h3><p><strong>无嵌套结构的json数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">spark =  SparkSession.builder.appName(<span class="string">&#x27;json_demo&#x27;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==========================================</span></span><br><span class="line"><span class="comment">#                无嵌套结构的json</span></span><br><span class="line"><span class="comment"># ==========================================</span></span><br><span class="line">jsonString = [</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01001&quot;, &quot;city&quot; : &quot;AGAWAM&quot;,  &quot;pop&quot; : 15338, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span>,</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01002&quot;, &quot;city&quot; : &quot;CUSHMAN&quot;, &quot;pop&quot; : 36963, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><p><strong>从json字符串数组得到DataFrame</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从json字符串数组得到rdd有两种方法</span></span><br><span class="line"><span class="comment"># 1. 转换为rdd，再从rdd到DataFrame</span></span><br><span class="line"><span class="comment"># 2. 直接利用spark.createDataFrame()，见后面例子</span></span><br><span class="line"></span><br><span class="line">jsonRDD = sc.parallelize(jsonString)   <span class="comment"># stringJSONRDD</span></span><br><span class="line">jsonDF =  spark.read.json(jsonRDD)  <span class="comment"># convert RDD into DataFrame</span></span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show()</span><br></pre></td></tr></table></figure><p><strong>直接从文件生成DataFrame</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -- 直接从文件生成DataFrame</span></span><br><span class="line"><span class="comment">#只有被压缩后的json文件内容，才能被spark-sql正确读取，否则格式化后的数据读取会出现问题</span></span><br><span class="line">jsonDF = spark.read.json(<span class="string">&quot;xxx.json&quot;</span>)</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line"><span class="comment"># jsonDF = spark.read.format(&#x27;json&#x27;).load(&#x27;xxx.json&#x27;)</span></span><br><span class="line"></span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show()</span><br><span class="line"></span><br><span class="line">jsonDF.<span class="built_in">filter</span>(jsonDF.pop&gt;<span class="number">4000</span>).show(<span class="number">10</span>)</span><br><span class="line"><span class="comment">#依照已有的DataFrame，创建一个临时的表(相当于mysql数据库中的一个表)，这样就可以用纯sql语句进行数据操作</span></span><br><span class="line">jsonDF.createOrReplaceTempView(<span class="string">&quot;tmp_table&quot;</span>)</span><br><span class="line"></span><br><span class="line">resultDF = spark.sql(<span class="string">&quot;select * from tmp_table where pop&gt;4000&quot;</span>)</span><br><span class="line">resultDF.show(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h3 id="动态json数据的读取和操作"><a href="#动态json数据的读取和操作" class="headerlink" title="动态json数据的读取和操作"></a>动态json数据的读取和操作</h3><p><strong>指定DataFrame的Schema</strong></p><p>3.1节中的例子为通过反射自动推断schema，适合静态数据</p><p>下面我们来讲解如何进行程序指定schema</p><p><strong>没有嵌套结构的json</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">jsonString = [</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01001&quot;, &quot;city&quot; : &quot;AGAWAM&quot;,  &quot;pop&quot; : 15338, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span>,</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01002&quot;, &quot;city&quot; : &quot;CUSHMAN&quot;, &quot;pop&quot; : 36963, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">jsonRDD = sc.parallelize(jsonString)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义结构类型</span></span><br><span class="line"><span class="comment">#StructType：schema的整体结构，表示JSON的对象结构</span></span><br><span class="line"><span class="comment">#XXXStype:指的是某一列的数据类型</span></span><br><span class="line">jsonSchema = StructType() \</span><br><span class="line">  .add(<span class="string">&quot;id&quot;</span>, StringType(),<span class="literal">True</span>) \</span><br><span class="line">  .add(<span class="string">&quot;city&quot;</span>, StringType()) \</span><br><span class="line">  .add(<span class="string">&quot;pop&quot;</span> , LongType()) \</span><br><span class="line">  .add(<span class="string">&quot;state&quot;</span>,StringType())</span><br><span class="line"></span><br><span class="line">jsonSchema = StructType() \</span><br><span class="line">  .add(<span class="string">&quot;id&quot;</span>, LongType(),<span class="literal">True</span>) \</span><br><span class="line">  .add(<span class="string">&quot;city&quot;</span>, StringType()) \</span><br><span class="line">  .add(<span class="string">&quot;pop&quot;</span> , DoubleType()) \</span><br><span class="line">  .add(<span class="string">&quot;state&quot;</span>,StringType())</span><br><span class="line"></span><br><span class="line">reader = spark.read.schema(jsonSchema)</span><br><span class="line"></span><br><span class="line">jsonDF = reader.json(jsonRDD)</span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show()</span><br></pre></td></tr></table></figure><p><strong>带有嵌套结构的json</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line">jsonSchema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;id&quot;</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;city&quot;</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;loc&quot;</span> , ArrayType(DoubleType())),</span><br><span class="line">    StructField(<span class="string">&quot;pop&quot;</span>, LongType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;state&quot;</span>, StringType(), <span class="literal">True</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">reader = spark.read.schema(jsonSchema)</span><br><span class="line">jsonDF = reader.json(<span class="string">&#x27;data/nest.json&#x27;</span>)</span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show(<span class="number">2</span>)</span><br><span class="line">jsonDF.<span class="built_in">filter</span>(jsonDF.pop&gt;<span class="number">4000</span>).show(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h1 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h1><p>前面我们处理的数据实际上都是已经被处理好的规整数据，但是在大数据整个生产过程中，需要先对数据进行数据清洗，将杂乱无章的数据整理为符合后面处理要求的规整数据。</p><p><strong>数据去重</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">1.删除重复数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">groupby().count()：可以看到数据的重复情况</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">  (<span class="number">1</span>, <span class="number">144.5</span>, <span class="number">5.9</span>, <span class="number">33</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">  (<span class="number">2</span>, <span class="number">167.2</span>, <span class="number">5.4</span>, <span class="number">45</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">  (<span class="number">3</span>, <span class="number">124.1</span>, <span class="number">5.2</span>, <span class="number">23</span>, <span class="string">&#x27;F&#x27;</span>),</span><br><span class="line">  (<span class="number">4</span>, <span class="number">144.5</span>, <span class="number">5.9</span>, <span class="number">33</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">  (<span class="number">5</span>, <span class="number">133.2</span>, <span class="number">5.7</span>, <span class="number">54</span>, <span class="string">&#x27;F&#x27;</span>),</span><br><span class="line">  (<span class="number">3</span>, <span class="number">124.1</span>, <span class="number">5.2</span>, <span class="number">23</span>, <span class="string">&#x27;F&#x27;</span>),</span><br><span class="line">  (<span class="number">5</span>, <span class="number">129.2</span>, <span class="number">5.3</span>, <span class="number">42</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">], [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看重复记录</span></span><br><span class="line"><span class="comment">#无意义重复数据去重：数据中行与行完全重复</span></span><br><span class="line"><span class="comment"># 1.首先删除完全一样的记录</span></span><br><span class="line">df2 = df.dropDuplicates()</span><br><span class="line"></span><br><span class="line"><span class="comment">#有意义去重：删除除去无意义字段之外的完全重复的行数据</span></span><br><span class="line"><span class="comment"># 2.其次，关键字段值完全一模一样的记录（在这个例子中，是指除了id之外的列一模一样）</span></span><br><span class="line"><span class="comment"># 删除某些字段值完全一样的重复记录，subset参数定义这些字段</span></span><br><span class="line">df3 = df2.dropDuplicates(subset = [c <span class="keyword">for</span> c <span class="keyword">in</span> df2.columns <span class="keyword">if</span> c!=<span class="string">&#x27;id&#x27;</span>])</span><br><span class="line"><span class="comment"># 3.有意义的重复记录去重之后，再看某个无意义字段的值是否有重复（在这个例子中，是看id是否重复）</span></span><br><span class="line"><span class="comment"># 查看某一列是否有重复值</span></span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> fn</span><br><span class="line">df3.agg(fn.count(<span class="string">&#x27;id&#x27;</span>).alias(<span class="string">&#x27;id_count&#x27;</span>),fn.countDistinct(<span class="string">&#x27;id&#x27;</span>).alias(<span class="string">&#x27;distinct_id_count&#x27;</span>)).collect()</span><br><span class="line"><span class="comment"># 4.对于id这种无意义的列重复，添加另外一列自增id</span></span><br><span class="line"></span><br><span class="line">df3.withColumn(<span class="string">&#x27;new_id&#x27;</span>,fn.monotonically_increasing_id()).show()</span><br></pre></td></tr></table></figure><p><strong>缺失值处理</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">2.处理缺失值</span></span><br><span class="line"><span class="string">2.1 对缺失值进行删除操作(行，列)</span></span><br><span class="line"><span class="string">2.2 对缺失值进行填充操作(列的均值)</span></span><br><span class="line"><span class="string">2.3 对缺失值对应的行或列进行标记</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">df_miss = spark.createDataFrame([</span><br><span class="line">(<span class="number">1</span>, <span class="number">143.5</span>, <span class="number">5.6</span>, <span class="number">28</span>,<span class="string">&#x27;M&#x27;</span>, <span class="number">100000</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="number">167.2</span>, <span class="number">5.4</span>, <span class="number">45</span>,<span class="string">&#x27;M&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="literal">None</span> , <span class="number">5.2</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">4</span>, <span class="number">144.5</span>, <span class="number">5.9</span>, <span class="number">33</span>, <span class="string">&#x27;M&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">5</span>, <span class="number">133.2</span>, <span class="number">5.7</span>, <span class="number">54</span>, <span class="string">&#x27;F&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">6</span>, <span class="number">124.1</span>, <span class="number">5.2</span>, <span class="literal">None</span>, <span class="string">&#x27;F&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">7</span>, <span class="number">129.2</span>, <span class="number">5.3</span>, <span class="number">42</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">76000</span>),],</span><br><span class="line"> [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;income&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.计算每条记录的缺失值情况</span></span><br><span class="line"></span><br><span class="line">df_miss.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> row:(row[<span class="string">&#x27;id&#x27;</span>],<span class="built_in">sum</span>([c==<span class="literal">None</span> <span class="keyword">for</span> c <span class="keyword">in</span> row]))).collect()</span><br><span class="line">[(<span class="number">1</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">1</span>), (<span class="number">3</span>, <span class="number">4</span>), (<span class="number">4</span>, <span class="number">1</span>), (<span class="number">5</span>, <span class="number">1</span>), (<span class="number">6</span>, <span class="number">2</span>), (<span class="number">7</span>, <span class="number">0</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.计算各列的缺失情况百分比</span></span><br><span class="line">df_miss.agg(*[(<span class="number">1</span> - (fn.count(c) / fn.count(<span class="string">&#x27;*&#x27;</span>))).alias(c + <span class="string">&#x27;_missing&#x27;</span>) <span class="keyword">for</span> c <span class="keyword">in</span> df_miss.columns]).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、删除缺失值过于严重的列</span></span><br><span class="line"><span class="comment"># 其实是先建一个DF，不要缺失值的列</span></span><br><span class="line">df_miss_no_income = df_miss.select([</span><br><span class="line">c <span class="keyword">for</span> c <span class="keyword">in</span> df_miss.columns <span class="keyword">if</span> c != <span class="string">&#x27;income&#x27;</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、按照缺失值删除行（threshold是根据一行记录中，缺失字段的百分比的定义）</span></span><br><span class="line">df_miss_no_income.dropna(thresh=<span class="number">3</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、填充缺失值，可以用fillna来填充缺失值，</span></span><br><span class="line"><span class="comment"># 对于bool类型、或者分类类型，可以为缺失值单独设置一个类型，missing</span></span><br><span class="line"><span class="comment"># 对于数值类型，可以用均值或者中位数等填充</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fillna可以接收两种类型的参数：</span></span><br><span class="line"><span class="comment"># 一个数字、字符串，这时整个DataSet中所有的缺失值都会被填充为相同的值。</span></span><br><span class="line"><span class="comment"># 也可以接收一个字典｛列名：值｝这样</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 先计算均值，并组织成一个字典</span></span><br><span class="line">means = df_miss_no_income.agg( *[fn.mean(c).alias(c) <span class="keyword">for</span> c <span class="keyword">in</span> df_miss_no_income.columns <span class="keyword">if</span> c != <span class="string">&#x27;gender&#x27;</span>]).toPandas().to_dict(<span class="string">&#x27;records&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 然后添加其它的列</span></span><br><span class="line">means[<span class="string">&#x27;gender&#x27;</span>] = <span class="string">&#x27;missing&#x27;</span></span><br><span class="line"></span><br><span class="line">df_miss_no_income.fillna(means).show()</span><br></pre></td></tr></table></figure><p><strong>异常值处理</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">3、异常值处理</span></span><br><span class="line"><span class="string">异常值：不属于正常的值 包含：缺失值，超过正常范围内的较大值或较小值</span></span><br><span class="line"><span class="string">分位数去极值</span></span><br><span class="line"><span class="string">中位数绝对偏差去极值</span></span><br><span class="line"><span class="string">正态分布去极值</span></span><br><span class="line"><span class="string">上述三种操作的核心都是：通过原始数据设定一个正常的范围，超过此范围的就是一个异常值</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">df_outliers = spark.createDataFrame([</span><br><span class="line">(<span class="number">1</span>, <span class="number">143.5</span>, <span class="number">5.3</span>, <span class="number">28</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="number">154.2</span>, <span class="number">5.5</span>, <span class="number">45</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="number">342.3</span>, <span class="number">5.1</span>, <span class="number">99</span>),</span><br><span class="line">(<span class="number">4</span>, <span class="number">144.5</span>, <span class="number">5.5</span>, <span class="number">33</span>),</span><br><span class="line">(<span class="number">5</span>, <span class="number">133.2</span>, <span class="number">5.4</span>, <span class="number">54</span>),</span><br><span class="line">(<span class="number">6</span>, <span class="number">124.1</span>, <span class="number">5.1</span>, <span class="number">21</span>),</span><br><span class="line">(<span class="number">7</span>, <span class="number">129.2</span>, <span class="number">5.3</span>, <span class="number">42</span>),</span><br><span class="line">], [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>])</span><br><span class="line"><span class="comment"># 设定范围 超出这个范围的 用边界值替换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># approxQuantile方法接收三个参数：参数1，列名；参数2：想要计算的分位点，可以是一个点，也可以是一个列表（0和1之间的小数），第三个参数是能容忍的误差，如果是0，代表百分百精确计算。</span></span><br><span class="line"></span><br><span class="line">cols = [<span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line"></span><br><span class="line">bounds = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols:</span><br><span class="line">    quantiles = df_outliers.approxQuantile(col, [<span class="number">0.25</span>, <span class="number">0.75</span>], <span class="number">0.05</span>)</span><br><span class="line">    IQR = quantiles[<span class="number">1</span>] - quantiles[<span class="number">0</span>]</span><br><span class="line">    bounds[col] = [</span><br><span class="line">        quantiles[<span class="number">0</span>] - <span class="number">1.5</span> * IQR,</span><br><span class="line">        quantiles[<span class="number">1</span>] + <span class="number">1.5</span> * IQR</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bounds</span><br><span class="line">&#123;<span class="string">&#x27;age&#x27;</span>: [-<span class="number">11.0</span>, <span class="number">93.0</span>], <span class="string">&#x27;height&#x27;</span>: [<span class="number">4.499999999999999</span>, <span class="number">6.1000000000000005</span>], <span class="string">&#x27;weight&#x27;</span>: [<span class="number">91.69999999999999</span>, <span class="number">191.7</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为异常值字段打标志</span></span><br><span class="line">outliers = df_outliers.select(*[<span class="string">&#x27;id&#x27;</span>] + [( (df_outliers[c] &lt; bounds[c][<span class="number">0</span>]) | (df_outliers[c] &gt; bounds[c][<span class="number">1</span>]) ).alias(c + <span class="string">&#x27;_o&#x27;</span>) <span class="keyword">for</span> c <span class="keyword">in</span> cols ])</span><br><span class="line">outliers.show()</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># +---+--------+--------+-----+</span></span><br><span class="line"><span class="comment"># | id|weight_o|height_o|age_o|</span></span><br><span class="line"><span class="comment"># +---+--------+--------+-----+</span></span><br><span class="line"><span class="comment"># |  1|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  2|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  3|    true|   false| true|</span></span><br><span class="line"><span class="comment"># |  4|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  5|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  6|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  7|   false|   false|false|</span></span><br><span class="line"><span class="comment"># +---+--------+--------+-----+</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 再回头看看这些异常值的值，重新和原始数据关联</span></span><br><span class="line"></span><br><span class="line">df_outliers = df_outliers.join(outliers, on=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">df_outliers.<span class="built_in">filter</span>(<span class="string">&#x27;weight_o&#x27;</span>).select(<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>).show()</span><br><span class="line"><span class="comment"># +---+------+</span></span><br><span class="line"><span class="comment"># | id|weight|</span></span><br><span class="line"><span class="comment"># +---+------+</span></span><br><span class="line"><span class="comment"># |  3| 342.3|</span></span><br><span class="line"><span class="comment"># +---+------+</span></span><br><span class="line"></span><br><span class="line">df_outliers.<span class="built_in">filter</span>(<span class="string">&#x27;age_o&#x27;</span>).select(<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;age&#x27;</span>).show()</span><br><span class="line"><span class="comment"># +---+---+</span></span><br><span class="line"><span class="comment"># | id|age|</span></span><br><span class="line"><span class="comment"># +---+---+</span></span><br><span class="line"><span class="comment"># |  3| 99|</span></span><br><span class="line"><span class="comment"># +---+---+</span></span><br></pre></td></tr></table></figure><h1 id="sparkStreaming"><a href="#sparkStreaming" class="headerlink" title="sparkStreaming"></a>sparkStreaming</h1><h2 id="sparkStreaming概述"><a href="#sparkStreaming概述" class="headerlink" title="sparkStreaming概述"></a>sparkStreaming概述</h2><h3 id="SparkStreaming是什么"><a href="#SparkStreaming是什么" class="headerlink" title="SparkStreaming是什么"></a>SparkStreaming是什么</h3><ul><li><p>它是一个可扩展，高吞吐具有容错性的流式计算框架</p><p>吞吐量：单位时间内成功传输数据的数量</p></li></ul><p>之前我们接触的spark-core和spark-sql都是处理属于离线批处理任务，数据一般都是在固定位置上，通常我们写好一个脚本，每天定时去处理数据，计算，保存数据结果。这类任务通常是T+1(一天一个任务)，对实时性要求不高。</p><p><img src="ss1.png" alt="ss1"></p><p>但在企业中存在很多实时性处理的需求，例如：双十一的京东阿里，通常会做一个实时的数据大屏，显示实时订单。这种情况下，对数据实时性要求较高，仅仅能够容忍到延迟1分钟或几秒钟。</p><p><img src="ss2.png" alt="ss2"></p><p><strong>实时计算框架对比</strong></p><p>Storm</p><ul><li>流式计算框架</li><li>以record为单位处理数据</li><li>也支持micro-batch方式（Trident）</li></ul><p>Spark</p><ul><li>批处理计算框架</li><li>以RDD为单位处理数据</li><li>支持micro-batch流式处理数据（Spark Streaming）</li></ul><p>对比：</p><ul><li>吞吐量：Spark Streaming优于Storm</li><li>延迟：Spark Streaming差于Storm</li></ul><h3 id="SparkStreaming的组件"><a href="#SparkStreaming的组件" class="headerlink" title="SparkStreaming的组件"></a>SparkStreaming的组件</h3><ul><li>Streaming Context<ul><li>一旦一个Context已经启动(调用了Streaming Context的start()),就不能有新的流算子(Dstream)建立或者是添加到context中</li><li>一旦一个context已经停止,不能重新启动(Streaming Context调用了stop方法之后 就不能再次调 start())</li><li>在JVM(java虚拟机)中, 同一时间只能有一个Streaming Context处于活跃状态, 一个SparkContext创建一个Streaming Context</li><li>在Streaming Context上调用Stop方法, 也会关闭SparkContext对象, 如果只想仅关闭Streaming Context对象,设置stop()的可选参数为false</li><li>一个SparkContext对象可以重复利用去创建多个Streaming Context对象(不关闭SparkContext前提下), 但是需要关一个再开下一个</li></ul></li><li>DStream (离散流)<ul><li>代表一个连续的数据流</li><li>在内部, DStream由一系列连续的RDD组成</li><li>DStreams中的每个RDD都包含确定时间间隔内的数据</li><li>任何对DStreams的操作都转换成了对DStreams隐含的RDD的操作</li><li>数据源<ul><li>基本源<ul><li>TCP/IP Socket</li><li>FileSystem</li></ul></li><li>高级源<ul><li>Kafka</li><li>Flume</li></ul></li></ul></li></ul></li></ul><h2 id="Spark-Streaming编码实践"><a href="#Spark-Streaming编码实践" class="headerlink" title="Spark Streaming编码实践"></a>Spark Streaming编码实践</h2><p><strong>Spark Streaming编码步骤：</strong></p><ul><li>创建一个StreamingContext</li><li>从StreamingContext中创建一个数据对象</li><li>对数据对象进行Transformations操作</li><li>输出结果</li><li>开始和停止</li></ul><p><strong>利用Spark Streaming实现WordCount</strong></p><p>需求：监听某个端口上的网络数据，实时统计出现的不同单词个数。</p><ol><li>需要安装一个nc工具：sudo yum install -y nc</li><li>执行指令：nc -lk 9999 -v</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line">SPARK_HOME = <span class="string">&quot;/home/hadoop/app/spark-2.3.0-bin-2.6.0-cdh5.7.0&quot;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;SPARK_HOME&quot;</span>] = SPARK_HOME</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    </span><br><span class="line">    sc = SparkContext(<span class="string">&quot;local[2]&quot;</span>,appName=<span class="string">&quot;NetworkWordCount&quot;</span>)</span><br><span class="line">    <span class="comment">#参数2：指定执行计算的时间间隔</span></span><br><span class="line">    ssc = StreamingContext(sc, <span class="number">1</span>)</span><br><span class="line">    <span class="comment">#监听ip，端口上的上的数据</span></span><br><span class="line">    lines = ssc.socketTextStream(<span class="string">&#x27;localhost&#x27;</span>,<span class="number">9999</span>)</span><br><span class="line">    <span class="comment">#将数据按空格进行拆分为多个单词</span></span><br><span class="line">    words = lines.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">    <span class="comment">#将单词转换为(单词，1)的形式</span></span><br><span class="line">    pairs = words.<span class="built_in">map</span>(<span class="keyword">lambda</span> word:(word,<span class="number">1</span>))</span><br><span class="line">    <span class="comment">#统计单词个数</span></span><br><span class="line">    wordCounts = pairs.reduceByKey(<span class="keyword">lambda</span> x,y:x+y)</span><br><span class="line">    <span class="comment">#打印结果信息，会使得前面的transformation操作执行</span></span><br><span class="line">    wordCounts.pprint()</span><br><span class="line">    <span class="comment">#启动StreamingContext</span></span><br><span class="line">    ssc.start()</span><br><span class="line">    <span class="comment">#等待计算结束</span></span><br><span class="line">    ssc.awaitTermination()</span><br></pre></td></tr></table></figure><p>可视化查看效果：<a href="http://192.168.199.188:4040">http://192.168.199.188:4040</a></p><p>点击streaming，查看效果</p><h2 id="Spark-Streaming的状态操作"><a href="#Spark-Streaming的状态操作" class="headerlink" title="Spark Streaming的状态操作"></a>Spark Streaming的状态操作</h2><p>在Spark Streaming中存在两种状态操作</p><ul><li>UpdateStateByKey</li><li>Windows操作</li></ul><p>使用有状态的transformation，需要开启Checkpoint</p><ul><li>spark streaming 的容错机制</li><li>它将足够多的信息checkpoint到某些具备容错性的存储系统如hdfs上，以便出错时能够迅速恢复</li></ul><h3 id="updateStateByKey"><a href="#updateStateByKey" class="headerlink" title="updateStateByKey"></a>updateStateByKey</h3><p>Spark Streaming实现的是一个实时批处理操作，每隔一段时间将数据进行打包，封装成RDD，是无状态的。</p><p>无状态：指的是每个时间片段的数据之间是没有关联的。</p><p>需求：想要将一个大时间段（1天），即多个小时间段的数据内的数据持续进行累积操作</p><p>一般超过一天都是用RDD或Spark SQL来进行离线批处理</p><p>如果没有UpdateStateByKey，我们需要将每一秒的数据计算好放入mysql中取，再用mysql来进行统计计算</p><p>Spark Streaming中提供这种状态保护机制，即updateStateByKey</p><p>步骤：</p><ul><li>首先，要定义一个state，可以是任意的数据类型</li><li>其次，要定义state更新函数—指定一个函数如何使用之前的state和新值来更新state</li><li>对于每个batch，Spark都会为每个之前已经存在的key去应用一次state更新函数，无论这个key在batch中是否有新的数据。如果state更新函数返回none，那么key对应的state就会被删除</li><li>对于每个新出现的key，也会执行state更新函数</li></ul><p>举例：词统计。</p><h3 id="案例：updateStateByKey"><a href="#案例：updateStateByKey" class="headerlink" title="案例：updateStateByKey"></a>案例：updateStateByKey</h3><p>需求：监听网络端口的数据，获取到每个批次的出现的单词数量，并且需要把每个批次的信息保留下来</p><p><strong>代码</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line">SPARK_HOME = <span class="string">&quot;/home/hadoop/app/spark-2.3.0-bin-2.6.0-cdh5.7.0&quot;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;SPARK_HOME&quot;</span>] = SPARK_HOME</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.session <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建SparkContext</span></span><br><span class="line">spark = SparkSession.builder.master(<span class="string">&quot;local[2]&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">ssc = StreamingContext(sc, <span class="number">3</span>)</span><br><span class="line"><span class="comment">#开启检查点</span></span><br><span class="line">ssc.checkpoint(<span class="string">&quot;checkpoint&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义state更新函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateFunc</span>(<span class="params">new_values, last_sum</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(new_values) + (last_sum <span class="keyword">or</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">lines = ssc.socketTextStream(<span class="string">&quot;localhost&quot;</span>, <span class="number">9999</span>)</span><br><span class="line"><span class="comment"># 对数据以空格进行拆分，分为多个单词</span></span><br><span class="line">counts = lines.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">&quot; &quot;</span>)) \</span><br><span class="line">    .<span class="built_in">map</span>(<span class="keyword">lambda</span> word: (word, <span class="number">1</span>)) \</span><br><span class="line">    .updateStateByKey(updateFunc=updateFunc)<span class="comment">#应用updateStateByKey函数</span></span><br><span class="line">    </span><br><span class="line">counts.pprint()</span><br><span class="line"></span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure><h3 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h3><ul><li>窗口长度L：运算的数据量</li><li>滑动间隔G：控制每隔多长时间做一次运算</li></ul><p>每隔G秒，统计最近L秒的数据</p><p><img src="ss14.png" alt="ss14"></p><p><strong>操作细节</strong></p><ul><li>Window操作是基于窗口长度和滑动间隔来工作的</li><li>窗口的长度控制考虑前几批次数据量</li><li>默认为批处理的滑动间隔来确定计算结果的频率</li></ul><p><strong>相关函数</strong></p><p><img src="ss15.png" alt="ss15"></p><ul><li>Smart computation</li><li>invAddFunc</li></ul><p>reduceByKeyAndWindow(func,invFunc,windowLength,slideInterval,[num,Tasks])</p><p>func:正向操作，类似于updateStateByKey</p><p>invFunc：反向操作</p><p><img src="ss16.png" alt="ss16"></p><p>例如在热词时，在上一个窗口中可能是热词，这个一个窗口中可能不是热词，就需要在这个窗口中把该次剔除掉</p><p>典型案例：热点搜索词滑动统计，每隔10秒，统计最近60秒钟的搜索词的搜索频次，并打印出最靠前的3个搜索词出现次数。</p><p><img src="ss17.png" alt="ss17"></p><p><strong>案例</strong></p><p>监听网络端口的数据，每隔3秒统计前6秒出现的单词数量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line">SPARK_HOME = <span class="string">&quot;/home/hadoop/app/spark-2.3.0-bin-2.6.0-cdh5.7.0&quot;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;SPARK_HOME&quot;</span>] = SPARK_HOME</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.session <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_countryname</span>(<span class="params">line</span>):</span></span><br><span class="line">    country_name = line.strip()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> country_name == <span class="string">&#x27;usa&#x27;</span>:</span><br><span class="line">        output = <span class="string">&#x27;USA&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> country_name == <span class="string">&#x27;ind&#x27;</span>:</span><br><span class="line">        output = <span class="string">&#x27;India&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> country_name == <span class="string">&#x27;aus&#x27;</span>:</span><br><span class="line">        output = <span class="string">&#x27;Australia&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output = <span class="string">&#x27;Unknown&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (output, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"><span class="comment">#定义处理的时间间隔</span></span><br><span class="line">    batch_interval = <span class="number">1</span> <span class="comment"># base time unit (in seconds)</span></span><br><span class="line">    <span class="comment">#定义窗口长度</span></span><br><span class="line">    window_length = <span class="number">6</span> * batch_interval</span><br><span class="line">    <span class="comment">#定义滑动时间间隔</span></span><br><span class="line">    frequency = <span class="number">3</span> * batch_interval</span><br><span class="line"></span><br><span class="line">    <span class="comment">#获取StreamingContext</span></span><br><span class="line">    spark = SparkSession.builder.master(<span class="string">&quot;local[2]&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">ssc = StreamingContext(sc, batch_interval)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#需要设置检查点</span></span><br><span class="line">    ssc.checkpoint(<span class="string">&quot;checkpoint&quot;</span>)</span><br><span class="line"></span><br><span class="line">    lines = ssc.socketTextStream(<span class="string">&#x27;localhost&#x27;</span>, <span class="number">9999</span>)</span><br><span class="line">    addFunc = <span class="keyword">lambda</span> x, y: x + y</span><br><span class="line">    invAddFunc = <span class="keyword">lambda</span> x, y: x - y</span><br><span class="line">    <span class="comment">#调用reduceByKeyAndWindow，来进行窗口函数的调用</span></span><br><span class="line">    window_counts = lines.<span class="built_in">map</span>(get_countryname) \</span><br><span class="line">        .reduceByKeyAndWindow(addFunc, invAddFunc, window_length, frequency)</span><br><span class="line"><span class="comment">#输出处理结果信息</span></span><br><span class="line">    window_counts.pprint()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br></pre></td></tr></table></figure><h2 id="Spark-Streaming对接Kafka"><a href="#Spark-Streaming对接Kafka" class="headerlink" title="Spark Streaming对接Kafka"></a>Spark Streaming对接Kafka</h2><h3 id="对接数据的两种方式"><a href="#对接数据的两种方式" class="headerlink" title="对接数据的两种方式"></a>对接数据的两种方式</h3><p>在前面的案例中，我们监听了来自网络端口的数据，实现了WordCount，但是在实际开发中并不是这样。我们更多的是接收来自高级数据源的数据，例如Kafka。</p><p>下面我们来介绍如何利用Spark Streaming对接Kafka</p><p><img src="ss13.png" alt=""></p><p>以下两种方式都是为了数据可靠性：</p><ul><li>Receiver-based Approach：由Receiver来对接数据，Receiver接收到数据后会将日志预先写入到hdfs上（WAL），同时也会将数据做副本传输到其他的Worker节点。在读取数据的过程中，Receiver是从Zookeeper中获取数据的偏移信息。</li><li>Direct Approach（No Receivers）：没有Receiver接收信息，由Spark Streaming直接对接Kafka的broker，获取数据和数据的偏移信息。</li></ul><p>上述两种方式中，Direct Approach方式更加可靠，不需要Spark Streaming自己去保证维护数据的可靠性，而是由善于处理这类工作的Kafka来做。</p><p><strong>对应代码</strong></p><ul><li>KafkaUtils.createStream(ssc,zkQuorum,”spark-streaming-consumer”,{topic:1})</li><li>KafkaUtils.createDirectStream(ssc,[topic],{“metadata.broker.list”:’localhost:9092’})</li></ul><p><strong>Direct API的好处</strong></p><ul><li><strong>简化的并行</strong>：在Receiver的方式中我们提到创建多个Receiver之后利用union来合并成一个Dstream的方式提高数据传输并行度。而在Direct方式中，<strong>Kafka中的partition与RDD中的partition是一一对应</strong>的并行读取Kafka数据，这种映射关系也更利于理解和优化。</li><li><strong>高效</strong>：在Receiver的方式中，为了达到0数据丢失需要将数据存入Write Ahead Log中，这样在Kafka和日志中就保存了两份数据，浪费！而第二种方式不存在这个问题，只要我们Kafka的数据保留时间足够长，我们都能够从Kafka进行数据恢复。</li><li><strong>精确一次</strong>：在Receiver的方式中，使用的是Kafka的高阶API接口从Zookeeper中获取offset值，这也是传统的从Kafka中读取数据的方式，但由于Spark Streaming消费的数据和Zookeeper中记录的offset不同步，这种方式偶尔会造成数据重复消费。而第二种方式，直接使用了简单的低阶Kafka API，Offsets则利用Spark Streaming的checkpoints进行记录，消除了这种不一致性。</li></ul><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p><strong>步骤：</strong></p><ul><li><p>配置spark streaming kafka开发环境</p><ul><li><ol><li>下载spark streaming集成kafka的jar包<br>spark-streaming-kafka-0-8-assembly_2.11-2.3.0.jar</li></ol></li><li><ol><li>将jar包放置到spark的jars目录下</li></ol></li><li><ol><li>编辑spark/conf目录下的spark-defaults.conf，添加如下两条配置</li></ol><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">spark.driver.extraClassPath</span>=<span class="string">$SPAKR_HOME/jars/spark-streaming-kafka-0-8-assembly_2.11-2.3.0.jar</span></span><br><span class="line"><span class="meta">spark.executor.extraClassPath</span>=<span class="string">$SPARK_HOME/jars/spark-streaming-kafka-0-8-assembly_2.11-2.3.0.jar</span></span><br><span class="line"><span class="comment">#driver和executor对应的两个路径一致</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>测试配置是否成功</p><ul><li><p>启动zookeeper</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure></li><li><p>启动kafka</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure></li><li><p>创建topic</p><ul><li><p>bin/kafka-topics.sh —create —zookeeper localhost:2181 —replication-factor 1 —partitions 1 —topic test</p><p>replication-factor：副本数量</p><p>partitions：分区数量</p><p>出现Created topic “test”，说明创建成功</p></li></ul></li><li><p>查看所有topic</p><ul><li>bin/kafka-topics.sh —list —zookeeper localhost:2181</li></ul></li><li><p>通过Pycharm远程连接Centos 创建代码</p></li><li><p>通过KafkaUtils 成功连接Kafka 创建DStream对象说明连接成功</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line">SPARK_HOME = <span class="string">&quot;/home/hadoop/app/spark-2.3.0-bin-2.6.0-cdh5.7.0&quot;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;SPARK_HOME&quot;</span>] = SPARK_HOME</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming.kafka <span class="keyword">import</span> KafkaUtils</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.session <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">sc = sparkContext（<span class="string">&#x27;master[2]&#x27;</span>,<span class="string">&#x27;kafkastreamingtest&#x27;</span></span><br><span class="line">ssc = StreamingContext(sc,<span class="number">3</span>)</span><br><span class="line"><span class="comment">#createDirectStream 连接kafka数据源获取数据</span></span><br><span class="line"><span class="comment"># 参数1 streamingcontext</span></span><br><span class="line"><span class="comment">#参数2 topic的名字</span></span><br><span class="line"><span class="comment"># 参数3 kafka broker地址</span></span><br><span class="line">ks = KafkaUtils.createDirectStream(ssc,[<span class="string">&quot;topic1&quot;</span>],&#123;<span class="string">&quot;metadata.broker.list&quot;</span>:<span class="string">&quot;localhost:9092&quot;</span>&#125;)</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="案例实现"><a href="#案例实现" class="headerlink" title="案例实现"></a>案例实现</h3><p>需求：利用Spark Streaming不断处理来自Kafka生产者生产的数据，并统计出现的单词数量</p><ul><li><ol><li>编写producer.py，用于生产数据</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaProducer</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建KafkaProducer，连接broker</span></span><br><span class="line">producer = KafkaProducer(bootstrap_servers=<span class="string">&#x27;localhost:9092&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#每隔一段时间发送一端字符串数据到broker</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send_data</span>():</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">60</span>):</span><br><span class="line">        <span class="comment"># (key,value) 参数2 是value </span></span><br><span class="line">        producer.send(<span class="string">&#x27;topic_name&#x27;</span>,<span class="string">&quot;hello,kafka,spark,streaming,kafka&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">2</span>)</span><br><span class="line">send_data()</span><br></pre></td></tr></table></figure></li><li><ol><li>编辑Spark Streaming代码，统计单词出现的数量</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming.kafka <span class="keyword">import</span> KafkaUtils</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.session <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">topic=<span class="string">&quot;topic_name&quot;</span></span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.master(<span class="string">&quot;local[2]&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">ssc = StreamingContext(sc,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建direct连接，指定要连接的topic和broker地址</span></span><br><span class="line">ks = KafkaUtils.createDirectStream(ssc,[topic],&#123;<span class="string">&quot;metadata.broker.list&quot;</span>:<span class="string">&quot;localhost:9092&quot;</span>&#125;)</span><br><span class="line"><span class="comment">#(None,内容)</span></span><br><span class="line">ks.pprint()</span><br><span class="line"><span class="comment">#（key,value)</span></span><br><span class="line"><span class="comment">#以下代码每操作一次，就打印输出一次</span></span><br><span class="line">lines = ks.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x[<span class="number">1</span>])</span><br><span class="line">lines.pprint()</span><br><span class="line"></span><br><span class="line">words = lines.flatMap(<span class="keyword">lambda</span> line:line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"><span class="comment">#words.pprint()</span></span><br><span class="line"></span><br><span class="line">pairs = words.<span class="built_in">map</span>(<span class="keyword">lambda</span> word:(word,<span class="number">1</span>))</span><br><span class="line"><span class="comment">#pairs.pprint()</span></span><br><span class="line"></span><br><span class="line">counts = pairs.reduceByKey(<span class="keyword">lambda</span> x,y:x+y)</span><br><span class="line">counts.pprint()</span><br><span class="line"></span><br><span class="line">ssc.start()</span><br><span class="line"><span class="comment">#等待计算结束</span></span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure></li><li><ol><li>开启Spark Streaming消费数据，将产生的日志结果存储到日志中</li></ol><p>spark-submit xxx.py&gt;a.log</p></li><li><ol><li>开启producer.py，生产数据</li></ol><p>python3 producer.py</p></li><li><ol><li>通过浏览器观察运算过程</li></ol><p><a href="http://node-teach:4040">http://node-teach:4040</a></p></li><li><ol><li>分析生成的日志内容</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">-------------------------------------------</span><br><span class="line">Time: 2018-12-11 01:31:21</span><br><span class="line">-------------------------------------------</span><br><span class="line">(None, &#x27;hello,kafka,spark,streaming,kafka&#x27;)</span><br><span class="line">(None, &#x27;hello,kafka,spark,streaming,kafka&#x27;)</span><br><span class="line">(None, &#x27;hello,kafka,spark,streaming,kafka&#x27;)</span><br><span class="line">(None, &#x27;hello,kafka,spark,streaming,kafka&#x27;)</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 2018-12-11 01:02:33</span><br><span class="line">-------------------------------------------</span><br><span class="line">hello,kafka,spark,streaming,kafka</span><br><span class="line">hello,kafka,spark,streaming,kafka</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 2018-12-11 01:02:33</span><br><span class="line">-------------------------------------------</span><br><span class="line">hello</span><br><span class="line">kafka</span><br><span class="line">spark</span><br><span class="line">streaming</span><br><span class="line">kafka</span><br><span class="line">hello</span><br><span class="line">kafka</span><br><span class="line">spark</span><br><span class="line">streaming</span><br><span class="line">kafka</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 2018-12-11 01:02:33</span><br><span class="line">-------------------------------------------</span><br><span class="line">(&#x27;hello&#x27;, 1)</span><br><span class="line">(&#x27;kafka&#x27;, 1)</span><br><span class="line">(&#x27;spark&#x27;, 1)</span><br><span class="line">(&#x27;streaming&#x27;, 1)</span><br><span class="line">(&#x27;kafka&#x27;, 1)</span><br><span class="line">(&#x27;hello&#x27;, 1)</span><br><span class="line">(&#x27;kafka&#x27;, 1)</span><br><span class="line">(&#x27;spark&#x27;, 1)</span><br><span class="line">(&#x27;streaming&#x27;, 1)</span><br><span class="line">(&#x27;kafka&#x27;, 1)</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 2018-12-11 01:02:33</span><br><span class="line">-------------------------------------------</span><br><span class="line">(&#x27;streaming&#x27;, 2)</span><br><span class="line">(&#x27;hello&#x27;, 2)</span><br><span class="line">(&#x27;kafka&#x27;, 4)</span><br><span class="line">(&#x27;spark&#x27;, 2)</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 2018-12-11 01:02:36</span><br><span class="line">-------------------------------------------</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 2018-12-11 01:02:36</span><br><span class="line">-------------------------------------------</span><br></pre></td></tr></table></figure></li></ul><h2 id="Spark-Streaming对接flume"><a href="#Spark-Streaming对接flume" class="headerlink" title="Spark Streaming对接flume"></a>Spark Streaming对接flume</h2><p>flume作为日志实时采集的框架，可以与SparkStreaming实时处理框架进行对接，flume实时产生数据，sparkStreaming做实时处理。</p><p>Spark Streaming对接FlumeNG有两种方式，一种是FlumeNG将消息<strong>Push</strong>推给Spark Streaming，还有一种是Spark Streaming从flume 中<strong>Pull</strong>拉取数据。</p><h3 id="Pull方式"><a href="#Pull方式" class="headerlink" title="Pull方式"></a>Pull方式</h3><ul><li><ol><li>安装flume1.6以上</li></ol></li><li><ol><li>下载依赖包</li></ol><p>spark-streaming-flume-assembly_2.11-2.3.0.jar放入到flume的lib目录下</p></li><li><ol><li>写flume的agent，注意既然是拉取的方式，那么flume向自己所在的机器上产数据就行</li></ol></li><li><ol><li>编写flume-pull.conf配置文件</li></ol><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">simple-agent.sources</span> = <span class="string">netcat-source</span></span><br><span class="line"><span class="meta">simple-agent.sinks</span> = <span class="string">spark-sink</span></span><br><span class="line"><span class="meta">simple-agent.channels</span> = <span class="string">memory-channel</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment"># source</span></span><br><span class="line"><span class="meta">simple-agent.sources.netcat-source.type</span> = <span class="string">netcat</span></span><br><span class="line"><span class="meta">simple-agent.sources.netcat-source.bind</span> = <span class="string">localhost</span></span><br><span class="line"><span class="meta">simple-agent.sources.netcat-source.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="meta">simple-agent.sinks.spark-sink.type</span> = <span class="string">org.apache.spark.streaming.flume.sink.SparkSink</span></span><br><span class="line"><span class="meta">simple-agent.sinks.spark-sink.hostname</span> = <span class="string">localhost</span></span><br><span class="line"><span class="meta">simple-agent.sinks.spark-sink.port</span> = <span class="string">41414</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="meta">simple-agent.channels.memory-channel.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="meta">simple-agent.sources.netcat-source.channels</span> = <span class="string">memory-channel</span></span><br><span class="line"><span class="meta">simple-agent.sinks.spark-sink.channel</span>=<span class="string">memory-channel</span></span><br></pre></td></tr></table></figure></li><li><p>5，启动flume</p><p>flume-ng agent -n simple-agent -f flume-pull.conf -Dflume.root.logger=INFO,console</p></li><li><p>6，编写word count代码</p><p>代码：</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming.flume <span class="keyword">import</span> FlumeUtils</span><br><span class="line"></span><br><span class="line">sc=SparkContext(<span class="string">&quot;local[2]&quot;</span>,<span class="string">&quot;FlumeWordCount_Pull&quot;</span>)</span><br><span class="line"><span class="comment">#处理时间间隔为2s</span></span><br><span class="line">ssc=StreamingContext(sc,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用flume工具类创建pull方式的流</span></span><br><span class="line">lines = FlumeUtils.createPollingStream(ssc, [(<span class="string">&quot;localhost&quot;</span>,<span class="number">41414</span>)])</span><br><span class="line"></span><br><span class="line">lines1=lines.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x[<span class="number">1</span>])</span><br><span class="line">counts = lines1.flatMap(<span class="keyword">lambda</span> line:line.split(<span class="string">&quot; &quot;</span>))\</span><br><span class="line">        .<span class="built_in">map</span>(<span class="keyword">lambda</span> word:(word,<span class="number">1</span>))\</span><br><span class="line">        .reduceByKey(<span class="keyword">lambda</span> a,b:a+b)</span><br><span class="line">counts.pprint()</span><br><span class="line"><span class="comment">#启动spark streaming应用</span></span><br><span class="line">ssc.start()</span><br><span class="line"><span class="comment">#等待计算终止</span></span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure><p>启动</p><p><code>bin/spark-submit --jars xxx/spark-streaming-flume-assembly_2.11-2.3.0.jar xxx/flume_pull.py</code></p><h2 id="push方式"><a href="#push方式" class="headerlink" title="push方式"></a>push方式</h2><p>大部分操作和之前一致</p><p>flume配置</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">simple-agent.sources</span> = <span class="string">netcat-source</span></span><br><span class="line"><span class="meta">simple-agent.sinks</span> = <span class="string">avro-sink</span></span><br><span class="line"><span class="meta">simple-agent.channels</span> = <span class="string">memory-channel</span></span><br><span class="line"></span><br><span class="line"><span class="meta">simple-agent.sources.netcat-source.type</span> = <span class="string">netcat</span></span><br><span class="line"><span class="meta">simple-agent.sources.netcat-source.bind</span> = <span class="string">localhost</span></span><br><span class="line"><span class="meta">simple-agent.sources.netcat-source.port</span> = <span class="string">44444</span></span><br><span class="line"></span><br><span class="line"><span class="meta">simple-agent.sinks.avro-sink.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="meta">simple-agent.sinks.avro-sink.hostname</span> = <span class="string">localhost</span></span><br><span class="line"><span class="meta">simple-agent.sinks.avro-sink.port</span> = <span class="string">41414</span></span><br><span class="line"><span class="meta">simple-agent.channels.memory-channel.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="meta">simple-agent.sources.netcat-source.channels</span> = <span class="string">memory-channel</span></span><br><span class="line"></span><br><span class="line"><span class="meta">simple-agent.sources.netcat-source.channels</span> = <span class="string">memory-channel</span></span><br><span class="line"><span class="meta">simple-agent.sinks.avro-sink.channel</span>=<span class="string">memory-channel</span></span><br></pre></td></tr></table></figure><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming.flume <span class="keyword">import</span> FlumeUtils</span><br><span class="line"></span><br><span class="line">sc=SparkContext(<span class="string">&quot;local[2]&quot;</span>,<span class="string">&quot;FlumeWordCount_Push&quot;</span>)</span><br><span class="line"><span class="comment">#处理时间间隔为2s</span></span><br><span class="line">ssc=StreamingContext(sc,<span class="number">2</span>)</span><br><span class="line"><span class="comment">#创建push方式的DStream</span></span><br><span class="line">lines = FlumeUtils.createStream(ssc, <span class="string">&quot;localhost&quot;</span>,<span class="number">41414</span>)</span><br><span class="line">lines1=lines.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x[<span class="number">1</span>].strip())</span><br><span class="line"><span class="comment">#对1s内收到的字符串进行分割</span></span><br><span class="line">words=lines1.flatMap(<span class="keyword">lambda</span> line:line.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"><span class="comment">#映射为（word，1）元祖</span></span><br><span class="line">pairs=words.<span class="built_in">map</span>(<span class="keyword">lambda</span> word:(word,<span class="number">1</span>))</span><br><span class="line">wordcounts=pairs.reduceByKey(<span class="keyword">lambda</span> x,y:x+y)</span><br><span class="line">wordcounts.pprint()</span><br><span class="line"><span class="comment">#启动spark streaming应用</span></span><br><span class="line">ssc.start()</span><br><span class="line"><span class="comment">#等待计算终止</span></span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Search / Advertisement / Recommendation / Causal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark core</title>
      <link href="/2022/01/18/5.5-Spark-core/"/>
      <url>/2022/01/18/5.5-Spark-core/</url>
      
        <content type="html"><![CDATA[<p><strong>推荐系统学习笔记目录</strong></p><ol><li><a href="https://xfliu1998.github.io/2022/01/18/5.1-Recommendation-System-Introduction/">推荐系统介绍</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/">推荐算法</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.3-Hadoop/">Hadoop</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.4-Hive/">Hive &amp; HBase</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.5-Spark-core/">Spark core</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.6-Spark-SQL/">Spark SQL &amp; Spark streaming</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.7-RS-case/">推荐系统案例</a></li></ol><h2 id="spark-入门"><a href="#spark-入门" class="headerlink" title="spark 入门"></a>spark 入门</h2><h3 id="spark概述"><a href="#spark概述" class="headerlink" title="spark概述"></a>spark概述</h3><ul><li><p>1、什么是spark</p><ul><li>基于内存的计算引擎，它的计算速度非常快。但是仅仅只涉及到数据的计算，并没有涉及到数据的存储。</li></ul></li><li><p>2、为什么要学习spark<br><strong>MapReduce框架局限性</strong></p><ul><li><ol><li>Map结果写磁盘，Reduce写HDFS，多个MR之间通过HDFS交换数据</li></ol></li><li><ol><li>任务调度和启动开销大</li></ol></li><li><ol><li>无法充分利用内存</li></ol></li><li><ol><li>不适合迭代计算（如机器学习、图计算等等），交互式处理（数据挖掘）</li></ol></li><li><ol><li>不适合流式处理（点击日志分析）</li></ol></li><li><ol><li>MapReduce编程不够灵活，仅支持Map和Reduce两种操作</li></ol></li></ul><p><strong>Hadoop生态圈</strong></p><ul><li>批处理：MapReduce、Hive、Pig</li><li>流式计算：Storm</li><li>交互式计算：Impala、presto</li></ul><p>需要一种灵活的框架可同时进行批处理、流式计算、交互式计算</p><ul><li>内存计算引擎，提供cache机制来支持需要反复迭代计算或者多次数据共享，减少数据读取的IO开销</li><li>DAG引擎，较少多次计算之间中间结果写到HDFS的开销</li><li>使用多线程模型来减少task启动开销，shuffle过程中避免不必要的sort操作以及减少磁盘IO</li></ul><p>spark的缺点是：吃内存，不太稳定</p></li><li><p>3、spark特点</p><ul><li>1、速度快（比mapreduce在内存中快100倍，在磁盘中快10倍）<ul><li>spark中的job中间结果可以不落地，可以存放在内存中。</li><li>mapreduce中map和reduce任务都是以进程的方式运行着，而spark中的job是以线程方式运行在进程中。</li></ul></li><li>2、易用性（可以通过java/scala/python/R开发spark应用程序）</li><li>3、通用性（可以使用spark sql/spark streaming/mlib/Graphx）</li><li>4、兼容性（spark程序可以运行在standalone/yarn/mesos）</li></ul></li></ul><h3 id="spark启动（local模式）和WordCount-演示"><a href="#spark启动（local模式）和WordCount-演示" class="headerlink" title="spark启动（local模式）和WordCount(演示)"></a>spark启动（local模式）和WordCount(演示)</h3><ul><li><p>启动pyspark</p><ul><li><p>在$SPARK_HOME/sbin目录下执行</p><ul><li>./pyspark<br><img src="pyspark.png" alt=""></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sc = spark.sparkContext</span><br><span class="line">words = sc.textFile(<span class="string">&#x27;file:///home/hadoop/tmp/word.txt&#x27;</span>) \</span><br><span class="line">            .flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">&quot; &quot;</span>)) \</span><br><span class="line">            .<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>)) \</span><br><span class="line">            .reduceByKey(<span class="keyword">lambda</span> a, b: a + b).collect()</span><br></pre></td></tr></table></figure></li><li><p>输出结果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(&#x27;python&#x27;, 2), (&#x27;hadoop&#x27;, 1), (&#x27;bc&#x27;, 1), (&#x27;foo&#x27;, 4), (&#x27;test&#x27;, 2), (&#x27;bar&#x27;, 2), (&#x27;quux&#x27;, 2), (&#x27;abc&#x27;, 2), (&#x27;ab&#x27;, 1), (&#x27;you&#x27;, 1), (&#x27;ac&#x27;, 1), (&#x27;bec&#x27;, 1), (&#x27;by&#x27;, 1), (&#x27;see&#x27;, 1), (&#x27;labs&#x27;, 2), (&#x27;me&#x27;, 1), (&#x27;welcome&#x27;, 1)]</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="spark-core概述"><a href="#spark-core概述" class="headerlink" title="spark-core概述"></a>spark-core概述</h2><h3 id="什么是RDD"><a href="#什么是RDD" class="headerlink" title="什么是RDD"></a>什么是RDD</h3><ul><li>RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合.<ul><li>Dataset:一个数据集，简单的理解为集合，用于存放数据的</li><li>Distributed：它的数据是分布式存储，并且可以做分布式的计算</li><li>Resilient：弹性的<ul><li>它表示的是数据可以保存在磁盘，也可以保存在内存中</li><li>数据分布式也是弹性的</li><li>弹性:并不是指他可以动态扩展，而是容错机制。<ul><li>RDD会在多个节点上存储，就和hdfs的分布式道理是一样的。hdfs文件被切分为多个block存储在各个节点上，而RDD是被切分为多个partition。不同的partition可能在不同的节点上</li><li>spark读取hdfs的场景下，spark把hdfs的block读到内存就会抽象为spark的partition。</li><li>spark计算结束，一般会把数据做持久化到hive，hbase，hdfs等等。我们就拿hdfs举例，将RDD持久化到hdfs上，RDD的每个partition就会存成一个文件，如果文件小于128M，就可以理解为一个partition对应hdfs的一个block。反之，如果大于128M，就会被且分为多个block，这样，一个partition就会对应多个block。</li></ul></li></ul></li><li>不可变</li><li>可分区</li><li>并行计算</li></ul></li></ul><h3 id="RDD的创建"><a href="#RDD的创建" class="headerlink" title="RDD的创建"></a>RDD的创建</h3><ul><li><p>第一步 创建sparkContext</p><ul><li>SparkContext, Spark程序的入口. SparkContext代表了和Spark集群的链接, 在Spark集群中通过SparkContext来创建RDD</li><li>SparkConf  创建SparkContext的时候需要一个SparkConf， 用来传递Spark应用的基本信息</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conf = SparkConf().setAppName(appName).setMaster(master)</span><br><span class="line">sc = SparkContext(conf=conf)</span><br></pre></td></tr></table></figure></li><li><p>创建RDD</p><ul><li>进入pyspark环境</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop000 ~]$ pyspark</span><br><span class="line">Python 3.5.0 (default, Nov 13 2018, 15:43:53)</span><br><span class="line">[GCC 4.8.5 20150623 (Red Hat 4.8.5-28)] on linux</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">19/03/08 12:19:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Setting default log level to &quot;WARN&quot;.</span><br><span class="line">To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).</span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  &#x27;_/</span><br><span class="line">   /__ / .__/\_,_/_/ /_/\_\   version 2.3.0</span><br><span class="line">      /_/</span><br><span class="line"></span><br><span class="line">Using Python version 3.5.0 (default, Nov 13 2018 15:43:53)</span><br><span class="line">SparkSession available as &#x27;spark&#x27;.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; sc</span></span><br><span class="line">&lt;SparkContext master=local[*] appName=PySparkShell&gt;</span><br></pre></td></tr></table></figure><ul><li>在spark shell中 已经为我们创建好了 SparkContext 通过sc直接使用</li><li>可以在spark UI中看到当前的Spark作业 在浏览器访问当前centos的4040端口</li></ul><p><img src="sparkui.png" alt=""></p><ul><li><p>Parallelized Collections方式创建RDD</p><ul><li>调用<code>SparkContext</code>的 <code>parallelize</code> 方法并且传入已有的可迭代对象或者集合</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">distData = sc.parallelize(data)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; data = [1, 2, 3, 4, 5]</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; distData = sc.parallelize(data)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; data</span></span><br><span class="line">[1, 2, 3, 4, 5]</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; distData</span></span><br><span class="line">ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:175</span><br></pre></td></tr></table></figure><ul><li>在spark ui中观察执行情况</li></ul><p><img src="createrdd.png" alt="createrdd"></p><ul><li>在通过<code>parallelize</code>方法创建RDD 的时候可以指定分区数量</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; distData = sc.parallelize(data,5)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; distData.reduce(lambda a, b: a + b)</span></span><br><span class="line">15</span><br></pre></td></tr></table></figure><ul><li>在spark ui中观察执行情况</li></ul><p><img src="createrdd2.png" alt=""></p><ul><li>Spark将为群集的每个分区（partition）运行一个任务（task）。 通常，可以根据CPU核心数量指定分区数量（每个CPU有2-4个分区）如未指定分区数量，Spark会自动设置分区数。</li></ul></li><li><p>通过外部数据创建RDD</p><ul><li>PySpark可以从Hadoop支持的任何存储源创建RDD，包括本地文件系统，HDFS，Cassandra，HBase，Amazon S3等</li><li>支持整个目录、多文件、通配符</li><li>支持压缩文件</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.textFile(<span class="string">&#x27;file:///home/hadoop/tmp/word.txt&#x27;</span>)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1.collect()</span></span><br><span class="line">[&#x27;foo foo quux labs foo bar quux abc bar see you by test welcome test&#x27;, &#x27;abc labs foo me python hadoop ab ac bc bec python&#x27;]</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="spark-core-RDD常用算子练习"><a href="#spark-core-RDD常用算子练习" class="headerlink" title="spark-core RDD常用算子练习"></a>spark-core RDD常用算子练习</h2><h3 id="RDD-常用操作"><a href="#RDD-常用操作" class="headerlink" title="RDD 常用操作"></a>RDD 常用操作</h3><ul><li><p>RDD 支持两种类型的操作：</p><ul><li>transformation<ul><li>从一个已经存在的数据集创建一个新的数据集<ul><li>rdd a ——-&gt;transformation ——&gt; rdd b</li></ul></li><li>比如， map就是一个transformation 操作，把数据集中的每一个元素传给一个函数并<strong>返回一个新的RDD</strong>，代表transformation操作的结果 </li></ul></li><li>action<ul><li>获取对数据进行运算操作之后的结果</li><li>比如， reduce 就是一个action操作，使用某个函数聚合RDD所有元素的操作，并<strong>返回最终计算结果</strong></li></ul></li></ul></li><li><p>所有的transformation操作都是惰性的（lazy）</p><ul><li>不会立即计算结果</li><li>只记下应用于数据集的transformation操作</li><li>只有调用action一类的操作之后才会计算所有transformation</li><li>这种设计使Spark运行效率更高</li><li>例如map reduce 操作，map创建的数据集将用于reduce，map阶段的结果不会返回，仅会返回reduce结果。</li></ul></li><li><em>persist</em> 操作<ul><li><em>persist</em>操作用于将数据缓存 可以缓存在内存中 也可以缓存到磁盘上， 也可以复制到磁盘的其它节点上</li></ul></li></ul><h3 id="RDD-Transformation算子"><a href="#RDD-Transformation算子" class="headerlink" title="RDD Transformation算子"></a>RDD Transformation算子</h3><ul><li><p>map: map(func)</p><ul><li>将func函数作用到数据集的每一个元素上，生成一个新的RDD返回</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([1,2,3,4,5,6,7,8,9],3)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = rdd1.map(lambda x: x+1)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2.collect()</span></span><br><span class="line">[2, 3, 4, 5, 6, 7, 8, 9, 10]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([1,2,3,4,5,6,7,8,9],3)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; def add(x):</span></span><br><span class="line">...     return x+1</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = rdd1.map(add)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2.collect()</span></span><br><span class="line">[2, 3, 4, 5, 6, 7, 8, 9, 10]</span><br></pre></td></tr></table></figure><p><img src="rdd_map.png" alt=""></p></li><li><p>filter</p><ul><li>filter(func) 选出所有func返回值为true的元素，生成一个新的RDD返回</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([1,2,3,4,5,6,7,8,9],3)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = rdd1.map(lambda x:x*2)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd3 = rdd2.filter(lambda x:x&gt;4)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd3.collect()</span></span><br><span class="line">[6, 8, 10, 12, 14, 16, 18]</span><br></pre></td></tr></table></figure></li><li><p>flatmap</p><ul><li>flatMap会先执行map的操作，再将所有对象合并为一个对象</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([<span class="string">&quot;a b c&quot;</span>,<span class="string">&quot;d e f&quot;</span>,<span class="string">&quot;h i j&quot;</span>])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = rdd1.flatMap(lambda x:x.split(<span class="string">&quot; &quot;</span>))</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2.collect()</span></span><br><span class="line">[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;h&#x27;, &#x27;i&#x27;, &#x27;j&#x27;]</span><br></pre></td></tr></table></figure><ul><li>flatMap和map的区别：flatMap在map的基础上将结果合并到一个list中</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([<span class="string">&quot;a b c&quot;</span>,<span class="string">&quot;d e f&quot;</span>,<span class="string">&quot;h i j&quot;</span>])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = rdd1.map(lambda x:x.split(<span class="string">&quot; &quot;</span>))</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2.collect()</span></span><br><span class="line">[[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], [&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;], [&#x27;h&#x27;, &#x27;i&#x27;, &#x27;j&#x27;]]</span><br></pre></td></tr></table></figure></li><li><p>union</p><ul><li>对两个RDD求并集</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([(<span class="string">&quot;a&quot;</span>,1),(<span class="string">&quot;b&quot;</span>,2)])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = sc.parallelize([(<span class="string">&quot;c&quot;</span>,1),(<span class="string">&quot;b&quot;</span>,3)])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd3 = rdd1.union(rdd2)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd3.collect()</span></span><br><span class="line">[(&#x27;a&#x27;, 1), (&#x27;b&#x27;, 2), (&#x27;c&#x27;, 1), (&#x27;b&#x27;, 3)]</span><br></pre></td></tr></table></figure></li><li><p>intersection</p><ul><li>对两个RDD求交集</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1 = sc.parallelize([(<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd2 = sc.parallelize([(<span class="string">&quot;c&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">3</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd3 = rdd1.union(rdd2)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd4 = rdd3.intersection(rdd2)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd4.collect()</span><br><span class="line">[(<span class="string">&#x27;c&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">3</span>)]</span><br></pre></td></tr></table></figure></li><li><p>groupByKey</p><ul><li>以元组中的第0个元素作为key，进行分组，返回一个新的RDD</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([(<span class="string">&quot;a&quot;</span>,1),(<span class="string">&quot;b&quot;</span>,2)])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = sc.parallelize([(<span class="string">&quot;c&quot;</span>,1),(<span class="string">&quot;b&quot;</span>,3)])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd3 = rdd1.union(rdd2)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd4 = rdd3.groupByKey()</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd4.collect()</span></span><br><span class="line">[(&#x27;a&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fba6a5e5898&gt;), (&#x27;c&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fba6a5e5518&gt;), (&#x27;b&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fba6a5e5f28&gt;)]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>groupByKey之后的结果中 value是一个Iterable</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>result[<span class="number">2</span>]</span><br><span class="line">(<span class="string">&#x27;b&#x27;</span>, &lt;pyspark.resultiterable.ResultIterable <span class="built_in">object</span> at <span class="number">0x7fba6c18e518</span>&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>result[<span class="number">2</span>][<span class="number">1</span>]</span><br><span class="line">&lt;pyspark.resultiterable.ResultIterable <span class="built_in">object</span> at <span class="number">0x7fba6c18e518</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(result[<span class="number">2</span>][<span class="number">1</span>])</span><br><span class="line">[<span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure><ul><li><p>reduceByKey</p><ul><li>将key相同的键值对，按照Function进行计算</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd.reduceByKey(<span class="keyword">lambda</span> x,y:x+y).collect()</span><br><span class="line">[(<span class="string">&#x27;b&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">2</span>)]</span><br></pre></td></tr></table></figure></li><li><p>sortByKey</p><ul><li><p><code>sortByKey</code>(<em>ascending=True</em>, <em>numPartitions=None</em>, <em>keyfunc=<function RDD.<lambda>&gt;</em>)</p><p>Sorts this RDD, which is assumed to consist of (key, value) pairs.</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>tmp = [(<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;1&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;d&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;2&#x27;</span>, <span class="number">5</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize(tmp).sortByKey().first()</span><br><span class="line">(<span class="string">&#x27;1&#x27;</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize(tmp).sortByKey(<span class="literal">True</span>, <span class="number">1</span>).collect()</span><br><span class="line">[(<span class="string">&#x27;1&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;2&#x27;</span>, <span class="number">5</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;d&#x27;</span>, <span class="number">4</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize(tmp).sortByKey(<span class="literal">True</span>, <span class="number">2</span>).collect()</span><br><span class="line">[(<span class="string">&#x27;1&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;2&#x27;</span>, <span class="number">5</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;d&#x27;</span>, <span class="number">4</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tmp2 = [(<span class="string">&#x27;Mary&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;had&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;little&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;lamb&#x27;</span>, <span class="number">5</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tmp2.extend([(<span class="string">&#x27;whose&#x27;</span>, <span class="number">6</span>), (<span class="string">&#x27;fleece&#x27;</span>, <span class="number">7</span>), (<span class="string">&#x27;was&#x27;</span>, <span class="number">8</span>), (<span class="string">&#x27;white&#x27;</span>, <span class="number">9</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize(tmp2).sortByKey(<span class="literal">True</span>, <span class="number">3</span>, keyfunc=<span class="keyword">lambda</span> k: k.lower()).collect()</span><br><span class="line">[(<span class="string">&#x27;a&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;fleece&#x27;</span>, <span class="number">7</span>), (<span class="string">&#x27;had&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;lamb&#x27;</span>, <span class="number">5</span>),...(<span class="string">&#x27;white&#x27;</span>, <span class="number">9</span>), (<span class="string">&#x27;whose&#x27;</span>, <span class="number">6</span>)]</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="RDD-Action算子"><a href="#RDD-Action算子" class="headerlink" title="RDD Action算子"></a>RDD Action算子</h3><ul><li><p>collect</p><ul><li>返回一个list，list中包含 RDD中的所有元素</li><li>只有当数据量较小的时候使用Collect 因为所有的结果都会加载到内存中</li></ul></li><li><p>reduce</p><ul><li><strong>reduce</strong>将<strong>RDD</strong>中元素两两传递给输入函数，同时产生一个新的值，新产生的值与RDD中下一个元素再被传递给输入函数直到最后只有一个值为止。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([1,2,3,4,5])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1.reduce(lambda x,y : x+y)</span></span><br><span class="line">15</span><br></pre></td></tr></table></figure></li><li><p>first</p><ul><li>返回RDD的第一个元素</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]).first()</span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure></li><li><p>take</p><ul><li>返回RDD的前N个元素</li><li><code>take</code>(<em>num</em>)</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; sc.parallelize([2, 3, 4, 5, 6]).take(2)</span></span><br><span class="line">[2, 3]</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; sc.parallelize([2, 3, 4, 5, 6]).take(10)</span></span><br><span class="line">[2, 3, 4, 5, 6]</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; sc.parallelize(range(100), 100).filter(lambda x: x &gt; 90).take(3)</span></span><br><span class="line">[91, 92, 93]</span><br></pre></td></tr></table></figure></li><li><p>count</p><p>返回RDD中元素的个数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; sc.parallelize([2, 3, 4]).count()</span><br><span class="line">3</span><br></pre></td></tr></table></figure></li></ul><h3 id="Spark-RDD两类算子执行示意"><a href="#Spark-RDD两类算子执行示意" class="headerlink" title="Spark RDD两类算子执行示意"></a>Spark RDD两类算子执行示意</h3><p><img src="s5.png" alt="s5"><br><img src="s6.png" alt="s6"></p><h2 id="spark-core-实战案例"><a href="#spark-core-实战案例" class="headerlink" title="spark-core 实战案例"></a>spark-core 实战案例</h2><h3 id="Pycharm编写spark代码环境配置"><a href="#Pycharm编写spark代码环境配置" class="headerlink" title="Pycharm编写spark代码环境配置"></a>Pycharm编写spark代码环境配置</h3><p>准备pycharm环境</p><ul><li><ol><li>对接到centos服务器，下载环境</li></ol><ul><li>1.1 选择Tools —&gt;Deployment—&gt;Configuration<br>注：选择Type为SFTP，写入主机名，登陆的用户名和密码<br>注：选择Deployment目录为基准的根目录</li><li>1.2 选择File—&gt;settings—&gt;Project xxx—&gt;Project Interpreter<br>注：输入远程连接的主机名，登陆的用户名和密码，进行远程python环境的对接。</li></ul></li></ul><h3 id="利用PyCharm编写spark-wordcount程序"><a href="#利用PyCharm编写spark-wordcount程序" class="headerlink" title="利用PyCharm编写spark wordcount程序"></a>利用PyCharm编写spark wordcount程序</h3><ul><li><p>环境配置<br>将spark目录下的python目录下的pyspark整体拷贝到pycharm使用的python环境下<br>将pyspark拷贝到pycharm使用的：xxx\Python\Python36\Lib\site-packages目录下</p></li><li><p>代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) != <span class="number">2</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Usage: avg &lt;input&gt;&quot;</span>, file=sys.stderr)</span><br><span class="line">        sys.exit(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">&quot;test&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">    counts = sc.textFile(sys.argv[<span class="number">1</span>]) \</span><br><span class="line">            .flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">&quot; &quot;</span>)) \</span><br><span class="line">            .<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>)) \</span><br><span class="line">            .reduceByKey(<span class="keyword">lambda</span> a, b: a + b)</span><br><span class="line"></span><br><span class="line">    output = counts.collect()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (word, count) <span class="keyword">in</span> output:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s: %i&quot;</span> % (word, count))</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br></pre></td></tr></table></figure></li><li><p>将代码上传到远程cent-os系统上</p></li><li><p>在系统上执行指令</p><p><code>spark-submit --master local wc.py file:///root/bigdata/data/spark_test.log</code></p></li></ul><h3 id="通过spark实现点击流日志分析"><a href="#通过spark实现点击流日志分析" class="headerlink" title="通过spark实现点击流日志分析"></a>通过spark实现点击流日志分析</h3><p>在新闻类网站中，经常要衡量一条网络新闻的页面访问量，最常见的就是uv和pv，如果在所有新闻中找到访问最多的前几条新闻，topN是最常见的指标。</p><ul><li><p>数据示例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">每条数据代表一次访问记录 包含了ip 访问时间 访问的请求方式 访问的地址...信息</span></span><br><span class="line">194.237.142.21 - - [18/Sep/2013:06:49:18 +0000] &quot;GET /wp-content/uploads/2013/07/rstudio-git3.png HTTP/1.1&quot; 304 0 &quot;-&quot; &quot;Mozilla/4.0 (compatible;)&quot;</span><br><span class="line">183.49.46.228 - - [18/Sep/2013:06:49:23 +0000] &quot;-&quot; 400 0 &quot;-&quot; &quot;-&quot;</span><br><span class="line">163.177.71.12 - - [18/Sep/2013:06:49:33 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">163.177.71.12 - - [18/Sep/2013:06:49:36 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">101.226.68.137 - - [18/Sep/2013:06:49:42 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">101.226.68.137 - - [18/Sep/2013:06:49:45 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">60.208.6.156 - - [18/Sep/2013:06:49:48 +0000] &quot;GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0&quot; 200 185524 &quot;http://cos.name/category/software/packages/&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;</span><br><span class="line">222.68.172.190 - - [18/Sep/2013:06:49:57 +0000] &quot;GET /images/my.jpg HTTP/1.1&quot; 200 19939 &quot;http://www.angularjs.cn/A00n&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;</span><br><span class="line">222.68.172.190 - - [18/Sep/2013:06:50:08 +0000] &quot;-&quot; 400 0 &quot;-&quot; &quot;-&quot;</span><br></pre></td></tr></table></figure></li><li><p>访问的pv</p><p>pv：网站的总访问量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;pv&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/bigdata/data/access.log&quot;</span>)</span><br><span class="line"><span class="comment">#把每一行数据记为(&quot;pv&quot;,1)</span></span><br><span class="line">rdd2 = rdd1.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(<span class="string">&quot;pv&quot;</span>,<span class="number">1</span>)).reduceByKey(<span class="keyword">lambda</span> a,b:a+b)</span><br><span class="line">rdd2.collect()</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></li><li><p>访问的uv</p><p>uv：网站的独立用户访问量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;pv&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/bigdata/data/access.log&quot;</span>)</span><br><span class="line"><span class="comment">#对每一行按照空格拆分，将ip地址取出</span></span><br><span class="line">rdd2 = rdd1.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.split(<span class="string">&quot; &quot;</span>)).<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line"><span class="comment">#把每个ur记为1</span></span><br><span class="line">rdd3 = rdd2.distinct().<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(<span class="string">&quot;uv&quot;</span>,<span class="number">1</span>))</span><br><span class="line">rdd4 = rdd3.reduceByKey(<span class="keyword">lambda</span> a,b:a+b)</span><br><span class="line">rdd4.saveAsTextFile(<span class="string">&quot;hdfs:///uv/result&quot;</span>)</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></li><li><p>访问的topN</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;topN&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/bigdata/data/access.log&quot;</span>)</span><br><span class="line"><span class="comment">#对每一行按照空格拆分，将url数据取出，把每个url记为1</span></span><br><span class="line">rdd2 = rdd1.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.split(<span class="string">&quot; &quot;</span>)).<span class="built_in">filter</span>(<span class="keyword">lambda</span> x:<span class="built_in">len</span>(x)&gt;<span class="number">10</span>).<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(x[<span class="number">10</span>],<span class="number">1</span>))</span><br><span class="line"><span class="comment">#对数据进行累加，按照url出现次数的降序排列</span></span><br><span class="line">rdd3 = rdd2.reduceByKey(<span class="keyword">lambda</span> a,b:a+b).sortBy(<span class="keyword">lambda</span> x:x[<span class="number">1</span>],ascending=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#取出序列数据中的前n个</span></span><br><span class="line">rdd4 = rdd3.take(<span class="number">5</span>)</span><br><span class="line">rdd4.collect()</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></li></ul><h2 id="spark-core实战"><a href="#spark-core实战" class="headerlink" title="spark-core实战"></a>spark-core实战</h2><h3 id="通过spark实现ip地址查询"><a href="#通过spark实现ip地址查询" class="headerlink" title="通过spark实现ip地址查询"></a>通过spark实现ip地址查询</h3><p><strong>需求</strong><br>在互联网中，我们经常会见到城市热点图这样的报表数据，例如在百度统计中，会统计今年的热门旅游城市、热门报考学校等，会将这样的信息显示在热点图中。</p><p>因此，我们需要通过日志信息（运行商或者网站自己生成）和城市ip段信息来判断用户的ip段，统计热点经纬度。</p><p><strong>ip日志信息</strong><br>在ip日志信息中，我们只需要关心ip这一个维度就可以了，其他的不做介绍</p><p><strong>思路</strong><br>1、 加载城市ip段信息，获取ip起始数字和结束数字，经度，纬度<br>2、 加载日志数据，获取ip信息，然后转换为数字，和ip段比较<br>3、 比较的时候采用二分法查找，找到对应的经度和纬度<br>4，对相同的经度和纬度做累计求和</p><p><strong>启动Spark集群</strong></p><ul><li><p>进入到$SPARK_HOME/sbin目录</p><ul><li>启动Master    <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-master.sh -h 192.168.199.188</span><br></pre></td></tr></table></figure></li><li>启动Slave<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-slave.sh spark://192.168.199.188:7077</span><br></pre></td></tr></table></figure></li><li>jps查看进程<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">27073 Master</span><br><span class="line">27151 Worker</span><br></pre></td></tr></table></figure></li><li>关闭防火墙<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure></li><li>通过SPARK WEB UI查看Spark集群及Spark<ul><li><a href="http://192.168.199.188:8080/">http://192.168.199.188:8080/</a>  监控Spark集群</li><li><a href="http://192.168.199.188:4040/">http://192.168.199.188:4040/</a>  监控Spark Job</li></ul></li></ul></li><li><p>代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="comment"># 255.255.255.255 0~255 256  2^8 8位2进制数</span></span><br><span class="line"><span class="comment">#将ip转换为特殊的数字形式  223.243.0.0|223.243.191.255|  255 2^8</span></span><br><span class="line"><span class="comment">#‭11011111‬</span></span><br><span class="line"><span class="comment">#00000000</span></span><br><span class="line"><span class="comment">#1101111100000000</span></span><br><span class="line"><span class="comment">#‭        11110011‬</span></span><br><span class="line"><span class="comment">#11011111111100110000000000000000</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ip_transform</span>(<span class="params">ip</span>):</span>     </span><br><span class="line">    ips = ip.split(<span class="string">&quot;.&quot;</span>)<span class="comment">#[223,243,0,0] 32位二进制数</span></span><br><span class="line">    ip_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> ips:</span><br><span class="line">        ip_num = <span class="built_in">int</span>(i) | ip_num &lt;&lt; <span class="number">8</span></span><br><span class="line">    <span class="keyword">return</span> ip_num</span><br><span class="line"></span><br><span class="line"><span class="comment">#二分法查找ip对应的行的索引</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">ip_num, broadcast_value</span>):</span></span><br><span class="line">    start = <span class="number">0</span></span><br><span class="line">    end = <span class="built_in">len</span>(broadcast_value) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> (start &lt;= end):</span><br><span class="line">        mid = <span class="built_in">int</span>((start + end) / <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">if</span> ip_num &gt;= <span class="built_in">int</span>(broadcast_value[mid][<span class="number">0</span>]) <span class="keyword">and</span> ip_num &lt;= <span class="built_in">int</span>(broadcast_value[mid][<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">return</span> mid</span><br><span class="line">        <span class="keyword">if</span> ip_num &lt; <span class="built_in">int</span>(broadcast_value[mid][<span class="number">0</span>]):</span><br><span class="line">            end = mid</span><br><span class="line">        <span class="keyword">if</span> ip_num &gt; <span class="built_in">int</span>(broadcast_value[mid][<span class="number">1</span>]):</span><br><span class="line">            start = mid</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">&quot;test&quot;</span>).getOrCreate()</span><br><span class="line">    sc = spark.sparkContext</span><br><span class="line">    city_id_rdd = sc.textFile(<span class="string">&quot;file:///home/hadoop/app/tmp/data/ip.txt&quot;</span>).<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.split(<span class="string">&quot;|&quot;</span>)).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x[<span class="number">2</span>], x[<span class="number">3</span>], x[<span class="number">13</span>], x[<span class="number">14</span>]))</span><br><span class="line">    <span class="comment">#创建一个广播变量</span></span><br><span class="line">    city_broadcast = sc.broadcast(city_id_rdd.collect())</span><br><span class="line">    dest_data = sc.textFile(<span class="string">&quot;file:///home/hadoop/app/tmp/data/20090121000132.394251.http.format&quot;</span>).<span class="built_in">map</span>(</span><br><span class="line">        <span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>)[<span class="number">1</span>])</span><br><span class="line">    <span class="comment">#根据取出对应的位置信息</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_pos</span>(<span class="params">x</span>):</span></span><br><span class="line">        city_broadcast_value = city_broadcast.value</span><br><span class="line">        <span class="comment">#根据单个ip获取对应经纬度信息</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">get_result</span>(<span class="params">ip</span>):</span></span><br><span class="line">            ip_num = ip_transform(ip)</span><br><span class="line">            index = binary_search(ip_num, city_broadcast_value)</span><br><span class="line">            <span class="comment">#((纬度,精度),1)</span></span><br><span class="line">            <span class="keyword">return</span> ((city_broadcast_value[index][<span class="number">2</span>], city_broadcast_value[index][<span class="number">3</span>]), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = <span class="built_in">map</span>(<span class="built_in">tuple</span>,[get_result(ip) <span class="keyword">for</span> ip <span class="keyword">in</span> x])</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    dest_rdd = dest_data.mapPartitions(<span class="keyword">lambda</span> x: get_pos(x)) <span class="comment">#((纬度,精度),1)</span></span><br><span class="line">    result_rdd = dest_rdd.reduceByKey(<span class="keyword">lambda</span> a, b: a + b)</span><br><span class="line">    <span class="built_in">print</span>(result_rdd.collect())</span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></li><li><p><strong>广播变量的使用</strong></p><ul><li>要统计Ip所对应的经纬度, 每一条数据都会去查询ip表</li><li>每一个task 都需要这一个ip表, 默认情况下, 所有task都会去复制ip表</li><li>实际上 每一个Worker上会有多个task, 数据也是只需要进行查询操作的, 所以这份数据可以共享,没必要每个task复制一份</li><li>可以通过广播变量, 通知当前worker上所有的task, 来共享这个数据,避免数据的多次复制,可以大大降低内存的开销</li><li>sparkContext.broadcast(要共享的数据)</li></ul></li></ul><h2 id="spark-相关概念补充"><a href="#spark-相关概念补充" class="headerlink" title="spark 相关概念补充"></a>spark 相关概念补充</h2><h3 id="spark的安装部署"><a href="#spark的安装部署" class="headerlink" title="spark的安装部署"></a>spark的安装部署</h3><ul><li><p>1、下载spark安装包<br><a href="http://spark.apache.org/downloads.html">http://spark.apache.org/downloads.html</a></p><p>高版本不存在cdh的编译版本，可以从官网下载源码版本，指定高版本hadoop进行编译</p><p>编译步骤：</p><ul><li><ol><li>安装java(JDK 1.7及以上)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/xxx</span><br><span class="line">export JRE_HOME=/xxx</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>安装Maven， 版本为3.3.9或者以上<br>下载地址：<a href="https://mirrors.tuna.tsinghua.edu.cn/apache//maven/maven-3/3.3.9/binaries">https://mirrors.tuna.tsinghua.edu.cn/apache//maven/maven-3/3.3.9/binaries</a><br>配置MAVEN_HOME<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export MAVEN_HOME=/xxx</span><br><span class="line">export PATH=$MAVEN_HOME/bin:$PATH</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>下载spark源码</li></ol></li><li><ol><li>增加cdh的repository<br>解压spark的源码包，编辑pom.xml文件， 在repositories节点 加入如下配置：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;repository&gt;</span><br><span class="line">        &lt;id&gt;cloudera&lt;/id&gt;</span><br><span class="line">        &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos/&lt;/url&gt;&lt;/repository&gt;</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>编译<br>设置内存：<br>export MAVEN_OPTS=”-Xmx2g -XX:ReservedCodeCacheSize=512m”<br>开始编译：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./dev/make-distribution.sh --name 2.6.0-cdh5.7.0 --tgz  -Pyarn -Phadoop-2.6 -Phive -Phive-thriftserver -Dhadoop.version=2.6.0-cdh5.7.0 -DskipTests clean package</span><br></pre></td></tr></table></figure>源码编译后，bin目录下的文件可能不存在可执行权限，需要通过chmod指令添加可执行权限<br>chmod +x xxx</li></ol></li></ul></li><li>2、规划spark安装目录</li><li>3、解压安装包</li><li>4、重命名安装目录</li><li>5、修改配置文件<ul><li>spark-env.sh(需要将spark-env.sh.template重命名)<ul><li>配置java环境变量<ul><li>export JAVA_HOME=java_home_path</li></ul></li><li>配置PYTHON环境<ul><li>export PYSPARK_PYTHON=/xx/pythonx_home/bin/pythonx</li></ul></li><li>配置master的地址<ul><li>export SPARK_MASTER_HOST=node-teach</li></ul></li><li>配置master的端口<ul><li>export SPARK_MASTER_PORT=7077</li></ul></li></ul></li></ul></li><li>6、配置spark环境变量<ul><li>export SPARK_HOME=/xxx/spark2.x</li><li>export PATH=$PATH:$SPARK_HOME/bin</li></ul></li></ul><h3 id="spark-集群相关概念"><a href="#spark-集群相关概念" class="headerlink" title="spark 集群相关概念"></a>spark 集群相关概念</h3><ul><li><p>spark集群架构(Standalone模式)<br><img src="spark1.png" alt=""></p><ul><li><p>Application</p><p>用户自己写的Spark应用程序，批处理作业的集合。Application的main方法为应用程序的入口，用户通过Spark的API，定义了RDD和对RDD的操作。</p></li><li><p>Master和Worker</p><p>整个集群分为 Master 节点和 Worker 节点，相当于 Hadoop 的 Master 和 Slave 节点。</p><ul><li>Master：Standalone模式中主控节点，负责接收Client提交的作业，管理Worker，并命令Worker启动Driver和Executor。</li><li>Worker：Standalone模式中slave节点上的守护进程，负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，启动Driver和Executor。</li></ul></li><li><p>Client：客户端进程，负责提交作业到Master。</p></li><li><p>Driver： 一个Spark作业运行时包括一个Driver进程，也是作业的主进程，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler。</p></li><li><p>Executor：即真正执行作业的地方，一个集群一般包含多个Executor，每个Executor接收Driver的命令Launch Task，一个Executor可以执行一到多个Task。</p></li></ul></li><li><p>Spark作业相关概念</p><ul><li><p>Stage：一个Spark作业一般包含一到多个Stage。</p></li><li><p>Task：一个Stage包含一到多个Task，通过多个Task实现并行运行的功能。</p></li><li><p>DAGScheduler： 实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。</p></li><li><p>TaskScheduler：实现Task分配到Executor上执行。<br><img src="spark2.png" alt=""><br><img src="spark3.png" alt=""></p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Search / Advertisement / Recommendation / Causal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive &amp; HBase</title>
      <link href="/2022/01/18/5.4-Hive/"/>
      <url>/2022/01/18/5.4-Hive/</url>
      
        <content type="html"><![CDATA[<p><strong>推荐系统学习笔记目录</strong></p><ol><li><a href="https://xfliu1998.github.io/2022/01/18/5.1-Recommendation-System-Introduction/">推荐系统介绍</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/">推荐算法</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.3-Hadoop/">Hadoop</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.4-Hive/">Hive &amp; HBase</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.5-Spark-core/">Spark core</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.6-Spark-SQL/">Spark SQL &amp; Spark streaming</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.7-RS-case/">推荐系统案例</a></li></ol><h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h2 id="Hive基本概念"><a href="#Hive基本概念" class="headerlink" title="Hive基本概念"></a>Hive基本概念</h2><h3 id="Hive简介"><a href="#Hive简介" class="headerlink" title="Hive简介"></a>Hive简介</h3><p><img src="hive.jpg" alt=""></p><h4 id="什么是-Hive"><a href="#什么是-Hive" class="headerlink" title="什么是 Hive"></a>什么是 Hive</h4><ul><li>Hive 由 Facebook 实现并开源，是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据映射为一张数据库表，并提供 HQL(Hive SQL)查询功能，底层数据是存储在 HDFS 上。</li><li>Hive 本质: 将 SQL 语句转换为 MapReduce 任务运行，使不熟悉 MapReduce 的用户很方便地利用 HQL 处理和计算 HDFS 上的结构化的数据,是一款基于 HDFS 的 MapReduce <strong>计算框架</strong></li><li>主要用途：用来做离线数据分析，比直接用 MapReduce 开发效率更高。</li></ul><h4 id="为什么使用-Hive"><a href="#为什么使用-Hive" class="headerlink" title="为什么使用 Hive"></a>为什么使用 Hive</h4><ul><li><p>直接使用 Hadoop MapReduce 处理数据所面临的问题：</p><ul><li>人员学习成本太高</li><li>MapReduce 实现复杂查询逻辑开发难度太大</li></ul></li><li><p>使用 Hive</p><ul><li><p>操作接口采用类 SQL 语法，提供快速开发的能力</p></li><li><p>避免了去写 MapReduce，减少开发人员的学习成本</p></li><li>功能扩展很方便</li></ul></li></ul><h3 id="Hive-架构"><a href="#Hive-架构" class="headerlink" title="Hive 架构"></a>Hive 架构</h3><h4 id="Hive-架构图"><a href="#Hive-架构图" class="headerlink" title="Hive 架构图"></a>Hive 架构图</h4><p><img src="hive2.jpg" alt=""></p><h4 id="Hive-组件"><a href="#Hive-组件" class="headerlink" title="Hive 组件"></a>Hive 组件</h4><ul><li>用户接口：包括 CLI、JDBC/ODBC、WebGUI。<ul><li>CLI(command line interface)为 shell 命令行</li><li>JDBC/ODBC 是 Hive 的 JAVA 实现，与传统数据库JDBC 类似</li><li>WebGUI 是通过浏览器访问 Hive。</li><li>HiveServer2基于Thrift, 允许远程客户端使用多种编程语言如Java、Python向Hive提交请求</li></ul></li><li>元数据存储：通常是存储在关系数据库如 mysql/derby 中。<ul><li>Hive 将元数据存储在数据库中。</li><li>Hive 中的元数据包括<ul><li>表的名字</li><li>表的列</li><li>分区及其属性</li><li>表的属性（是否为外部表等）</li><li>表的数据所在目录等。</li></ul></li></ul></li><li>解释器、编译器、优化器、执行器:完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后由 MapReduce 调用执行</li></ul><h4 id="Hive-与-Hadoop-的关系"><a href="#Hive-与-Hadoop-的关系" class="headerlink" title="Hive 与 Hadoop 的关系"></a>Hive 与 Hadoop 的关系</h4><p>Hive 利用 HDFS 存储数据，利用 MapReduce 查询分析数据。</p><p>Hive是数据仓库工具，没有集群的概念，如果想提交Hive作业只需要在hadoop集群 Master节点上装Hive就可以了</p><h3 id="Hive-与传统数据库对比"><a href="#Hive-与传统数据库对比" class="headerlink" title="Hive 与传统数据库对比"></a>Hive 与传统数据库对比</h3><ul><li>hive 用于海量数据的离线数据分析。</li></ul><table>  <tr>    <th></th>    <th>Hive</th>    <th>关系型数据库</th>  </tr>  <tr>    <td> ANSI SQL </td>    <td> 不完全支持 </td>    <td> 支持 </td>  </tr>  <tr>    <td> 更新 </td>    <td> INSERT OVERWRITE\INTO TABLE(默认) </td>    <td> UPDATE\INSERT\DELETE </td>  </tr>  <tr>    <td> 事务 </td>    <td> 不支持(默认) </td>    <td> 支持 </td>  </tr>  <tr>    <td> 模式 </td>    <td> 读模式 </td>    <td> 写模式 </td>  </tr>  <tr>    <td> 查询语言 </td>    <td> HQL  </td>    <td> SQL</td>  </tr>  <tr>    <td> 数据存储 </td>    <td> HDFS </td>    <td> Raw Device or Local FS </td>  </tr>  <tr>    <td> 执行 </td>    <td> MapReduce </td>    <td> Executor</td>  </tr>  <tr>    <td> 执行延迟 </td>    <td> 高 </td>    <td> 低 </td>  </tr>  <tr>    <td> 子查询 </td>    <td> 只能用在From子句中 </td>    <td> 完全支持 </td>  </tr>  <tr>    <td> 处理数据规模 </td>    <td> 大 </td>    <td> 小 </td>  </tr>  <tr>    <td> 可扩展性 </td>    <td> 高 </td>    <td> 低 </td>  </tr>  <tr>    <td> 索引 </td>    <td> 0.8版本后加入位图索引 </td>    <td> 有复杂的索引 </td>  </tr></table><ul><li>hive支持的数据类型<ul><li>原子数据类型  <ul><li>TINYINT SMALLINT INT BIGINT BOOLEAN FLOAT DOUBLE STRING BINARY TIMESTAMP DECIMAL CHAR VARCHAR DATE</li></ul></li><li>复杂数据类型<ul><li>ARRAY</li><li>MAP</li><li>STRUCT</li></ul></li></ul></li><li>hive中表的类型<ul><li>托管表 (managed table) (内部表)</li><li>外部表</li></ul></li></ul><h3 id="Hive-数据模型"><a href="#Hive-数据模型" class="headerlink" title="Hive 数据模型"></a>Hive 数据模型</h3><ul><li>Hive 中所有的数据都存储在 HDFS 中，没有专门的数据存储格式</li><li>在创建表时指定数据中的分隔符，Hive 就可以映射成功，解析数据。</li><li>Hive 中包含以下数据模型：<ul><li>db：在 hdfs 中表现为 hive.metastore.warehouse.dir 目录下一个文件夹</li><li>table：在 hdfs 中表现所属 db 目录下一个文件夹</li><li>external table：数据存放位置可以在 HDFS 任意指定路径</li><li>partition：在 hdfs 中表现为 table 目录下的子目录</li><li>bucket：在 hdfs 中表现为同一个表目录下根据 hash 散列之后的多个文件</li></ul></li></ul><h3 id="Hive-安装部署"><a href="#Hive-安装部署" class="headerlink" title="Hive 安装部署"></a>Hive 安装部署</h3><ul><li><p>Hive 安装前需要安装好 JDK 和 Hadoop。配置好环境变量。</p></li><li><p>下载Hive的安装包 <a href="http://archive.cloudera.com/cdh5/cdh/5/">http://archive.cloudera.com/cdh5/cdh/5/</a> 并解压</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hive-1.1.0-cdh5.7.0.tar.gz  -C ~/app/</span><br></pre></td></tr></table></figure></li><li><p>进入到 解压后的hive目录 找到 conf目录, 修改配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp hive-env.sh.template hive-env.sh</span><br><span class="line">vi hive-env.sh</span><br></pre></td></tr></table></figure><p>在hive-env.sh中指定hadoop的路径</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_HOME=/home/hadoop/app/hadoop-2.6.0-cdh5.7.0</span><br></pre></td></tr></table></figure></li><li><p>配置环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_HOME=/home/hadoop/app/hive-1.1.0-cdh5.7.0</span><br><span class="line">export PATH=$HIVE_HOME/bin:$PATH</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure></li><li><p>根据元数据存储的介质不同，分为下面两个版本，其中 derby 属于内嵌模式。实际生产环境中则使用 mysql 来进行元数据的存储。</p><ul><li><p>内置 derby 版：<br>bin/hive 启动即可使用<br>缺点：不同路径启动 hive，每一个 hive 拥有一套自己的元数据，无法共享</p></li><li><p>mysql 版： </p><ul><li><p>上传 mysql驱动到 hive安装目录的lib目录下</p><p>mysql-connector-java-5.*.jar</p></li><li><p>vi conf/hive-site.xml 配置 Mysql 元数据库信息(MySql安装见文档)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- 插入以下代码 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hive&lt;/value&gt;&lt;!-- 指定mysql用户名 --&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hive&lt;/value&gt;&lt;!-- 指定mysql密码 --&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;mysql</span><br><span class="line">        &lt;value&gt;jdbc:mysql://127.0.0.1:3306/hive&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;&lt;!-- 指定mysql数据库地址 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;!-- 指定mysql驱动 --&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">        &lt;!-- 到此结束代码 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.exec.script.wrapper&lt;/name&gt;</span><br><span class="line">    &lt;value/&gt;</span><br><span class="line">    &lt;description/&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li><p>hive启动</p><ul><li><p>启动docker </p><p><code>service docker start</code></p></li><li><p>通过docker 启动mysql</p><p><code>docker start mysql</code></p></li><li><p>启动 hive的metastore元数据服务</p><p><code>hive --service metastore</code></p></li><li><p>启动hive</p><p><code>hive</code></p></li><li><p>MySQL root 密码 password         hive用户 密码 hive</p></li></ul></li></ul><h2 id="Hive-基本操作"><a href="#Hive-基本操作" class="headerlink" title="Hive 基本操作"></a>Hive 基本操作</h2><h3 id="Hive-HQL操作初体验"><a href="#Hive-HQL操作初体验" class="headerlink" title="Hive HQL操作初体验"></a>Hive HQL操作初体验</h3><ul><li><p>创建数据库</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE test;</span><br></pre></td></tr></table></figure></li><li><p>显示所有数据库</p> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> DATABASES;</span><br></pre></td></tr></table></figure></li><li><p>创建表</p> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student(classNo string, stuNo string, score <span class="type">int</span>) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure><ul><li>row format delimited fields terminated by ‘,’  指定了字段的分隔符为逗号，所以load数据的时候，load的文本也要为逗号，否则加载后为NULL。hive只支持单个字符的分隔符，hive默认的分隔符是\001</li></ul></li><li><p>将数据load到表中</p><ul><li><p>在本地文件系统创建一个如下的文本文件：/home/hadoop/tmp/student.txt</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">C01,N0101,82</span><br><span class="line">C01,N0102,59</span><br><span class="line">C01,N0103,65</span><br><span class="line">C02,N0201,81</span><br><span class="line">C02,N0202,82</span><br><span class="line">C02,N0203,79</span><br><span class="line">C03,N0301,56</span><br><span class="line">C03,N0302,92</span><br><span class="line">C03,N0306,72</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/hadoop/tmp/student.txt&#x27;</span>overwrite <span class="keyword">into</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure></li><li><p>这个命令将student.txt文件复制到hive的warehouse目录中，这个目录由hive.metastore.warehouse.dir配置项设置，默认值为/user/hive/warehouse。Overwrite选项将导致Hive事先删除student目录下所有的文件, 并将文件内容映射到表中。<br> Hive不会对student.txt做任何格式处理，因为Hive本身并不强调数据的存储格式。</p></li></ul></li><li><p>查询表中的数据 跟SQL类似</p> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br></pre></td></tr></table></figure></li><li><p>分组查询group by和统计 count</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span><span class="keyword">select</span> classNo,<span class="built_in">count</span>(score) <span class="keyword">from</span> student <span class="keyword">where</span> score<span class="operator">&gt;=</span><span class="number">60</span> <span class="keyword">group</span> <span class="keyword">by</span> classNo;</span><br></pre></td></tr></table></figure><p>从执行结果可以看出 hive把查询的结果变成了MapReduce作业通过hadoop执行</p></li></ul><h3 id="Hive的内部表和外部表"><a href="#Hive的内部表和外部表" class="headerlink" title="Hive的内部表和外部表"></a>Hive的内部表和外部表</h3><table>  <tr>    <th></th>    <th>内部表(managed table)</th>    <th>外部表(external table)</th>  </tr>  <tr>    <td> 概念 </td>    <td> 创建表时无external修饰 </td>    <td> 创建表时被external修饰 </td>  </tr>  <tr>    <td> 数据管理 </td>    <td> 由Hive自身管理 </td>    <td> 由HDFS管理 </td>  </tr>  <tr>    <td> 数据保存位置 </td>    <td> hive.metastore.warehouse.dir  （默认：/user/hive/warehouse） </td>    <td> hdfs中任意位置 </td>  </tr>  <tr>    <td> 删除时影响 </td>    <td> 直接删除元数据（metadata）及存储数据 </td>    <td> 仅会删除元数据，HDFS上的文件并不会被删除 </td>  </tr>  <tr>    <td> 表结构修改时影响 </td>    <td> 修改会将修改直接同步给元数据  </td>    <td> 表结构和分区进行修改，则需要修复（MSCK REPAIR TABLE table_name;）</td>  </tr></table><ul><li><p>案例</p><ul><li>创建一个外部表student2<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> student2 (classNo string, stuNo string, score <span class="type">int</span>) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> location <span class="string">&#x27;/tmp/student&#x27;</span>;</span><br></pre></td></tr></table></figure></li><li>装载数据   <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/hadoop/tmp/student.txt&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> student2;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>显示表信息</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">desc</span> formatted table_name;</span><br></pre></td></tr></table></figure></li><li>删除表查看结果<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure></li><li>再次创建外部表 student2</li><li>不插入数据直接查询查看结果<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student2;</span><br></pre></td></tr></table></figure></li></ul><h3 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h3><ul><li><p>什么是分区表</p><ul><li>随着表的不断增大，对于新纪录的增加，查找，删除等(DML)的维护也更加困难。对于数据库中的超大型表，可以通过把它的数据分成若干个小表，从而简化数据库的管理活动，对于每一个简化后的小表，我们称为一个单个的分区。</li><li>hive中分区表实际就是对应hdfs文件系统上独立的文件夹，该文件夹内的文件是该分区所有数据文件。</li><li>分区可以理解为分类，通过分类把不同类型的数据放到不同的目录下。</li><li>分类的标准就是分区字段，可以一个，也可以多个。</li><li>分区表的意义在于优化查询。查询时尽量利用分区字段。如果不使用分区字段，就会全部扫描。</li></ul></li><li><p>创建分区表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tom,4300</span><br><span class="line">jerry,12000</span><br><span class="line">mike,13000</span><br><span class="line">jake,11000</span><br><span class="line">rob,10000</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> employee (name string,salary <span class="type">bigint</span>) partitioned <span class="keyword">by</span> (date1 string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span> stored <span class="keyword">as</span> textfile;</span><br></pre></td></tr></table></figure></li><li><p>查看表的分区</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> partitions employee;</span><br></pre></td></tr></table></figure></li><li><p>添加分区</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table employee add if not exists partition(date1=&#x27;2018-12-01&#x27;);</span><br></pre></td></tr></table></figure></li><li><p>加载数据到分区</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#x27;/home/hadoop/tmp/employee.txt&#x27; into table employee partition(date1=&#x27;2018-12-01&#x27;);</span><br></pre></td></tr></table></figure></li><li><p>如果重复加载同名文件，不会报错，会自动创建一个*_copy_1.txt</p></li><li><p>外部分区表即使有分区的目录结构, 也必须要通过hql添加分区, 才能看到相应的数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /user/hive/warehouse/emp/dt=2018-12-04</span><br><span class="line">hadoop fs -copyFromLocal /tmp/employee.txt /user/hive/warehouse/test.db/emp/dt=2018-12-04/employee.txt</span><br></pre></td></tr></table></figure><ul><li><p>此时查看表中数据发现数据并没有变化, 需要通过hql添加分区</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table emp add if not exists partition(dt=&#x27;2018-12-04&#x27;);</span><br></pre></td></tr></table></figure></li><li><p>此时再次查看才能看到新加入的数据</p></li></ul></li><li><p>总结</p><ul><li>利用分区表方式减少查询时需要扫描的数据量<ul><li>分区字段不是表中的列, 数据文件中没有对应的列</li><li>分区仅仅是一个目录名</li><li>查看数据时, hive会自动添加分区列</li><li>支持多级分区, 多级子目录</li></ul></li></ul></li></ul><h3 id="2-4-动态分区"><a href="#2-4-动态分区" class="headerlink" title="2.4 动态分区"></a>2.4 动态分区</h3><ul><li><p>在写入数据时自动创建分区(包括目录结构)</p></li><li><p>创建表</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table employee2 (name string,salary bigint) partitioned by (date1 string) row format delimited fields terminated by &#x27;,&#x27; lines terminated by &#x27;\n&#x27; stored as textfile;</span><br></pre></td></tr></table></figure></li><li><p>导入数据</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> employee2 <span class="keyword">partition</span>(date1) <span class="keyword">select</span> name,salary,date1 <span class="keyword">from</span> employee;</span><br></pre></td></tr></table></figure></li><li><p>使用动态分区需要设置参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.dynamic.partition.mode=nonstrict;</span><br></pre></td></tr></table></figure></li></ul><h2 id="Hive-函数"><a href="#Hive-函数" class="headerlink" title="Hive 函数"></a>Hive 函数</h2><h3 id="内置运算符"><a href="#内置运算符" class="headerlink" title="内置运算符"></a>内置运算符</h3><p>在 Hive 有四种类型的运算符：</p><ul><li><p>关系运算符</p></li><li><p>算术运算符</p></li><li><p>逻辑运算符</p></li><li><p>复杂运算</p><p>(内容较多，见《Hive 官方文档》》)</p></li></ul><h3 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h3><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF</a></p><ul><li>简单函数: 日期函数 字符串函数 类型转换 </li><li>统计函数: sum avg distinct</li><li>集合函数</li><li>分析函数</li><li>show functions;  显示所有函数</li><li>desc function 函数名;</li><li>desc function extended 函数名;</li></ul><h3 id="Hive-自定义函数和-Transform"><a href="#Hive-自定义函数和-Transform" class="headerlink" title="Hive 自定义函数和 Transform"></a>Hive 自定义函数和 Transform</h3><ul><li><p>UDF</p><ul><li><p>当 Hive 提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined function）。</p></li><li><p>TRANSFORM,and UDF and UDAF</p><p>it is possible to plug in your own custom mappers and reducers<br> A UDF is basically only a transformation done by a mapper meaning that each row should be mapped to exactly one row. A UDAF on the other hand allows us to transform a group of rows into one or more rows, meaning that we can reduce the number of input rows to a single output row by some custom aggregation.</p><p><strong>UDF</strong>：就是做一个mapper，对每一条输入数据，映射为一条输出数据。</p><p><strong>UDAF</strong>:就是一个reducer，把一组输入数据映射为一条(或多条)输出数据。</p><p>一个脚本至于是做mapper还是做reducer，又或者是做udf还是做udaf，取决于我们把它放在什么样的hive操作符中。放在select中的基本就是udf，放在distribute by和cluster by中的就是reducer。<br>We can control if the script is run in a mapper or reducer step by the way we formulate our HiveQL query.<br>The statements DISTRIBUTE BY and CLUSTER BY allow us to indicate that we want to actually perform an aggregation.<br>User-Defined Functions (UDFs) for transformations and even aggregations which are therefore called User-Defined Aggregation Functions (UDAFs)</p></li></ul></li><li><p>UDF示例(运行java已经编写好的UDF)</p><ul><li><p>在hdfs中创建 /user/hive/lib目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /user/hive/lib</span><br></pre></td></tr></table></figure></li><li><p>把 hive目录下 lib/hive-contrib-hive-contrib-1.1.0-cdh5.7.0.jar 放到hdfs中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put hive-contrib-1.1.0-cdh5.7.0.jar /user/hive/lib/</span><br></pre></td></tr></table></figure></li><li><p>把集群中jar包的位置添加到hive中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> add jar hdfs:///user/hive/lib/hive-contrib-1.1.0-cdh5.7.0.jar;</span></span><br></pre></td></tr></table></figure></li><li><p>在hive中创建<strong>临时</strong>UDF</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">CREATE</span> TEMPORARY <span class="keyword">FUNCTION</span> row_sequence <span class="keyword">as</span> <span class="string">&#x27;org.apache.hadoop.hive.contrib.udf.UDFRowSequence&#x27;</span></span><br></pre></td></tr></table></figure></li><li><p>在之前的案例中使用<strong>临时</strong>自定义函数(函数功能: 添加自增长的行号)</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Select</span> row_sequence(),<span class="operator">*</span> <span class="keyword">from</span> employee;</span><br></pre></td></tr></table></figure></li><li><p>创建<strong>非临时</strong>自定义函数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE FUNCTION row_sequence as &#x27;org.apache.hadoop.hive.contrib.udf.UDFRowSequence&#x27; using jar &#x27;hdfs:///user/hive/lib/hive-contrib-1.1.0-cdh5.7.0.jar&#x27;;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Python UDF</p><ul><li><p>准备案例环境</p><ul><li>创建表<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">table</span> u(fname STRING,lname STRING);</span><br></pre></td></tr></table></figure></li><li>向表中插入数据<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> u2 <span class="keyword">values</span>(<span class="string">&#x27;George&#x27;</span>,<span class="string">&#x27;washington&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> u2 <span class="keyword">values</span>(<span class="string">&#x27;George&#x27;</span>,<span class="string">&#x27;bush&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> u2 <span class="keyword">values</span>(<span class="string">&#x27;Bill&#x27;</span>,<span class="string">&#x27;clinton&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> u2 <span class="keyword">values</span>(<span class="string">&#x27;Bill&#x27;</span>,<span class="string">&#x27;gates&#x27;</span>);</span><br></pre></td></tr></table></figure></li></ul></li><li><p>编写map风格脚本</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    line = line.strip()</span><br><span class="line">    fname , lname = line.split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">    l_name = lname.upper()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\t&#x27;</span>.join([fname, <span class="built_in">str</span>(l_name)])</span><br></pre></td></tr></table></figure></li><li><p>通过hdfs向hive中ADD file</p><ul><li><p>加载文件到hdfs</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put udf.py /user/hive/lib/</span><br></pre></td></tr></table></figure></li><li><p>hive从hdfs中加载python脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ADD FILE hdfs:///user/hive/lib/udf.py;</span><br><span class="line">ADD FILE /root/tmp/udf1.py;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Transform</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> TRANSFORM(fname, lname) <span class="keyword">USING</span> <span class="string">&#x27;python udf1.py&#x27;</span> <span class="keyword">AS</span> (fname, l_name) <span class="keyword">FROM</span> u;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Python UDAF</p></li></ul><h2 id="hive综合案例"><a href="#hive综合案例" class="headerlink" title="hive综合案例"></a>hive综合案例</h2><ul><li><p>内容推荐数据处理</p><p><img src="hive3.png" alt=""></p><ul><li>需求<ul><li>根据用户行为以及文章标签筛选出用户最感兴趣(阅读最多)的标签</li></ul></li></ul></li><li><p>相关数据</p><p>​    user_id article_id event_time</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">11,101,2018-12-01 06:01:10</span><br><span class="line">22,102,2018-12-01 07:28:12</span><br><span class="line">33,103,2018-12-01 07:50:14</span><br><span class="line">11,104,2018-12-01 09:08:12</span><br><span class="line">22,103,2018-12-01 13:37:12</span><br><span class="line">33,102,2018-12-02 07:09:12</span><br><span class="line">11,101,2018-12-02 18:42:12</span><br><span class="line">35,105,2018-12-03 09:21:12</span><br><span class="line">22,104,2018-12-03 16:42:12</span><br><span class="line">77,103,2018-12-03 18:31:12</span><br><span class="line">99,102,2018-12-04 00:04:12</span><br><span class="line">33,101,2018-12-04 19:10:12</span><br><span class="line">11,101,2018-12-05 09:07:12</span><br><span class="line">35,102,2018-12-05 11:00:12</span><br><span class="line">22,103,2018-12-05 12:11:12</span><br><span class="line">77,104,2018-12-05 18:02:02</span><br><span class="line">99,105,2018-12-05 20:09:11</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>文章数据</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">artical_id,artical_url,artical_keywords</span><br><span class="line">101,http://www.itcast.cn/1.html,kw8|kw1</span><br><span class="line">102,http://www.itcast.cn/2.html,kw6|kw3</span><br><span class="line">103,http://www.itcast.cn/3.html,kw7</span><br><span class="line">104,http://www.itcast.cn/4.html,kw5|kw1|kw4|kw9</span><br><span class="line">105,http://www.itcast.cn/5.html,</span><br></pre></td></tr></table></figure></li><li><p>数据上传hdfs</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /tmp/demo</span><br><span class="line">hadoop fs -mkdir /tmp/demo/user_action</span><br></pre></td></tr></table></figure></li><li><p>创建外部表</p><ul><li>用户行为表</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span> user_actions;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> user_actions(</span><br><span class="line">    user_id STRING,</span><br><span class="line">    article_id STRING,</span><br><span class="line">    time_stamp STRING</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">LOCATION <span class="string">&#x27;/tmp/demo/user_action&#x27;</span>;</span><br></pre></td></tr></table></figure><ul><li>文章表</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span> articles;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> articles(</span><br><span class="line">    article_id STRING,</span><br><span class="line">    url STRING,</span><br><span class="line">    key_words <span class="keyword">array</span><span class="operator">&lt;</span>STRING<span class="operator">&gt;</span></span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> </span><br><span class="line">COLLECTION ITEMS terminated <span class="keyword">BY</span> <span class="string">&#x27;|&#x27;</span> </span><br><span class="line">LOCATION <span class="string">&#x27;/tmp/demo/article_keywords&#x27;</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">key_words array&lt;STRING&gt;  数组的数据类型</span></span><br><span class="line"><span class="comment">COLLECTION ITEMS terminated BY &#x27;|&#x27;  数组的元素之间用&#x27;|&#x27;分割</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><ul><li>查看数据</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> user_actions;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> articles;</span><br></pre></td></tr></table></figure><ul><li><p>分组查询每个用户的浏览记录</p><ul><li>collect_set/collect_list作用:<ul><li>将group by中的某列转为一个数组返回</li><li>collect_list<strong>不去重</strong>而collect_set<strong>去重</strong></li></ul></li><li>collect_set</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user_id,collect_set(article_id) </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">group</span> <span class="keyword">by</span> user_id;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">11      [&quot;101&quot;,&quot;104&quot;]</span><br><span class="line">22      [&quot;102&quot;,&quot;103&quot;,&quot;104&quot;]</span><br><span class="line">33      [&quot;103&quot;,&quot;102&quot;,&quot;101&quot;]</span><br><span class="line">35      [&quot;105&quot;,&quot;102&quot;]</span><br><span class="line">77      [&quot;103&quot;,&quot;104&quot;]</span><br><span class="line">99      [&quot;102&quot;,&quot;105&quot;]</span><br></pre></td></tr></table></figure><ul><li>collect_list</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user_id,collect_list(article_id) </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">group</span> <span class="keyword">by</span> user_id;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">11      [&quot;101&quot;,&quot;104&quot;,&quot;101&quot;,&quot;101&quot;]</span><br><span class="line">22      [&quot;102&quot;,&quot;103&quot;,&quot;104&quot;,&quot;103&quot;]</span><br><span class="line">33      [&quot;103&quot;,&quot;102&quot;,&quot;101&quot;]</span><br><span class="line">35      [&quot;105&quot;,&quot;102&quot;]</span><br><span class="line">77      [&quot;103&quot;,&quot;104&quot;]</span><br><span class="line">99      [&quot;102&quot;,&quot;105&quot;]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>sort_array: 对数组排序</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user_id,sort_array(collect_list(article_id)) <span class="keyword">as</span> contents </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">group</span> <span class="keyword">by</span> user_id;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">11      [&quot;101&quot;,&quot;101&quot;,&quot;101&quot;,&quot;104&quot;]</span><br><span class="line">22      [&quot;102&quot;,&quot;103&quot;,&quot;103&quot;,&quot;104&quot;]</span><br><span class="line">33      [&quot;101&quot;,&quot;102&quot;,&quot;103&quot;]</span><br><span class="line">35      [&quot;102&quot;,&quot;105&quot;]</span><br><span class="line">77      [&quot;103&quot;,&quot;104&quot;]</span><br><span class="line">99      [&quot;102&quot;,&quot;105&quot;]</span><br></pre></td></tr></table></figure></li><li><p>查看每一篇文章的关键字 lateral view explode</p><ul><li>explode函数 将array 拆分</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> explode(key_words) <span class="keyword">from</span> articles;</span><br></pre></td></tr></table></figure><ul><li>lateral view 和 explode 配合使用,将一行数据拆分成多行数据，在此基础上可以对拆分的数据进行聚合</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles <span class="keyword">lateral</span> <span class="keyword">view</span> explode(key_words) t <span class="keyword">as</span> kw;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">101     kw8</span><br><span class="line">101     kw1</span><br><span class="line">102     kw6</span><br><span class="line">102     kw3</span><br><span class="line">103     kw7</span><br><span class="line">104     kw5</span><br><span class="line">104     kw1</span><br><span class="line">104     kw4</span><br><span class="line">104     kw9</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles <span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">101     kw8</span><br><span class="line">101     kw1</span><br><span class="line">102     kw6</span><br><span class="line">102     kw3</span><br><span class="line">103     kw7</span><br><span class="line">104     kw5</span><br><span class="line">104     kw1</span><br><span class="line">104     kw4</span><br><span class="line">104     kw9</span><br><span class="line">105     NULL</span><br><span class="line"><span class="meta">#</span><span class="bash">含有outer</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p>根据文章id找到用户查看文章的关键字</p><ul><li>原始数据</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">101     http://www.itcast.cn/1.html     [&quot;kw8&quot;,&quot;kw1&quot;]</span><br><span class="line">102     http://www.itcast.cn/2.html     [&quot;kw6&quot;,&quot;kw3&quot;]</span><br><span class="line">103     http://www.itcast.cn/3.html     [&quot;kw7&quot;]</span><br><span class="line">104     http://www.itcast.cn/4.html     [&quot;kw5&quot;,&quot;kw1&quot;,&quot;kw4&quot;,&quot;kw9&quot;]</span><br><span class="line">105     http://www.itcast.cn/5.html     []</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.user_id, b.kw <span class="keyword">from</span> user_actions </span><br><span class="line"><span class="keyword">as</span> a <span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b</span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> a.user_id;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">11      kw1</span><br><span class="line">11      kw8</span><br><span class="line">11      kw5</span><br><span class="line">11      kw1</span><br><span class="line">11      kw4</span><br><span class="line">11      kw1</span><br><span class="line">11      kw9</span><br><span class="line">11      kw8</span><br><span class="line">11      kw1</span><br><span class="line">11      kw8</span><br><span class="line">22      kw1</span><br><span class="line">22      kw7</span><br><span class="line">22      kw9</span><br><span class="line">22      kw4</span><br><span class="line">22      kw5</span><br><span class="line">22      kw7</span><br><span class="line">22      kw3</span><br><span class="line">22      kw6</span><br><span class="line">33      kw8</span><br><span class="line">33      kw1</span><br><span class="line">33      kw3</span><br><span class="line">33      kw6</span><br><span class="line">33      kw7</span><br><span class="line">35      NULL</span><br><span class="line">35      kw6</span><br><span class="line">35      kw3</span><br><span class="line">77      kw9</span><br><span class="line">77      kw1</span><br><span class="line">77      kw7</span><br><span class="line">77      kw4</span><br><span class="line">77      kw5</span><br><span class="line">99      kw3</span><br><span class="line">99      kw6</span><br><span class="line">99      NULL</span><br></pre></td></tr></table></figure></li><li><p>根据文章id找到用户查看文章的关键字并统计频率</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.user_id, b.kw,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> weight </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">as</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b</span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.user_id,b.kw </span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> a.user_id,weight <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">11      kw1     4</span><br><span class="line">11      kw8     3</span><br><span class="line">11      kw5     1</span><br><span class="line">11      kw9     1</span><br><span class="line">11      kw4     1</span><br><span class="line">22      kw7     2</span><br><span class="line">22      kw9     1</span><br><span class="line">22      kw1     1</span><br><span class="line">22      kw3     1</span><br><span class="line">22      kw4     1</span><br><span class="line">22      kw5     1</span><br><span class="line">22      kw6     1</span><br><span class="line">33      kw3     1</span><br><span class="line">33      kw8     1</span><br><span class="line">33      kw7     1</span><br><span class="line">33      kw6     1</span><br><span class="line">33      kw1     1</span><br><span class="line">35      NULL    1</span><br><span class="line">35      kw3     1</span><br><span class="line">35      kw6     1</span><br><span class="line">77      kw1     1</span><br><span class="line">77      kw4     1</span><br><span class="line">77      kw5     1</span><br><span class="line">77      kw7     1</span><br><span class="line">77      kw9     1</span><br><span class="line">99      NULL    1</span><br><span class="line">99      kw3     1</span><br><span class="line">99      kw6     1</span><br></pre></td></tr></table></figure></li><li><p>CONCAT：<br>CONCAT(str1,str2,…)  </p><p>返回结果为连接参数产生的字符串。如有任何一个参数为NULL ，则返回值为 NULL。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> concat(user_id,article_id) <span class="keyword">from</span> user_actions;</span><br></pre></td></tr></table></figure><p>CONCAT_WS:</p><p>使用语法为：CONCAT_WS(separator,str1,str2,…)</p><p>CONCAT_WS() 代表 CONCAT With Separator ，是CONCAT()的特殊形式。第一个参数是其它参数的分隔符。分隔符的位置放在要连接的两个字符串之间。分隔符可以是一个字符串，也可以是其它参数。如果分隔符为 NULL，则结果为 NULL。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> concat_ws(<span class="string">&#x27;:&#x27;</span>,user_id,article_id) <span class="keyword">from</span> user_actions;</span><br></pre></td></tr></table></figure></li><li><p>将用户查看的关键字和频率合并成 key:value形式</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.user_id, concat_ws(<span class="string">&#x27;:&#x27;</span>,b.kw,<span class="built_in">cast</span> (<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> string)) <span class="keyword">as</span> kw_w </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">as</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b</span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.user_id,b.kw;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">11      kw1:4</span><br><span class="line">11      kw4:1</span><br><span class="line">11      kw5:1</span><br><span class="line">11      kw8:3</span><br><span class="line">11      kw9:1</span><br><span class="line">22      kw1:1</span><br><span class="line">22      kw3:1</span><br><span class="line">22      kw4:1</span><br><span class="line">22      kw5:1</span><br><span class="line">22      kw6:1</span><br><span class="line">22      kw7:2</span><br><span class="line">22      kw9:1</span><br><span class="line">33      kw1:1</span><br><span class="line">33      kw3:1</span><br><span class="line">33      kw6:1</span><br><span class="line">33      kw7:1</span><br><span class="line">33      kw8:1</span><br><span class="line">35      1</span><br><span class="line">35      kw3:1</span><br><span class="line">35      kw6:1</span><br><span class="line">77      kw1:1</span><br><span class="line">77      kw4:1</span><br><span class="line">77      kw5:1</span><br><span class="line">77      kw7:1</span><br><span class="line">77      kw9:1</span><br><span class="line">99      1</span><br><span class="line">99      kw3:1</span><br><span class="line">99      kw6:1</span><br></pre></td></tr></table></figure></li><li><p>将用户查看的关键字和频率合并成 key:value形式并按用户聚合</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> cc.user_id,concat_ws(<span class="string">&#x27;,&#x27;</span>,collect_set(cc.kw_w))</span><br><span class="line"><span class="keyword">from</span>(</span><br><span class="line"><span class="keyword">select</span> a.user_id, concat_ws(<span class="string">&#x27;:&#x27;</span>,b.kw,<span class="built_in">cast</span> (<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> string)) <span class="keyword">as</span> kw_w </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">as</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b</span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.user_id,b.kw</span><br><span class="line">) <span class="keyword">as</span> cc </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> cc.user_id;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">11      kw1:4,kw4:1,kw5:1,kw8:3,kw9:1</span><br><span class="line">22      kw1:1,kw3:1,kw4:1,kw5:1,kw6:1,kw7:2,kw9:1</span><br><span class="line">33      kw1:1,kw3:1,kw6:1,kw7:1,kw8:1</span><br><span class="line">35      1,kw3:1,kw6:1</span><br><span class="line">77      kw1:1,kw4:1,kw5:1,kw7:1,kw9:1</span><br><span class="line">99      1,kw3:1,kw6:1</span><br></pre></td></tr></table></figure></li><li><p>将上面聚合结果转换成map</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> cc.user_id,str_to_map(concat_ws(<span class="string">&#x27;,&#x27;</span>,collect_set(cc.kw_w))) <span class="keyword">as</span> wm</span><br><span class="line"><span class="keyword">from</span>(</span><br><span class="line"><span class="keyword">select</span> a.user_id, concat_ws(<span class="string">&#x27;:&#x27;</span>,b.kw,<span class="built_in">cast</span> (<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> string)) <span class="keyword">as</span> kw_w </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">as</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b</span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.user_id,b.kw</span><br><span class="line">) <span class="keyword">as</span> cc </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> cc.user_id;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">11      &#123;&quot;kw1&quot;:&quot;4&quot;,&quot;kw4&quot;:&quot;1&quot;,&quot;kw5&quot;:&quot;1&quot;,&quot;kw8&quot;:&quot;3&quot;,&quot;kw9&quot;:&quot;1&quot;&#125;</span><br><span class="line">22      &#123;&quot;kw1&quot;:&quot;1&quot;,&quot;kw3&quot;:&quot;1&quot;,&quot;kw4&quot;:&quot;1&quot;,&quot;kw5&quot;:&quot;1&quot;,&quot;kw6&quot;:&quot;1&quot;,&quot;kw7&quot;:&quot;2&quot;,&quot;kw9&quot;:&quot;1&quot;&#125;</span><br><span class="line">33      &#123;&quot;kw1&quot;:&quot;1&quot;,&quot;kw3&quot;:&quot;1&quot;,&quot;kw6&quot;:&quot;1&quot;,&quot;kw7&quot;:&quot;1&quot;,&quot;kw8&quot;:&quot;1&quot;&#125;</span><br><span class="line">35      &#123;&quot;1&quot;:null,&quot;kw3&quot;:&quot;1&quot;,&quot;kw6&quot;:&quot;1&quot;&#125;</span><br><span class="line">77      &#123;&quot;kw1&quot;:&quot;1&quot;,&quot;kw4&quot;:&quot;1&quot;,&quot;kw5&quot;:&quot;1&quot;,&quot;kw7&quot;:&quot;1&quot;,&quot;kw9&quot;:&quot;1&quot;&#125;</span><br><span class="line">99      &#123;&quot;1&quot;:null,&quot;kw3&quot;:&quot;1&quot;,&quot;kw6&quot;:&quot;1&quot;&#125;</span><br></pre></td></tr></table></figure></li><li><p>将用户的阅读偏好结果保存到表中</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> user_kws <span class="keyword">as</span> </span><br><span class="line"><span class="keyword">select</span> cc.user_id,str_to_map(concat_ws(<span class="string">&#x27;,&#x27;</span>,collect_set(cc.kw_w))) <span class="keyword">as</span> wm</span><br><span class="line"><span class="keyword">from</span>(</span><br><span class="line"><span class="keyword">select</span> a.user_id, concat_ws(<span class="string">&#x27;:&#x27;</span>,b.kw,<span class="built_in">cast</span> (<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> string)) <span class="keyword">as</span> kw_w </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">as</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b</span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.user_id,b.kw</span><br><span class="line">) <span class="keyword">as</span> cc </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> cc.user_id;</span><br></pre></td></tr></table></figure></li><li><p>从表中通过key查询map中的值</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user_id, wm[<span class="string">&#x27;kw1&#x27;</span>] <span class="keyword">from</span> user_kws;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">11      4</span><br><span class="line">22      1</span><br><span class="line">33      1</span><br><span class="line">35      NULL</span><br><span class="line">77      1</span><br><span class="line">99      NULL</span><br></pre></td></tr></table></figure></li><li><p>从表中获取map中所有的key 和 所有的value</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user_id,map_keys(wm),map_values(wm) <span class="keyword">from</span> user_kws;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">11      [&quot;kw1&quot;,&quot;kw4&quot;,&quot;kw5&quot;,&quot;kw8&quot;,&quot;kw9&quot;] [&quot;4&quot;,&quot;1&quot;,&quot;1&quot;,&quot;3&quot;,&quot;1&quot;]</span><br><span class="line">22      [&quot;kw1&quot;,&quot;kw3&quot;,&quot;kw4&quot;,&quot;kw5&quot;,&quot;kw6&quot;,&quot;kw7&quot;,&quot;kw9&quot;]     [&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;2&quot;,&quot;1&quot;]</span><br><span class="line">33      [&quot;kw1&quot;,&quot;kw3&quot;,&quot;kw6&quot;,&quot;kw7&quot;,&quot;kw8&quot;] [&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;]</span><br><span class="line">35      [&quot;1&quot;,&quot;kw3&quot;,&quot;kw6&quot;]       [null,&quot;1&quot;,&quot;1&quot;]</span><br><span class="line">77      [&quot;kw1&quot;,&quot;kw4&quot;,&quot;kw5&quot;,&quot;kw7&quot;,&quot;kw9&quot;] [&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;]</span><br><span class="line">99      [&quot;1&quot;,&quot;kw3&quot;,&quot;kw6&quot;]       [null,&quot;1&quot;,&quot;1&quot;]</span><br></pre></td></tr></table></figure></li><li><p>用lateral view explode把map中的数据转换成多列</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user_id,keyword,weight <span class="keyword">from</span> user_kws <span class="keyword">lateral</span> <span class="keyword">view</span> explode(wm) t <span class="keyword">as</span> keyword,weight;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">11      kw1     4</span><br><span class="line">11      kw4     1</span><br><span class="line">11      kw5     1</span><br><span class="line">11      kw8     3</span><br><span class="line">11      kw9     1</span><br><span class="line">22      kw1     1</span><br><span class="line">22      kw3     1</span><br><span class="line">22      kw4     1</span><br><span class="line">22      kw5     1</span><br><span class="line">22      kw6     1</span><br><span class="line">22      kw7     2</span><br><span class="line">22      kw9     1</span><br><span class="line">33      kw1     1</span><br><span class="line">33      kw3     1</span><br><span class="line">33      kw6     1</span><br><span class="line">33      kw7     1</span><br><span class="line">33      kw8     1</span><br><span class="line">35      1       NULL</span><br><span class="line">35      kw3     1</span><br><span class="line">35      kw6     1</span><br><span class="line">77      kw1     1</span><br><span class="line">77      kw4     1</span><br><span class="line">77      kw5     1</span><br><span class="line">77      kw7     1</span><br><span class="line">77      kw9     1</span><br><span class="line">99      1       NULL</span><br><span class="line">99      kw3     1</span><br><span class="line">99      kw6     1</span><br></pre></td></tr></table></figure></li></ul><h2 id="HBase简介与环境部署"><a href="#HBase简介与环境部署" class="headerlink" title="HBase简介与环境部署"></a>HBase简介与环境部署</h2><h3 id="HBase简介-amp-在Hadoop生态中的地位"><a href="#HBase简介-amp-在Hadoop生态中的地位" class="headerlink" title="HBase简介&amp;在Hadoop生态中的地位"></a>HBase简介&amp;在Hadoop生态中的地位</h3><h4 id="什么是HBase"><a href="#什么是HBase" class="headerlink" title="什么是HBase"></a>什么是HBase</h4><ul><li>HBase是一个分布式的、面向列的开源数据库</li><li>HBase是Google BigTable的开源实现</li><li>HBase不同于一般的关系数据库, 适合非结构化数据存储</li></ul><h4 id="BigTable"><a href="#BigTable" class="headerlink" title="BigTable"></a>BigTable</h4><ul><li>BigTable是Google设计的分布式数据存储系统，用来处理海量的数据的一种非关系型的数据库。<ul><li>适合大规模海量数据，PB级数据；</li><li>分布式、并发数据处理，效率极高；</li><li>易于扩展，支持动态伸缩</li><li>适用于廉价设备；</li><li>不适用于传统关系型数据的存储；</li></ul></li></ul><h4 id="面向列的数据库"><a href="#面向列的数据库" class="headerlink" title="面向列的数据库"></a>面向列的数据库</h4><p><strong>HBase 与 传统关系数据库的区别</strong></p><table>  <tr>    <th></th>    <th>HBase</th>    <th>关系型数据库</th>  </tr>  <tr>    <td> 数据库大小 </td>    <td> PB级别  </td>    <td>GB TB</td>  </tr>  <tr>    <td> 数据类型 </td>    <td> Bytes </td>    <td> 丰富的数据类型 </td>  </tr>    <tr>    <td> 事务支持 </td>    <td> ACID只支持单个Row级别 </td>    <td> 全面的ACID支持, 对Row和表</td>  </tr>  <tr>    <td> 索引 </td>    <td> 只支持Row-key </td>    <td> 支持 </td>  </tr>    <tr>    <td> 吞吐量 </td>    <td> 百万写入/秒 </td>    <td> 数千写入/秒</td>  </tr></table><ul><li>关系型数据库中数据示例</li></ul><table>  <tr>    <th>ID</th>    <th>FILE NAME</th>    <th>FILE PATH</th>    <th>FILE TYPE</th>    <th>FILE SIZE</th>    <th>CREATOR</th>  </tr>  <tr>    <td> 1 </td>    <td> file1.txt  </td>    <td>/home</td>    <td> txt </td>    <td> 1024 </td>    <td> tom </td>  </tr>  <tr>    <td> 2 </td>    <td> file2.txt  </td>    <td>/home/pics</td>    <td> jpg </td>    <td> 5032 </td>    <td> jerry </td>  </tr></table><ul><li>同样数据保存到列式数据库中</li></ul><table><tr><th>RowKey</th><th>FILE INFO</th><th>SAVE INFO</th></tr><tr><td> 1 </td><td> name:file1.txttype:txtsize:1024</td><td>path:/home/picscreator:Jerry</td></tr><tr><td> 2 </td><td>name:file2.jpgtype:jpgsize:5032</td><td> path:/homecreator:Tom</td></tr></table><ul><li>行数据库&amp;列数据库存储方式比较<br><img src="hbase4.png" alt=""></li></ul><h4 id="什么是非结构化数据存储"><a href="#什么是非结构化数据存储" class="headerlink" title="什么是非结构化数据存储"></a>什么是非结构化数据存储</h4><ul><li>结构化数据<ul><li>适合用二维表来展示的数据</li></ul></li><li>非结构化数据<ul><li>非结构化数据是数据结构不规则或不完整</li><li>没有预定义的数据模型</li><li>不方便用数据库二维逻辑表来表现</li><li>办公文档、文本、图片、XML, HTML、各类报表、图像和音频/视频信息等</li></ul></li></ul><h4 id="HBase在Hadoop生态中的地位"><a href="#HBase在Hadoop生态中的地位" class="headerlink" title="HBase在Hadoop生态中的地位"></a>HBase在Hadoop生态中的地位</h4><ul><li><p>HBase是Apache基金会顶级项目</p></li><li><p>HBase基于HDFS进行数据存储</p></li><li><p>HBase可以存储超大数据并适合用来进行大数据的实时查询</p><p><img src="hbase&amp;hive.png" alt=""></p></li></ul><h4 id="HBase与HDFS"><a href="#HBase与HDFS" class="headerlink" title="HBase与HDFS"></a>HBase与HDFS</h4><ul><li>HBase建立在Hadoop文件系统上, 利用了HDFS的容错能力</li><li>HBase提供对数据的随机实时读/写访问功能</li><li>HBase内部使用哈希表, 并存储索引, 可以快速查找HDFS中数据</li></ul><h4 id="HBase使用场景"><a href="#HBase使用场景" class="headerlink" title="HBase使用场景"></a>HBase使用场景</h4><ul><li>瞬间写入量很大</li><li>大量数据需要长期保存, 且数量会持续增长</li><li>HBase不适合有join, 多级索引, 表关系复杂的数据模型</li></ul><h2 id="HBase的数据模型"><a href="#HBase的数据模型" class="headerlink" title="HBase的数据模型"></a>HBase的数据模型</h2><ul><li>NameSpace: 关系型数据库的”数据库”(database)</li><li>表(table)：用于存储管理数据，具有稀疏的、面向列的特点。HBase中的每一张表，就是所谓的大表(Bigtable)，可以有上亿行，上百万列。对于为值为空的列，并不占用存储空间，因此表可以设计的非常稀疏。</li><li>行(Row)：在表里面,每一行代表着一个数据对象,每一行都是以一个行键(Row Key)来进行唯一标识的, 行键并没有什么特定的数据类型, 以二进制的字节来存储</li><li>列(Column): HBase的列由 Column family 和 Column qualifier 组成, 由冒号: 进行行间隔, 如 family: qualifier</li><li>行键(RowKey)：类似于MySQL中的主键，HBase根据行键来快速检索数据，一个行键对应一条记录。与MySQL主键不同的是，HBase的行键是天然固有的，每一行数据都存在行键。</li><li>列族(ColumnFamily)：是列的集合。列族在表定义时需要指定，而列在插入数据时动态指定。列中的数据都是以二进制形式存在，没有数据类型。在物理存储结构上，每个表中的每个列族单独以一个文件存储。一个表可以有多个列簇。</li><li>列修饰符(<em>Column</em> <em>Qualifier</em>) : 列族中的数据通过列标识来进行映射, 可以理解为一个键值对(key-value), 列修饰符(<em>Column</em> <em>Qualifier</em>) 就是key 对应关系型数据库的列</li><li>时间戳(TimeStamp)：是列的一个属性，是一个64位整数。由行键和列确定的单元格，可以存储多个数据，每个数据含有时间戳属性，数据具有版本特性。可根据版本(VERSIONS)或时间戳来指定查询历史版本数据，如果都不指定，则默认返回最新版本的数据。</li><li><p>区域(Region)：HBase自动把表水平划分成的多个区域，划分的区域随着数据的增大而增多。</p></li><li><p>HBase 支持特定场景下的 ACID，即对行级别的 操作保证完全的 ACID</p></li><li><h4 id="cap定理"><a href="#cap定理" class="headerlink" title="cap定理"></a>cap定理</h4><ul><li><p>分布式系统的最大难点，就是各个节点的状态如何同步。CAP 定理是这方面的基本定理，也是理解分布式系统的起点。</p><ul><li><p>一致性(所有节点在同一时间具有相同的数据)</p><p><img src="Consistency.png" alt="img"></p></li><li><p>可用性(保证每个请求不管成功或失败都有响应,但不保证获取的数据的正确性)</p></li><li><p>分区容错性(系统中任意信息的丢失或失败不会影响系统的运行,系统如果不能在某个时限内达成数据一致性,就必须在上面两个操作之间做出选择)</p></li></ul><p><img src="cap.jpg" alt="img"></p><p><strong>hbase是CAP中的CP系统,即hbase是强一致性的</strong></p></li></ul></li></ul><h2 id="HBase-的安装与实战"><a href="#HBase-的安装与实战" class="headerlink" title="HBase 的安装与实战"></a>HBase 的安装与实战</h2><h3 id="HBase的安装"><a href="#HBase的安装" class="headerlink" title="HBase的安装"></a>HBase的安装</h3><ul><li><p>下载安装包 <a href="http://archive.cloudera.com/cdh5/cdh/5/hbase-1.2.0-cdh5.7.0.tar.gz">http://archive.cloudera.com/cdh5/cdh/5/hbase-1.2.0-cdh5.7.0.tar.gz</a></p></li><li><p>配置伪分布式环境</p><ul><li><p>环境变量配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HBASE_HOME=/usr/local/development/hbase-1.2.4</span><br><span class="line">export PATH=$HBASE_HOME/bin:$PATH</span><br></pre></td></tr></table></figure></li><li><p>配置hbase-env.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/local/development/jdk1.7.0_15</span><br><span class="line">export HBASE_MANAGES_ZK=false  --如果你是使用hbase自带的zk就是true，如果使用自己的zk就是false</span><br></pre></td></tr></table></figure></li><li><p>配置hbase-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>　　--hbase持久保存的目录</span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop001:8020/opt/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span>   </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  --是否是分布式</span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>     </span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.clientPort<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    --指定要连接zk的端口</span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>        </span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>            <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/app/hbase/zkData<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>          </span><br></pre></td></tr></table></figure></li><li><p>启动hbase（启动的hbase的时候要保证hadoop集群已经启动）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/hbase/bin/start-hbase.sh</span><br></pre></td></tr></table></figure></li><li><p>输入hbase shell（进入shell命令行）</p></li></ul></li></ul><h3 id="HBase-shell"><a href="#HBase-shell" class="headerlink" title="HBase shell"></a>HBase shell</h3><ul><li>HBase DDL 和 DML 命令</li></ul><table>  <tr>    <th>名称</th>    <th>命令表达式</th>  </tr>  <tr>    <td> 创建表 </td>   <td> create '表名', '列族名1','列族名2','列族名n' </td>  </tr>  <tr>    <td> 添加记录 </td>    <td> put '表名','行名','列名:','值 </td>  </tr>    <tr>    <td> 查看记录 </td>    <td> get '表名','行名' </td>  </tr>  <tr>    <td> 查看表中的记录总数 </td>    <td> count '表名' </td>  </tr>    <tr>    <td> 删除记录 </td>    <td> delete '表名', '行名','列名' </td>  </tr>  <tr>    <td> 删除一张表 </td>    <td> 第一步 disable '表名' 第二步 drop '表名' </td>  </tr>  <tr>    <td> 查看所有记录 </td>    <td> scan "表名称" </td>  </tr>  <tr>    <td> 查看指定表指定列所有数据 </td>    <td> scan '表名' ,{COLUMNS=>'列族名:列名'} </td>  </tr>   <tr>    <td> 更新记录 </td>    <td> 重写覆盖 </td>  </tr></table><ul><li>连接集群</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase shell</span><br></pre></td></tr></table></figure><ul><li>创建表</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;base_info&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>删除表</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">disable <span class="string">&#x27;user&#x27;</span></span><br><span class="line"><span class="keyword">drop</span> <span class="string">&#x27;user&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>创建名称空间</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create_namespace <span class="string">&#x27;test&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>展示现有名称空间</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list_namespace</span><br></pre></td></tr></table></figure><ul><li>创建表的时候添加namespace</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;test:user&#x27;</span>,<span class="string">&#x27;base_info&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>显示某个名称空间下有哪些表</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list_namespace_tables &#x27;test&#x27;</span><br></pre></td></tr></table></figure><ul><li><p>插入数据</p><p>put  ‘表名’，‘rowkey的值’，’列族：列标识符‘，’值‘</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">put &#x27;user&#x27;,&#x27;rowkey_10&#x27;,&#x27;base_info:username&#x27;,&#x27;Tom&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_10&#x27;,&#x27;base_info:birthday&#x27;,&#x27;2014-07-10&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_10&#x27;,&#x27;base_info:sex&#x27;,&#x27;1&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_10&#x27;,&#x27;base_info:address&#x27;,&#x27;Tokyo&#x27;</span><br><span class="line"></span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_16&#x27;,&#x27;base_info:username&#x27;,&#x27;Mike&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_16&#x27;,&#x27;base_info:birthday&#x27;,&#x27;2014-07-10&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_16&#x27;,&#x27;base_info:sex&#x27;,&#x27;1&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_16&#x27;,&#x27;base_info:address&#x27;,&#x27;beijing&#x27;</span><br><span class="line"></span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_22&#x27;,&#x27;base_info:username&#x27;,&#x27;Jerry&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_22&#x27;,&#x27;base_info:birthday&#x27;,&#x27;2014-07-10&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_22&#x27;,&#x27;base_info:sex&#x27;,&#x27;1&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_22&#x27;,&#x27;base_info:address&#x27;,&#x27;Newyork&#x27;</span><br><span class="line"></span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_24&#x27;,&#x27;base_info:username&#x27;,&#x27;Nico&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_24&#x27;,&#x27;base_info:birthday&#x27;,&#x27;2014-07-10&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_24&#x27;,&#x27;base_info:sex&#x27;,&#x27;1&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_24&#x27;,&#x27;base_info:address&#x27;,&#x27;shanghai&#x27;</span><br><span class="line"></span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_25&#x27;,&#x27;base_info:username&#x27;,&#x27;Rose&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_25&#x27;,&#x27;base_info:birthday&#x27;,&#x27;2014-07-10&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_25&#x27;,&#x27;base_info:sex&#x27;,&#x27;1&#x27;</span><br><span class="line">put &#x27;user&#x27;,&#x27;rowkey_25&#x27;,&#x27;base_info:address&#x27;,&#x27;Soul&#x27;</span><br></pre></td></tr></table></figure><ul><li>查询表中的所有数据</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;user&#x27;</span><br></pre></td></tr></table></figure><ul><li>查询某个rowkey的数据</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">get &#x27;user&#x27;,&#x27;rowkey_16&#x27;</span><br></pre></td></tr></table></figure><ul><li>查询某个列簇的数据</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">get &#x27;user&#x27;,&#x27;rowkey_16&#x27;,&#x27;base_info&#x27;</span><br><span class="line">get &#x27;user&#x27;,&#x27;rowkey_16&#x27;,&#x27;base_info:username&#x27;</span><br><span class="line">get &#x27;user&#x27;, &#x27;rowkey_16&#x27;, &#123;COLUMN =&gt; [&#x27;base_info:username&#x27;,&#x27;base_info:sex&#x27;]&#125;</span><br></pre></td></tr></table></figure><ul><li>删除表中的数据</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">delete &#x27;user&#x27;, &#x27;rowkey_16&#x27;, &#x27;base_info:username&#x27;</span><br></pre></td></tr></table></figure><ul><li>清空数据</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">truncate &#x27;user&#x27;</span><br></pre></td></tr></table></figure><ul><li>操作列簇</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alter &#x27;user&#x27;, NAME =&gt; &#x27;f2&#x27;</span><br><span class="line">alter &#x27;user&#x27;, &#x27;delete&#x27; =&gt; &#x27;f2&#x27;</span><br></pre></td></tr></table></figure><ul><li><p>HBase 追加型数据库 会保留多个版本数据</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">desc</span> <span class="string">&#x27;user&#x27;</span></span><br><span class="line"><span class="keyword">Table</span> <span class="keyword">user</span> <span class="keyword">is</span> ENABLED</span><br><span class="line"><span class="keyword">user</span></span><br><span class="line"><span class="keyword">COLUMN</span> FAMILIES DESCRIPTION</span><br><span class="line">&#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;base_info&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;1&#x27;</span>, EVICT_BLOCKS_ON_CLOSE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;false&#x27;</span>, NEW_VERSION_B</span><br><span class="line">HE_DATA_ON_WRITE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;false&#x27;</span>, DATA_BLOCK_ENCODING <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;NONE&#x27;</span>, TTL <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;FOREVER&#x27;</span>, MI</span><br><span class="line">ER <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;NONE&#x27;</span>, CACHE_INDEX_ON_WRITE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;false&#x27;</span>, IN_MEMORY <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;false&#x27;</span>, CACHE_BLOOM</span><br><span class="line">se<span class="string">&#x27;, COMPRESSION =&gt; &#x27;</span><span class="keyword">NONE</span><span class="string">&#x27;, BLOCKCACHE =&gt; &#x27;</span><span class="literal">false</span><span class="string">&#x27;, BLOCKSIZE =&gt; &#x27;</span><span class="number">65536</span><span class="string">&#x27;&#125;</span></span><br></pre></td></tr></table></figure><ul><li>VERSIONS=&gt;’1’说明最多可以显示一个版本 修改数据</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_10&#x27;</span>,<span class="string">&#x27;base_info:username&#x27;</span>,<span class="string">&#x27;Tom&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>指定显示多个版本</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">get &#x27;user&#x27;,&#x27;rowkey_10&#x27;,&#123;COLUMN=&gt;&#x27;base_info:username&#x27;,VERSIONS=&gt;2&#125;</span><br></pre></td></tr></table></figure><ul><li>修改可以显示的版本数量</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter &#x27;user&#x27;,NAME=&gt;&#x27;base_info&#x27;,VERSIONS=&gt;10</span><br></pre></td></tr></table></figure></li></ul><ul><li>命令表</li></ul><p><img src="2017-12-27_230420.jpg" alt=""></p><p>可以通过HbaseUi界面查看表的信息</p><p>端口60010打不开的情况，是因为hbase 1.0 以后的版本，需要自己手动配置，在文件 hbase-site</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;  </span><br><span class="line">&lt;name&gt;hbase.master.info.port&lt;/name&gt;  </span><br><span class="line">&lt;value&gt;60010&lt;/value&gt;  </span><br><span class="line">&lt;/property&gt; </span><br></pre></td></tr></table></figure><h3 id="HappyBase操作Hbase"><a href="#HappyBase操作Hbase" class="headerlink" title="HappyBase操作Hbase"></a>HappyBase操作Hbase</h3><ul><li><p>什么是HappyBase</p><ul><li><strong>HappyBase</strong> is a developer-friendly <a href="http://python.org/">Python</a> library to interact with <a href="http://hbase.apache.org/">Apache HBase</a>. HappyBase is designed for use in standard HBase setups, and offers application developers a Pythonic API to interact with HBase. Below the surface, HappyBase uses the <a href="http://pypi.python.org/pypi/thrift">Python Thrift library</a> to connect to HBase using its <a href="http://thrift.apache.org/">Thrift</a> gateway, which is included in the standard HBase 0.9x releases.</li></ul></li><li><p>HappyBase 是FaceBook员工开发的操作HBase的python库, 其基于Python Thrift, 但使用方式比Thrift简单, 已被广泛应用</p></li><li><p>启动hbase thrift server : hbase-daemon.sh start thrift</p></li><li><p>安装happy base</p><ul><li>pip install happybase</li></ul></li><li><p>使用happy base时可能出现的问题(windows系统)</p><ul><li>happybase1.0在win下不支持绝对路径</li><li>解决方案：将488行的url_scheme == ”改为url_scheme in (‘代码盘符’, ”)</li></ul></li><li><p>如何使用HappyBase</p><ul><li>建立连接</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> happybase</span><br><span class="line">connection = happybase.Connection(<span class="string">&#x27;somehost&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li>当连接建立时, 会自动创建一个与 HBase Thrift server的socket链接. 可以通过参数禁止自动链接, 然后再需要连接是调用 <a href="https://happybase.readthedocs.io/en/latest/api.html#happybase.Connection.open"><code>Connection.open()</code></a>:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">connection = happybase.Connection(<span class="string">&#x27;somehost&#x27;</span>, autoconnect=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># before first use:</span></span><br><span class="line">connection.<span class="built_in">open</span>()</span><br></pre></td></tr></table></figure><ul><li><a href="https://happybase.readthedocs.io/en/latest/api.html#happybase.Connection"><code>Connection</code></a>  这个类提供了一个与HBase交互的入口, 比如获取HBase中所有的表:  <a href="https://happybase.readthedocs.io/en/latest/api.html#happybase.Connection.tables"><code>Connection.tables()</code></a>:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(connection.tables())</span><br></pre></td></tr></table></figure><ul><li>操作表<ul><li>Table类提供了大量API, 这些API用于检索和操作HBase中的数据。 在上面的示例中，我们已经使用Connection.tables（）方法查询HBase中的表。 如果还没有任何表，可使用Connection.create_table（）创建一个新表：</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">connection.create_table(<span class="string">&#x27;users&#x27;</span>,&#123;<span class="string">&#x27;cf1&#x27;</span>: <span class="built_in">dict</span>()&#125;)</span><br></pre></td></tr></table></figure><ul><li><p>创建表之后可以传入表名获取到Table类的实例:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">table = connection.table(&#x27;mytable&#x27;)</span><br></pre></td></tr></table></figure></li><li><p>查询操作</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># api</span></span><br><span class="line">table.scan() <span class="comment">#全表查询</span></span><br><span class="line">table.row(row_keys[<span class="number">0</span>]) <span class="comment"># 查询一行</span></span><br><span class="line">table.rows(row_keys) <span class="comment"># 查询多行</span></span><br><span class="line"><span class="comment">#封装函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_rows</span>(<span class="params">table, row_keys=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> row_keys:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;show value of row named %s&#x27;</span> % row_keys)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(row_keys) == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(table.row(row_keys[<span class="number">0</span>]))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(table.rows(row_keys))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;show all row values of table named %s&#x27;</span> % table.name)</span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> table.scan():</span><br><span class="line">            <span class="built_in">print</span>(key, value)</span><br></pre></td></tr></table></figure><ul><li>插入数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#api</span></span><br><span class="line">table.put(row_key, &#123;cf:cq:value&#125;)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">put_row</span>(<span class="params">table, column_family, row_key, value</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;insert one row to hbase&#x27;</span>)</span><br><span class="line">    <span class="comment">#put &#x27;user&#x27;,&#x27;rowkey_10&#x27;,&#x27;base_info:username&#x27;,&#x27;Tom&#x27;</span></span><br><span class="line">    <span class="comment">#&#123;&#x27;cf:cq&#x27;:’数据‘&#125;</span></span><br><span class="line">    table.put(row_key, &#123;<span class="string">&#x27;%s:name&#x27;</span> % column_family:<span class="string">&#x27;name_%s&#x27;</span> % value&#125;)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">put_rows</span>(<span class="params">table, column_family, row_lines=<span class="number">30</span></span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;insert rows to hbase now&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(row_lines):</span><br><span class="line">        put_row(table, column_family, <span class="string">&#x27;row_%s&#x27;</span> % i, i)</span><br></pre></td></tr></table></figure><ul><li>删除数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#api</span></span><br><span class="line">table.delete(row_key, cf_list)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#函数封装    </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">delete_row</span>(<span class="params">table, row_key, column_family=<span class="literal">None</span>, keys=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> keys:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;delete keys:%s from row_key:%s&#x27;</span> % (keys, row_key))</span><br><span class="line">        key_list = [<span class="string">&#x27;%s:%s&#x27;</span> % (column_family, key) <span class="keyword">for</span> key <span class="keyword">in</span> keys]</span><br><span class="line">        table.delete(row_key, key_list)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;delete row(column_family:) from hbase&#x27;</span>)</span><br><span class="line">        table.delete(row_key)</span><br></pre></td></tr></table></figure><ul><li>删除表</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#api</span></span><br><span class="line">conn.delete_table(table_name, <span class="literal">True</span>)</span><br><span class="line"><span class="comment">#函数封装</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">delete_table</span>(<span class="params">table_name</span>):</span></span><br><span class="line">    pretty_print(<span class="string">&#x27;delete table %s now.&#x27;</span> % table_name)</span><br><span class="line">    conn.delete_table(table_name, <span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li></ul><ul><li>完整代码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> happybase</span><br><span class="line"></span><br><span class="line">hostname = <span class="string">&#x27;192.168.199.188&#x27;</span></span><br><span class="line">table_name = <span class="string">&#x27;users&#x27;</span></span><br><span class="line">column_family = <span class="string">&#x27;cf&#x27;</span></span><br><span class="line">row_key = <span class="string">&#x27;row_1&#x27;</span></span><br><span class="line"></span><br><span class="line">conn = happybase.Connection(hostname)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_tables</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;show all tables now&#x27;</span>)</span><br><span class="line">    tables =  conn.tables()</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> tables:</span><br><span class="line">        <span class="built_in">print</span> t</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_table</span>(<span class="params">table_name, column_family</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;create table %s&#x27;</span> % table_name)</span><br><span class="line">    conn.create_table(table_name, &#123;column_family:<span class="built_in">dict</span>()&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_rows</span>(<span class="params">table, row_keys=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> row_keys:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;show value of row named %s&#x27;</span> % row_keys)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(row_keys) == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span> table.row(row_keys[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span> table.rows(row_keys)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;show all row values of table named %s&#x27;</span> % table.name)</span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> table.scan():</span><br><span class="line">            <span class="built_in">print</span> key, value</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">put_row</span>(<span class="params">table, column_family, row_key, value</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;insert one row to hbase&#x27;</span>)</span><br><span class="line">    table.put(row_key, &#123;<span class="string">&#x27;%s:name&#x27;</span> % column_family:<span class="string">&#x27;name_%s&#x27;</span> % value&#125;)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">put_rows</span>(<span class="params">table, column_family, row_lines=<span class="number">30</span></span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;insert rows to hbase now&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(row_lines):</span><br><span class="line">        put_row(table, column_family, <span class="string">&#x27;row_%s&#x27;</span> % i, i)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">delete_row</span>(<span class="params">table, row_key, column_family=<span class="literal">None</span>, keys=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> keys:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;delete keys:%s from row_key:%s&#x27;</span> % (keys, row_key))</span><br><span class="line">        key_list = [<span class="string">&#x27;%s:%s&#x27;</span> % (column_family, key) <span class="keyword">for</span> key <span class="keyword">in</span> keys]</span><br><span class="line">        table.delete(row_key, key_list)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;delete row(column_family:) from hbase&#x27;</span>)</span><br><span class="line">        table.delete(row_key)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">delete_table</span>(<span class="params">table_name</span>):</span></span><br><span class="line">    pretty_print(<span class="string">&#x27;delete table %s now.&#x27;</span> % table_name)</span><br><span class="line">    conn.delete_table(table_name, <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool</span>():</span></span><br><span class="line">    pretty_print(<span class="string">&#x27;test pool connection now.&#x27;</span>)</span><br><span class="line">    pool = happybase.ConnectionPool(size=<span class="number">3</span>, host=hostname)</span><br><span class="line">    <span class="keyword">with</span> pool.connection() <span class="keyword">as</span> connection:</span><br><span class="line">        <span class="built_in">print</span> connection.tables()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment"># show_tables()</span></span><br><span class="line">    <span class="comment"># create_table(table_name, column_family)</span></span><br><span class="line">    <span class="comment"># show_tables()</span></span><br><span class="line"></span><br><span class="line">    table = conn.table(table_name)</span><br><span class="line">    show_rows(table)</span><br><span class="line">    put_rows(table, column_family)</span><br><span class="line">    show_rows(table)</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># # 更新操作</span></span><br><span class="line">    <span class="comment"># put_row(table, column_family, row_key, &#x27;xiaoh.me&#x27;)</span></span><br><span class="line">    <span class="comment"># show_rows(table, [row_key])</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># # 删除数据</span></span><br><span class="line">    <span class="comment"># delete_row(table, row_key)</span></span><br><span class="line">    <span class="comment"># show_rows(table, [row_key])</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># delete_row(table, row_key, column_family, [&#x27;name&#x27;])</span></span><br><span class="line">    <span class="comment"># show_rows(table, [row_key])</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># counter(table, row_key, column_family)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># delete_table(table_name)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h2 id="HBase表设计"><a href="#HBase表设计" class="headerlink" title="HBase表设计"></a>HBase表设计</h2><ul><li>设计HBase表时需要注意的特点<ul><li>HBase中表的索引是通过rowkey实现的</li><li>在表中是通过Row key的字典顺序来对数据进行排序的, 表中Region的划分通过起始Rowkey和结束Rowkey来决定的</li><li>所有存储在HBase中的数据都是二进制字节, 没有数据类型</li><li>原子性只在行内保证, HBase表中没有多行事务</li><li>列族(Column Family)在表创建之前就要定义好</li><li>列族中的列标识(Column Qualifier)可以在表创建后动态插入数据的时候添加</li><li>不同的column family保存在不同的文件中。</li></ul></li><li>如何设计HBase表<ul><li>Row key的结构该如何设置, Row key中又该包含什么样的信息</li><li>表中应该有多少的列族</li><li>列族中应该存储什么样的数据</li><li>每个列族中存储多少列数据</li><li>列的名字分别是什么</li><li>cell中应该存储什么样的信息</li><li>每个cell中存储多少个版本信息</li></ul></li><li>DDI  目的是为了克服HBase架构上的缺陷(join繁琐 只有row key索引等)<ul><li>Denormalization (反规范化, 解决join麻烦的问题)</li><li>Duplication (数据冗余)</li><li>Intelligent keys(通过row key设计实现 索引 排序对读写优化) </li></ul></li></ul><h3 id="HBase表设计案例-社交应用互粉信息表"><a href="#HBase表设计案例-社交应用互粉信息表" class="headerlink" title="HBase表设计案例: 社交应用互粉信息表"></a>HBase表设计案例: 社交应用互粉信息表</h3><ul><li><p>设计表保存应用中用户互粉的信息</p><ul><li>读场景:<ul><li>某用户都关注了哪些用户</li><li>用户A有没有关注用户B</li><li>谁关注了用户A</li></ul></li><li>写场景<ul><li>用户关注了某个用户</li><li>用户取消关注了某个用户</li></ul></li></ul></li><li><p>设计1:</p><ul><li>colunm qulifier(列名)  1:  2:</li></ul><p><img src="table1.png" alt=""></p></li><li><p>设计2</p><ul><li>添加了一个 count 记录当前的最后一个记录的列名</li></ul><p><img src="table2.png" alt=""></p></li><li><p>设计3</p><ul><li>列名 user_id</li></ul><p><img src="table3.png" alt=""></p></li><li><p>最终设计(DDI)</p><ul><li>解决谁关注了用户A问题<ul><li>① 设计一张新表, 里面保存某个用户和他的粉丝</li><li>② 在同一张表中同时记录粉丝列表的和用户关注的列表, 并通过Rowkey来区分<ul><li>01_userid: 用户关注列表</li><li>02_userid: 粉丝列表</li></ul></li><li>上两种设计方案的问题(事务)</li></ul></li></ul></li><li><p>案例总结</p><ul><li>Rowkey是HBase表结构设计中很重要的环节, 直接影响到HBase的效率和性能</li><li>HBase的表结构比传统关系型数据库更灵活, 能存储任何二进制数据,无需考虑数据类型</li><li>利用列标识(Column Qualifier)来存储数据</li><li>衡量设计好坏的简单标准 是否会全表查询 </li></ul></li></ul><h2 id="HBase组件"><a href="#HBase组件" class="headerlink" title="HBase组件"></a>HBase组件</h2><h3 id="HBase-基础架构"><a href="#HBase-基础架构" class="headerlink" title="HBase 基础架构"></a>HBase 基础架构</h3><p><img src="structure.jpg" alt=""></p><p><strong>Client</strong></p><ul><li>①与zookeeper通信, 找到数据入口地址</li><li>②使用HBase RPC机制与HMaster和HRegionServer进行通信；</li><li>③Client与HMaster进行通信进行管理类操作；</li><li>④Client与HRegionServer进行数据读写类操作。</li></ul><p><strong>Zookeeper</strong></p><ul><li>①保证任何时候，集群中只有一个running master，避免单点问题；</li><li>②存贮所有Region的寻址入口，包括-ROOT-表地址、HMaster地址；</li><li>③实时监控Region Server的状态，将Region server的上线和下线信息，实时通知给Master；</li><li>④存储Hbase的schema，包括有哪些table，每个table有哪些column family。</li></ul><p><strong>HMaster</strong></p><p>可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行。</p><p>角色功能：</p><ul><li>①为Region server分配region；</li><li>②负责region server的负载均衡；</li><li>③发现失效的region serve并重新分配其上的region；</li><li>④HDFS上的垃圾文件回收；</li><li>⑤处理用户对表的增删改查操作。</li></ul><p><strong>HRegionServer</strong></p><p>HBase中最核心的模块，主要负责响应用户I/O请求，向HDFS文件系统中读写数据。</p><p>作用：</p><ul><li>①维护Master分配给它的region，处理对这些region的IO请求；</li><li>②负责切分在运行过程中变得过大的region。</li><li>此外，HRegionServer管理一系列HRegion对象，每个HRegion对应Table中一个Region，HRegion由多个HStore组成，每个HStore对应Table中一个Column Family的存储，Column Family就是一个集中的存储单元，故将具有相同IO特性的Column放在一个Column Family会更高效。</li></ul><p><strong>HStore</strong></p><ul><li>HBase存储的核心，由MemStore和StoreFile组成。</li></ul><p><img src="2.png" alt=""></p><ul><li>用户写入数据的流程为：client访问ZK, ZK返回RegionServer地址-&gt; client访问RegionServer写入数据 -&gt; 数据存入MemStore，一直到MemStore满 -&gt; Flush成StoreFile</li></ul><p><strong>HRegion</strong></p><ul><li>一个表最开始存储的时候，是一个region。</li><li>一个Region中会有个多个store，每个store用来存储一个列簇。如果只有一个column family，就只有一个store。</li><li>region会随着插入的数据越来越多，会进行拆分。默认大小是10G一个。</li></ul><p><strong>HLog</strong></p><ul><li>在分布式系统环境中，无法避免系统出错或者宕机，一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况。</li></ul><h3 id="HBase模块协作"><a href="#HBase模块协作" class="headerlink" title="HBase模块协作"></a>HBase模块协作</h3><ul><li>HBase启动<ul><li>HMaster启动, 注册到Zookeeper, 等待RegionServer汇报</li><li>RegionServer注册到Zookeeper, 并向HMaster汇报</li><li>对各个RegionServer(包括失效的)的数据进行整理, 分配Region和meta信息</li></ul></li><li>RegionServer失效<ul><li>HMaster将失效RegionServer上的Region分配到其他节点</li><li>HMaster更新hbase: meta 表以保证数据正常访问</li></ul></li><li>HMaster失效<ul><li>处于Backup状态的其他HMaster节点推选出一个转为Active状态</li><li>数据能正常读写, 但是不能创建删除表, 也不能更改表结构</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Search / Advertisement / Recommendation / Causal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop</title>
      <link href="/2022/01/18/5.3-Hadoop/"/>
      <url>/2022/01/18/5.3-Hadoop/</url>
      
        <content type="html"><![CDATA[<p><strong>推荐系统学习笔记目录</strong></p><ol><li><a href="https://xfliu1998.github.io/2022/01/18/5.1-Recommendation-System-Introduction/">推荐系统介绍</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/">推荐算法</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.3-Hadoop/">Hadoop</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.4-Hive/">Hive &amp; HBase</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.5-Spark-core/">Spark core</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.6-Spark-SQL/">Spark SQL &amp; Spark streaming</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.7-RS-case/">推荐系统案例</a></li></ol><h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><h3 id="什么是Hadoop"><a href="#什么是Hadoop" class="headerlink" title="什么是Hadoop"></a>什么是Hadoop</h3><ul><li><p>Hadoop名字的由来</p><ul><li>作者：Doug cutting</li><li>Hadoop项目作者的孩子给一个棕黄色的大象样子的填充玩具的命名<br><img src="image-hadoop1.png" alt=""></li></ul></li><li><p>Hadoop的概念:</p><ul><li>Apache™ Hadoop®  是一个开源的, <strong>可靠的</strong>(reliable), <strong>可扩展</strong>的(scalable)<strong>分布式计算框架</strong><ul><li>允许使用简单的编程模型跨计算机集群分布式处理大型数据集</li><li><strong>可扩展</strong>: 从单个服务器扩展到数千台计算机，每台计算机都提供本地计算和存储</li><li><strong>可靠的</strong>: 不依靠硬件来提供高可用性(high-availability)，而是在应用层检测和处理故障，从而在计算机集群之上提供高可用服务</li></ul></li></ul></li><li><p>Hadoop能做什么?</p><ul><li>搭建大型数据仓库</li><li>PB级数据的存储 处理 分析 统计等业务<ul><li>搜索引擎</li><li>日志分析</li><li>数据挖掘</li><li>商业智能(Business Intelligence，简称：BI)<br>商业智能通常被理解为将企业中现有的数据(订单、库存、交易账目、客户和供应商等数据)转化为知识，帮助企业做出明智的业务经营决策的工具。从技术层面上讲，是数据仓库、数据挖掘等技术的综合运用。</li></ul></li></ul></li></ul><ul><li>Hadoop发展史<ul><li>2003-2004年 Google发表了三篇论文<ul><li>GFS：Google的分布式文件系统Google File System </li><li><a href="https://en.wikipedia.org/wiki/MapReduce">MapReduce</a>: Simplified Data Processing on Large Clusters </li><li>BigTable：一个大型的分布式数据库</li></ul></li><li>2006年2月Hadoop成为Apache的独立开源项目( Doug Cutting等人实现了DFS和MapReduce机制)。</li><li>2006年4月— 标准排序(10 GB每个节点)在188个节点上运行47.9个小时。 </li><li>2008年4月— 赢得世界最快1TB数据排序在900个节点上用时209秒。 </li><li>2008年— <strong>淘宝开始投入研究基于Hadoop的系统–云梯</strong>。云梯总容量约9.3PB，共有1100台机器，每天处理18000道作业，扫描500TB数据。 </li><li>2009年3月— <strong>Cloudera推出CDH（Cloudera’s Dsitribution Including Apache Hadoop）</strong></li><li>2009年5月— Yahoo的团队使用Hadoop对1 TB的数据进行排序只花了62秒时间。 </li><li>2009年7月— <strong>Hadoop Core项目更名为Hadoop Common;</strong> </li><li>2009年7月— <strong>MapReduce和Hadoop Distributed File System (HDFS)成为Hadoop项目的独立子项目。</strong></li><li>2012年11月— Apache Hadoop 1.0 Available</li><li>2018年4月— Apache Hadoop 3.1 Available</li><li>搜索引擎时代<ul><li>有保存大量网页的需求(单机  集群)</li><li>词频统计 word count  PageRank</li></ul></li><li>数据仓库时代<ul><li>FaceBook推出Hive</li><li>曾经进行数分析与统计时, 仅限于数据库,受数据量和计算能力的限制, 我们只能对最重要的数据进行统计和分析(决策数据,财务相关)</li><li>Hive可以在Hadoop上运行SQL操作, 可以把运行日志, 应用采集数据,数据库数据放到一起分析</li></ul></li><li>数据挖掘时代<ul><li>啤酒尿不湿</li><li>关联分析</li><li>用户画像/物品画像</li></ul></li><li>机器学习时代  广义大数据<ul><li>大数据提高数据存储能力, 为机器学习提供燃料</li><li>alpha go</li><li>siri 小爱 天猫精灵</li></ul></li></ul></li></ul><h3 id="Hadoop核心组件"><a href="#Hadoop核心组件" class="headerlink" title="Hadoop核心组件"></a>Hadoop核心组件</h3><ul><li><p>Hadoop是所有搜索引擎的共性问题的廉价解决方案</p><ul><li>如何存储持续增长的海量网页:  单节点 V.S. 分布式存储</li><li>如何对持续增长的海量网页进行排序: 超算 V.S. 分布式计算</li><li>HDFS 解决分布式存储问题</li><li>MapReduce 解决分布式计算问题</li></ul></li><li><p><strong>Hadoop Common</strong>: The common utilities that support the other Hadoop modules.(hadoop的核心组件)</p></li><li><strong>Hadoop Distributed File System (HDFS™)</strong>: A distributed file system that provides high-throughput access to application data.(分布式文件系统)<ul><li>源自于Google的GFS论文, 论文发表于2003年10月</li><li>HDFS是GFS的开源实现</li><li>HDFS的特点:扩展性&amp;容错性&amp;海量数量存储</li><li>将文件切分成指定大小的数据块, 并在多台机器上保存多个副本</li><li>数据切分、多副本、容错等操作对用户是透明的</li></ul></li><li>下面这张图是数据块多份复制存储的示意<ul><li>图中对于文件 /users/sameerp/data/part-0，其复制备份数设置为2, 存储的BlockID分别为1、3。</li><li>Block1的两个备份存储在DataNode0和DataNode2两个服务器上</li><li>Block3的两个备份存储在DataNode4和DataNode6两个服务器上</li></ul></li></ul><p><img src="hadoop-hdfs1.png" alt=""></p><ul><li><p><strong>Hadoop MapReduce</strong>: A YARN-based system for parallel processing of large data sets.</p><ul><li>分布式计算框架</li><li>源于Google的MapReduce论文，论文发表于2004年12月</li><li>MapReduce是GoogleMapReduce的开源实现</li><li>MapReduce特点:扩展性&amp;容错性&amp;海量数据离线处理</li></ul><p><img src="image-mapreduce.png" alt=""></p></li><li><p><strong>Hadoop YARN</strong>: A framework for job scheduling and cluster resource management.(资源调度系统)</p><ul><li><p>YARN: Yet Another Resource Negotiator</p></li><li><p>负责整个集群资源的管理和调度</p></li><li><p>YARN特点:扩展性&amp;容错性&amp;多框架资源统一调度</p><p><img src="image-yarn.png" alt=""></p></li></ul></li></ul><h3 id="Hadoop优势"><a href="#Hadoop优势" class="headerlink" title="Hadoop优势"></a>Hadoop优势</h3><ul><li>高可靠<ul><li>数据存储: 数据块多副本</li><li>数据计算: 某个节点崩溃, 会自动重新调度作业计算</li></ul></li><li>高扩展性<ul><li>存储/计算资源不够时，可以横向的线性扩展机器</li><li>一个集群中可以包含数以千计的节点</li><li>集群可以使用廉价机器，成本低</li></ul></li><li>Hadoop生态系统成熟</li></ul><h2 id="分布式文件系统-HDFS"><a href="#分布式文件系统-HDFS" class="headerlink" title="分布式文件系统 HDFS"></a>分布式文件系统 HDFS</h2><h3 id="HDFS的使用"><a href="#HDFS的使用" class="headerlink" title="HDFS的使用"></a>HDFS的使用</h3><ul><li><p>启动HDFS</p><ul><li>来到$HADOOP_HOME/sbin目录下</li><li>执行start-dfs.sh</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop00 sbin]$ ./start-dfs.sh</span><br></pre></td></tr></table></figure><ul><li>可以看到 namenode和 datanode启动的日志信息</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Starting namenodes on [hadoop00]</span><br><span class="line">hadoop00: starting namenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-namenode-hadoop00.out</span><br><span class="line">localhost: starting datanode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-hadoop00.out</span><br><span class="line">Starting secondary namenodes [0.0.0.0]</span><br><span class="line">0.0.0.0: starting secondarynamenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-secondarynamenode-hadoop00.out</span><br></pre></td></tr></table></figure><ul><li>通过jps命令查看当前运行的进程</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop00 sbin]$ jps</span><br><span class="line">4416 DataNode</span><br><span class="line">4770 Jps</span><br><span class="line">4631 SecondaryNameNode</span><br><span class="line">4251 NameNode</span><br></pre></td></tr></table></figure><ul><li>可以看到 NameNode DataNode 以及 SecondaryNameNode 说明启动成功</li></ul></li><li><p>通过可视化界面查看HDFS的运行情况</p><ul><li>通过浏览器查看 主机ip:50070端口 </li></ul><p><img src="hadoop-state.png" alt="1551174774098"></p><ul><li>Overview界面查看整体情况</li></ul><p><img src="hadoop-state1.png" alt="1551174978741"></p><ul><li><p>Datanodes界面查看datanode的情况</p><p><img src="hadoop-state2.png" alt="1551175081051"></p></li></ul></li></ul><h3 id="HDFS-shell操作"><a href="#HDFS-shell操作" class="headerlink" title="HDFS shell操作"></a>HDFS shell操作</h3><ul><li><p>调用文件系统(FS)Shell命令应使用 bin/hadoop fs <args>的形式</p><ul><li>ls<br>使用方法：hadoop fs -ls <args><br>如果是文件，则按照如下格式返回文件信息：<br>文件名 &lt;副本数&gt; 文件大小 修改日期 修改时间 权限 用户ID 组ID<br>如果是目录，则返回它直接子文件的一个列表，就像在Unix中一样。目录返回列表的信息如下：<br>目录名 <dir> 修改日期 修改时间 权限 用户ID 组ID<br>示例：<br>hadoop fs -ls /user/hadoop/file1 /user/hadoop/file2 hdfs://host:port/user/hadoop/dir1 /nonexistentfile<br>返回值：<br>成功返回0，失败返回-1。 </li><li>text<br>使用方法：hadoop fs -text <src><br>将源文件输出为文本格式。允许的格式是zip和TextRecordInputStream。</li><li><p>mv<br>使用方法：hadoop fs -mv URI [URI …] <dest><br>将文件从源路径移动到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。不允许在不同的文件系统间移动文件。<br>示例：</p><ul><li>hadoop fs -mv /user/hadoop/file1 /user/hadoop/file2</li><li>hadoop fs -mv hdfs://host:port/file1 hdfs://host:port/file2 hdfs://host:port/file3 hdfs://host:port/dir1</li></ul><p>返回值：成功返回0，失败返回-1。</p></li><li><p>put<br>使用方法：hadoop fs -put <localsrc> … <dst><br>从本地文件系统中复制单个或多个源路径到目标文件系统。也支持从标准输入中读取输入写入目标文件系统。</p><ul><li>hadoop fs -put localfile /user/hadoop/hadoopfile</li><li>hadoop fs -put localfile1 localfile2 /user/hadoop/hadoopdir</li><li>hadoop fs -put localfile hdfs://host:port/hadoop/hadoopfile</li><li>hadoop fs -put - hdfs://host:port/hadoop/hadoopfile<br>从标准输入中读取输入。</li></ul><p>返回值：成功返回0，失败返回-1。</p></li><li><p>rm<br>使用方法：hadoop fs -rm URI [URI …]<br>删除指定的文件。只删除非空目录和文件。请参考rmr命令了解递归删除。<br>示例：</p><ul><li>hadoop fs -rm hdfs://host:port/file /user/hadoop/emptydir<br>返回值：<br>成功返回0，失败返回-1。</li></ul></li></ul></li><li><p><a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html">http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html</a></p></li></ul><h3 id="HDFS-shell操作练习"><a href="#HDFS-shell操作练习" class="headerlink" title="HDFS shell操作练习"></a>HDFS shell操作练习</h3><ul><li><p>在centos 中创建 test.txt  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch test.txt</span><br></pre></td></tr></table></figure></li><li><p>在centos中为test.txt 添加文本内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi test.txt</span><br></pre></td></tr></table></figure></li><li><p>在HDFS中创建 hadoop001/test 文件夹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p /hadoop001/test</span><br></pre></td></tr></table></figure></li><li><p>把text.txt文件上传到HDFS中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put test.txt /hadoop001/test/</span><br></pre></td></tr></table></figure></li><li><p>查看hdfs中 hadoop001/test/test.txt 文件内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /hadoop001/test/test.txt</span><br></pre></td></tr></table></figure></li><li><p>将hdfs中 hadoop001/test/test.txt文件下载到centos</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get /hadoop001/test/test.txt test.txt</span><br></pre></td></tr></table></figure></li><li><p>删除HDFS中 hadoop001/test/</p><p> hadoop fs -rm -r /hadoop001</p></li></ul><h3 id="HDFS环境搭建"><a href="#HDFS环境搭建" class="headerlink" title="HDFS环境搭建"></a>HDFS环境搭建</h3><ul><li><p>下载jdk 和 hadoop 放到 ~/software目录下 然后解压到 ~/app目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf 压缩包名字 -C ~/app/</span><br></pre></td></tr></table></figure></li><li><p>配置环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br><span class="line">export JAVA_HOME=/home/hadoop/app/jdk1.8.0_91</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export HADOOP_HOME=/home/hadoop/app/hadoop......</span><br><span class="line">export PATH=$HADOOP_HOME/bin:$PATH</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 保存退出后</span></span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure></li><li><p>进入到解压后的hadoop目录 修改配置文件</p><ul><li><p>配置文件作用</p><ul><li>core-site.xml  指定hdfs的访问方式</li><li>hdfs-site.xml  指定namenode 和 datanode 的数据存储位置</li><li>mapred-site.xml 配置mapreduce</li><li>yarn-site.xml  配置yarn</li></ul></li><li><p>修改hadoop-env.sh</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd etc/hadoop</span><br><span class="line">vi hadoop-env.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 找到下面内容添加java home</span></span><br><span class="line">export_JAVA_HOME=/home/hadoop/app/jdk1.8.0_91</span><br></pre></td></tr></table></figure><ul><li>修改 core-site.xml 在 <configuration>节点中添加</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop000:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>修改hdfs-site.xml 在 configuration节点中添加</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/app/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/app/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>修改 mapred-site.xml </li><li>默认没有这个 从模板文件复制 </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br></pre></td></tr></table></figure><p>​    在mapred-site.xml  的configuration 节点中添加</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>修改yarn-site.xml configuration 节点中添加</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>来到hadoop的bin目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./hadoop namenode -format (这个命令只运行一次)</span><br></pre></td></tr></table></figure></li><li><p>启动hdfs 进入到  sbin</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-dfs.sh</span><br></pre></td></tr></table></figure></li><li><p>启动启动yarn 在sbin中</p></li></ul><h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><h3 id="什么是YARN"><a href="#什么是YARN" class="headerlink" title="什么是YARN"></a>什么是YARN</h3><ul><li>Yet Another Resource Negotiator, 另一种资源协调者</li><li>通用资源管理系统</li><li>为上层应用提供统一的资源管理和调度，为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处</li></ul><h3 id="YARN产生背景"><a href="#YARN产生背景" class="headerlink" title="YARN产生背景"></a>YARN产生背景</h3><ul><li><p>通用资源管理系统</p><ul><li>Hadoop数据分布式存储（数据分块，冗余存储）</li><li>当多个MapReduce任务要用到相同的hdfs数据， 需要进行资源调度管理</li><li>Hadoop1.x时并没有YARN，MapReduce 既负责进行计算作业又处理服务器集群资源调度管理</li></ul></li><li><p>服务器集群资源调度管理和MapReduce执行过程耦合在一起带来的问题</p><ul><li><p>Hadoop早期, 技术只有Hadoop, 这个问题不明显</p></li><li><p>随着大数据技术的发展，Spark Storm … 计算框架都要用到服务器集群资源 </p></li><li><p>如果没有通用资源管理系统，只能为多个集群分别提供数据</p><ul><li>资源利用率低 运维成本高</li></ul><p><img src="image-yarn2.png" alt=""></p></li><li><p>Yarn (Yet Another Resource Negotiator) 另一种资源调度器</p><ul><li>Mesos 大数据资源管理产品</li></ul></li></ul></li><li><p>不同计算框架可以共享同一个HDFS集群上的数据，享受整体的资源调度</p><p><img src="hadoop-yarn3.png" alt=""></p></li></ul><h3 id="YARN的架构和执行流程"><a href="#YARN的架构和执行流程" class="headerlink" title="YARN的架构和执行流程"></a>YARN的架构和执行流程</h3><ul><li>ResourceManager: RM 资源管理器<br>​    整个集群同一时间提供服务的RM只有一个，负责集群资源的统一管理和调度<br>​    处理客户端的请求： submit, kill<br>​    监控我们的NM，一旦某个NM挂了，那么该NM上运行的任务需要告诉我们的AM来如何进行处理</li><li>NodeManager: NM 节点管理器<br>​    整个集群中有多个，负责自己本身节点资源管理和使用<br>​    定时向RM汇报本节点的资源使用情况<br>​    接收并处理来自RM的各种命令：启动Container<br>​    处理来自AM的命令</li><li>ApplicationMaster: AM<br>​    每个应用程序对应一个：MR、Spark，负责应用程序的管理<br>​    为应用程序向RM申请资源（core、memory），分配给内部task<br>​    需要与NM通信：启动/停止task，task是运行在container里面，AM也是运行在container里面</li><li>Container 容器: 封装了CPU、Memory等资源的一个容器,是一个任务运行环境的抽象</li><li>Client: 提交作业 查询作业的运行进度,杀死作业</li></ul><p><img src="yarn4.png" alt=""></p><ol><li>Client提交作业请求</li><li>ResourceManager 进程和 NodeManager 进程通信，根据集群资源，为用户程序分配第一个Container(容器)，并将 ApplicationMaster 分发到这个容器上面</li><li>在启动的Container中创建ApplicationMaster</li><li>ApplicationMaster启动后向ResourceManager注册进程,申请资源</li><li>ApplicationMaster申请到资源后，向对应的NodeManager申请启动Container,将要执行的程序分发到NodeManager上</li><li>Container启动后，执行对应的任务</li><li>Tast执行完毕之后，向ApplicationMaster返回结果</li><li>ApplicationMaster向ResourceManager 请求kill</li></ol><h3 id="YARN环境搭建"><a href="#YARN环境搭建" class="headerlink" title="YARN环境搭建"></a>YARN环境搭建</h3><p>1）mapred-site.xml<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><br>2）yarn-site.xml<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><br>3) 启动YARN相关的进程<br>sbin/start-yarn.sh<br>4）验证<br>​    jps<br>​        ResourceManager<br>​        NodeManager<br>​    <a href="http://192,168.199.188:8088">http://192,168.199.188:8088</a><br>5）停止YARN相关的进程<br>​    sbin/stop-yarn.sh</p><h2 id="分布式处理框架-MapReduce"><a href="#分布式处理框架-MapReduce" class="headerlink" title="分布式处理框架 MapReduce"></a>分布式处理框架 MapReduce</h2><h3 id="什么是MapReduce"><a href="#什么是MapReduce" class="headerlink" title="什么是MapReduce"></a>什么是MapReduce</h3><ul><li>源于Google的MapReduce论文(2004年12月)</li><li>Hadoop的MapReduce是Google论文的开源实现</li><li>MapReduce优点: 海量数据离线处理&amp;易开发</li><li>MapReduce缺点: 实时流式计算</li></ul><h3 id="MapReduce编程模型"><a href="#MapReduce编程模型" class="headerlink" title="MapReduce编程模型"></a>MapReduce编程模型</h3><ul><li>MapReduce分而治之的思想<ul><li>数钱实例：一堆钞票，各种面值分别是多少<ul><li>单点策略<ul><li>一个人数所有的钞票，数出各种面值有多少张</li></ul></li><li>分治策略<ul><li>每个人分得一堆钞票，数出各种面值有多少张</li><li>汇总，每个人负责统计一种面值</li></ul></li><li>解决数据可以切割进行计算的应用</li></ul></li></ul></li><li>MapReduce编程分Map和Reduce阶段<ul><li>将作业拆分成Map阶段和Reduce阶段</li><li>Map阶段 Map Tasks 分：把复杂的问题分解为若干”简单的任务”</li><li>Reduce阶段: Reduce Tasks 合：reduce</li></ul></li><li><p>MapReduce编程执行步骤</p><ul><li>准备MapReduce的输入数据</li><li>准备Mapper数据</li><li>Shuffle</li><li>Reduce处理</li><li>结果输出</li></ul></li><li><p><strong>编程模型</strong></p><ul><li><p>借鉴函数式编程方式</p></li><li><p>用户只需要实现两个函数接口：</p><ul><li><p>Map(in_key,in_value)</p><p>—-&gt;(out_key,intermediate_value) list</p></li><li><p>Reduce(out_key,intermediate_value) list</p><p>—-&gt;out_value list</p></li></ul></li><li><p>Word Count 词频统计案例</p><p><img src="image-mapreduce.png" alt=""></p></li></ul></li></ul><h3 id="Hadoop-Streaming-实现wordcount-（实验-了解）"><a href="#Hadoop-Streaming-实现wordcount-（实验-了解）" class="headerlink" title="Hadoop Streaming 实现wordcount （实验 了解）"></a>Hadoop Streaming 实现wordcount （实验 了解）</h3><ul><li><p>Mapper</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入为标准输入stdin</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    <span class="comment">#删除开头和结尾的空行</span></span><br><span class="line">    line = line.strip()</span><br><span class="line">    <span class="comment">#以默认空格分隔单词到words列表</span></span><br><span class="line">    words = line.split()</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        <span class="comment">#输出所有单词，格式为“单词 1”以便作为Reduce的输入</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;%s %s&quot;</span>%(word,<span class="number">1</span>))</span><br></pre></td></tr></table></figure></li><li><p>Reducer</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">current_word = <span class="literal">None</span></span><br><span class="line">current_count = <span class="number">0</span></span><br><span class="line">word = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取标准输入，即mapper.py的标准输出</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    <span class="comment">#删除开头和结尾的空行</span></span><br><span class="line">    line = line.strip()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#解析mapper.py输出作为程序的输入，以tab作为分隔符</span></span><br><span class="line">    word,count = line.split()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#转换count从字符型到整型</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        count = <span class="built_in">int</span>(count)</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="comment">#count非数字时，忽略此行</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#要求mapper.py的输出做排序（sort）操作，以便对连续的word做判断</span></span><br><span class="line">    <span class="keyword">if</span> current_word == word:</span><br><span class="line">        current_count += count</span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        <span class="comment">#出现了一个新词</span></span><br><span class="line">        <span class="comment">#输出当前word统计结果到标准输出</span></span><br><span class="line">        <span class="keyword">if</span> current_word :</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;%s\t%s&#x27;</span> % (current_word,current_count))</span><br><span class="line">        <span class="comment">#开始对新词的统计</span></span><br><span class="line">        current_count = count</span><br><span class="line">        current_word = word</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出最后一个word统计</span></span><br><span class="line"><span class="keyword">if</span> current_word == word:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s\t%s&quot;</span>% (current_word,current_count))</span><br></pre></td></tr></table></figure><p>cat xxx.txt|python3 map.py|sort|python3 red.py</p><p>得到最终的输出</p><p>注：hadoop-streaming会主动将map的输出数据进行字典排序</p></li><li><p>通过Hadoop Streaming 提交作业到Hadoop集群</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">STREAM_JAR_PATH=&quot;/root/bigdata/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.9.1.jar&quot;    # hadoop streaming jar包所在位置</span><br><span class="line">INPUT_FILE_PATH_1=&quot;/The_Man_of_Property.txt&quot;  #要进行词频统计的文档在hdfs中的路径</span><br><span class="line">OUTPUT_PATH=&quot;/output&quot;                         #MR作业后结果的存放路径</span><br><span class="line"></span><br><span class="line">hadoop fs -rm -r -skipTrash $OUTPUT_PATH    # 输出路径如果之前存在 先删掉否则会报错</span><br><span class="line"></span><br><span class="line">hadoop jar $STREAM_JAR_PATH \   </span><br><span class="line">-input $INPUT_FILE_PATH_1 \ # 指定输入文件位置</span><br><span class="line">-output $OUTPUT_PATH \      #指定输出结果位置</span><br><span class="line">-mapper &quot;python map.py&quot; \   #指定mapper执行的程序</span><br><span class="line">-reducer &quot;python red.py&quot; \  # 指定reduce阶段执行的程序</span><br><span class="line">-file ./map.py \            # 通过-file 把python源文件分发到集群的每一台机器上  </span><br><span class="line">-file ./red.py</span><br></pre></td></tr></table></figure></li><li><p>到Hadoop集群查看运行结果</p><p><img src="mr_result.png" alt=""></p></li></ul><h3 id="利用MRJob编写和运行MapReduce代码"><a href="#利用MRJob编写和运行MapReduce代码" class="headerlink" title="利用MRJob编写和运行MapReduce代码"></a>利用MRJob编写和运行MapReduce代码</h3><p><strong>mrjob 简介</strong></p><ul><li>使用python开发在Hadoop上运行的程序, mrjob是最简单的方式</li><li>mrjob程序可以在本地测试运行也可以部署到Hadoop集群上运行</li><li>如果不想成为hadoop专家, 但是需要利用Hadoop写MapReduce代码,mrJob是很好的选择</li></ul><p><strong>mrjob 安装</strong></p><ul><li>使用pip安装<ul><li>pip install mrjob</li></ul></li></ul><p><strong>mrjob实现WordCount</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from mrjob.job import MRJob</span><br><span class="line"></span><br><span class="line">class MRWordFrequencyCount(MRJob):</span><br><span class="line"></span><br><span class="line">    def mapper(self, _, line):</span><br><span class="line">        yield &quot;chars&quot;, len(line)</span><br><span class="line">        yield &quot;words&quot;, len(line.split())</span><br><span class="line">        yield &quot;lines&quot;, 1</span><br><span class="line"></span><br><span class="line">    def reducer(self, key, values):</span><br><span class="line">        yield key, sum(values)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    MRWordFrequencyCount.run()</span><br></pre></td></tr></table></figure><p><strong>运行WordCount代码</strong></p><p>打开命令行, 找到一篇文本文档, 敲如下命令:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python mr_word_count.py my_file.txt</span><br></pre></td></tr></table></figure><h3 id="运行MRJOB的不同方式"><a href="#运行MRJOB的不同方式" class="headerlink" title="运行MRJOB的不同方式"></a>运行MRJOB的不同方式</h3><p>1、内嵌(-r inline)方式</p><p>特点是调试方便，启动单一进程模拟任务执行状态和结果，默认(-r inline)可以省略，输出文件使用 &gt; output-file 或-o output-file，比如下面两种运行方式是等价的</p><p>python word_count.py -r inline input.txt &gt; output.txt<br>python word_count.py input.txt &gt; output.txt</p><p>2、本地(-r local)方式</p><p>用于本地模拟Hadoop调试，与内嵌(inline)方式的区别是启动了多进程执行每一个任务。如：</p><p>python word_count.py -r local input.txt &gt; output1.txt</p><p>3、Hadoop(-r hadoop)方式</p><p>用于hadoop环境，支持Hadoop运行调度控制参数，如：</p><p>1)指定Hadoop任务调度优先级(VERY_HIGH|HIGH),如：—jobconf mapreduce.job.priority=VERY_HIGH。</p><p>2)Map及Reduce任务个数限制，如：—jobconf mapreduce.map.tasks=2  —jobconf mapreduce.reduce.tasks=5</p><p>python word_count.py -r hadoop hdfs:///test.txt -o  hdfs:///output</p><h3 id="mrjob-实现-topN统计（实验）"><a href="#mrjob-实现-topN统计（实验）" class="headerlink" title="mrjob 实现 topN统计（实验）"></a>mrjob 实现 topN统计（实验）</h3><p>统计数据中出现次数最多的前n个数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob,MRStep</span><br><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TopNWords</span>(<span class="params">MRJob</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span>(<span class="params">self, _, line</span>):</span></span><br><span class="line">        <span class="keyword">if</span> line.strip() != <span class="string">&quot;&quot;</span>:</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> line.strip().split():</span><br><span class="line">                <span class="keyword">yield</span> word,<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#介于mapper和reducer之间，用于临时的将mapper输出的数据进行统计</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combiner</span>(<span class="params">self, word, counts</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> word,<span class="built_in">sum</span>(counts)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer_sum</span>(<span class="params">self, word, counts</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> <span class="literal">None</span>,(<span class="built_in">sum</span>(counts),word)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#利用heapq将数据进行排序，将最大的2个取出</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">top_n_reducer</span>(<span class="params">self,_,word_cnts</span>):</span></span><br><span class="line">        <span class="keyword">for</span> cnt,word <span class="keyword">in</span> heapq.nlargest(<span class="number">2</span>,word_cnts):</span><br><span class="line">            <span class="keyword">yield</span> word,cnt</span><br><span class="line">    </span><br><span class="line"><span class="comment">#实现steps方法用于指定自定义的mapper，comnbiner和reducer方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">steps</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [</span><br><span class="line">            MRStep(mapper=self.mapper,</span><br><span class="line">                   combiner=self.combiner,</span><br><span class="line">                   reducer=self.reducer_sum),</span><br><span class="line">            MRStep(reducer=self.top_n_reducer)</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    TopNWords.run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h3 id="MRJOB-文件合并"><a href="#MRJOB-文件合并" class="headerlink" title="MRJOB 文件合并"></a>MRJOB 文件合并</h3><p><strong>需求描述</strong></p><ul><li>两个文件合并 类似于数据库中的两张表合并</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">uid uname</span><br><span class="line">01 user1 </span><br><span class="line">02 user2</span><br><span class="line">03 user3</span><br><span class="line">uid orderid order_price</span><br><span class="line">01   01     80</span><br><span class="line">01   02     90</span><br><span class="line">02   03    82</span><br><span class="line">02   04    95</span><br></pre></td></tr></table></figure><p><strong>mrjob 实现</strong></p><p>实现对两个数据表进行join操作，显示效果为每个用户的所有订单信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;01:user1&quot;&quot;01:80,02:90&quot;</span><br><span class="line">&quot;02:user2&quot;&quot;03:82,04:95&quot;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserOrderJoin</span>(<span class="params">MRJob</span>):</span></span><br><span class="line">    SORT_VALUES = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 二次排序参数：http://mrjob.readthedocs.io/en/latest/job.html</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span>(<span class="params">self, _, line</span>):</span></span><br><span class="line">        fields = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(fields) == <span class="number">2</span>:</span><br><span class="line">            <span class="comment"># user data</span></span><br><span class="line">            source = <span class="string">&#x27;A&#x27;</span></span><br><span class="line">            user_id = fields[<span class="number">0</span>]</span><br><span class="line">            user_name = fields[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">yield</span>  user_id,[source,user_name] <span class="comment"># 01 [A,user1]</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">len</span>(fields) == <span class="number">3</span>:</span><br><span class="line">            <span class="comment"># order data</span></span><br><span class="line">            source =<span class="string">&#x27;B&#x27;</span></span><br><span class="line">            user_id = fields[<span class="number">0</span>]</span><br><span class="line">            order_id = fields[<span class="number">1</span>]</span><br><span class="line">            price = fields[<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">yield</span> user_id,[source,order_id,price] <span class="comment">#01 [&#x27;B&#x27;,01,80][&#x27;B&#x27;,02,90]</span></span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer</span>(<span class="params">self,user_id,values</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        每个用户的订单列表</span></span><br><span class="line"><span class="string">        &quot;01:user1&quot;&quot;01:80,02:90&quot;</span></span><br><span class="line"><span class="string">        &quot;02:user2&quot;&quot;03:82,04:95&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param user_id:</span></span><br><span class="line"><span class="string">        :param values:[A,user1]  [&#x27;B&#x27;,01,80]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        values = [v <span class="keyword">for</span> v <span class="keyword">in</span> values]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(values)&gt;<span class="number">1</span> :</span><br><span class="line">            user_name = values[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">            order_info = [<span class="string">&#x27;:&#x27;</span>.join([v[<span class="number">1</span>],v[<span class="number">2</span>]]) <span class="keyword">for</span> v <span class="keyword">in</span> values[<span class="number">1</span>:]] <span class="comment">#[01:80,02:90]</span></span><br><span class="line">            <span class="keyword">yield</span> <span class="string">&#x27;:&#x27;</span>.join([user_id,user_name]),<span class="string">&#x27;,&#x27;</span>.join(order_info)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    UserOrderJoin.run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>实现对两个数据表进行join操作，显示效果为每个用户所下订单的订单总量和累计消费金额</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;01:user1&quot;[2, 170]</span><br><span class="line">&quot;02:user2&quot;[2, 177]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserOrderJoin</span>(<span class="params">MRJob</span>):</span></span><br><span class="line">    <span class="comment"># 二次排序参数：http://mrjob.readthedocs.io/en/latest/job.html</span></span><br><span class="line">    SORT_VALUES = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span>(<span class="params">self, _, line</span>):</span></span><br><span class="line">        fields = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(fields) == <span class="number">2</span>:</span><br><span class="line">            <span class="comment"># user data</span></span><br><span class="line">            source = <span class="string">&#x27;A&#x27;</span></span><br><span class="line">            user_id = fields[<span class="number">0</span>]</span><br><span class="line">            user_name = fields[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">yield</span>  user_id,[source,user_name]</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">len</span>(fields) == <span class="number">3</span>:</span><br><span class="line">            <span class="comment"># order data</span></span><br><span class="line">            source =<span class="string">&#x27;B&#x27;</span></span><br><span class="line">            user_id = fields[<span class="number">0</span>]</span><br><span class="line">            order_id = fields[<span class="number">1</span>]</span><br><span class="line">            price = fields[<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">yield</span> user_id,[source,order_id,price]</span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer</span>(<span class="params">self,user_id,values</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        统计每个用户的订单数量和累计消费金额</span></span><br><span class="line"><span class="string">        :param user_id:</span></span><br><span class="line"><span class="string">        :param values:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        values = [v <span class="keyword">for</span> v <span class="keyword">in</span> values]</span><br><span class="line">        user_name = <span class="literal">None</span></span><br><span class="line">        order_cnt = <span class="number">0</span></span><br><span class="line">        order_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(values)&gt;<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">for</span> v <span class="keyword">in</span> values:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(v) ==  <span class="number">2</span> :</span><br><span class="line">                    user_name = v[<span class="number">1</span>]</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">len</span>(v) == <span class="number">3</span>:</span><br><span class="line">                    order_cnt += <span class="number">1</span></span><br><span class="line">                    order_sum += <span class="built_in">int</span>(v[<span class="number">2</span>])</span><br><span class="line">            <span class="keyword">yield</span> <span class="string">&quot;:&quot;</span>.join([user_id,user_name]),(order_cnt,order_sum)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    UserOrderJoin().run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h3 id="MapReduce原理详解"><a href="#MapReduce原理详解" class="headerlink" title="MapReduce原理详解"></a>MapReduce原理详解</h3><p><strong>单机程序计算流程</strong></p><p>输入数据—-&gt;读取数据—-&gt;处理数据—-&gt;写入数据—-&gt;输出数据</p><p><strong>Hadoop计算流程</strong></p><p>input data：输入数据</p><p>InputFormat：对数据进行切分，格式化处理</p><p>map：将前面切分的数据做map处理(将数据进行分类，输出(k,v)键值对数据)</p><p>shuffle&amp;sort:将相同的数据放在一起，并对数据进行排序处理</p><p>reduce：将map输出的数据进行hash计算，对每个map数据进行统计计算</p><p>OutputFormat：格式化输出数据</p><p><img src="mp3.png" alt=""></p><p><img src="mp4.png" alt=""></p><p><img src="mp5.png" alt=""></p><p><img src="mp6.png" alt=""></p><p><img src="mp1.png" alt=""></p><p>map：将数据进行处理</p><p>buffer in memory：达到80%数据时，将数据锁在内存上，将这部分输出到磁盘上</p><p>partitions：在磁盘上有很多”小的数据”，将这些数据进行归并排序。</p><p>merge on disk：将所有的”小的数据”进行合并。</p><p>reduce：不同的reduce任务，会从map中对应的任务中copy数据</p><p>​        在reduce中同样要进行merge操作</p><h3 id="MapReduce架构"><a href="#MapReduce架构" class="headerlink" title="MapReduce架构"></a>MapReduce架构</h3><ul><li>MapReduce架构 1.X<ul><li>JobTracker:负责接收客户作业提交，负责任务到作业节点上运行，检查作业的状态</li><li>TaskTracker：由JobTracker指派任务，定期向JobTracker汇报状态，在每一个工作节点上永远只会有一个TaskTracker</li></ul></li></ul><p><img src="image-MapReduce4.png" alt=""></p><ul><li><p>MapReduce2.X架构</p><ul><li>ResourceManager：负责资源的管理，负责提交任务到NodeManager所在的节点运行，检查节点的状态</li><li>NodeManager：由ResourceManager指派任务，定期向ResourceManager汇报状态</li></ul><p><img src="image-MapReduce5.png" alt=""></p></li></ul><h2 id="hadoop概念扩展"><a href="#hadoop概念扩展" class="headerlink" title="hadoop概念扩展"></a>hadoop概念扩展</h2><h3 id="Hadoop生态系统"><a href="#Hadoop生态系统" class="headerlink" title="Hadoop生态系统"></a>Hadoop生态系统</h3><p><strong>狭义的Hadoop VS 广义的Hadoop</strong></p><ul><li>广义的Hadoop：指的是Hadoop生态系统，Hadoop生态系统是一个很庞大的概念，hadoop是其中最重要最基础的一个部分，生态系统中每一子系统只解决某一个特定的问题域（甚至可能更窄），不搞统一型的全能系统，而是小而精的多个小系统；</li></ul><p><img src="hadoop-%E7%94%9F%E6%80%81.png" alt=""></p><p>Hive:数据仓库</p><p>R:数据分析</p><p>Mahout:机器学习库</p><p>pig：脚本语言，跟Hive类似</p><p>Oozie:工作流引擎，管理作业执行顺序</p><p>Zookeeper:用户无感知，主节点挂掉选择从节点作为主的</p><p>Flume:日志收集框架</p><p>Sqoop:数据交换框架，例如：关系型数据库与HDFS之间的数据交换</p><p>Hbase : 海量数据中的查询，相当于分布式文件系统中的数据库</p><p>Spark: 分布式的计算框架基于内存</p><ul><li>spark core</li><li>spark sql</li><li>spark streaming 准实时 不算是一个标准的流式计算</li><li>spark ML spark MLlib</li></ul><p>Kafka: 消息队列</p><p>Storm: 分布式的流式计算框架  python操作storm </p><p>Flink: 分布式的流式计算框架</p><p><strong>Hadoop生态系统的特点</strong></p><ul><li><p>开源、社区活跃</p></li><li><p>囊括了大数据处理的方方面面</p></li><li>成熟的生态圈</li></ul><h3 id="HDFS-读写流程-amp-高可用"><a href="#HDFS-读写流程-amp-高可用" class="headerlink" title="HDFS 读写流程 &amp; 高可用"></a>HDFS 读写流程 &amp; 高可用</h3><ul><li><p>HDFS读写流程</p><p><img src="hdfs_read_write/a.jpg" alt=""></p><p><img src="hdfs_read_write/b.jpg" alt=""></p><p><img src="hdfs_read_write/c.jpg" alt=""></p><p><img src="hdfs_read_write/d.jpg" alt=""></p><ul><li><p>客户端向NameNode发出写文件请求。</p></li><li><p>检查是否已存在文件、检查权限。若通过检查，直接先将操作写入EditLog，并返回输出流对象。<br>（注：WAL，write ahead log，先写Log，再写内存，因为EditLog记录的是最新的HDFS客户端执行所有的写操作。如果后续真实写操作失败了，由于在真实写操作之前，操作就被写入EditLog中了，故EditLog中仍会有记录，我们不用担心后续client读不到相应的数据块，因为在第5步中DataNode收到块后会有一返回确认信息，若没写成功，发送端没收到确认信息，会一直重试，直到成功）</p></li><li><p>client端按128MB的块切分文件。</p></li><li><p>client将NameNode返回的分配的可写的DataNode列表和Data数据一同发送给最近的第一个DataNode节点，此后client端和NameNode分配的多个DataNode构成pipeline管道，client端向输出流对象中写数据。client每向第一个DataNode写入一个packet，这个packet便会直接在pipeline里传给第二个、第三个…DataNode。<br>（注：并不是写好一个块或一整个文件后才向后分发）</p></li><li><p>每个DataNode写完一个块后，会返回确认信息。<br>（注：并不是每写完一个packet后就返回确认信息，个人觉得因为packet中的每个chunk都携带校验信息，没必要每写一个就汇报一下，这样效率太慢。正确的做法是写完一个block块后，对校验信息进行汇总分析，就能得出是否有块写错的情况发生）</p></li><li><p>写完数据，关闭输输出流。</p></li><li><p>发送完成信号给NameNode。</p><p>（注：发送完成信号的时机取决于集群是强一致性还是最终一致性，强一致性则需要所有DataNode写完后才向NameNode汇报。最终一致性则其中任意一个DataNode写完后就能单独向NameNode汇报，HDFS一般情况下都是强调强一致性） </p></li></ul></li><li><p>HDFS如何实现高可用(HA)</p><ul><li>数据存储故障容错<ul><li>磁盘介质在存储过程中受环境或者老化影响,数据可能错乱</li><li>对于存储在 DataNode 上的数据块，计算并存储校验和（CheckSum)</li><li>读取数据的时候, 重新计算读取出来的数据校验和, 校验不正确抛出异常, 从其它DataNode上读取备份数据</li></ul></li><li>磁盘故障容错<ul><li>DataNode 监测到本机的某块磁盘损坏</li><li>将该块磁盘上存储的所有 BlockID 报告给 NameNode</li><li>NameNode 检查这些数据块在哪些DataNode上有备份,</li><li>通知相应DataNode, 将数据复制到其他服务器上</li></ul></li><li>DataNode故障容错<ul><li>通过心跳和NameNode保持通讯</li><li>超时未发送心跳, NameNode会认为这个DataNode已经宕机</li><li>NameNode查找这个DataNode上有哪些数据块, 以及这些数据在其它DataNode服务器上的存储情况</li><li>从其它DataNode服务器上复制数据</li></ul></li><li>NameNode故障容错<ul><li>主从热备 secondary namenode</li><li>zookeeper配合 master节点选举</li></ul></li></ul></li></ul><h3 id="Hadoop发行版的选择"><a href="#Hadoop发行版的选择" class="headerlink" title="Hadoop发行版的选择"></a>Hadoop发行版的选择</h3><ul><li>Apache Hadoop<ul><li>开源社区版</li><li>最新的Hadoop版本都是从Apache Hadoop发布的</li><li>Hadoop Hive Flume  版本不兼容的问题 jar包  spark scala  Java-&gt;.class-&gt;.jar -&gt;JVM</li></ul></li><li><p>CDH: Cloudera Distributed Hadoop</p><ul><li><p>Cloudera 在社区版的基础上做了一些修改</p></li><li><p><a href="http://archive.cloudera.com/cdh5/cdh/5/">http://archive.cloudera.com/cdh5/cdh/5/</a></p><p><img src="cdh.png" alt=""></p></li><li><p>hadoop-2.6.0-cdh-5.7.0 和 Flume<strong>*</strong>-cdh5.7.0 cdh版本一致 的各个组件配合是有不会有兼容性问题</p></li><li>CDH版本的这些组件 没有全部开源</li></ul></li><li>HDP: Hortonworks Data Platform</li></ul><h3 id="大数据产品与互联网产品结合"><a href="#大数据产品与互联网产品结合" class="headerlink" title="大数据产品与互联网产品结合"></a>大数据产品与互联网产品结合</h3><ul><li>分布式系统执行任务瓶颈: 延迟高 MapReduce 几分钟 Spark几秒钟</li><li>互联网产品要求<ul><li>毫秒级响应(1秒以内完成)</li><li>需要通过大数据实现 统计分析 数据挖掘 关联推荐 用户画像</li></ul></li><li>大数据平台<ul><li>整合网站应用和大数据系统之间的差异, 将应用产生的数据导入到大数据系统, 经过处理计算后再导出给应用程序使用</li></ul></li><li>互联网大数据平台架构:</li></ul><p><img src="bigdata_arcit.png" alt=""></p><ul><li>数据采集<ul><li>App/Web 产生的数据&amp;日志同步到大数据系统</li><li>数据库同步:Sqoop  日志同步:Flume 打点: Kafka</li><li>不同数据源产生的数据质量可能差别很大<ul><li>数据库 也许可以直接用</li><li>日志 爬虫 大量的清洗,转化处理 </li></ul></li></ul></li><li><p>数据处理</p><ul><li>大数据存储与计算的核心</li><li>数据同步后导入HDFS</li><li>MapReduce Hive Spark 读取数据进行计算 结果再保存到HDFS</li><li>MapReduce Hive Spark 离线计算, HDFS 离线存储<ul><li>离线计算通常针对(某一类别)全体数据, 比如 历史上所有订单</li><li>离线计算特点: 数据规模大, 运行时间长</li></ul></li><li>流式计算<ul><li>淘宝双11 每秒产生订单数 监控宣传</li><li>Storm(毫秒) SparkStreaming(秒)</li></ul></li></ul></li><li><p>数据输出与展示</p><ul><li>HDFS需要把数据导出交给应用程序, 让用户实时展示  ECharts<ul><li>淘宝卖家量子魔方</li></ul></li><li>给运营和决策层提供各种统计报告, 数据需要写入数据库<ul><li>很多运营管理人员, 上班后就会登陆后台数据系统</li></ul></li></ul></li><li>任务调度系统<ul><li>将上面三个部分整合起来</li></ul></li></ul><h3 id="大数据应用—数据分析"><a href="#大数据应用—数据分析" class="headerlink" title="大数据应用—数据分析"></a>大数据应用—数据分析</h3><ul><li><p>通过数据分析指标监控企业运营状态, 及时调整运营和产品策略,是大数据技术的关键价值之一</p></li><li><p>大数据平台(互联网企业)运行的绝大多数大数据计算都是关于数据分析的</p><ul><li>统计指标</li><li>关联分析,</li><li>汇总报告,</li></ul></li><li><p>运营数据是公司管理的基础</p><ul><li>了解公司目前发展的状况</li><li>数据驱动运营: 调节指标对公司进行管理</li></ul></li><li><p>运营数据的获取需要大数据平台的支持</p><ul><li>埋点采集数据</li><li>数据库,日志 三方采集数据</li><li>对数据清洗 转换 存储 </li><li>利用SQL进行数据统计 汇总 分析</li><li>得到需要的运营数据报告</li></ul></li><li><p>运营常用数据指标</p><ul><li><p>新增用户数  UG  user growth 用户增长</p><ul><li>产品增长性的关键指标</li><li>新增访问网站(新下载APP)的用户数</li></ul></li><li><p>用户留存率</p><ul><li>用户留存率 = 留存用户数 / 当期新增用户数</li><li>3日留存  5日留存 7日留存</li></ul></li><li><p>活跃用户数</p><ul><li>打开使用产品的用户</li><li>日活</li><li>月活</li><li>提升活跃是网站运营的重要目标</li></ul></li><li><p>PV Page View</p><ul><li>打开产品就算活跃</li><li>打开以后是否频繁操作就用PV衡量, 每次点击, 页面跳转都记一次PV</li></ul></li><li><p>GMV</p><ul><li>成交总金额(Gross Merchandise Volume) 电商网站统计营业额, 反应网站应收能力的重要指标</li><li>GMV相关的指标: 订单量 客单价</li></ul></li><li><p>转化率<br>转化率 = 有购买行为的用户数 / 总访问用户数</p></li></ul></li></ul><h3 id="数据分析案例"><a href="#数据分析案例" class="headerlink" title="数据分析案例"></a>数据分析案例</h3><ul><li><p>背景: 某电商网站, 垂直领域领头羊, 各项指标相对稳定</p></li><li><p>运营人员发现从 8 月 15 日开始，网站的订单量连续四天明显下跌</p></li><li><p>8 月 18 号早晨发现 8 月 17 号的订单量没有恢复正常，运营人员开始尝试寻找原因</p><ul><li>是否有负面报道被扩散</li><li>是否竞争对手在做活动</li><li>是否某类商品缺货</li><li>价格异常</li></ul></li><li><p>没有找到原因, 将问题交给数据分析团队</p><p><img src="case1.png" alt=""></p></li><li><p>数据分析师分析可能性</p><ul><li>新增用户出现问题</li><li>查看日活数据, 发现日活没有明显下降<ul><li>基本判断, 用户在访问网站的过程中,转化出了问题</li></ul></li></ul><p><img src="case2.png" alt=""></p></li><li><p>转化过程:</p><ul><li>打开APP</li><li>搜索关键词 浏览搜索结果列表</li><li>点击商品访问详情</li><li>有购买意向开始咨询</li><li>放入购物车</li><li>支付</li></ul><p><img src="case3.png" alt=""></p></li><li><p>订单活跃转化率 = 日订单量 / 打开用户数</p></li><li><p>搜索打开转化率 = 搜索用户数 / 打开用户数</p></li><li><p>有明显降幅的是咨询详情转化率</p><p><img src="case4.png" alt=""></p><ul><li>对咨询信息分类统计后发现，新用户的咨询量几乎为 0</li><li>于是将问题提交给技术部门调查，工程师查看 8 月 15 日当天发布记录,发现有消息队列SDK更新</li></ul></li></ul><p><strong>Hadoop企业应用案例之消费大数据</strong></p><p>亚马逊提前发货系统</p><p><strong>Hadoop企业案例之商业零售大数据</strong></p><p>智能推荐</p>]]></content>
      
      
      <categories>
          
          <category> Search / Advertisement / Recommendation / Causal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Recommendation System Algorithm</title>
      <link href="/2022/01/18/5.2-RS-Algorithm/"/>
      <url>/2022/01/18/5.2-RS-Algorithm/</url>
      
        <content type="html"><![CDATA[<p><strong>推荐系统学习笔记目录</strong></p><ol><li><a href="https://xfliu1998.github.io/2022/01/18/5.1-Recommendation-System-Introduction/">推荐系统介绍</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/">推荐算法</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.3-Hadoop/">Hadoop</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.4-Hive/">Hive &amp; HBase</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.5-Spark-core/">Spark core</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.6-Spark-SQL/">Spark SQL &amp; Spark streaming</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.7-RS-case/">推荐系统案例</a></li></ol><h2 id="Model-Based-协同过滤算法"><a href="#Model-Based-协同过滤算法" class="headerlink" title="Model-Based 协同过滤算法"></a>Model-Based 协同过滤算法</h2><p>随着机器学习技术的逐渐发展与完善，推荐系统也逐渐运用机器学习的思想来进行推荐。将机器学习应用到推荐系统中的方案真是不胜枚举。以下对Model-Based CF算法做一个大致的分类：</p><ul><li>基于分类算法、回归算法、聚类算法</li><li>基于矩阵分解的推荐</li><li>基于神经网络算法</li><li>基于图模型算法</li></ul><p>接下来我们重点学习以下几种应用较多的方案：</p><ul><li><strong>基于K最近邻的协同过滤推荐</strong></li><li><strong>基于回归模型的协同过滤推荐</strong></li><li><strong>基于矩阵分解的协同过滤推荐</strong></li></ul><h2 id="基于K最近邻的协同过滤推荐"><a href="#基于K最近邻的协同过滤推荐" class="headerlink" title="基于K最近邻的协同过滤推荐"></a>基于K最近邻的协同过滤推荐</h2><p>基于K最近邻的协同过滤推荐其实本质上就是MemoryBased CF，只不过在选取近邻的时候，加上K最近邻的限制。</p><p>这里我们直接根据MemoryBased CF的代码实现 修改以下地方</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CollaborativeFiltering</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    based = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, k=<span class="number">40</span>, rules=<span class="literal">None</span>, use_cache=<span class="literal">False</span>, standard=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param k: 取K个最近邻来进行预测</span></span><br><span class="line"><span class="string">        :param rules: 过滤规则，四选一，否则将抛异常：&quot;unhot&quot;, &quot;rated&quot;, [&quot;unhot&quot;,&quot;rated&quot;], None</span></span><br><span class="line"><span class="string">        :param use_cache: 相似度计算结果是否开启缓存</span></span><br><span class="line"><span class="string">        :param standard: 评分标准化方法，None表示不使用、mean表示均值中心化、zscore表示Z-Score标准化</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.k = <span class="number">40</span></span><br><span class="line">        self.rules = rules</span><br><span class="line">        self.use_cache = use_cache</span><br><span class="line">        self.standard = standard</span><br></pre></td></tr></table></figure><p>修改所有的选取近邻的地方的代码，根据相似度来选取K个最近邻</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">similar_users = self.similar[uid].drop([uid]).dropna().sort_values(ascending=<span class="literal">False</span>)[:self.k]</span><br><span class="line">similar_items = self.similar[iid].drop([iid]).dropna().sort_values(ascending=<span class="literal">False</span>)[:self.k]</span><br></pre></td></tr></table></figure><p>但由于原始数据较少，这里我们的KNN方法的效果会比纯粹的MemoryBasedCF要差</p><h2 id="基于回归模型的协同过滤推荐"><a href="#基于回归模型的协同过滤推荐" class="headerlink" title="基于回归模型的协同过滤推荐"></a>基于回归模型的协同过滤推荐</h2><p>如果我们将评分看作是一个连续的值而不是离散的值，那么就可以借助线性回归思想来预测目标用户对某物品的评分。其中一种实现策略被称为Baseline（基准预测）。</p><h3 id="Baseline：基准预测"><a href="#Baseline：基准预测" class="headerlink" title="Baseline：基准预测"></a>Baseline：基准预测</h3><p>Baseline设计思想基于以下的假设：</p><ul><li>有些用户的评分普遍高于其他用户，有些用户的评分普遍低于其他用户。比如有些用户天生愿意给别人好评，心慈手软，比较好说话，而有的人就比较苛刻，总是评分不超过3分（5分满分）</li><li>一些物品的评分普遍高于其他物品，一些物品的评分普遍低于其他物品。比如一些物品一被生产便决定了它的地位，有的比较受人们欢迎，有的则被人嫌弃。</li></ul><p>这个用户或物品普遍高于或低于平均值的差值，我们称为偏置(bias)</p><p><strong>Baseline目标：</strong></p><ul><li>找出每个用户普遍高于或低于他人的偏置值$b_u$</li><li>找出每件物品普遍高于或低于其他物品的偏置值$b_i$</li><li>我们的目标也就转化为寻找最优的$b_u$和$b_i$</li></ul><p>使用Baseline的算法思想预测评分的步骤如下：</p><ul><li>计算所有电影的平均评分$\mu$（即全局平均评分）</li><li>计算每个用户评分与平均评分$\mu$的偏置值$b_u$</li><li>计算每部电影所接受的评分与平均评分$\mu$的偏置值$b_i$</li><li>预测用户对电影的评分：<script type="math/tex; mode=display">\hat r_{ui} = b_{ui} = \mu + b_u + b_i</script></li></ul><p>举例：<br>​比如我们想通过Baseline来预测用户A对电影“阿甘正传”的评分，那么首先计算出整个评分数据集的平均评分$\mu$是3.5分；而用户A是一个比较苛刻的用户，他的评分比较严格，普遍比平均评分低0.5分，即用户A的偏置值$b_i$是-0.5；而电影“阿甘正传”是一部比较热门而且备受好评的电影，它的评分普遍比平均评分要高1.2分，那么电影“阿甘正传”的偏置值$b_i$是+1.2，因此就可以预测出用户A对电影“阿甘正传”的评分为：$3.5+(-0.5)+1.2$，也就是4.2分。</p><p>对于所有电影的平均评分$\mu$是直接能计算出的，因此问题在于要测出每个用户的$b_u$值和每部电影的$b_i$的值。对于线性回归问题，我们可以利用平方差构建损失函数如下：</p><script type="math/tex; mode=display">\begin{split}Cost &= \sum_{u,i\in R}(r_{ui}-\hat r_{ui})^2\\&=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2\end{split}</script><p>加入L2正则化：</p><script type="math/tex; mode=display">Cost=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)</script><p>公式解析：</p><ul><li>公式第一部分$ \sum<em>{u,i\in R}(r</em>{ui}-\mu-b_u-b_i)^2$是用来寻找与已知评分数据拟合最好的$b_u$和$b_i$</li><li>公式第二部分$\lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)​$是正则化项，用于避免过拟合现象</li></ul><p>对于最小过程的求解，我们一般采用<strong>随机梯度下降法</strong>或者<strong>交替最小二乘法</strong>来优化实现。</p><h3 id="方法一：随机梯度下降法优化"><a href="#方法一：随机梯度下降法优化" class="headerlink" title="方法一：随机梯度下降法优化"></a>方法一：随机梯度下降法优化</h3><p>使用随机梯度下降优化算法预测Baseline偏置值</p><h4 id="step-1：梯度下降法推导"><a href="#step-1：梯度下降法推导" class="headerlink" title="step 1：梯度下降法推导"></a>step 1：梯度下降法推导</h4><p>损失函数：</p><script type="math/tex; mode=display">\begin{split}&J(\theta)=Cost=f(b_u, b_i)\\\\&J(\theta)=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)\end{split}</script><p>梯度下降参数更新原始公式：</p><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha\cfrac{\partial }{\partial \theta_j}J(\theta)</script><p>梯度下降更新$b_u​$:</p><p>损失函数偏导推导：</p><script type="math/tex; mode=display">\begin{split}\cfrac{\partial}{\partial b_u} J(\theta)&=\cfrac{\partial}{\partial b_u} f(b_u, b_i)\\&=2\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)(-1) + 2\lambda{b_u}\\&=-2\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + 2\lambda*b_u\end{split}</script><p>$b_u$更新(因为alpha可以人为控制，所以2可以省略掉)：</p><script type="math/tex; mode=display">\begin{split}b_u&:=b_u - \alpha*(-\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + \lambda * b_u)\\&:=b_u + \alpha*(\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) - \lambda* b_u)\end{split}</script><p>同理可得，梯度下降更新$b_i​$:</p><script type="math/tex; mode=display">b_i:=b_i + \alpha*(\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) -\lambda*b_i)</script><h4 id="step-2：随机梯度下降"><a href="#step-2：随机梯度下降" class="headerlink" title="step 2：随机梯度下降"></a>step 2：随机梯度下降</h4><p>由于<strong>随机梯度下降法</strong>本质上利用<strong>每个样本的损失</strong>来更新参数，而不用每次求出全部的损失和，因此使用SGD时：</p><p>单样本损失值：</p><script type="math/tex; mode=display">error = r_{ui}-\hat r_{ui} = r_{ui}-(\mu + b_u + b_i) = r_{ui} - \mu - b_u - b_i</script><p>参数更新：</p><script type="math/tex; mode=display">b_u := b_u + \alpha *((r_{ui} - \mu - b_u - b_i) -\lambda * b_u):= b_u + \alpha *(error - \lambda * b_u) := b_i + \alpha *((r_{ui}-\mu -b_u-b_i) -\lambda * b_i):= b_i + \alpha *(error -\lambda * b_i)</script><h4 id="step-3：算法实现"><a href="#step-3：算法实现" class="headerlink" title="step 3：算法实现"></a>step 3：算法实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFBySGD</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, alpha, reg, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># 学习率</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="comment"># 正则参数</span></span><br><span class="line">        self.reg = reg</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                error = real_rating - (self.global_mean + bu[uid] + bi[iid])</span><br><span class="line"></span><br><span class="line">                bu[uid] += self.alpha * (error - self.reg * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (error - self.reg * bi[iid])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">3</span>), dtype=<span class="built_in">dict</span>(dtype))</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFBySGD(<span class="number">20</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;uid: &quot;</span>))</span><br><span class="line">        iid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;iid: &quot;</span>))</span><br><span class="line">        <span class="built_in">print</span>(bcf.predict(uid, iid))</span><br></pre></td></tr></table></figure><h4 id="step-4-准确性指标评估"><a href="#step-4-准确性指标评估" class="headerlink" title="step 4: 准确性指标评估"></a>step 4: 准确性指标评估</h4><ul><li>添加test方法，然后使用之前实现accuary方法计算准确性指标</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span>(<span class="params">data_path, x=<span class="number">0.8</span>, random=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    切分数据集， 这里为了保证用户数量保持不变，将每个用户的评分数据按比例进行拆分</span></span><br><span class="line"><span class="string">    :param data_path: 数据集路径</span></span><br><span class="line"><span class="string">    :param x: 训练集的比例，如x=0.8，则0.2是测试集</span></span><br><span class="line"><span class="string">    :param random: 是否随机切分，默认False</span></span><br><span class="line"><span class="string">    :return: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始切分数据集...&quot;</span>)</span><br><span class="line">    <span class="comment"># 设置要加载的数据字段的类型</span></span><br><span class="line">    dtype = &#123;<span class="string">&quot;userId&quot;</span>: np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32, <span class="string">&quot;rating&quot;</span>: np.float32&#125;</span><br><span class="line">    <span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">    ratings = pd.read_csv(data_path, dtype=dtype, usecols=<span class="built_in">range</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    testset_index = []</span><br><span class="line">    <span class="comment"># 为了保证每个用户在测试集和训练集都有数据，因此按userId聚合</span></span><br><span class="line">    <span class="keyword">for</span> uid <span class="keyword">in</span> ratings.groupby(<span class="string">&quot;userId&quot;</span>).<span class="built_in">any</span>().index:</span><br><span class="line">        user_rating_data = ratings.where(ratings[<span class="string">&quot;userId&quot;</span>]==uid).dropna()</span><br><span class="line">        <span class="keyword">if</span> random:</span><br><span class="line">            <span class="comment"># 因为不可变类型不能被 shuffle方法作用，所以需要强行转换为列表</span></span><br><span class="line">            index = <span class="built_in">list</span>(user_rating_data.index)</span><br><span class="line">            np.random.shuffle(index)    <span class="comment"># 打乱列表</span></span><br><span class="line">            _index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x)</span><br><span class="line">            testset_index += <span class="built_in">list</span>(index[_index:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 将每个用户的x比例的数据作为训练集，剩余的作为测试集</span></span><br><span class="line">            index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x)</span><br><span class="line">            testset_index += <span class="built_in">list</span>(user_rating_data.index.values[index:])</span><br><span class="line"></span><br><span class="line">    testset = ratings.loc[testset_index]</span><br><span class="line">    trainset = ratings.drop(testset_index)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;完成数据集切分...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuray</span>(<span class="params">predict_results, method=<span class="string">&quot;all&quot;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    准确性指标计算方法</span></span><br><span class="line"><span class="string">    :param predict_results: 预测结果，类型为容器，每个元素是一个包含uid,iid,real_rating,pred_rating的序列</span></span><br><span class="line"><span class="string">    :param method: 指标方法，类型为字符串，rmse或mae，否则返回两者rmse和mae</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse_mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse和mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse, mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>), <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> method.lower() == <span class="string">&quot;rmse&quot;</span>:</span><br><span class="line">        rmse(predict_results)</span><br><span class="line">    <span class="keyword">elif</span> method.lower() == <span class="string">&quot;mae&quot;</span>:</span><br><span class="line">        mae(predict_results)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> rmse_mae(predict_results)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFBySGD</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, alpha, reg, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># 学习率</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="comment"># 正则参数</span></span><br><span class="line">        self.reg = reg</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                error = real_rating - (self.global_mean + bu[uid] + bi[iid])</span><br><span class="line"></span><br><span class="line">                bu[uid] += self.alpha * (error - self.reg * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (error - self.reg * bi[iid])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;评分预测&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;无法预测用户&lt;&#123;uid&#125;&gt;对电影&lt;&#123;iid&#125;&gt;的评分，因为训练集中缺失&lt;&#123;iid&#125;&gt;的数据&quot;</span>.<span class="built_in">format</span>(uid=uid, iid=iid))</span><br><span class="line"></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self,testset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;预测测试集数据&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> testset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                pred_rating = self.predict(uid, iid)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(e)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">yield</span> uid, iid, real_rating, pred_rating</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    trainset, testset = data_split(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, random=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFBySGD(<span class="number">20</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(trainset)</span><br><span class="line"></span><br><span class="line">    pred_results = bcf.test(testset)</span><br><span class="line"></span><br><span class="line">    rmse, mae = accuray(pred_results)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;rmse: &quot;</span>, rmse, <span class="string">&quot;mae: &quot;</span>, mae)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="方法二：交替最小二乘法优化"><a href="#方法二：交替最小二乘法优化" class="headerlink" title="方法二：交替最小二乘法优化"></a>方法二：交替最小二乘法优化</h3><p>使用交替最小二乘法优化算法预测Baseline偏置值</p><h4 id="step-1-交替最小二乘法推导"><a href="#step-1-交替最小二乘法推导" class="headerlink" title="step 1: 交替最小二乘法推导"></a>step 1: 交替最小二乘法推导</h4><p>最小二乘法和梯度下降法一样，可以用于求极值。</p><p><strong>最小二乘法思想：对损失函数求偏导，然后再使偏导为0</strong></p><p>同样，损失函数：</p><script type="math/tex; mode=display">J(\theta)=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)</script><p>对损失函数求偏导：</p><script type="math/tex; mode=display">\cfrac{\partial}{\partial b_u} f(b_u, b_i) =-2 \sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + 2\lambda * b_u</script><p>令偏导为0，则可得：</p><script type="math/tex; mode=display">\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) = \lambda* b_u\\\sum_{u,i\in R}(r_{ui}-\mu-b_i) = \sum_{u,i\in R} b_u+\lambda * b_u</script><p>为了简化公式，这里令$\sum_{u,i\in R} b_u \approx |R(u)|*b_u$，即直接假设每一项的偏置都相等，可得：</p><script type="math/tex; mode=display">b_u := \cfrac {\sum_{u,i\in R}(r_{ui}-\mu-b_i)}{\lambda_1 + |R(u)|}</script><p>其中$|R(u)|$表示用户$u​$的有过评分数量</p><p>同理可得：</p><script type="math/tex; mode=display">b_i := \cfrac {\sum_{u,i\in R}(r_{ui}-\mu-b_u)}{\lambda_2 + |R(i)|}</script><p>其中$|R(i)|$表示物品$i​$收到的评分数量</p><p>$b_u$和$b_i​$分别属于用户和物品的偏置，因此他们的正则参数可以分别设置两个独立的参数</p><h4 id="step-2-交替最小二乘法应用"><a href="#step-2-交替最小二乘法应用" class="headerlink" title="step 2: 交替最小二乘法应用"></a>step 2: 交替最小二乘法应用</h4><p>通过最小二乘推导，我们最终分别得到了$b_u$和$b_i$的表达式，但他们的表达式中却又各自包含对方，因此这里我们将利用一种叫交替最小二乘的方法来计算他们的值：    </p><ul><li>计算其中一项，先固定其他未知参数，即看作其他未知参数为已知</li><li>如求$b_u$时，将$b_i$看作是已知；求$b_i$时，将$b_u$看作是已知；如此反复交替，不断更新二者的值，求得最终的结果。这就是<strong>交替最小二乘法（ALS）</strong></li></ul><h4 id="step-3-算法实现"><a href="#step-3-算法实现" class="headerlink" title="step 3: 算法实现"></a>step 3: 算法实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFByALS</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, reg_bu, reg_bi, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># bu的正则参数</span></span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        <span class="comment"># bi的正则参数</span></span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.als()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">als</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> iid, uids, ratings <span class="keyword">in</span> self.items_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _<span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> uid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(uids, ratings):</span><br><span class="line">                    _<span class="built_in">sum</span> += rating - self.global_mean - bu[uid]</span><br><span class="line">                bi[iid] = _<span class="built_in">sum</span> / (self.reg_bi + <span class="built_in">len</span>(uids))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> uid, iids, ratings <span class="keyword">in</span> self.users_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _<span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> iid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(iids, ratings):</span><br><span class="line">                    _<span class="built_in">sum</span> += rating - self.global_mean - bi[iid]</span><br><span class="line">                bu[uid] = _<span class="built_in">sum</span> / (self.reg_bu + <span class="built_in">len</span>(iids))</span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">3</span>), dtype=<span class="built_in">dict</span>(dtype))</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFByALS(<span class="number">20</span>, <span class="number">25</span>, <span class="number">15</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;uid: &quot;</span>))</span><br><span class="line">        iid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;iid: &quot;</span>))</span><br><span class="line">        <span class="built_in">print</span>(bcf.predict(uid, iid))</span><br></pre></td></tr></table></figure><h4 id="step-4-准确性指标评估-1"><a href="#step-4-准确性指标评估-1" class="headerlink" title="step 4: 准确性指标评估"></a>step 4: 准确性指标评估</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span>(<span class="params">data_path, x=<span class="number">0.8</span>, random=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    切分数据集， 这里为了保证用户数量保持不变，将每个用户的评分数据按比例进行拆分</span></span><br><span class="line"><span class="string">    :param data_path: 数据集路径</span></span><br><span class="line"><span class="string">    :param x: 训练集的比例，如x=0.8，则0.2是测试集</span></span><br><span class="line"><span class="string">    :param random: 是否随机切分，默认False</span></span><br><span class="line"><span class="string">    :return: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始切分数据集...&quot;</span>)</span><br><span class="line">    <span class="comment"># 设置要加载的数据字段的类型</span></span><br><span class="line">    dtype = &#123;<span class="string">&quot;userId&quot;</span>: np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32, <span class="string">&quot;rating&quot;</span>: np.float32&#125;</span><br><span class="line">    <span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">    ratings = pd.read_csv(data_path, dtype=dtype, usecols=<span class="built_in">range</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    testset_index = []</span><br><span class="line">    <span class="comment"># 为了保证每个用户在测试集和训练集都有数据，因此按userId聚合</span></span><br><span class="line">    <span class="keyword">for</span> uid <span class="keyword">in</span> ratings.groupby(<span class="string">&quot;userId&quot;</span>).<span class="built_in">any</span>().index:</span><br><span class="line">        user_rating_data = ratings.where(ratings[<span class="string">&quot;userId&quot;</span>]==uid).dropna()</span><br><span class="line">        <span class="keyword">if</span> random:</span><br><span class="line">            <span class="comment"># 因为不可变类型不能被 shuffle方法作用，所以需要强行转换为列表</span></span><br><span class="line">            index = <span class="built_in">list</span>(user_rating_data.index)</span><br><span class="line">            np.random.shuffle(index)    <span class="comment"># 打乱列表</span></span><br><span class="line">            _index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x)</span><br><span class="line">            testset_index += <span class="built_in">list</span>(index[_index:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 将每个用户的x比例的数据作为训练集，剩余的作为测试集</span></span><br><span class="line">            index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x)</span><br><span class="line">            testset_index += <span class="built_in">list</span>(user_rating_data.index.values[index:])</span><br><span class="line"></span><br><span class="line">    testset = ratings.loc[testset_index]</span><br><span class="line">    trainset = ratings.drop(testset_index)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;完成数据集切分...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuray</span>(<span class="params">predict_results, method=<span class="string">&quot;all&quot;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    准确性指标计算方法</span></span><br><span class="line"><span class="string">    :param predict_results: 预测结果，类型为容器，每个元素是一个包含uid,iid,real_rating,pred_rating的序列</span></span><br><span class="line"><span class="string">    :param method: 指标方法，类型为字符串，rmse或mae，否则返回两者rmse和mae</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse_mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse和mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse, mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>), <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> method.lower() == <span class="string">&quot;rmse&quot;</span>:</span><br><span class="line">        rmse(predict_results)</span><br><span class="line">    <span class="keyword">elif</span> method.lower() == <span class="string">&quot;mae&quot;</span>:</span><br><span class="line">        mae(predict_results)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> rmse_mae(predict_results)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFByALS</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, reg_bu, reg_bi, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># bu的正则参数</span></span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        <span class="comment"># bi的正则参数</span></span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.als()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">als</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> iid, uids, ratings <span class="keyword">in</span> self.items_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _<span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> uid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(uids, ratings):</span><br><span class="line">                    _<span class="built_in">sum</span> += rating - self.global_mean - bu[uid]</span><br><span class="line">                bi[iid] = _<span class="built_in">sum</span> / (self.reg_bi + <span class="built_in">len</span>(uids))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> uid, iids, ratings <span class="keyword">in</span> self.users_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _<span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> iid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(iids, ratings):</span><br><span class="line">                    _<span class="built_in">sum</span> += rating - self.global_mean - bi[iid]</span><br><span class="line">                bu[uid] = _<span class="built_in">sum</span> / (self.reg_bu + <span class="built_in">len</span>(iids))</span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;评分预测&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;无法预测用户&lt;&#123;uid&#125;&gt;对电影&lt;&#123;iid&#125;&gt;的评分，因为训练集中缺失&lt;&#123;iid&#125;&gt;的数据&quot;</span>.<span class="built_in">format</span>(uid=uid, iid=iid))</span><br><span class="line"></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self,testset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;预测测试集数据&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> testset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                pred_rating = self.predict(uid, iid)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(e)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">yield</span> uid, iid, real_rating, pred_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    trainset, testset = data_split(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, random=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFByALS(<span class="number">20</span>, <span class="number">25</span>, <span class="number">15</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(trainset)</span><br><span class="line"></span><br><span class="line">    pred_results = bcf.test(testset)</span><br><span class="line"></span><br><span class="line">    rmse, mae = accuray(pred_results)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;rmse: &quot;</span>, rmse, <span class="string">&quot;mae: &quot;</span>, mae)</span><br></pre></td></tr></table></figure><h2 id="基于矩阵分解的CF算法"><a href="#基于矩阵分解的CF算法" class="headerlink" title="基于矩阵分解的CF算法"></a>基于矩阵分解的CF算法</h2><h3 id="矩阵分解发展史"><a href="#矩阵分解发展史" class="headerlink" title="矩阵分解发展史"></a>矩阵分解发展史</h3><p><strong>Traditional SVD:</strong></p><p>通常SVD矩阵分解指的是SVD（奇异值）分解技术，在这我们姑且将其命名为Traditional SVD（传统并经典）其公式如下：</p><p><img src="矩阵分解1.jpg" alt="img"></p><p>Traditional SVD分解的形式为3个矩阵相乘，中间矩阵为奇异值矩阵。如果想运用SVD分解的话，有一个前提是要求矩阵是稠密的，即矩阵里的元素要非空，否则就不能运用SVD分解。</p><p>很显然我们的数据其实绝大多数情况下都是稀疏的，因此如果要使用Traditional SVD，一般的做法是先用均值或者其他统计学方法来填充矩阵，然后再运用Traditional SVD分解降维，但这样做明显对数据的原始性造成一定影响。</p><p><strong>FunkSVD（LFM）</strong></p><p>刚才提到的Traditional SVD首先需要填充矩阵，然后再进行分解降维，同时存在计算复杂度高的问题，因为要分解成3个矩阵，所以后来提出了Funk SVD的方法，它不在将矩阵分解为3个矩阵，而是分解为2个用户-隐含特征，项目-隐含特征的矩阵，Funk SVD也被称为最原始的LFM模型</p><p><img src="矩阵分解2.jpg" alt="img"></p><p>借鉴线性回归的思想，通过最小化观察数据的平方来寻求最优的用户和项目的隐含向量表示。同时为了避免过度拟合（Overfitting）观测数据，又提出了带有L2正则项的FunkSVD，上公式：</p><p><img src="矩阵分解3.jpg" alt="img"></p><p>以上两种最优化函数都可以通过梯度下降或者随机梯度下降法来寻求最优解。</p><p><strong>BiasSVD:</strong></p><p>在FunkSVD提出来之后，出现了很多变形版本，其中一个相对成功的方法是BiasSVD，顾名思义，即带有偏置项的SVD分解：</p><p><img src="矩阵分解4.jpg" alt="img"></p><p>它基于的假设和Baseline基准预测是一样的，但这里将Baseline的偏置引入到了矩阵分解中</p><p><strong>SVD++:</strong></p><p>人们后来又提出了改进的BiasSVD，被称为SVD++，该算法是在BiasSVD的基础上添加了用户的隐式反馈信息：</p><p><img src="矩阵分解5.jpg" alt="img"></p><p>显示反馈指的用户的评分这样的行为，隐式反馈指用户的浏览记录、购买记录、收听记录等。</p><p>SVD++是基于这样的假设：在BiasSVD基础上，认为用户对于项目的历史浏览记录、购买记录、收听记录等可以从侧面反映用户的偏好。</p><h2 id="基于矩阵分解的CF算法实现（二）：BiasSvd"><a href="#基于矩阵分解的CF算法实现（二）：BiasSvd" class="headerlink" title="基于矩阵分解的CF算法实现（二）：BiasSvd"></a>基于矩阵分解的CF算法实现（二）：BiasSvd</h2><p>BiasSvd其实就是前面提到的Funk SVD矩阵分解基础上加上了偏置项。</p><h3 id="BiasSvd"><a href="#BiasSvd" class="headerlink" title="BiasSvd"></a>BiasSvd</h3><p>利用BiasSvd预测用户对物品的评分，$k$表示隐含特征数量：</p><script type="math/tex; mode=display">\hat r_{ui} = \mu + b_u + b_i + \vec {p_{uk}} \cdot \vec {q_{ki}}= \mu + b_u + b_i + \sum_{k=1}^k p_{uk} q_{ik}</script><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>同样对于评分预测我们利用平方差来构建损失函数：</p><script type="math/tex; mode=display">Cost = \sum_{u,i \in R} (r_{ui}-\hat r_{ui})^2= \sum_{u,i \in R} (r_{ui}- \mu - b_u - b_i - \sum_{k=1}^k p_{uk} q_{ik})^2</script><p>加入L2正则化：</p><script type="math/tex; mode=display">Cost = \sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)</script><p>对损失函数求偏导：</p><script type="math/tex; mode=display">\begin{split}\cfrac {\partial}{\partial p_{uk}}Cost &= \cfrac {\partial}{\partial p_{uk}}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}\\\\\cfrac {\partial}{\partial q_{ik}}Cost &= \cfrac {\partial}{\partial q_{ik}}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-p_{uk}) + 2\lambda q_{ik}\end{split}</script><script type="math/tex; mode=display">\begin{split}\cfrac {\partial}{\partial b_u}Cost &= \cfrac {\partial}{\partial b_u}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-1) + 2\lambda b_u\\\\\cfrac {\partial}{\partial b_i}Cost &= \cfrac {\partial}{\partial b_i}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-1) + 2\lambda b_i\end{split}</script><h3 id="随机梯度下降法优化"><a href="#随机梯度下降法优化" class="headerlink" title="随机梯度下降法优化"></a>随机梯度下降法优化</h3><p>梯度下降更新参数$p_{uk}$：</p><script type="math/tex; mode=display">\begin{split}p_{uk}&:=p_{uk} - \alpha\cfrac {\partial}{\partial p_{uk}}Cost\\&:=p_{uk}-\alpha [2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}]\\&:=p_{uk}+\alpha [\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda p_{uk}]\end{split}</script><p> 同理：</p><script type="math/tex; mode=display">\begin{split}q_{ik}&:=q_{ik} + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda q_{ik}]\end{split}</script><script type="math/tex; mode=display">b_u:=b_u + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda b_u]</script><script type="math/tex; mode=display">b_i:=b_i + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda b_i]</script><p><strong>随机梯度下降：</strong></p><script type="math/tex; mode=display">\begin{split}&p_{uk}:=p_{uk}+\alpha [(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda_1 p_{uk}]\\&q_{ik}:=q_{ik} + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda_2 q_{ik}]\end{split}</script><script type="math/tex; mode=display">b_u:=b_u + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda_3 b_u]</script><script type="math/tex; mode=display">b_i:=b_i + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda_4 b_i]</script><p>由于P矩阵和Q矩阵是两个不同的矩阵，通常分别采取不同的正则参数，如$\lambda_1$和$\lambda_2$</p><p><strong>算法实现</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">BiasSvd Model</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BiasSvd</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, alpha, reg_p, reg_q, reg_bu, reg_bi, number_LatentFactors=<span class="number">10</span>, number_epochs=<span class="number">10</span>, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        self.alpha = alpha <span class="comment"># 学习率</span></span><br><span class="line">        self.reg_p = reg_p</span><br><span class="line">        self.reg_q = reg_q</span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        self.number_LatentFactors = number_LatentFactors  <span class="comment"># 隐式类别数量</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        fit dataset</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        self.dataset = pd.DataFrame(dataset)</span><br><span class="line"></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        self.globalMean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line"></span><br><span class="line">        self.P, self.Q, self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_matrix</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        初始化P和Q矩阵，同时为设置0，1之间的随机值作为初始值</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># User-LF</span></span><br><span class="line">        P = <span class="built_in">dict</span>(<span class="built_in">zip</span>(</span><br><span class="line">            self.users_ratings.index,</span><br><span class="line">            np.random.rand(<span class="built_in">len</span>(self.users_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="comment"># Item-LF</span></span><br><span class="line">        Q = <span class="built_in">dict</span>(<span class="built_in">zip</span>(</span><br><span class="line">            self.items_ratings.index,</span><br><span class="line">            np.random.rand(<span class="built_in">len</span>(self.items_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="keyword">return</span> P, Q</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        使用随机梯度下降，优化结果</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        P, Q = self._init_matrix()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;iter%d&quot;</span>%i)</span><br><span class="line">            error_list = []</span><br><span class="line">            <span class="keyword">for</span> uid, iid, r_ui <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                v_pu = P[uid]</span><br><span class="line">                v_qi = Q[iid]</span><br><span class="line">                err = np.float32(r_ui - self.globalMean - bu[uid] - bi[iid] - np.dot(v_pu, v_qi))</span><br><span class="line"></span><br><span class="line">                v_pu += self.alpha * (err * v_qi - self.reg_p * v_pu)</span><br><span class="line">                v_qi += self.alpha * (err * v_pu - self.reg_q * v_qi)</span><br><span class="line">                </span><br><span class="line">                P[uid] = v_pu </span><br><span class="line">                Q[iid] = v_qi</span><br><span class="line">                </span><br><span class="line">                bu[uid] += self.alpha * (err - self.reg_bu * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (err - self.reg_bi * bi[iid])</span><br><span class="line"></span><br><span class="line">                error_list.append(err ** <span class="number">2</span>)</span><br><span class="line">            <span class="built_in">print</span>(np.sqrt(np.mean(error_list)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> P, Q, bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> uid <span class="keyword">not</span> <span class="keyword">in</span> self.users_ratings.index <span class="keyword">or</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">return</span> self.globalMean</span><br><span class="line"></span><br><span class="line">        p_u = self.P[uid]</span><br><span class="line">        q_i = self.Q[iid]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.globalMean + self.bu[uid] + self.bi[iid] + np.dot(p_u, q_i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">3</span>), dtype=<span class="built_in">dict</span>(dtype))</span><br><span class="line"></span><br><span class="line">    bsvd = BiasSvd(<span class="number">0.02</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">    bsvd.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = <span class="built_in">input</span>(<span class="string">&quot;uid: &quot;</span>)</span><br><span class="line">        iid = <span class="built_in">input</span>(<span class="string">&quot;iid: &quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(bsvd.predict(<span class="built_in">int</span>(uid), <span class="built_in">int</span>(iid)))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="基于内容的推荐算法（Content-Based）"><a href="#基于内容的推荐算法（Content-Based）" class="headerlink" title="基于内容的推荐算法（Content-Based）"></a>基于内容的推荐算法（Content-Based）</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>基于内容的推荐方法是非常直接的，它以物品的内容描述信息为依据来做出的推荐，本质上是基于对物品和用户自身的特征或属性的直接分析和计算。</p><p>例如，假设已知电影A是一部喜剧，而恰巧我们得知某个用户喜欢看喜剧电影，那么我们基于这样的已知信息，就可以将电影A推荐给该用户。</p><h3 id="基于内容的推荐实现步骤"><a href="#基于内容的推荐实现步骤" class="headerlink" title="基于内容的推荐实现步骤"></a>基于内容的推荐实现步骤</h3><ul><li><p><strong>画像构建</strong>。顾名思义，画像就是刻画物品或用户的特征。本质上就是给用户或物品贴标签。</p><ul><li><p><strong>物品画像</strong>：例如给电影《战狼2》贴标签，可以有哪些？</p><p><img src="基于内容推荐1.png" alt=""></p><p>“动作”、”吴京”、”吴刚”、”张翰”、”大陆电影”、”国产”、”爱国”、”军事”等等一系列标签是不是都可以贴上</p></li><li><p><strong>用户画像</strong>：例如已知用户的观影历史是：”《战狼1》”、”《战狼2》”、”《建党伟业》”、”《建军大业》”、”《建国大业》”、”《红海行动》”、”《速度与激情1-8》”等，我们是不是就可以分析出该用户的一些兴趣特征如：”爱国”、”战争”、”赛车”、”动作”、”军事”、”吴京”、”韩三平”等标签。</p></li></ul></li></ul><h4 id="问题：物品的标签来自哪儿？"><a href="#问题：物品的标签来自哪儿？" class="headerlink" title="问题：物品的标签来自哪儿？"></a>问题：物品的标签来自哪儿？</h4><ol><li>PGC    物品画像—冷启动<ul><li>物品自带的属性（物品一产生就具备的）：如电影的标题、导演、演员、类型等等</li><li>服务提供方设定的属性（服务提供方为物品附加的属性）：如短视频话题、微博话题（平台拟定）</li><li>其他渠道：如爬虫</li></ul></li><li>UGC    冷启动问题<ul><li>用户在享受服务过程中提供的物品的属性：如用户评论内容，微博话题（用户拟定）</li></ul></li></ol><p>根据PGC内容构建的物品画像的可以解决物品的冷启动问题</p><h4 id="基于内容推荐的算法流程："><a href="#基于内容推荐的算法流程：" class="headerlink" title="基于内容推荐的算法流程："></a>基于内容推荐的算法流程：</h4><ul><li>根据PGC/UGC内容构建物品画像</li><li>根据用户行为记录生成用户画像</li><li>根据用户画像从物品中寻找最匹配的TOP-N物品进行推荐</li></ul><h4 id="物品冷启动处理："><a href="#物品冷启动处理：" class="headerlink" title="物品冷启动处理："></a>物品冷启动处理：</h4><ul><li>根据PGC内容构建物品画像</li><li>利用物品画像计算物品间两两相似情况</li><li>为每个物品产生TOP-N最相似的物品进行相关推荐：如与该商品相似的商品有哪些？与该文章相似文章有哪些？</li></ul><h2 id="基于内容的电影推荐：物品画像"><a href="#基于内容的电影推荐：物品画像" class="headerlink" title="基于内容的电影推荐：物品画像"></a>基于内容的电影推荐：物品画像</h2><p>物品画像构建步骤：</p><ul><li>利用tags.csv中每部电影的标签作为电影的候选关键词</li><li>利用TF·IDF计算每部电影的标签的tfidf值，选取TOP-N个关键词作为电影画像标签</li><li>将电影的分类词直接作为每部电影的画像标签</li></ul><h2 id="基于TF-IDF的特征提取技术"><a href="#基于TF-IDF的特征提取技术" class="headerlink" title="基于TF-IDF的特征提取技术"></a>基于TF-IDF的特征提取技术</h2><p>前面提到，物品画像的特征标签主要都是指的如电影的导演、演员、图书的作者、出版社等结构话的数据，也就是他们的特征提取，尤其是体征向量的计算是比较简单的，如直接给作品的分类定义0或者1的状态。</p><p>但另外一些特征，比如电影的内容简介、电影的影评、图书的摘要等文本数据，这些被称为非结构化数据，首先他们本应该也属于物品的一个特征标签，但是这样的特征标签进行量化时，也就是计算它的特征向量时是很难去定义的。</p><p>因此这时就需要借助一些自然语言处理、信息检索等技术，将如用户的文本评论或其他文本内容信息的非结构化数据进行量化处理，从而实现更加完善的物品画像/用户画像。</p><p>TF-IDF算法便是其中一种在自然语言处理领域中应用比较广泛的一种算法。可用来提取目标文档中，并得到关键词用于计算对于目标文档的权重，并将这些权重组合到一起得到特征向量。</p><h3 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h3><p>TF-IDF自然语言处理领域中计算文档中词或短语的权值的方法，是<strong>词频</strong>（Term Frequency，TF）和逆转文档频率（Inverse Document Frequency，IDF）的乘积。TF指的是某一个给定的词语在该文件中出现的次数。这个数字通常会被正规化，以防止它偏向长的文件（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否）。IDF是一个词语普遍重要性的度量，某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。</p><p>TF-IDF算法基于一个这样的假设：若一个词语在目标文档中出现的频率高而在其他文档中出现的频率低，那么这个词语就可以用来区分出目标文档。这个假设需要掌握的有两点：</p><ul><li>在本文档出现的频率高；</li><li>在其他文档出现的频率低。</li></ul><p>因此，TF-IDF算法的计算可以分为词频（Term Frequency，TF）和逆转文档频率（Inverse Document Frequency，IDF）两部分，由TF和IDF的乘积来设置文档词语的权重。</p><p>TF指的是一个词语在文档中的出现频率。假设文档集包含的文档数为$N​$，文档集中包含关键词$k<em>i​$的文档数为$n_i​$，$f</em>{ij}​$表示关键词$k<em>i​$在文档$d_j​$中出现的次数，$f</em>{dj}​$表示文档$d<em>j​$中出现的词语总数，$k_i​$在文档dj中的词频$TF</em>{ij}​$定义为：<script type="math/tex">TF_{ij}=\frac {f_{ij}}{f_{dj}}​</script><br>这个数字通常会被正规化，以防止它偏向长的文件（指同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否）。</p><p>IDF是一个词语普遍重要性的度量。表示某一词语在整个文档集中出现的频率，由它计算的结果取对数得到关键词$k_i​$的逆文档频率$IDF_i​$：<script type="math/tex">IDF_i=log\frac {N}{n_i}​</script></p><p>由TF和IDF计算词语的权重为：<script type="math/tex">w_{ij}=TF_{ij}</script></p><script type="math/tex; mode=display">IDF_{i}=\frac {f_{ij}}{f_{dj}}</script><script type="math/tex; mode=display">log\frac {N}{n_i}</script><p><strong>结论：TF-IDF与词语在文档中的出现次数成正比，与该词在整个文档集中的出现次数成反比。</strong></p><p><strong>用途：在目标文档中，提取关键词(特征标签)的方法就是将该文档所有词语的TF-IDF计算出来并进行对比，取其中TF-IDF值最大的k个数组成目标文档的特征向量用以表示文档。</strong></p><p>注意：文档中存在的停用词（Stop Words），如“是”、“的”之类的，对于文档的中心思想表达没有意义的词，在分词时需要先过滤掉再计算其他词语的TF-IDF值。</p><h3 id="算法举例"><a href="#算法举例" class="headerlink" title="算法举例"></a>算法举例</h3><p>对于计算影评的TF-IDF，以电影“加勒比海盗：黑珍珠号的诅咒”为例，假设它总共有1000篇影评，其中一篇影评的总词语数为200，其中出现最频繁的词语为“海盗”、“船长”、“自由”，分别是20、15、10次，并且这3个词在所有影评中被提及的次数分别为1000、500、100，就这3个词语作为关键词的顺序计算如下。</p><ol><li><p>将影评中出现的停用词过滤掉，计算其他词语的词频。以出现最多的三个词为例进行计算如下：</p><ul><li>“海盗”出现的词频为20/200＝0.1</li><li>“船长”出现的词频为15/200=0.075</li><li>“自由”出现的词频为10/200=0.05；</li></ul></li><li><p>计算词语的逆文档频率如下：</p><ul><li>“海盗”的IDF为：log(1000/1000)=0</li><li>“船长”的IDF为：log(1000/500)=0.3<br>“自由”的IDF为：log(1000/100)=1</li></ul></li><li>由1和2计算的结果求出词语的TF-IDF结果，“海盗”为0，“船长”为0.0225，“自由”为0.05。</li></ol><p>通过对比可得，该篇影评的关键词排序应为：“自由”、“船长”、“海盗”。把这些词语的TF-IDF值作为它们的权重按照对应的顺序依次排列，就得到这篇影评的特征向量，我们就用这个向量来代表这篇影评，向量中每一个维度的分量大小对应这个属性的重要性。</p><p>将总的影评集中所有的影评向量与特定的系数相乘求和，得到这部电影的综合影评向量，与电影的基本属性结合构建视频的物品画像，同理构建用户画像，可采用多种方法计算物品画像和用户画像之间的相似度，为用户做出推荐。</p><h3 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">- 利用tags.csv中每部电影的标签作为电影的候选关键词</span></span><br><span class="line"><span class="string">- 利用TF·IDF计算每部电影的标签的tfidf值，选取TOP-N个关键词作为电影画像标签</span></span><br><span class="line"><span class="string">- 并将电影的分类词直接作为每部电影的画像标签</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie_dataset</span>():</span></span><br><span class="line">    <span class="comment"># 加载基于所有电影的标签</span></span><br><span class="line">    <span class="comment"># all-tags.csv来自ml-latest数据集中</span></span><br><span class="line">    <span class="comment"># 由于ml-latest-small中标签数据太多，因此借助其来扩充</span></span><br><span class="line">    _tags = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/all-tags.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>)).dropna()</span><br><span class="line">    tags = _tags.groupby(<span class="string">&quot;movieId&quot;</span>).agg(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载电影列表数据集</span></span><br><span class="line">    movies = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/movies.csv&quot;</span>, index_col=<span class="string">&quot;movieId&quot;</span>)</span><br><span class="line">    <span class="comment"># 将类别词分开</span></span><br><span class="line">    movies[<span class="string">&quot;genres&quot;</span>] = movies[<span class="string">&quot;genres&quot;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment"># 为每部电影匹配对应的标签数据，如果没有将会是NAN</span></span><br><span class="line">    movies_index = <span class="built_in">set</span>(movies.index) &amp; <span class="built_in">set</span>(tags.index)</span><br><span class="line">    new_tags = tags.loc[<span class="built_in">list</span>(movies_index)]</span><br><span class="line">    ret = movies.join(new_tags)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建电影数据集，包含电影Id、电影名称、类别、标签四个字段</span></span><br><span class="line">    <span class="comment"># 如果电影没有标签数据，那么就替换为空列表</span></span><br><span class="line">    <span class="comment"># map(fun,可迭代对象)</span></span><br><span class="line">    movie_dataset = pd.DataFrame(</span><br><span class="line">        <span class="built_in">map</span>(</span><br><span class="line">            <span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], x[<span class="number">2</span>]+x[<span class="number">3</span>]) <span class="keyword">if</span> x[<span class="number">3</span>] <span class="keyword">is</span> <span class="keyword">not</span> np.nan <span class="keyword">else</span> (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], []), ret.itertuples())</span><br><span class="line">        , columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;genres&quot;</span>,<span class="string">&quot;tags&quot;</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    movie_dataset.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_dataset</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line"><span class="built_in">print</span>(movie_dataset)</span><br></pre></td></tr></table></figure><h3 id="基于TF·IDF提取TOP-N关键词，构建电影画像"><a href="#基于TF·IDF提取TOP-N关键词，构建电影画像" class="headerlink" title="基于TF·IDF提取TOP-N关键词，构建电影画像"></a>基于TF·IDF提取TOP-N关键词，构建电影画像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset: </span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    <span class="comment"># 根据数据集建立词袋，并统计词频，将所有词放入一个词典，使用索引进行获取</span></span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    <span class="comment"># 根据将每条数据，返回对应的词索引和词频</span></span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line">    <span class="comment"># 训练TF-IDF模型，即计算TF-IDF值</span></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    movie_profile = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i, mid <span class="keyword">in</span> <span class="built_in">enumerate</span>(movie_dataset.index):</span><br><span class="line">        <span class="comment"># 根据每条数据返回，向量</span></span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        <span class="comment"># 按照TF-IDF值得到top-n的关键词</span></span><br><span class="line">        movie_tags = <span class="built_in">sorted</span>(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        <span class="comment"># 根据关键词提取对应的名称</span></span><br><span class="line">        movie_profile[mid] = <span class="built_in">dict</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">pprint(create_movie_profile(movie_dataset))</span><br></pre></td></tr></table></figure><h3 id="完善画像关键词"><a href="#完善画像关键词" class="headerlink" title="完善画像关键词"></a>完善画像关键词</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    <span class="comment"># 根据数据集建立词袋，并统计词频，将所有词放入一个词典，使用索引进行获取</span></span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    <span class="comment"># 根据将每条数据，返回对应的词索引和词频</span></span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line">    <span class="comment"># 训练TF-IDF模型，即计算TF-IDF值</span></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    _movie_profile = []</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(movie_dataset.itertuples()):</span><br><span class="line">        mid = data[<span class="number">0</span>]</span><br><span class="line">        title = data[<span class="number">1</span>]</span><br><span class="line">        genres = data[<span class="number">2</span>]</span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        movie_tags = <span class="built_in">sorted</span>(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        topN_tags_weights = <span class="built_in">dict</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line">        <span class="comment"># 将类别词的添加进去，并设置权重值为1.0</span></span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> genres:</span><br><span class="line">            topN_tags_weights[g] = <span class="number">1.0</span></span><br><span class="line">        topN_tags = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> topN_tags_weights.items()]</span><br><span class="line">        _movie_profile.append((mid, title, topN_tags, topN_tags_weights))</span><br><span class="line"></span><br><span class="line">    movie_profile = pd.DataFrame(_movie_profile, columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;profile&quot;</span>, <span class="string">&quot;weights&quot;</span>])</span><br><span class="line">    movie_profile.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">pprint(create_movie_profile(movie_dataset))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为了根据指定关键词迅速匹配到对应的电影，因此需要对物品画像的标签词，建立<strong>倒排索引</strong></p><p><strong>倒排索引介绍</strong></p><p>通常数据存储数据，都是以物品的ID作为索引，去提取物品的其他信息数据<br>而倒排索引就是用物品的其他数据作为索引，去提取它们对应的物品的ID列表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">建立tag-物品的倒排索引</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_inverted_table</span>(<span class="params">movie_profile</span>):</span></span><br><span class="line">    inverted_table = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> mid, weights <span class="keyword">in</span> movie_profile[<span class="string">&quot;weights&quot;</span>].iteritems():</span><br><span class="line">        <span class="keyword">for</span> tag, weight <span class="keyword">in</span> weights.items():</span><br><span class="line">            <span class="comment">#到inverted_table dict 用tag作为Key去取值 如果取不到就返回[]</span></span><br><span class="line">            _ = inverted_table.get(tag, [])</span><br><span class="line">            _.append((mid, weight))</span><br><span class="line">            inverted_table.setdefault(tag, _)</span><br><span class="line">    <span class="keyword">return</span> inverted_table</span><br><span class="line"></span><br><span class="line">inverted_table = create_inverted_table(movie_profile)</span><br><span class="line">pprint(inverted_table)</span><br></pre></td></tr></table></figure><h2 id="基于内容的电影推荐：用户画像"><a href="#基于内容的电影推荐：用户画像" class="headerlink" title="基于内容的电影推荐：用户画像"></a>基于内容的电影推荐：用户画像</h2><p>用户画像构建步骤：</p><ul><li>根据用户的评分历史，结合物品画像，将有观影记录的电影的画像标签作为初始标签反打到用户身上</li><li>通过对用户观影标签的次数进行统计，计算用户的每个初始标签的权重值，排序后选取TOP-N作为用户最终的画像标签</li></ul><h3 id="用户画像建立"><a href="#用户画像建立" class="headerlink" title="用户画像建立"></a>用户画像建立</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">user profile画像建立：</span></span><br><span class="line"><span class="string">1. 提取用户观看列表</span></span><br><span class="line"><span class="string">2. 根据观看列表和物品画像为用户匹配关键词，并统计词频</span></span><br><span class="line"><span class="string">3. 根据词频排序，最多保留TOP-k个词，这里K设为100，作为用户的标签</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_user_profile</span>():</span></span><br><span class="line">    watch_record = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">2</span>), dtype=&#123;<span class="string">&quot;userId&quot;</span>:np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32&#125;)</span><br><span class="line"></span><br><span class="line">    watch_record = watch_record.groupby(<span class="string">&quot;userId&quot;</span>).agg(<span class="built_in">list</span>)</span><br><span class="line">    <span class="comment"># print(watch_record)</span></span><br><span class="line"></span><br><span class="line">    movie_dataset = get_movie_dataset()</span><br><span class="line">    movie_profile = create_movie_profile(movie_dataset)</span><br><span class="line"></span><br><span class="line">    user_profile = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> uid, mids <span class="keyword">in</span> watch_record.itertuples():</span><br><span class="line">        record_movie_prifole = movie_profile.loc[<span class="built_in">list</span>(mids)]</span><br><span class="line">        counter = collections.Counter(reduce(<span class="keyword">lambda</span> x, y: <span class="built_in">list</span>(x)+<span class="built_in">list</span>(y), record_movie_prifole[<span class="string">&quot;profile&quot;</span>].values))</span><br><span class="line">        <span class="comment"># 兴趣词</span></span><br><span class="line">        interest_words = counter.most_common(<span class="number">50</span>)</span><br><span class="line">        maxcount = interest_words[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">        interest_words = [(w,<span class="built_in">round</span>(c/maxcount, <span class="number">4</span>)) <span class="keyword">for</span> w,c <span class="keyword">in</span> interest_words]</span><br><span class="line">        user_profile[uid] = interest_words</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> user_profile</span><br><span class="line"></span><br><span class="line">user_profile = create_user_profile()</span><br><span class="line">pprint(user_profile)</span><br></pre></td></tr></table></figure><h2 id="基于内容的电影推荐：为用户产生TOP-N推荐结果"><a href="#基于内容的电影推荐：为用户产生TOP-N推荐结果" class="headerlink" title="基于内容的电影推荐：为用户产生TOP-N推荐结果"></a>基于内容的电影推荐：为用户产生TOP-N推荐结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">user_profile = create_user_profile()</span><br><span class="line"></span><br><span class="line">watch_record = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">2</span>),dtype=&#123;<span class="string">&quot;userId&quot;</span>: np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32&#125;)</span><br><span class="line"></span><br><span class="line">watch_record = watch_record.groupby(<span class="string">&quot;userId&quot;</span>).agg(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> uid, interest_words <span class="keyword">in</span> user_profile.items():</span><br><span class="line">    result_table = &#123;&#125; <span class="comment"># 电影id:[0.2,0.5,0.7]</span></span><br><span class="line">    <span class="keyword">for</span> interest_word, interest_weight <span class="keyword">in</span> interest_words:</span><br><span class="line">        related_movies = inverted_table[interest_word]</span><br><span class="line">        <span class="keyword">for</span> mid, related_weight <span class="keyword">in</span> related_movies:</span><br><span class="line">            _ = result_table.get(mid, [])</span><br><span class="line">            _.append(interest_weight)    <span class="comment"># 只考虑用户的兴趣程度</span></span><br><span class="line">            <span class="comment"># _.append(related_weight)    # 只考虑兴趣词与电影的关联程度</span></span><br><span class="line">            <span class="comment"># _.append(interest_weight*related_weight)    # 二者都考虑</span></span><br><span class="line">            result_table.setdefault(mid, _)</span><br><span class="line"></span><br><span class="line">    rs_result = <span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x[<span class="number">0</span>], <span class="built_in">sum</span>(x[<span class="number">1</span>])), result_table.items())</span><br><span class="line">    rs_result = <span class="built_in">sorted</span>(rs_result, key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">100</span>]</span><br><span class="line">    <span class="built_in">print</span>(uid)</span><br><span class="line">    pprint(rs_result)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 历史数据  ==&gt;  历史兴趣程度 ==&gt;  历史推荐结果       离线推荐    离线计算</span></span><br><span class="line">    <span class="comment"># 在线推荐 ===&gt;    娱乐(王思聪)   ===&gt;   我 ==&gt;  王思聪 100%  </span></span><br><span class="line">    <span class="comment"># 近线：最近1天、3天、7天           实时计算</span></span><br></pre></td></tr></table></figure><h2 id="基于内容的电影推荐：物品冷启动处理"><a href="#基于内容的电影推荐：物品冷启动处理" class="headerlink" title="基于内容的电影推荐：物品冷启动处理"></a>基于内容的电影推荐：物品冷启动处理</h2><p>利用Word2Vec可以计算电影所有标签词之间的关系程度，可用于计算电影之间的相似度</p><h3 id="word2vec原理简介"><a href="#word2vec原理简介" class="headerlink" title="word2vec原理简介"></a>word2vec原理简介</h3><ul><li><p>word2vec是google在2013年开源的一个NLP(Natural Language Processing自然语言处理) 工具，它的特点是将所有的词向量化，这样词与词之间就可以定量的去度量他们之间的关系，挖掘词之间的联系。</p></li><li><p>one-hot vector VS. word vector</p><ul><li>用向量来表示词并不是word2vec的首创</li><li>最早的词向量是很冗长的，它使用是词向量维度大小为整个词汇表的大小，对于每个具体的词汇表中的词，将对应的位置置为1。</li><li>比如下面5个词组成词汇表，词”Queen”的序号为2， 那么它的词向量就是(0,1,0,0,0)同样的道理，词”Woman”的词向量就是(0,0,0,1,0)。</li></ul><p><img src="word2vec1.png" alt=""></p></li><li><p>one hot vector的问题</p><ul><li>如果词汇表非常大，如达到万级别，这样每个词都用万维的向量来表示浪费内存。这样的向量除了一个位置是1，其余位置全部为0，表达效率低(稀疏)，需要降低词向量的维度</li><li>难以发现词之间的关系，以及难以捕捉句法（结构）和语义（意思）之间的关系</li><li>Dristributed representation可以解决One hot representation的问题，它的思路是通过训练，将每个词都映射到一个较短的词向量上来。所有的这些词向量就构成了向量空间，进而可以用普通的统计学的方法来研究词与词之间的关系。这个较短的词向量维度一般需要我们在训练时指定。</li><li>比如下图我们将词汇表里的词用”Royalty(王位)”,”Masculinity(男性气质)”, “Femininity(女性气质)”和”Age”4个维度来表示，King这个词对应的词向量可能是(0.99,0.99,0.05,0.7)。当然在实际情况中，我们并不一定能对词向量的每个维度做一个很好的解释。</li></ul><p><img src="word2vec2.png" alt=""></p></li><li><p>有了用Dristributed representation表示的较短的词向量，就可以较容易的分析词之间的关系，比如将词的维度降维到2维，用下图的词向量表示我们的词时，发现：$\vec{King} - \vec{Man} + \vec{Woman} = \vec{Queen}​$ </p><p><img src="word2vec3.png" alt=""></p></li><li><p>什么是word vector（词向量）</p><ul><li>每个单词被表征为多维的浮点数，每一维的浮点数的数值大小表示了它与另一个单词之间的“距离”，表征的结果就是语义相近的词被映射到相近的集合空间上，好处是这样单词之间就是可以计算的：</li></ul><table>    <th>    <td> animal </td>    <td> pet </td>    </th><tr> <td> dog </td> <td> -0.4 </td> <td> 0.02 </td></tr><tr> <td> lion </td> <td> 0.2 </td> <td> 0.35 </td></tr></table><p>animal那一列表示的就是左边的词与animal这个概念的”距离“</p></li></ul><h3 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h3><h4 id="两个重要模型：CBOW和Skip-Gram"><a href="#两个重要模型：CBOW和Skip-Gram" class="headerlink" title="两个重要模型：CBOW和Skip-Gram"></a>两个重要模型：CBOW和Skip-Gram</h4><ul><li><p>介绍：CBOW把一个词从词窗剔除。在CBOW下给定<em>n</em>词围绕着词<em>w</em>，word2vec预测一个句子中其中一个缺漏的词<em>c</em>，即以概率$p(c|w)$来表示。相反地，Skip-gram给定词窗中的文本，预测当前的词$p(w|c)​$。</p></li><li><p>原理：拥有差不多上下文的两个单词的意思往往是相近的</p></li><li><p><strong>Continuous Bag-of-Words(CBOW)</strong> 连续词袋向量</p><ul><li><p>功能：通过上下文预测当前词出现的概率</p></li><li><p>原理分析</p><p>假设文本如下：“the florid <u>prose of</u> <strong>the</strong> <u>nineteenth century.</u>”</p><p>想象有个滑动窗口，中间的词是关键词，两边为相等长度的文本来帮助分析。文本的长度为7，就得到了7个one-hot向量，作为神经网络的输入向量，训练目标是：最大化在给定前后文本情况下输出正确关键词的概率，比如给定(“prose”,”of”,”nineteenth”,”century”)的情况下，要最大化输出”the”的概率，用公式表示就是：<br>P(“the”|(“prose”,”of”,”nineteenth”,”century”))</p></li><li><p>特性</p><ul><li>hidden layer只是将权重求和，传递到下一层，是线性的</li></ul></li></ul></li><li><p><strong>Continuous Skip-gram</strong></p><ul><li>功能：根据当前词预测上下文</li><li>原理分析<ul><li>和CBOW相反，则我们要求的概率就变为P(Context(w)|w)</li></ul></li></ul></li></ul><ul><li><strong>总结：</strong>word2vec算法可以计算出每个词语的一个词向量，我们可以用它来表示该词的语义层面的含义</li></ul><h3 id="Word2Vec使用"><a href="#Word2Vec使用" class="headerlink" title="Word2Vec使用"></a>Word2Vec使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie_dataset</span>():</span></span><br><span class="line">    <span class="comment"># 加载基于所有电影的标签</span></span><br><span class="line">    <span class="comment"># all-tags.csv来自ml-latest数据集中</span></span><br><span class="line">    <span class="comment"># 由于ml-latest-small中标签数据太多，因此借助其来扩充</span></span><br><span class="line">    _tags = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/all-tags.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>)).dropna()</span><br><span class="line">    tags = _tags.groupby(<span class="string">&quot;movieId&quot;</span>).agg(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载电影列表数据集</span></span><br><span class="line">    movies = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/movies.csv&quot;</span>, index_col=<span class="string">&quot;movieId&quot;</span>)</span><br><span class="line">    <span class="comment"># 将类别词分开</span></span><br><span class="line">    movies[<span class="string">&quot;genres&quot;</span>] = movies[<span class="string">&quot;genres&quot;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment"># 为每部电影匹配对应的标签数据，如果没有将会是NAN</span></span><br><span class="line">    movies_index = <span class="built_in">set</span>(movies.index) &amp; <span class="built_in">set</span>(tags.index)</span><br><span class="line">    new_tags = tags.loc[<span class="built_in">list</span>(movies_index)]</span><br><span class="line">    ret = movies.join(new_tags)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建电影数据集，包含电影Id、电影名称、类别、标签四个字段</span></span><br><span class="line">    <span class="comment"># 如果电影没有标签数据，那么就替换为空列表</span></span><br><span class="line">    movie_dataset = pd.DataFrame(</span><br><span class="line">        <span class="built_in">map</span>(</span><br><span class="line">            <span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], x[<span class="number">2</span>]+x[<span class="number">3</span>]) <span class="keyword">if</span> x[<span class="number">3</span>] <span class="keyword">is</span> <span class="keyword">not</span> np.nan <span class="keyword">else</span> (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], []), ret.itertuples())</span><br><span class="line">        , columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;genres&quot;</span>,<span class="string">&quot;tags&quot;</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    movie_dataset.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line"></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    _movie_profile = []</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(movie_dataset.itertuples()):</span><br><span class="line">        mid = data[<span class="number">0</span>]</span><br><span class="line">        title = data[<span class="number">1</span>]</span><br><span class="line">        genres = data[<span class="number">2</span>]</span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        movie_tags = <span class="built_in">sorted</span>(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        topN_tags_weights = <span class="built_in">dict</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line">        <span class="comment"># 将类别词的添加进去，并设置权重值为1.0</span></span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> genres:</span><br><span class="line">            topN_tags_weights[g] = <span class="number">1.0</span></span><br><span class="line">        topN_tags = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> topN_tags_weights.items()]</span><br><span class="line">        _movie_profile.append((mid, title, topN_tags, topN_tags_weights))</span><br><span class="line"></span><br><span class="line">    movie_profile = pd.DataFrame(_movie_profile, columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;profile&quot;</span>, <span class="string">&quot;weights&quot;</span>])</span><br><span class="line">    movie_profile.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">movie_profile = create_movie_profile(movie_dataset)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> gensim, logging</span><br><span class="line"></span><br><span class="line">logging.basicConfig(<span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s : %(levelname)s : %(message)s&#x27;</span>, level=logging.INFO)</span><br><span class="line"></span><br><span class="line">sentences = <span class="built_in">list</span>(movie_profile[<span class="string">&quot;profile&quot;</span>].values)</span><br><span class="line"></span><br><span class="line">model = gensim.models.Word2Vec(sentences, window=<span class="number">3</span>, min_count=<span class="number">1</span>, <span class="built_in">iter</span>=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    words = <span class="built_in">input</span>(<span class="string">&quot;words: &quot;</span>)  <span class="comment"># action</span></span><br><span class="line">    ret = model.wv.most_similar(positive=[words], topn=<span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(ret)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><p>Doc2Vec是建立在Word2Vec上的，用于直接计算以文档为单位的文档向量，这里我们将一部电影的所有标签词，作为整个文档，这样可以计算出每部电影的向量，通过计算向量之间的距离，来判断用于计算电影之间的相似程度。</p><p>这样可以解决物品冷启动问题</p><h3 id="Doc2Vec使用"><a href="#Doc2Vec使用" class="headerlink" title="Doc2Vec使用"></a>Doc2Vec使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie_dataset</span>():</span></span><br><span class="line">    <span class="comment"># 加载基于所有电影的标签</span></span><br><span class="line">    <span class="comment"># all-tags.csv来自ml-latest数据集中</span></span><br><span class="line">    <span class="comment"># 由于ml-latest-small中标签数据太多，因此借助其来扩充</span></span><br><span class="line">    _tags = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/all-tags.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>)).dropna()</span><br><span class="line">    tags = _tags.groupby(<span class="string">&quot;movieId&quot;</span>).agg(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载电影列表数据集</span></span><br><span class="line">    movies = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/movies.csv&quot;</span>, index_col=<span class="string">&quot;movieId&quot;</span>)</span><br><span class="line">    <span class="comment"># 将类别词分开</span></span><br><span class="line">    movies[<span class="string">&quot;genres&quot;</span>] = movies[<span class="string">&quot;genres&quot;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment"># 为每部电影匹配对应的标签数据，如果没有将会是NAN</span></span><br><span class="line">    movies_index = <span class="built_in">set</span>(movies.index) &amp; <span class="built_in">set</span>(tags.index)</span><br><span class="line">    new_tags = tags.loc[<span class="built_in">list</span>(movies_index)]</span><br><span class="line">    ret = movies.join(new_tags)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建电影数据集，包含电影Id、电影名称、类别、标签四个字段</span></span><br><span class="line">    <span class="comment"># 如果电影没有标签数据，那么就替换为空列表</span></span><br><span class="line">    movie_dataset = pd.DataFrame(</span><br><span class="line">        <span class="built_in">map</span>(</span><br><span class="line">            <span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], x[<span class="number">2</span>]+x[<span class="number">3</span>]) <span class="keyword">if</span> x[<span class="number">3</span>] <span class="keyword">is</span> <span class="keyword">not</span> np.nan <span class="keyword">else</span> (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], []), ret.itertuples())</span><br><span class="line">        , columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;genres&quot;</span>,<span class="string">&quot;tags&quot;</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    movie_dataset.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line"></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    _movie_profile = []</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(movie_dataset.itertuples()):</span><br><span class="line">        mid = data[<span class="number">0</span>]</span><br><span class="line">        title = data[<span class="number">1</span>]</span><br><span class="line">        genres = data[<span class="number">2</span>]</span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        movie_tags = <span class="built_in">sorted</span>(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        topN_tags_weights = <span class="built_in">dict</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line">        <span class="comment"># 将类别词的添加进去，并设置权重值为1.0</span></span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> genres:</span><br><span class="line">            topN_tags_weights[g] = <span class="number">1.0</span></span><br><span class="line">        topN_tags = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> topN_tags_weights.items()]</span><br><span class="line">        _movie_profile.append((mid, title, topN_tags, topN_tags_weights))</span><br><span class="line"></span><br><span class="line">    movie_profile = pd.DataFrame(_movie_profile, columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;profile&quot;</span>, <span class="string">&quot;weights&quot;</span>])</span><br><span class="line">    movie_profile.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">movie_profile = create_movie_profile(movie_dataset)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> gensim, logging</span><br><span class="line"><span class="keyword">from</span> gensim.models.doc2vec <span class="keyword">import</span> Doc2Vec, TaggedDocument</span><br><span class="line"></span><br><span class="line">logging.basicConfig(<span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s : %(levelname)s : %(message)s&#x27;</span>, level=logging.INFO)</span><br><span class="line"></span><br><span class="line">documents = [TaggedDocument(words, [movie_id]) <span class="keyword">for</span> movie_id, words <span class="keyword">in</span> movie_profile[<span class="string">&quot;profile&quot;</span>].iteritems()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型并保存</span></span><br><span class="line">model = Doc2Vec(documents, vector_size=<span class="number">100</span>, window=<span class="number">3</span>, min_count=<span class="number">1</span>, workers=<span class="number">4</span>, epochs=<span class="number">20</span>)</span><br><span class="line"><span class="keyword">from</span> gensim.test.utils <span class="keyword">import</span> get_tmpfile</span><br><span class="line">fname = get_tmpfile(<span class="string">&quot;my_doc2vec_model&quot;</span>)</span><br><span class="line">model.save(fname)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">words = movie_profile[<span class="string">&quot;profile&quot;</span>].loc[<span class="number">6</span>]</span><br><span class="line"><span class="built_in">print</span>(words)</span><br><span class="line">inferred_vector = model.infer_vector(words)</span><br><span class="line">sims = model.docvecs.most_similar([inferred_vector], topn=<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(sims)</span><br></pre></td></tr></table></figure><h2 id="基于关联规则的推荐"><a href="#基于关联规则的推荐" class="headerlink" title="基于关联规则的推荐"></a>基于关联规则的推荐</h2><p>基于关联规则的推荐思想类似基于物品的协同过滤推荐</p><p><strong>“啤酒与尿布”</strong></p><p>关联分析中最有名的例子就是“啤酒与尿布”。</p><p>据报道，在美国沃尔玛超市会发现一个很有趣的现象：货架上啤酒与尿布竟然放在一起售卖，这看似两者毫不相关的东西，为什么会放在一起售卖呢？</p><p>原来，在美国，妇女们经常会嘱咐她们的丈夫下班以后给孩子买一点尿布回来，而丈夫在买完尿布后，大都会顺手买回一瓶自己爱喝的啤酒（由此看出美国人爱喝酒）。商家通过对一年多的原始交易记录进行详细的分析，发现了这对神奇的组合。于是就毫不犹豫地将尿布与啤酒摆放在一起售卖，通过它们的关联性，互相促进销售。“啤酒与尿布”的故事一度是营销界的神话。</p><p>那么问题来了，<strong>商家是如何发现啤酒与尿布两者之间的关联性呢？</strong></p><p>这里我们可以使用数据挖掘中的关联规则挖掘技术，目的就是为了找出两个对象（如X,Y）之间的关联性。一旦找出二者关联性，那么就可以根据它来进行推荐。</p><p><strong>基于关联规则的推荐</strong></p><p>一般我们可以找出用户购买的所有物品数据里频繁出现的项集活序列，来做频繁集挖掘，找到满足支持度阈值的关联物品的频繁N项集或者序列。如果用户购买了频繁N项集或者序列里的部分物品，那么我们可以将频繁项集或序列里的其他物品按一定的评分准则推荐给用户，这个评分准则可以包括支持度，置信度和提升度等。</p><p>常用的关联推荐算法有Apriori，FP-Growth</p><h3 id="关联分析"><a href="#关联分析" class="headerlink" title="关联分析"></a>关联分析</h3><p>关联分析是一种在大规模数据集中寻找有趣关系的任务。 这些关系可以有两种形式:</p><ul><li>频繁项集（frequent item sets）是指经常出现在一块的物品的集合。</li><li>关联规则（associational rules）是暗示两种物品之间可能存在很强的关系。</li></ul><p>从大规模数据集中寻找物品间的隐含关系被称作关联分析(association analysis)或者关联规则学习（association rule learning）</p><h3 id="关联性衡量指标"><a href="#关联性衡量指标" class="headerlink" title="关联性衡量指标"></a>关联性衡量指标</h3><p>假设我们下图所示的一份数据集</p><p><img src="关联规则数据示例.png" alt=""></p><p>确定X， Y的关联性，需要用两个指标来衡量：</p><ul><li><p><strong>支持度（support）</strong></p><p>支持度是针对项集而言的</p><p>项集的支持度被定义为数据集中包含该项集的记录所占的比例</p><p>那么项集<code>&#123;豆奶&#125;</code>的支持度就是4/5，那么项集<code>&#123;豆奶, 莴苣&#125;</code>的支持度就是3/5</p></li><li><p><strong>置信度（confidence）</strong></p><p>置信度也成为可信度，是针对一个关联规则而言的，如<code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>，表示<code>&#123;豆奶&#125;</code>之于<code>&#123;莴苣&#125;</code>的关联程度（注意：<code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>不等价于<code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>）</p><p><code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>的置信度 = 支持度(<code>&#123;豆奶, 莴苣&#125;</code>)/支持度(<code>&#123;豆奶&#125;</code>)，即3/4</p><p><code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>的置信度 = 支持度(<code>&#123;豆奶, 莴苣&#125;</code>)/支持度(<code>&#123;莴苣&#125;</code>)，即3/4</p><p>注意：这里他们俩的置信度相等纯属巧合</p></li></ul><p>如果不考虑关联规则的支持度和置信度，那么在数据库中会存在着无穷多的关联规则。因此我们为了提取出真正的频繁项集和关联规则，必须指定一个最小支持度阈值和最小置信度阈值，因为对于支持度和置信度太低的关联规则基本没有什么使用价值。</p><ul><li><p><strong>最小支持度</strong>：</p><p>它表示了一组物品集在统计意义上需要满足的最低程度</p></li><li><p><strong>最小可信度</strong></p><p>它反映了关联规则的最低可靠程度</p></li></ul><p><strong>同时满足最小可信度阈值和最小支持度阈值的关联规则被称为强关联规则。</strong>比如啤酒与尿布。</p><p>比如这里，如果我们假设最小支持度阈值为50%，最小可信度阈值为70%，那么这里<code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>和<code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>都属于符合条件的两条关联规则，分别表示：</p><ul><li>同时购买豆奶和莴苣的顾客占全部顾客的60%</li><li><code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>：在购买豆奶的用户中，有75%的顾客会购买莴苣</li><li><code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>：在购买莴苣的用户中，有75%的顾客会购买豆奶</li></ul><h2 id="关键规则挖掘算法（一）Apriori算法"><a href="#关键规则挖掘算法（一）Apriori算法" class="headerlink" title="关键规则挖掘算法（一）Apriori算法"></a>关键规则挖掘算法（一）Apriori算法</h2><h3 id="Apriori算法原理"><a href="#Apriori算法原理" class="headerlink" title="Apriori算法原理"></a>Apriori算法原理</h3><p>Apriori算法是著名的关联规则挖掘算法。</p><p>假如我们在经营一家商品种类并不多的杂货店，我们对哪些经常在一起被购买的商品非常感兴趣。我们只有四种商品：商品0、商品1、商品2、商品3。那么所有可能被一起购买的商品组合都有哪些？这些商品组合可能著有一种商品，比如商品0，也可能包括两种、三种或所有四种商品。但我们不关心某人买了两件商品0以及四件商品2的情况，只关心他购买了一种或多种商品。</p><p>下图显示了物品之间所有可能的组合：</p><ul><li>图中使用物品的编号0来表示物品0本身。</li><li>图中从上往下的第一个集合是$\phi$，表示空集或不包含任何物品的集合。</li><li>物品集合之间的连线表明两个或者更多集合可以组合形成一个更大的集合。</li></ul><p><img src="apriori1.png" alt=""></p><p><strong>目标：</strong>我们的目标是找到经常在一起购买的物品集合。我们使用集合的支持度来度量其出现的频率。</p><blockquote><p>一个集合的支持度是指有多少比例的交易记录包含该集合。</p></blockquote><p><strong>问题：</strong> 如何对一个给定的集合，比如<code>&#123;0，3&#125;</code>，来计算其支持度？</p><ul><li>我们可以遍历毎条记录并检查该记录包含0和3，如果记录确实同时包含这两项，那么就增加总计数值。在扫描完所有数据之后，使用统计得到的总数除以总的交易记录数，就可以得到支持度。</li></ul><p><strong>注意：</strong>上述过程和结果只是针对单个集合{0,3}。要获得每种可能集合的支持度就需要多次重复上述过程。我们可以数一下图中的集合数目，会发现即使对于仅有4种物品的集合，也需要遍历数据15次。而随着物品数目的增加遍历次数会急剧增长。对于包含N种物品的数据集共有$2^{N-1}$种项集组合。而且实际上出售10 000或更多种物品的商店并不少见。即使只出售100种商品的商店也会有$1.26 * 10^{30}$种可能的项集组合。这样的运算量，其实即使是对于现在的很多计算机而言，也需要很长的时间才能完成运算。</p><p><strong>Apriori算法的原理可以帮我们减少可能感兴趣的项集，降低所需的计算时间。</strong></p><p>Apriori算法原理：</p><ul><li><p>如果某个项集是频繁的，那么它的所有子集都是频繁的，例如，假设<code>&#123;1,2&#125;</code>是频繁的，那么<code>&#123;1&#125;</code>和<code>&#123;2&#125;</code>也一定是频繁的。</p></li><li><p>将这个原理取反会发现：如果一个项集是非频繁的，那么它的所有超集也是非频繁的</p><p>如下图中，已知项集<code>&#123;2,3&#125;</code>是非频繁的，那么可立即判断出项集<code>&#123;0,2,3&#125;</code>、<code>&#123;1,2,3&#125;</code>、<code>&#123;0,1,2,3&#125;</code>都是非频繁的，因此这些项集的支持度也就不需要再计算</p><p><img src="apriori2.png" alt=""></p></li></ul><p><strong>Apriori算法的一般过程：</strong></p><ol><li>收集数据：使用任意方法。</li><li>准备数据：任何数据类型都可以，因为我们只保存集合。</li><li>分析数据：使用任意方法。</li><li>训练算法：使用Apriori算法来找到频繁项集。</li><li>测试算法：不需要测试过程。</li><li>使用算法：用于发现频繁项集以及物品之间的关联规则。</li></ol><h3 id="Apriori算法实现"><a href="#Apriori算法实现" class="headerlink" title="Apriori算法实现"></a>Apriori算法实现</h3><p><img src="挖掘频繁项集.png" alt=""></p><p>实现数据集扫描方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    加载数据集</span></span><br><span class="line"><span class="string">    :return: dataset</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> [[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">2</span>, <span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createC1</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    创建C1候选项集，C1是所有大小为1的候选项集的列表</span></span><br><span class="line"><span class="string">    :param dataSet:</span></span><br><span class="line"><span class="string">    :return: C1</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># C1是所有大小为1的候选项集的列表</span></span><br><span class="line">    C1 = []</span><br><span class="line">    <span class="comment"># 遍历数据集，逐个添加到C1中</span></span><br><span class="line">    <span class="keyword">for</span> record <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> record:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> [item] <span class="keyword">in</span> C1:</span><br><span class="line">                C1.append([item])</span><br><span class="line">    C1.sort()</span><br><span class="line">    <span class="comment"># 使用不变集合存储C1内部的每个候选项集，那么就可以将其作为字典的Key，如果是list类型不能直接作为字典的Key</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">frozenset</span>, C1))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanDataset</span>(<span class="params">dataset, ck, minSupport</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    扫描数据集，判断频繁项集</span></span><br><span class="line"><span class="string">    :param dataset:</span></span><br><span class="line"><span class="string">    :param ck: ck是所有大小为k的候选项集的列表</span></span><br><span class="line"><span class="string">    :param minSupport: 设置的最小支持度阈值</span></span><br><span class="line"><span class="string">    :return: 符合条件的项集、每个项集的支持度</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 存储项集的出现次数</span></span><br><span class="line">    selectedSetCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> record <span class="keyword">in</span> dataset:    <span class="comment"># 遍历每一条记录</span></span><br><span class="line">        <span class="keyword">for</span> candidateSet <span class="keyword">in</span> ck:</span><br><span class="line">            <span class="comment"># 判断当前候选项集是不是当前记录的子集</span></span><br><span class="line">            <span class="keyword">if</span> candidateSet.issubset(record):    </span><br><span class="line">                <span class="keyword">if</span> candidateSet <span class="keyword">not</span> <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">                    selectedSetCount[candidateSet] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    selectedSetCount[candidateSet] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 计算总条目数</span></span><br><span class="line">    numItems = <span class="built_in">float</span>(<span class="built_in">len</span>(dataset))</span><br><span class="line">    <span class="comment"># 存储符合条件的项集</span></span><br><span class="line">    retList = []</span><br><span class="line">    <span class="comment"># 存储项集的支持度</span></span><br><span class="line">    supportData = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">        <span class="comment"># 计算支持度</span></span><br><span class="line">        support = selectedSetCount[key] / numItems</span><br><span class="line">        <span class="keyword">if</span> support &gt;= minSupport:</span><br><span class="line">            retList.insert(<span class="number">0</span>, key)</span><br><span class="line">        supportData[key] = support</span><br><span class="line">    <span class="keyword">return</span> retList, supportData</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    c1 = createC1(dataset)</span><br><span class="line">    pprint(scanDataset(dataset, c1, <span class="number">0.5</span>))</span><br></pre></td></tr></table></figure><p>实现频繁项集挖掘：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createCk</span>(<span class="params">lastFrequentItems, k</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    根据k-1项的频繁项集列表生成k项的候选项集</span></span><br><span class="line"><span class="string">    :param lastFrequentItems: k-1项的频繁项集</span></span><br><span class="line"><span class="string">    :param k: 第k个项集</span></span><br><span class="line"><span class="string">    :return: ck项集</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    retList = []</span><br><span class="line">    lenLk = <span class="built_in">len</span>(lastFrequentItems)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lenLk):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, lenLk):</span><br><span class="line">            <span class="comment"># 因为新构建的ck项集，特征是任意一个k项集其中k-1项都必须存在于lastCk中</span></span><br><span class="line">            <span class="comment"># 通过以下判断，能筛选出那些符合要求的k-1项</span></span><br><span class="line">            L1 = <span class="built_in">list</span>(lastFrequentItems[i])[:k-<span class="number">2</span>]; L2 = <span class="built_in">list</span>(lastFrequentItems[j])[:k-<span class="number">2</span>]</span><br><span class="line">            L1.sort(); L2.sort()</span><br><span class="line">            <span class="keyword">if</span> L1==L2:</span><br><span class="line">                retList.append(lastFrequentItems[i] | lastFrequentItems[j])</span><br><span class="line">    <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apriori</span>(<span class="params">dataSet, minSupport=<span class="number">0.5</span></span>):</span></span><br><span class="line">    C1 = createC1(dataSet)</span><br><span class="line">    k1FrequentItems, supportData = scanDataset(dataSet, C1, minSupport)</span><br><span class="line">    frequentItemsList = [k1FrequentItems]</span><br><span class="line">    <span class="comment"># 应为k=1的频繁项集已经找到，因此从k=2继续</span></span><br><span class="line">    k = <span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 根据k-1的频繁项集，创建k候选集，</span></span><br><span class="line">        <span class="comment"># k-1-1是因为列表下表从0开始</span></span><br><span class="line">        ck = createCk(frequentItemsList[k-<span class="number">1</span>-<span class="number">1</span>], k)</span><br><span class="line">        <span class="comment"># 再次扫描数据集，找出新的k项频繁项集</span></span><br><span class="line">        newFrequentItems, supK = scanDataset(dataSet, ck, minSupport)</span><br><span class="line">        <span class="comment"># 更新项集的支持度</span></span><br><span class="line">        supportData.update(supK)</span><br><span class="line">        <span class="comment"># 如果无法生成新的频繁项集，那么推出循环</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(newFrequentItems) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 存储所有的频繁项集</span></span><br><span class="line">        frequentItemsList.append(newFrequentItems)</span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> frequentItemsList, supportData</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    c1 = createC1(dataset)</span><br><span class="line"></span><br><span class="line">    pprint(apriori(dataset, <span class="number">0.3</span>))</span><br></pre></td></tr></table></figure><p>实现关联规则挖掘：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateRules</span>(<span class="params">frequentItemsList, supportData, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    <span class="comment"># 存储关联规则</span></span><br><span class="line">    ruleList = []</span><br><span class="line">    <span class="comment"># 从含有2项item的频繁项集开始遍历，计算两两的置信度</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(frequentItemsList)):</span><br><span class="line">        <span class="comment"># 遍历每一阶段的频繁项集</span></span><br><span class="line">        <span class="keyword">for</span> frequentItem <span class="keyword">in</span> frequentItemsList[i]:</span><br><span class="line">            <span class="built_in">print</span>(frequentItem)</span><br><span class="line">            subItems = [<span class="built_in">frozenset</span>([item]) <span class="keyword">for</span> item <span class="keyword">in</span> frequentItem]</span><br><span class="line">            <span class="built_in">print</span>(subItems)</span><br><span class="line">            <span class="keyword">if</span> (i == <span class="number">1</span>):</span><br><span class="line">                <span class="comment"># 先计算2项item的频繁项集的置信度，并将关联规则存储到ruleList</span></span><br><span class="line">                calculateConfidence(frequentItem, subItems, supportData, ruleList, minConf)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 然后使用递归依次计算3到k项item频繁项集之间两两的置信度，并提取关联规则</span></span><br><span class="line">                rulesFromRecursive(frequentItem, subItems, supportData, ruleList, minConf)</span><br><span class="line">    <span class="keyword">return</span> ruleList</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculateConfidence</span>(<span class="params">frequentItem, subItems, supportData, ruleList, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    <span class="comment"># 存储符合最小置信度阈值的item</span></span><br><span class="line">    retList = []</span><br><span class="line">    <span class="keyword">for</span> subItem <span class="keyword">in</span> subItems:</span><br><span class="line">        <span class="comment">#支持度(&#123;豆奶, 莴苣&#125;)/支持度(&#123;豆奶&#125;)</span></span><br><span class="line">        <span class="comment"># 计算置信度[frozenset(&#123;2, 3&#125;), frozenset(&#123;3, 5&#125;), frozenset(&#123;2, 5&#125;), frozenset(&#123;1, 3&#125;)],</span></span><br><span class="line">        conf = supportData[frequentItem]/supportData[frequentItem-subItem]</span><br><span class="line">        <span class="keyword">if</span> conf &gt;= minConf:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Rule：&quot;</span>, frequentItem-subItem, <span class="string">&#x27;--&gt;&#x27;</span>, subItem, <span class="string">&#x27;confidence:&#x27;</span>, conf)</span><br><span class="line">            ruleList.append((frequentItem-subItem, subItem, conf))</span><br><span class="line">            retList.append(subItem)</span><br><span class="line">    <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rulesFromRecursive</span>(<span class="params">frequentItem, subItems, supportData, ruleList, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    m = <span class="built_in">len</span>(subItems[<span class="number">0</span>])    <span class="comment"># 判断当前子项集的长度</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(frequentItem) &gt; (m + <span class="number">1</span>)): <span class="comment">#frozenset(&#123;2, 3, 5&#125;)</span></span><br><span class="line">        <span class="comment"># 根据子项集得出CK候选集</span></span><br><span class="line">        ck = createCk(subItems, m+<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 根据候选集再筛选出符合最小置信度的item集合</span></span><br><span class="line">        newItems = calculateConfidence(frequentItem, ck, supportData, ruleList, minConf)</span><br><span class="line">        <span class="comment"># 如果符合要求的item至少有2个，那么继续递归</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">len</span>(newItems) &gt; <span class="number">1</span>):</span><br><span class="line">            rulesFromRecursive(frequentItem, newItems, supportData, ruleList, minConf)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    c1 = createC1(dataset)</span><br><span class="line">    <span class="comment"># pprint(scanDataset(dataset, c1, 0.5))</span></span><br><span class="line"></span><br><span class="line">    pprint(generateRules(*apriori(dataset, <span class="number">0.3</span>)))</span><br></pre></td></tr></table></figure><p>面向对象封装</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    加载数据集</span></span><br><span class="line"><span class="string">    :return: dataset</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> [[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">2</span>, <span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AssociationRule</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, minSupport=<span class="number">0.5</span>, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">        self.minSupport = minSupport</span><br><span class="line">        self.minConf = minConf</span><br><span class="line">        self.dataset = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        self.frequentItemsList, self.supportData = self.apriori(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_createC1</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        创建C1候选项集，C1是所有大小为1的候选项集的列表</span></span><br><span class="line"><span class="string">        :return: C1</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># C1是所有大小为1的候选项集的列表</span></span><br><span class="line">        C1 = []</span><br><span class="line">        <span class="comment"># 遍历数据集，逐个添加到C1中</span></span><br><span class="line">        <span class="keyword">for</span> record <span class="keyword">in</span> dataset:</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> record:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> [item] <span class="keyword">in</span> C1:</span><br><span class="line">                    C1.append([item])</span><br><span class="line">        C1.sort()</span><br><span class="line">        <span class="comment"># 使用不变集合存储C1内部的每个候选项集，那么就可以将其作为字典的Key，如果是list类型不能直接作为字典的Key</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">frozenset</span>, C1))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_scanDataset</span>(<span class="params">self, ck</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        扫描数据集，判断频繁项集</span></span><br><span class="line"><span class="string">        :param ck: ck是所有大小为k的候选项集的列表</span></span><br><span class="line"><span class="string">        :return: 符合条件的项集、每个项集的支持度</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 存储项集的出现次数</span></span><br><span class="line">        selectedSetCount = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> record <span class="keyword">in</span> self.dataset:  <span class="comment"># 遍历每一条记录</span></span><br><span class="line">            <span class="keyword">for</span> candidateSet <span class="keyword">in</span> ck:</span><br><span class="line">                <span class="comment"># 判断当前候选项集是不是当前记录的子集</span></span><br><span class="line">                <span class="keyword">if</span> candidateSet.issubset(record):</span><br><span class="line">                    <span class="keyword">if</span> candidateSet <span class="keyword">not</span> <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">                        selectedSetCount[candidateSet] = <span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        selectedSetCount[candidateSet] += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 计算总条目数</span></span><br><span class="line">        numItems = <span class="built_in">float</span>(<span class="built_in">len</span>(self.dataset))</span><br><span class="line">        <span class="comment"># 存储符合条件的项集</span></span><br><span class="line">        retList = []</span><br><span class="line">        <span class="comment"># 存储项集的支持度</span></span><br><span class="line">        supportData = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">            <span class="comment"># 计算支持度</span></span><br><span class="line">            support = selectedSetCount[key] / numItems</span><br><span class="line">            <span class="keyword">if</span> support &gt;= self.minSupport:</span><br><span class="line">                retList.insert(<span class="number">0</span>, key)</span><br><span class="line">            supportData[key] = support</span><br><span class="line">        <span class="keyword">return</span> retList, supportData</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_createCk</span>(<span class="params">self, lastFrequentItems, k</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        根据k-1项的频繁项集列表生成k项的候选项集</span></span><br><span class="line"><span class="string">        :param lastFrequentItems: k-1项的频繁项集</span></span><br><span class="line"><span class="string">        :param k: 第k个项集</span></span><br><span class="line"><span class="string">        :return: ck项集</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        retList = []</span><br><span class="line">        lenLk = <span class="built_in">len</span>(lastFrequentItems)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lenLk):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, lenLk):</span><br><span class="line">                <span class="comment"># 因为新构建的ck项集，特征是任意一个k项集其中k-1项都必须存在于lastCk中</span></span><br><span class="line">                <span class="comment"># 通过以下判断，能筛选出那些符合要求的k-1项</span></span><br><span class="line">                L1 = <span class="built_in">list</span>(lastFrequentItems[i])[:k - <span class="number">2</span>]</span><br><span class="line">                L2 = <span class="built_in">list</span>(lastFrequentItems[j])[:k - <span class="number">2</span>]</span><br><span class="line">                L1.sort()</span><br><span class="line">                L2.sort()</span><br><span class="line">                <span class="keyword">if</span> L1 == L2:</span><br><span class="line">                    retList.append(lastFrequentItems[i] | lastFrequentItems[j])</span><br><span class="line">        <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">apriori</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        C1 = self._createC1(dataset)</span><br><span class="line">        k1FrequentItems, supportData = self._scanDataset(C1)</span><br><span class="line">        frequentItemsList = [k1FrequentItems]</span><br><span class="line">        <span class="comment"># 应为k=1的频繁项集已经找到，因此从k=2继续</span></span><br><span class="line">        k = <span class="number">2</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="comment"># 根据k-1的频繁项集，创建k候选集，</span></span><br><span class="line">            <span class="comment"># k-1-1是因为列表下表从0开始</span></span><br><span class="line">            ck = self._createCk(frequentItemsList[k - <span class="number">1</span> - <span class="number">1</span>], k)</span><br><span class="line">            <span class="comment"># 再次扫描数据集，找出新的k项频繁项集</span></span><br><span class="line">            newFrequentItems, supK = self._scanDataset(ck)</span><br><span class="line">            <span class="comment"># 更新项集的支持度</span></span><br><span class="line">            supportData.update(supK)</span><br><span class="line">            <span class="comment"># 如果无法生成新的频繁项集，那么推出循环</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(newFrequentItems) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="comment"># 存储所有的频繁项集</span></span><br><span class="line">            frequentItemsList.append(newFrequentItems)</span><br><span class="line">            k += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> frequentItemsList, supportData</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generateRules</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 存储关联规则</span></span><br><span class="line">        ruleList = []</span><br><span class="line">        <span class="comment"># 从含有2项item的频繁项集开始遍历，计算两两的置信度</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(self.frequentItemsList)):</span><br><span class="line">            <span class="comment"># 遍历每一阶段的频繁项集</span></span><br><span class="line">            <span class="keyword">for</span> frequentItem <span class="keyword">in</span> self.frequentItemsList[i]:</span><br><span class="line">                subItems = [<span class="built_in">frozenset</span>([item]) <span class="keyword">for</span> item <span class="keyword">in</span> frequentItem]</span><br><span class="line">                <span class="keyword">if</span> (i == <span class="number">1</span>):</span><br><span class="line">                    <span class="comment"># 先计算2项item的频繁项集的置信度，并将关联规则存储到ruleList</span></span><br><span class="line">                    self._calculateConfidence(frequentItem, subItems, self.supportData, ruleList)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 然后使用递归依次计算3到k项item频繁项集之间两两的置信度，并提取关联规则</span></span><br><span class="line">                    self._rulesFromRecursive(frequentItem, subItems, self.supportData, ruleList)</span><br><span class="line">        <span class="keyword">return</span> ruleList</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_calculateConfidence</span>(<span class="params">self, frequentItem, subItems, supportData, ruleList</span>):</span></span><br><span class="line">        <span class="comment"># 存储符合最小置信度阈值的item</span></span><br><span class="line">        retList = []</span><br><span class="line">        <span class="keyword">for</span> subItem <span class="keyword">in</span> subItems:</span><br><span class="line">            <span class="comment"># 计算置信度</span></span><br><span class="line">            conf = supportData[frequentItem] / supportData[frequentItem - subItem]</span><br><span class="line">            <span class="keyword">if</span> conf &gt;= self.minConf:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Rule：&quot;</span>, frequentItem - subItem, <span class="string">&#x27;--&gt;&#x27;</span>, subItem, <span class="string">&#x27;confidence:&#x27;</span>, conf)</span><br><span class="line">                ruleList.append((frequentItem - subItem, subItem, conf))</span><br><span class="line">                retList.append(subItem)</span><br><span class="line">        <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_rulesFromRecursive</span>(<span class="params">self, frequentItem, subItems, supportData, ruleList</span>):</span></span><br><span class="line">        m = <span class="built_in">len</span>(subItems[<span class="number">0</span>])  <span class="comment"># 判断当前子项集的长度</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">len</span>(frequentItem) &gt; (m + <span class="number">1</span>)):</span><br><span class="line">            <span class="comment"># 根据子项集得出CK候选集</span></span><br><span class="line">            ck = self._createCk(subItems, m + <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 根据候选集再筛选出符合最小置信度的item集合</span></span><br><span class="line">            newItems = self._calculateConfidence(frequentItem, ck, supportData, ruleList)</span><br><span class="line">            <span class="comment"># 如果符合要求的item至少有2个，那么继续递归</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">len</span>(newItems) &gt; <span class="number">1</span>):</span><br><span class="line">                self._rulesFromRecursive(frequentItem, newItems, supportData, ruleList)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    ar = AssociationRule()</span><br><span class="line">    <span class="comment"># pprint(scanDataset(dataset, c1, 0.5))</span></span><br><span class="line">    ar.fit(dataset)</span><br><span class="line">    pprint(ar.generateRules())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pprint(ar.generateRules(*ar.apriori(dataset, 0.3)))</span></span><br></pre></td></tr></table></figure><h2 id="频繁项集挖掘（二）FP-Growth算法"><a href="#频繁项集挖掘（二）FP-Growth算法" class="headerlink" title="频繁项集挖掘（二）FP-Growth算法"></a>频繁项集挖掘（二）FP-Growth算法</h2><p>FP-Growth（Frequent Patterns）相比于Apriori是一种更加有效的频繁项集挖掘算法，FP-Growth算法只需要对数据库进行两次扫描，而Apriori算法对于每次产生的候选项集都会扫描一次数据集来判断是否频繁，因此当数据量特别巨大，且扫描数据库的成本比较高时，FP-Growth的速度要比Apriori快。</p><p>但是FP-Growth只能用于发现频繁项集，不能用于发现关联规则。</p><h3 id="FP-Growth原理分析"><a href="#FP-Growth原理分析" class="headerlink" title="FP-Growth原理分析"></a>FP-Growth原理分析</h3><p>FP-Growth算法实现步骤</p><ul><li>构建FP树</li><li>从FP树中挖掘频繁项集</li></ul><p>FP-Growth算法将数据存储在一种被称为FP树的紧凑数据结构中。</p><p><img src="fp-growth2.png" alt=""></p><p>下图就是利用上面的数据构建的一棵FP树（最小支持度为3）：</p><p><img src="fp-growth1.png" alt=""></p><ul><li>FP树中最小支持度指项集总共出现的次数</li><li>一个元素项可以在一棵FP树中出现多次</li><li>FP树存储项集的出现频率，且每个项集会以路径的方式存储在树中</li><li>存在相似元素的集合会共享树的一部分</li><li>只有当集合之间完全不同时，树才会分叉</li><li>树节点上给出集合中的单个元素及其在序列中的出现次数，路径会给出该序列的出现次数</li></ul><p>FP-Growth算法工作流程：</p><ul><li>扫描数据集两遍</li><li>第一遍对所有元素项的出现次数进行计数</li><li>根据前面的结论，如果某元素是不频繁的，那么包含该元素的超集也是不频繁的</li><li>第二遍扫描，只考虑那些频繁元素，并且第二遍扫描开始构建FP树</li></ul><h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">treeNode</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, nameValue, numOccur, parentNode</span>):</span></span><br><span class="line">        <span class="comment"># 节点名称</span></span><br><span class="line">        self.name = nameValue</span><br><span class="line">        <span class="comment"># 节点计数</span></span><br><span class="line">        self.count = numOccur</span><br><span class="line">        <span class="comment"># 记录相似的元素项</span></span><br><span class="line">        self.nodeLink = <span class="literal">None</span></span><br><span class="line">        <span class="comment"># 父节点对象</span></span><br><span class="line">        self.parent = parentNode</span><br><span class="line">        <span class="comment"># 子节点</span></span><br><span class="line">        self.children = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inc</span>(<span class="params">self, numOccur</span>):</span></span><br><span class="line">        self.count += numOccur</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">disp</span>(<span class="params">self, ind=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;--&#x27;</span>*ind, self.name, <span class="string">&#x27; &#x27;</span>, self.count)</span><br><span class="line">        <span class="keyword">for</span> child <span class="keyword">in</span> self.children.values():</span><br><span class="line">            child.disp(ind+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span>(<span class="params">dataSet, minSup=<span class="number">1</span></span>):</span>  <span class="comment"># create FP-tree from dataset but don&#x27;t mine</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;遍历数据集两遍&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 第一遍对元素计数</span></span><br><span class="line">    originHeaderTable = &#123;&#125;    <span class="comment"># headerTable用于记录树的结构情况</span></span><br><span class="line">    <span class="keyword">for</span> trans <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> trans:</span><br><span class="line">            originHeaderTable[item] = originHeaderTable.get(item, <span class="number">0</span>) + dataSet[trans]</span><br><span class="line"></span><br><span class="line">    popKeys = []</span><br><span class="line">    <span class="comment"># 过滤掉非频繁项集</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> originHeaderTable.keys():</span><br><span class="line">        <span class="comment"># 记录非频繁项</span></span><br><span class="line">        <span class="keyword">if</span> originHeaderTable[k] &lt; minSup:</span><br><span class="line">            popKeys.append(k)</span><br><span class="line"></span><br><span class="line">    freqItemSet = <span class="built_in">set</span>(originHeaderTable.keys()) - <span class="built_in">set</span>(popKeys)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># headerTable用于记录树的结构情况</span></span><br><span class="line">    headerTable = &#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(freqItemSet) == <span class="number">0</span>:   <span class="comment"># 如果初选没有频繁项集，那么直接退出</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 重新构建headerTable</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> freqItemSet:</span><br><span class="line">        headerTable[k] = [originHeaderTable[k], <span class="literal">None</span>]  <span class="comment"># reformat headerTable to use Node link</span></span><br><span class="line">    <span class="keyword">del</span> originHeaderTable</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建空树，根节点为空集</span></span><br><span class="line">    root_node = treeNode(<span class="string">&#x27;Null Set&#x27;</span>, <span class="number">1</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># 第二遍扫描，开始构建FP树</span></span><br><span class="line">    <span class="keyword">for</span> tranSet, count <span class="keyword">in</span> dataSet.items():  <span class="comment"># go through dataset 2nd time</span></span><br><span class="line">        localD = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> tranSet:  <span class="comment"># put transaction items in order</span></span><br><span class="line">            <span class="keyword">if</span> item <span class="keyword">in</span> freqItemSet:</span><br><span class="line">                localD[item] = headerTable[item][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(localD) &gt; <span class="number">0</span>:</span><br><span class="line">            orderedItems = [v[<span class="number">0</span>] <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">sorted</span>(localD.items(), key=<span class="keyword">lambda</span> p: p[<span class="number">1</span>], reverse=<span class="literal">True</span>)]</span><br><span class="line">            updateTree(orderedItems, root_node, headerTable, count)  <span class="comment"># populate tree with ordered freq itemset</span></span><br><span class="line">    <span class="keyword">return</span> root_node, headerTable  <span class="comment"># return tree and header table</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateTree</span>(<span class="params">items, parentNode, headerTable, count</span>):</span></span><br><span class="line">    <span class="comment"># 判断第一个项集是已经是当前节点的子节点</span></span><br><span class="line">    <span class="keyword">if</span> items[<span class="number">0</span>] <span class="keyword">in</span> parentNode.children:  <span class="comment"># check if orderedItems[0] in retTree.children</span></span><br><span class="line">        <span class="comment"># 如果是，那么直接count + 1</span></span><br><span class="line">        parentNode.children[items[<span class="number">0</span>]].inc(count)  <span class="comment"># incrament count</span></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># add items[0] to inTree.children</span></span><br><span class="line">        <span class="comment"># 如果不是，那么新建节点，并存储为当前节点的子节点</span></span><br><span class="line">        parentNode.children[items[<span class="number">0</span>]] = treeNode(items[<span class="number">0</span>], count, parentNode)</span><br><span class="line">        <span class="comment"># 更新headerTable</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 判断当前item是否是第一次记录</span></span><br><span class="line">        <span class="keyword">if</span> headerTable[items[<span class="number">0</span>]][<span class="number">1</span>] == <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 如果是第一次，那么把新建的节点直接记录到头表中</span></span><br><span class="line">            headerTable[items[<span class="number">0</span>]][<span class="number">1</span>] = parentNode.children[items[<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 如果不是第一次，那么说明新节点是当前item的节点的子节点，因此将它记录到当前分支的末位去，即设置为当前分支的叶子节点</span></span><br><span class="line">            updateHeader(headerTable[items[<span class="number">0</span>]][<span class="number">1</span>], parentNode.children[items[<span class="number">0</span>]])</span><br><span class="line">    <span class="comment"># 如果还有第二个元素，那么递归执行以上操作</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(items) &gt; <span class="number">1</span>:</span><br><span class="line">        updateTree(items[<span class="number">1</span>::], parentNode.children[items[<span class="number">0</span>]], headerTable, count)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateHeader</span>(<span class="params">lastNode, newLeafNode</span>):</span></span><br><span class="line">    <span class="comment"># 判断上一节点是否有连接节点，如果没有，那么说明上一节点就是叶子节点，那么直接将新节点设为叶子节点</span></span><br><span class="line">    <span class="keyword">while</span> (lastNode.nodeLink != <span class="literal">None</span>):</span><br><span class="line">        <span class="comment"># 如果上一节点已经有连接节点，那么循环知道遍历到叶子节点，再设置新叶子节点</span></span><br><span class="line">        lastNode = lastNode.nodeLink</span><br><span class="line">    <span class="comment"># 将新的叶子节点设置为旧叶子节点的连接节点</span></span><br><span class="line">    lastNode.nodeLink = newLeafNode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadTestDataset</span>():</span></span><br><span class="line">    dataset = [[<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;j&#x27;</span>, <span class="string">&#x27;p&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, <span class="string">&#x27;v&#x27;</span>, <span class="string">&#x27;u&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;s&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;z&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;s&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;q&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;p&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;q&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;m&#x27;</span>]]</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createInitDataset</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    dictDataset = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> trans <span class="keyword">in</span> dataSet:</span><br><span class="line">        dictDataset[<span class="built_in">frozenset</span>(trans)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> dictDataset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildCombinedItems</span>(<span class="params">leafNode, combinedItems</span>):</span></span><br><span class="line">    <span class="keyword">if</span> leafNode.parent != <span class="literal">None</span>:</span><br><span class="line">        combinedItems.append(leafNode.name)</span><br><span class="line">        buildCombinedItems(leafNode.parent, combinedItems)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildCombinedDataset</span>(<span class="params">nodeObject</span>):</span></span><br><span class="line">    <span class="comment"># 根据节点名称，组合出新的项集节点</span></span><br><span class="line">    combinedDataset = &#123;&#125;</span><br><span class="line">    <span class="keyword">while</span> nodeObject != <span class="literal">None</span>:</span><br><span class="line">        combinedItems = []</span><br><span class="line">        buildCombinedItems(nodeObject, combinedItems)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(combinedItems) &gt; <span class="number">1</span>:</span><br><span class="line">            combinedDataset[<span class="built_in">frozenset</span>(combinedItems[<span class="number">1</span>:])] = nodeObject.count</span><br><span class="line">        nodeObject = nodeObject.nodeLink</span><br><span class="line">    <span class="keyword">return</span> combinedDataset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanFPTree</span>(<span class="params">headerTable, minSup, parentNodeNames, freqItemList</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历排序后的headerTable，(节点名称，节点信息）</span></span><br><span class="line">    <span class="keyword">for</span> baseNode, nodeInfo <span class="keyword">in</span> headerTable.items():</span><br><span class="line">        <span class="comment"># 根据prefix</span></span><br><span class="line">        newFreqSet = parentNodeNames.copy()</span><br><span class="line">        newFreqSet.add(baseNode)</span><br><span class="line">        <span class="comment"># 节点计数值</span></span><br><span class="line">        nodeCount = nodeInfo[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 节点对象</span></span><br><span class="line">        nodeObject = nodeInfo[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 记录下频繁项集以及计数</span></span><br><span class="line">        freqItemList.append((newFreqSet, nodeCount))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据当前节点的子节点，构建出新的项集组合</span></span><br><span class="line">        combinedDataset = buildCombinedDataset(nodeObject)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据新的项集组合，重合构建子FP树</span></span><br><span class="line">        subFPTree, subFPTreeHeaderTable = createTree(combinedDataset, minSup)</span><br><span class="line">        <span class="comment"># 如果头表不为空，那么递归新树的头表</span></span><br><span class="line">        <span class="keyword">if</span> subFPTreeHeaderTable != <span class="literal">None</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;conditional tree for: &#x27;</span>, newFreqSet)</span><br><span class="line">            subFPTree.disp(<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 根据新的头表 扫描FP-Tree</span></span><br><span class="line">            scanFPTree(subFPTreeHeaderTable, minSup, newFreqSet, freqItemList)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    simpDat = loadTestDataset()</span><br><span class="line">    initSet = createInitDataset(simpDat)</span><br><span class="line">    <span class="comment"># 构建初始的FP-Tree</span></span><br><span class="line">    initFPtree, initFPtreeHeaderTable = createTree(initSet, <span class="number">3</span>)</span><br><span class="line">    initFPtree.disp(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    freqItems = []    <span class="comment"># 存储频繁项集</span></span><br><span class="line">    <span class="comment"># 扫描FP树，找出所有符合条件的频繁项集</span></span><br><span class="line"></span><br><span class="line">    root_node_names = <span class="built_in">set</span>([])    <span class="comment"># 从根路径空集开始扫描</span></span><br><span class="line">    scanFPTree(initFPtreeHeaderTable, <span class="number">3</span>, root_node_names, freqItems)</span><br><span class="line">    pprint(freqItems)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Search / Advertisement / Recommendation / Causal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Recommendation System Introduction</title>
      <link href="/2022/01/18/5.1-Recommendation-System-Introduction/"/>
      <url>/2022/01/18/5.1-Recommendation-System-Introduction/</url>
      
        <content type="html"><![CDATA[<p><strong>推荐系统学习笔记目录</strong></p><ol><li><a href="https://xfliu1998.github.io/2022/01/18/5.1-Recommendation-System-Introduction/">推荐系统介绍</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/">推荐算法</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.3-Hadoop/">Hadoop</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.4-Hive/">Hive &amp; HBase</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.5-Spark-core/">Spark core</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.6-Spark-SQL/">Spark SQL &amp; Spark streaming</a></li><li><a href="https://xfliu1998.github.io/2022/01/18/5.7-RS-case/">推荐系统案例</a></li></ol><h2 id="推荐系统简介"><a href="#推荐系统简介" class="headerlink" title="推荐系统简介"></a>推荐系统简介</h2><p>个性化推荐(推荐系统)经历了多年的发展，已经成为互联网产品的标配，也是AI成功落地的分支之一，在电商(淘宝/京东)、资讯(今日头条/微博)、音乐(网易云音乐/QQ音乐)、短视频(抖音/快手)等热门应用中，推荐系统都是核心组件之一。</p><ul><li><p>推荐系统产生背景</p><ul><li>信息过载 &amp; 用户需求不明确<ul><li>分类⽬录（1990s）：覆盖少量热门⽹站。Hao123 Yahoo</li><li>搜索引擎（2000s）：通过搜索词明确需求。Google Baidu</li><li>推荐系统（2010s）：不需要⽤户提供明确的需求，通过分析⽤户的历史⾏为给⽤户的兴趣进⾏建模，从⽽主动给⽤户推荐能够满⾜他们兴趣和需求的信息。</li></ul></li></ul></li><li><p>什么是推荐系统</p><ul><li>没有明确需求的用户访问了我们的服务, 且服务的物品对用户构成了信息过载, 系统通过一定的规则对物品进行排序，并将排在前面的物品展示给用户，这样的系统就是推荐系统</li></ul></li><li><p>推荐系统 V.S. 搜索引擎</p><table align='center'>  <tr>    <th></th>    <th>搜索</th>    <th>推荐</th>  </tr>  <tr>    <td> 行为方式 </td>    <td> 主动 </td>    <td> 被动 </td>  </tr>  <tr>    <td> 意图 </td>    <td> 明确 </td>    <td> 模糊 </td>  </tr>  <tr>    <td> 个性化 </td>    <td> 弱 </td>    <td> 强 </td>  </tr>  <tr>    <td> 流量分布 </td>    <td> 马太效应 </td>    <td> 长尾效应 </td>  </tr>  <tr>    <td> 目标 </td>    <td> 快速满足  </td>    <td> 持续服务 </td>  </tr>  <tr>    <td> 评估指标 </td>    <td> 简明 </td>    <td> 复杂 </td>  </tr></table></li><li><p>推荐系统的作用</p><ul><li>高效连接用户和物品, 发现长尾商品</li><li>留住用户和内容生产者, 实现商业目标</li></ul></li><li><p>推荐系统的工作原理</p><ul><li><strong>社会化推荐</strong> 向朋友咨询, 社会化推荐, 让好友给自己推荐物品</li><li><strong>基于内容的推荐</strong> 打开搜索引擎, 输入自己喜欢的演员的名字, 看返回结果中还有什么电影是自己没看过的</li><li><strong>基于流行度的推荐</strong> 查看票房排行榜</li><li><strong>基于协同过滤的推荐</strong> 找到和自己历史兴趣相似的用户, 看看他们最近在看什么电影</li></ul></li><li><p>推荐系统的应用场景 feed流 信息流 </p></li><li><p>推荐系统和Web项目的区别</p><ul><li>稳定的信息流通系统 V.S. 通过信息过滤实现目标提升 <ul><li>web项目: 处理复杂逻辑 处理高并发 实现高可用 为用户提供稳定服务, 构建一个稳定的信息流通的服务</li><li>推荐系统: 追求指标增长, 留存率/阅读时间/GMV (Gross Merchandise Volume电商网站成交金额)/视频网站VV (Video View)</li></ul></li><li>确定 V.S. 不确定思维<ul><li>web项目: 对结果有确定预期</li><li>推荐系统: 结果是概率问题</li></ul></li></ul></li></ul><h2 id="推荐系统设计"><a href="#推荐系统设计" class="headerlink" title="推荐系统设计"></a>推荐系统设计</h2><h3 id="推荐系统要素"><a href="#推荐系统要素" class="headerlink" title="推荐系统要素"></a>推荐系统要素</h3><ul><li>UI 和 UE(前端界面)</li><li>数据 (Lambda架构)</li><li>业务知识</li><li>算法</li></ul><h3 id="推荐系统架构"><a href="#推荐系统架构" class="headerlink" title="推荐系统架构"></a>推荐系统架构</h3><ul><li><p>推荐系统整体架构<br><img src="%E6%8E%A8%E8%8D%90%E6%B5%81%E7%A8%8B.png" alt=""></p></li><li><p>大数据Lambda架构</p><ul><li>由Twitter工程师Nathan Marz(storm项目发起人)提出</li><li><p>Lambda系统架构提供了一个结合实时数据和Hadoop预先计算的数据环境和混合平台, 提供一个实时的数据视图</p></li><li><p>分层架构</p><ul><li>批处理层<ul><li>数据不可变, 可进行任何计算, 可水平扩展</li><li>高延迟  几分钟~几小时(计算量和数据量不同)</li><li>日志收集 Flume</li><li>分布式存储 Hadoop hdfs</li><li>分布式计算 Hadoop MapReduce &amp; spark</li><li>视图存储数据库<ul><li>nosql(HBase/Cassandra)</li><li>Redis/memcache</li><li>MySQL</li></ul></li></ul></li><li>实时处理层<ul><li>流式处理, 持续计算</li><li>存储和分析某个窗口期内的数据</li><li>最终正确性(Eventual accuracy)</li><li>实时数据收集 flume &amp; kafka</li><li>实时数据分析  spark streaming/storm/flink</li></ul></li><li>服务层<ul><li>支持随机读</li><li>需要在非常短的时间内返回结果</li><li>读取批处理层和实时处理层结果并对其归并</li></ul></li></ul></li><li><p>Lambda架构图<br><img src="lambda3.png" alt=""></p></li></ul></li><li><p>推荐算法架构</p><ul><li>召回阶段(海选)<ul><li>召回决定了最终推荐结果的天花板</li><li>常用算法:<ul><li>协同过滤(基于用户 基于物品的)</li><li>基于内容 (根据用户行为总结出自己的偏好 根据偏好 通过文本挖掘技术找到内容上相似的商品)</li><li>基于隐语义</li></ul></li></ul></li><li>排序阶段<ul><li>召回决定了最终推荐结果的天花板, 排序逼近这个极限, 决定了最终的推荐效果</li><li>CTR预估 (点击率预估 使用LR算法) 估计用户是否会点击某个商品，需要用户的点击数据</li></ul></li><li>策略调整<br><img src="recommend7.jpeg" alt=""></li></ul></li><li><p>推荐系统的整体架构<br><img src="RS基础业务架构.png" alt=""><br><img src="RS基础技术架构.png" alt=""></p></li></ul><h2 id="推荐算法"><a href="#推荐算法" class="headerlink" title="推荐算法"></a>推荐算法</h2><ul><li>推荐模型构建流程</li><li>推荐算法概述</li><li>基于协同过滤的推荐算法</li><li>协同过滤实现</li></ul><h3 id="推荐模型构建流程"><a href="#推荐模型构建流程" class="headerlink" title="推荐模型构建流程"></a>推荐模型构建流程</h3><p>Data(数据)-&gt;Features(特征)-&gt;ML Algorithm(机器学习算法)-&gt;Prediction Output(预测输出)</p><ul><li><p>数据清洗/数据处理<br><img src="algorithm1.png" alt=""></p></li><li><p>数据来源</p><ul><li>显性数据<ul><li>Rating 打分</li><li>Comments 评论/评价</li></ul></li><li>隐形数据<ul><li> Order history 历史订单</li><li> Cart events    加购物车</li><li> Page views    页面浏览</li><li> Click-thru      点击</li><li> Search log     搜索记录</li></ul></li></ul></li><li>数据量/数据能否满足要求</li><li><p>特征工程<br><img src="algorithm2.png" alt=""></p></li><li><p>从数据中筛选特征</p><ul><li>一个给定的商品，可能被拥有类似品味或需求的用户购买</li><li>使用用户行为数据描述商品<br><img src="algorithm3.png" alt=""></li></ul></li><li><p>用数据表示特征</p><ul><li>将所有用户行为合并在一起 ，形成一个user-item 矩阵<br><img src="algorithm4.png" alt="1545452707102"></li></ul></li><li><p>选择合适的算法<br><img src="algorithm5.png" alt=""></p></li><li><p>产生推荐结果<br><img src="algorithm6.png" alt=""></p></li></ul><h3 id="最经典的推荐算法：协同过滤推荐算法（Collaborative-Filtering）"><a href="#最经典的推荐算法：协同过滤推荐算法（Collaborative-Filtering）" class="headerlink" title="最经典的推荐算法：协同过滤推荐算法（Collaborative Filtering）"></a>最经典的推荐算法：协同过滤推荐算法（Collaborative Filtering）</h3><p>算法思想：<strong>物以类聚，人以群分</strong></p><p>基本的协同过滤推荐算法基于以下假设：</p><ul><li>“跟你喜好<strong>相似的人</strong>喜欢的东西你也很有可能喜欢” ：基于用户的协同过滤推荐（User-based CF）</li><li>“跟你喜欢的东西<strong>相似的东西</strong>你也很有可能喜欢 ”：基于物品的协同过滤推荐（Item-based CF）</li></ul><p>实现协同过滤推荐有以下几个步骤：</p><ol><li><strong>找出最相似的人或物品：TOP-N相似的人或物品</strong><br>通过计算两两的相似度来进行排序，即可找出TOP-N相似的人或物品</li><li><strong>根据相似的人或物品产生推荐结果</strong><br>利用TOP-N结果生成初始推荐结果，然后过滤掉用户已经有过记录的物品或明确表示不感兴趣的物品</li></ol><p>以下是一个简单的示例，数据集相当于一个用户对物品的购买记录表：打勾表示用户对物品的有购买记录</p><ul><li><p>关于相似度计算这里先用一个简单的思想：如有两个同学X和Y，X同学爱好[足球、篮球、乒乓球]，Y同学爱好[网球、足球、篮球、羽毛球]，可见他们的共同爱好有2个，那么他们的相似度可以用：2/3 * 2/4 = 1/3 ≈ 0.33 来表示。</p><p><strong>User-Based CF</strong><br><img src="%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%901.png" alt=""></p><p><strong>Item-Based CF</strong><br><img src="%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%901.png" alt=""></p></li></ul><h3 id="相似度计算-Similarity-Calculation"><a href="#相似度计算-Similarity-Calculation" class="headerlink" title="相似度计算(Similarity Calculation)"></a>相似度计算(Similarity Calculation)</h3><ul><li>相似度的计算方法<ul><li>数据分类<ul><li>实数值(物品评分情况)</li><li>布尔值(用户的行为 是否点击 是否收藏)</li></ul></li><li>欧氏距离，衡量这两个点之间的距离，不适用于布尔向量之间<script type="math/tex; mode=display">E(p,q) = \sqrt{\sum_{i=1}^n (p_i - q_i)^2}</script>​    欧氏距离的值非负, 最大值正无穷, 通常计算相似度的结果希望是[-1,1]或[0,1]之间,一般可以使用如下转化公式:$\frac{1}{1+E(p,q)}$</li></ul></li><li><p>杰卡德相似度&amp;余弦相似度&amp;皮尔逊相关系数</p><ul><li>余弦相似度<ul><li>度量的是两个向量之间的夹角, 用夹角的余弦值来度量相似的情况</li><li>两个向量的夹角为0余弦值为1, 当夹角为90度是余弦值为0,为180度是余弦值为-1</li><li>余弦相似度在度量文本相似度, 用户相似度,物品相似度的时候较为常用</li><li>余弦相似度的特点, 与向量长度无关，余弦相似度计算要对向量长度归一化, 两个向量只要方向一致,无论程度强弱, 都可以视为’相似’</li></ul></li><li>皮尔逊相关系数Pearson<ul><li>实际上也是一种余弦相似度, 不过先对向量做了中心化, 向量a b 各自减去向量的均值后, 再计算余弦相似度</li><li>皮尔逊相似度计算结果在-1,1之间 -1表示负相关, 1表示正相关</li><li>度量两个变量是不是同增同减</li><li>皮尔逊相关系数度量的是两个变量的变化趋势是否一致, <strong>不适合计算布尔值向量之间的相关度</strong></li></ul></li><li>杰卡德相似度 Jaccard<ul><li>两个集合的交集元素个数在并集中所占的比例, 非常适用于布尔向量表示</li><li>分子是两个布尔向量做点积计算, 得到的就是交集元素的个数</li><li>分母是两个布尔向量做或运算, 再求元素和</li></ul></li><li>余弦相似度适合用户评分数据(实数值), 杰卡德相似度适用于隐式反馈数据(0,1布尔值)(是否收藏,是否点击,是否加购物车)</li></ul><p><img src="similarity_calc2.png" alt=""></p></li><li><p>余弦相似度<br><img src="similarity_calc5.png" alt=""></p></li><li><p>皮尔逊相关系数<br><img src="similarity_calc3.png" alt=""><br><img src="similarity_calc4.png" alt=""></p></li><li><p>计算出用户1和其它用户之间的相似度<br><img src="similarity_calc6.png" alt=""></p></li><li><p>按照相似度大小排序, K近邻 如K取4:<br><img src="similarity_calc7.png" alt=""></p></li><li><p>取出近邻用户的购物清单<br><img src="similarity_calc8.png" alt=""></p></li><li><p>去除用户1已经购买过的商品<br><img src="similarity_calc9.png" alt=""></p></li><li><p>在剩余的物品中根据评分排序<br><img src="similarity_calc10.png" alt=""></p></li><li><p>物品相似度计算</p><ul><li>余弦相似度对绝对值大小不敏感带来的问题<ul><li>用户A对两部电影评分分别是1分和2分, 用户B对同样这两部电影进行评分是4分,5分 用余弦相似度计算,两个用户的相似度达到0.98    </li><li>可以采用改进的余弦相似度, 先计算向量每个维度上的均值, 然后每个向量在各个维度上都减去均值后,在计算余弦相似度, 用调整的余弦相似度计算得到的相似度是-0.1</li></ul></li></ul></li></ul><p><img src="similarity_calc11.png" alt=""></p><ul><li><p>物品相似度计算案例<br><img src="similarity_calc12.png" alt=""></p></li><li><p>找出物品1的相似商品<br><img src="similarity_calc13.png" alt=""></p></li><li><p>选择最近似的物品<br><img src="similarity_calc14.png" alt=""></p></li><li><p>基于用户与物品的协同过滤比较<br><img src="similarity_calc15.png" alt=""><br><img src="similarity_calc16.png" alt=""></p></li></ul><h3 id="协同过滤推荐算法代码实现"><a href="#协同过滤推荐算法代码实现" class="headerlink" title="协同过滤推荐算法代码实现"></a>协同过滤推荐算法代码实现</h3><ul><li><p>构建数据集： </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">users = [<span class="string">&quot;User1&quot;</span>, <span class="string">&quot;User2&quot;</span>, <span class="string">&quot;User3&quot;</span>, <span class="string">&quot;User4&quot;</span>, <span class="string">&quot;User5&quot;</span>]</span><br><span class="line">items = [<span class="string">&quot;Item A&quot;</span>, <span class="string">&quot;Item B&quot;</span>, <span class="string">&quot;Item C&quot;</span>, <span class="string">&quot;Item D&quot;</span>, <span class="string">&quot;Item E&quot;</span>]</span><br><span class="line"><span class="comment"># 构建数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="string">&quot;buy&quot;</span>,<span class="literal">None</span>,<span class="string">&quot;buy&quot;</span>,<span class="string">&quot;buy&quot;</span>,<span class="literal">None</span>],</span><br><span class="line">    [<span class="string">&quot;buy&quot;</span>,<span class="literal">None</span>,<span class="literal">None</span>,<span class="string">&quot;buy&quot;</span>,<span class="string">&quot;buy&quot;</span>],</span><br><span class="line">    [<span class="string">&quot;buy&quot;</span>,<span class="literal">None</span>,<span class="string">&quot;buy&quot;</span>,<span class="literal">None</span>,<span class="literal">None</span>],</span><br><span class="line">    [<span class="literal">None</span>,<span class="string">&quot;buy&quot;</span>,<span class="literal">None</span>,<span class="string">&quot;buy&quot;</span>,<span class="string">&quot;buy&quot;</span>],</span><br><span class="line">    [<span class="string">&quot;buy&quot;</span>,<span class="string">&quot;buy&quot;</span>,<span class="string">&quot;buy&quot;</span>,<span class="literal">None</span>,<span class="string">&quot;buy&quot;</span>],</span><br><span class="line">]</span><br></pre></td></tr></table></figure></li><li><p>计算时我们数据通常都需要对数据进行处理，或者编码，目的是为了便于我们对数据进行运算处理，比如这里是比较简单的情形，我们用1、0分别来表示用户的是否购买过该物品，则我们的数据集其实应该是这样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">users = [<span class="string">&quot;User1&quot;</span>, <span class="string">&quot;User2&quot;</span>, <span class="string">&quot;User3&quot;</span>, <span class="string">&quot;User4&quot;</span>, <span class="string">&quot;User5&quot;</span>]</span><br><span class="line">items = [<span class="string">&quot;Item A&quot;</span>, <span class="string">&quot;Item B&quot;</span>, <span class="string">&quot;Item C&quot;</span>, <span class="string">&quot;Item D&quot;</span>, <span class="string">&quot;Item E&quot;</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure></li><li><p>进行相似度的计算，不过对于相似度的计算其实是有很多专门的相似度计算方法的，比如余弦相似度、皮尔逊相关系数、杰卡德相似度等等。选择使用杰卡德相似系数[0,1]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接计算某两项的杰卡德相似系数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> jaccard_similarity_score</span><br><span class="line"><span class="comment"># 计算Item A 和Item B的相似度</span></span><br><span class="line"><span class="built_in">print</span>(jaccard_similarity_score(df[<span class="string">&quot;Item A&quot;</span>], df[<span class="string">&quot;Item B&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算所有的数据两两的杰卡德相似系数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances</span><br><span class="line"><span class="comment"># 计算用户间相似度</span></span><br><span class="line">user_similar = <span class="number">1</span> - pairwise_distances(df, metric=<span class="string">&quot;jaccard&quot;</span>)</span><br><span class="line">user_similar = pd.DataFrame(user_similar, columns=users, index=users)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;用户之间的两两相似度：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(user_similar)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算物品间相似度</span></span><br><span class="line">item_similar = <span class="number">1</span> - pairwise_distances(df.T, metric=<span class="string">&quot;jaccard&quot;</span>)</span><br><span class="line">item_similar = pd.DataFrame(item_similar, columns=items, index=items)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;物品之间的两两相似度：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(item_similar)</span><br></pre></td></tr></table></figure><p>有了两两的相似度，接下来筛选TOP-N相似结果，并进行推荐</p></li><li><p>User-Based CF</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">users = [<span class="string">&quot;User1&quot;</span>, <span class="string">&quot;User2&quot;</span>, <span class="string">&quot;User3&quot;</span>, <span class="string">&quot;User4&quot;</span>, <span class="string">&quot;User5&quot;</span>]</span><br><span class="line">items = [<span class="string">&quot;Item A&quot;</span>, <span class="string">&quot;Item B&quot;</span>, <span class="string">&quot;Item C&quot;</span>, <span class="string">&quot;Item D&quot;</span>, <span class="string">&quot;Item E&quot;</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算所有的数据两两的杰卡德相似系数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances</span><br><span class="line"><span class="comment"># 计算用户间相似度</span></span><br><span class="line">user_similar = <span class="number">1</span> - pairwise_distances(df, metric=<span class="string">&quot;jaccard&quot;</span>)</span><br><span class="line">user_similar = pd.DataFrame(user_similar, columns=users, index=users)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;用户之间的两两相似度：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(user_similar)</span><br><span class="line"></span><br><span class="line">topN_users = &#123;&#125;</span><br><span class="line"><span class="comment"># 遍历每一行数据</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> user_similar.index:</span><br><span class="line">    <span class="comment"># 取出每一列数据，并删除自身，然后排序数据</span></span><br><span class="line">    _df = user_similar.loc[i].drop([i])</span><br><span class="line">    _df_sorted = _df.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    top2 = <span class="built_in">list</span>(_df_sorted.index[:<span class="number">2</span>])</span><br><span class="line">    topN_users[i] = top2</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Top2相似用户：&quot;</span>)</span><br><span class="line">pprint(topN_users)</span><br><span class="line"></span><br><span class="line">rs_results = &#123;&#125;</span><br><span class="line"><span class="comment"># 构建推荐结果</span></span><br><span class="line"><span class="keyword">for</span> user, sim_users <span class="keyword">in</span> topN_users.items():</span><br><span class="line">    rs_result = <span class="built_in">set</span>()    <span class="comment"># 存储推荐结果</span></span><br><span class="line">    <span class="keyword">for</span> sim_user <span class="keyword">in</span> sim_users:</span><br><span class="line">        <span class="comment"># 构建初始的推荐结果</span></span><br><span class="line">        rs_result = rs_result.union(<span class="built_in">set</span>(df.ix[sim_user].replace(<span class="number">0</span>,np.nan).dropna().index))</span><br><span class="line">    <span class="comment"># 过滤掉已经购买过的物品</span></span><br><span class="line">    rs_result -= <span class="built_in">set</span>(df.ix[user].replace(<span class="number">0</span>,np.nan).dropna().index)</span><br><span class="line">    rs_results[user] = rs_result</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最终推荐结果：&quot;</span>)</span><br><span class="line">pprint(rs_results)</span><br></pre></td></tr></table></figure></li><li><p>Item-Based CF</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">users = [<span class="string">&quot;User1&quot;</span>, <span class="string">&quot;User2&quot;</span>, <span class="string">&quot;User3&quot;</span>, <span class="string">&quot;User4&quot;</span>, <span class="string">&quot;User5&quot;</span>]</span><br><span class="line">items = [<span class="string">&quot;Item A&quot;</span>, <span class="string">&quot;Item B&quot;</span>, <span class="string">&quot;Item C&quot;</span>, <span class="string">&quot;Item D&quot;</span>, <span class="string">&quot;Item E&quot;</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算所有的数据两两的杰卡德相似系数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances</span><br><span class="line"><span class="comment"># 计算物品间相似度</span></span><br><span class="line">item_similar = <span class="number">1</span> - pairwise_distances(df.T.values, metric=<span class="string">&quot;jaccard&quot;</span>)</span><br><span class="line">item_similar = pd.DataFrame(item_similar, columns=items, index=items)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;物品之间的两两相似度：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(item_similar)</span><br><span class="line"></span><br><span class="line">topN_items = &#123;&#125;</span><br><span class="line"><span class="comment"># 遍历每一行数据</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> item_similar.index:</span><br><span class="line">    <span class="comment"># 取出每一列数据，并删除自身，然后排序数据</span></span><br><span class="line">    _df = item_similar.loc[i].drop([i])</span><br><span class="line">    _df_sorted = _df.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    top2 = <span class="built_in">list</span>(_df_sorted.index[:<span class="number">2</span>])</span><br><span class="line">    topN_items[i] = top2</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Top2相似物品：&quot;</span>)</span><br><span class="line">pprint(topN_items)</span><br><span class="line"></span><br><span class="line">rs_results = &#123;&#125;</span><br><span class="line"><span class="comment"># 构建推荐结果</span></span><br><span class="line"><span class="keyword">for</span> user <span class="keyword">in</span> df.index:    <span class="comment"># 遍历所有用户</span></span><br><span class="line">    rs_result = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> df.ix[user].replace(<span class="number">0</span>,np.nan).dropna().index:   <span class="comment"># 取出每个用户当前已购物品列表</span></span><br><span class="line">        <span class="comment"># 根据每个物品找出最相似的TOP-N物品，构建初始推荐结果</span></span><br><span class="line">        rs_result = rs_result.union(topN_items[item])</span><br><span class="line">    <span class="comment"># 过滤掉用户已购的物品</span></span><br><span class="line">    rs_result -= <span class="built_in">set</span>(df.ix[user].replace(<span class="number">0</span>,np.nan).dropna().index)</span><br><span class="line">    <span class="comment"># 添加到结果中</span></span><br><span class="line">    rs_results[user] = rs_result</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最终推荐结果：&quot;</span>)</span><br><span class="line">pprint(rs_results)</span><br></pre></td></tr></table></figure></li></ul><p><strong>关于协同过滤推荐算法使用的数据集</strong><br>在前面的demo中，我们只是使用用户对物品的一个购买记录，类似也可以是比如浏览点击记录、收听记录等等。这样数据我们预测的结果其实相当于是在预测用户是否对某物品感兴趣，对于喜好程度不能很好的预测。</p><p>因此在协同过滤推荐算法中其实会更多的利用用户对物品的“评分”数据来进行预测，通过评分数据集，我们可以预测用户对于他没有评分过的物品的评分。其实现原理和思想和都是一样的，只是使用的数据集是用户-物品的评分数据。</p><p><strong>关于用户-物品评分矩阵</strong><br>用户-物品的评分矩阵，根据评分矩阵的稀疏程度会有不同的解决方案</p><ul><li>稠密评分矩阵(可直接使用皮尔逊相似度计算)</li><li>稀疏评分矩阵(需要进行矩阵分解)</li></ul><h4 id="使用协同过滤推荐算法对用户进行评分预测"><a href="#使用协同过滤推荐算法对用户进行评分预测" class="headerlink" title="使用协同过滤推荐算法对用户进行评分预测"></a>使用协同过滤推荐算法对用户进行评分预测</h4><p><strong>目的：预测用户1对物品E的评分</strong></p><ul><li><p>构建数据集：对于缺失的部分我们需要保留为None，如果设置为0那么会被当作评分值为0去对待</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">users = [<span class="string">&quot;User1&quot;</span>, <span class="string">&quot;User2&quot;</span>, <span class="string">&quot;User3&quot;</span>, <span class="string">&quot;User4&quot;</span>, <span class="string">&quot;User5&quot;</span>]</span><br><span class="line">items = [<span class="string">&quot;Item A&quot;</span>, <span class="string">&quot;Item B&quot;</span>, <span class="string">&quot;Item C&quot;</span>, <span class="string">&quot;Item D&quot;</span>, <span class="string">&quot;Item E&quot;</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="literal">None</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>],</span><br><span class="line">    [<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">4</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br></pre></td></tr></table></figure></li><li><p>计算相似度：对于评分数据这里我们采用皮尔逊相关系数[-1,1]来计算，-1表示强负相关，+1表示强正相关</p><blockquote><p>pandas中corr方法可直接用于计算皮尔逊相关系数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;用户之间的两两相似度：&quot;</span>)</span><br><span class="line"><span class="comment"># 直接计算皮尔逊相关系数</span></span><br><span class="line"><span class="comment"># 默认是按列进行计算，因此如果计算用户间的相似度，当前需要进行转置</span></span><br><span class="line">user_similar = df.T.corr()</span><br><span class="line"><span class="built_in">print</span>(user_similar.<span class="built_in">round</span>(<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;物品之间的两两相似度：&quot;</span>)</span><br><span class="line">item_similar = df.corr()</span><br><span class="line"><span class="built_in">print</span>(item_similar.<span class="built_in">round</span>(<span class="number">4</span>))</span><br></pre></td></tr></table></figure></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 运行结果：</span><br><span class="line">用户之间的两两相似度：</span><br><span class="line">        User1   User2   User3   User4   User5</span><br><span class="line">User1  1.0000  0.8528  0.7071  0.0000 -0.7921</span><br><span class="line">User2  0.8528  1.0000  0.4677  0.4900 -0.9001</span><br><span class="line">User3  0.7071  0.4677  1.0000 -0.1612 -0.4666</span><br><span class="line">User4  0.0000  0.4900 -0.1612  1.0000 -0.6415</span><br><span class="line">User5 -0.7921 -0.9001 -0.4666 -0.6415  1.0000</span><br><span class="line">物品之间的两两相似度：</span><br><span class="line">        Item A  Item B  Item C  Item D  Item E</span><br><span class="line">Item A  1.0000 -0.4767 -0.1231  0.5322  0.9695</span><br><span class="line">Item B -0.4767  1.0000  0.6455 -0.3101 -0.4781</span><br><span class="line">Item C -0.1231  0.6455  1.0000 -0.7206 -0.4276</span><br><span class="line">Item D  0.5322 -0.3101 -0.7206  1.0000  0.5817</span><br><span class="line">Item E  0.9695 -0.4781 -0.4276  0.5817  1.0000</span><br></pre></td></tr></table></figure><p>可以看到与用户1最相似的是用户2和用户3；与物品A最相似的物品分别是物品E和物品D。</p><p><strong>注意：</strong>我们在预测评分时，往往是通过与其有正相关的用户或物品进行预测，如果不存在正相关的情况，那么将无法做出预测。这一点尤其是在稀疏评分矩阵中尤为常见，因为稀疏评分矩阵中很难得出正相关系数。</p></li><li><p><strong>评分预测：</strong><br><strong>User-Based CF 评分预测：使用用户间的相似度进行预测</strong></p><p>关于评分预测的方法也有比较多的方案，下面介绍一种效果比较好的方案，该方案考虑了用户本身的评分以及近邻用户的加权平均相似度打分来进行预测：<script type="math/tex">pred(u,i)=\hat r_{ui}=\frac{\sum_{v\in U}sim(u,v)*r_{vi}}{\sum_{v\in U}|sim(u,v)|}</script></p><p>我们要预测用户1对物品E的评分，那么可以根据与用户1最近邻的用户2和用户3进行预测，计算如下：</p><script type="math/tex; mode=display">pred(u_1,i_5) = \frac{0.85 * 3 + 0.71 * 5}{0.85+0.71}=3.91</script><p>最终预测出用户1对物品5的评分为3.91</p><p><strong>Item-Based CF 评分预测：使用物品间的相似度进行预测</strong></p><p>这里利用物品相似度预测的计算同上，同样考虑了用户自身的平均打分因素，结合预测物品与相似物品的加权平均相似度打分进行来进行预测</p><script type="math/tex; mode=display">pred(u,i)=\hat r_{ui}=\frac{\sum_{j\in I_{rated}}sim(i,j)*r_{uj}}{\sum_{j\in I_{rated}}sim(i,j)}</script><p>我们要预测用户1对物品E的评分，那么可以根据与物品E最近邻的物品A和物品D进行预测，计算如下：</p><script type="math/tex; mode=display">pred(u_1, i_5) = \frac{0.97 * 5 + 0.58 * 4}{0.97+0.58} = 4.63</script><p>对比可见，User-Based CF预测评分和Item-Based CF的评分结果也是存在差异的，因为严格意义上他们其实应当属于两种不同的推荐算法，各自在不同的领域不同场景下，都会比另一种的效果更佳，但具体哪一种更佳，必须经过合理的效果评估，因此在实现推荐系统时这两种算法往往都是需要去实现的，然后对产生的推荐效果进行评估分析选出更优方案。</p></li></ul><h3 id="基于模型的方法"><a href="#基于模型的方法" class="headerlink" title="基于模型的方法"></a>基于模型的方法</h3><ul><li><p>思想</p><ul><li>通过机器学习算法，在数据中找出模式，并将用户与物品间的互动方式模式化</li><li>基于模型的协同过滤方式是构建协同过滤更高级的算法</li></ul></li><li><p>近邻模型的问题</p><ul><li>物品之间存在相关性, 信息量并不随着向量维度增加而线性增加</li><li>矩阵元素稀疏, 计算结果不稳定,增减一个向量维度, 导致近邻结果差异很大的情况存在</li></ul></li><li><p>算法分类</p><ul><li>基于图的模型</li><li><strong>基于矩阵分解的方法</strong></li></ul></li><li><p>基于图的模型</p><ul><li><p>基于邻域的模型看做基于图的模型的简单形式<br><img src="graph1.png" alt=""></p></li><li><p>原理</p><ul><li>将用户的行为数据表示为二分图</li><li>基于二分图为用户进行推荐</li><li>根据两个顶点之间的路径数、路径长度和经过的顶点数来评价两个顶点的相关性</li></ul></li></ul></li><li><p>基于矩阵分解的模型</p><ul><li><p>原理</p><ul><li>根据用户与物品的潜在表现，我们就可以预测用户对未评分的物品的喜爱程度</li><li>把原来的大矩阵, 近似分解成两个小矩阵的乘积, 在实际推荐计算时不再使用大矩阵, 而是使用分解得到的两个小矩阵  </li><li>用户-物品评分矩阵A是M X N维, 即一共有M个用户, N个物品 我们选一个很小的数 K (K &lt;&lt; M, K &lt;&lt; N)</li><li>通过计算得到两个矩阵U、V，U是M <em> K矩阵 , V是 N </em> K矩阵</li><li>$U<em>{m<em>k} </em> V^T</em>{n<em>k}$ 约等于 $A_{m</em>n}$<br>$U<em>{m*k} * V^{T}</em>{n*k}$ 约等于 $A_{m*n}$<br>类似这样的计算过程就是矩阵分解</li></ul></li><li><p>基于矩阵分解的方法</p><ul><li>ALS交替最小二乘<ul><li>ALS-WR(加权正则化交替最小二乘法): alternating-least-squares with weighted-λ –regularization</li><li>将用户(user)对商品(item)的评分矩阵分解为两个矩阵：一个是用户对商品隐含特征的偏好矩阵，另一个是商品所包含的隐含特征的矩阵。在这个矩阵分解的过程中，评分缺失项得到了填充，也就是说我们可以基于这个填充的评分来给用户做商品推荐了。</li></ul></li><li>SVD奇异值分解矩阵</li></ul></li></ul></li><li><p>ALS方法<br><img src="als1.png" alt=""></p><ul><li>ALS的矩阵分解算法常应用于推荐系统中，将用户(user)对商品(item)的评分矩阵，分解为用户对商品隐含特征的偏好矩阵，和商品在隐含特征上的映射矩阵。</li><li>与传统的矩阵分解SVD方法来分解矩阵R(R∈ℝm×n)不同的是，ALS(alternating least squares)希望找到两个低维矩阵，以 R̃ =XY 来逼近矩阵R，其中 ，X∈ℝm×d，Y∈ℝd×n，这样，将问题的复杂度由O(m<em>n)转换为O((m+n)</em>d)。</li><li>计算X和Y过程：首先用一个小于1的随机数初始化Y，并根据公式求X，此时就可以得到初始的XY矩阵了，根据平方差和得到的X，重新计算并覆盖Y，计算差平方和，反复进行以上两步的计算，直到差平方和小于一个预设的数，或者迭代次数满足要求则停止</li></ul></li></ul><h2 id="推荐系统评估"><a href="#推荐系统评估" class="headerlink" title="推荐系统评估"></a>推荐系统评估</h2><ul><li><p>好的推荐系统可以实现用户, 服务提供方, 内容提供方的共赢<br><img src="recommend2.png" alt=""></p></li><li><p>显示反馈和隐式反馈</p><table>  <tr>    <th></th>    <th>显式反馈</th>    <th>隐式反馈</th>  </tr>  <tr> <td> 例子 </td> <td> 电影/书籍评分  是否喜欢这个推荐 </td> <td> 播放/点击 评论 下载 购买 </td>  </tr>  <tr>    <td> 准确性 </td>    <td> 高 </td>    <td> 低 </td>  </tr>  <tr>    <td> 数量 </td>    <td> 少 </td>    <td> 多 </td>  </tr>  <tr>    <td> 获取成本 </td>    <td> 高 </td>    <td> 低 </td>  </tr></table></li><li><p>常用评估指标<br>• 准确性  • 信任度<br>• 满意度  • 实时性<br>• 覆盖率  • 鲁棒性<br>• 多样性  • 可扩展性<br>• 新颖性  • 商业⽬标<br>• 惊喜度  • ⽤户留存</p><ul><li>准确性 (理论角度) Netflix 美国录像带租赁<ul><li>评分预测<ul><li>RMSE   MAE</li></ul></li><li>topN推荐<ul><li>召回率 精准率</li></ul></li></ul></li><li><p>准确性 (业务角度)<br><img src="recommend3.png" alt=""></p></li><li><p>覆盖度</p><ul><li>信息熵 对于推荐越大越好</li><li>覆盖率</li></ul></li><li>多样性&amp;新颖性&amp;惊喜性<ul><li>多样性：推荐列表中两两物品的不相似性。（相似性如何度量？</li><li>新颖性：未曾关注的类别、作者；推荐结果的平均流⾏度</li><li>惊喜性：历史不相似（惊）但很满意（喜）</li><li>往往需要牺牲准确性</li><li>使⽤历史⾏为预测⽤户对某个物品的喜爱程度</li><li>系统过度强调实时性</li></ul></li><li>Exploitation &amp; Exploration 探索与利用问题<ul><li>Exploitation(开发 利用)：选择现在可能最佳的⽅案</li><li>Exploration(探测 搜索)：选择现在不确定的⼀些⽅案，但未来可能会有⾼收益的⽅案</li><li>在做两类决策的过程中，不断更新对所有决策的不确定性的认知，优化<br>长期的⽬标</li></ul></li><li>EE问题实践<ul><li>兴趣扩展: 相似话题, 搭配推荐</li><li>人群算法: userCF 用户聚类</li><li>平衡个性化推荐和热门推荐比例</li><li>随机丢弃用户行为历史</li><li>随机扰动模型参数</li></ul></li><li>EE可能带来的问题<ul><li>探索伤害用户体验, 可能导致用户流失</li><li>探索带来的长期收益(留存率)评估周期长, KPI压力大</li><li>如何平衡实时兴趣和长期兴趣</li><li>如何平衡短期产品体验和长期系统生态</li><li>如何平衡大众口味和小众需求</li></ul></li><li>评估方法<ul><li>问卷调查: 成本高</li><li>离线评估:<ul><li>只能在用户看到过的候选集上做评估, 且跟线上真实效果存在偏差</li><li>只能评估少数指标</li><li>速度快, 不损害用户体验</li></ul></li><li>在线评估: 灰度发布 &amp; A/B测试 50% 全量上线</li><li>实践: 离线评估和在线评估结合, 定期做问卷调查</li></ul></li></ul></li></ul><h2 id="推荐系统的冷启动问题"><a href="#推荐系统的冷启动问题" class="headerlink" title="推荐系统的冷启动问题"></a>推荐系统的冷启动问题</h2><ul><li><p>推荐系统冷启动概念</p><ul><li>⽤户冷启动：如何为新⽤户做个性化推荐</li><li>物品冷启动：如何将新物品推荐给⽤户（协同过滤）</li><li>系统冷启动：⽤户冷启动+物品冷启动</li><li>本质是推荐系统依赖历史数据，没有历史数据⽆法预测⽤户偏好</li></ul></li><li><p>用户冷启动</p><ul><li><p>1.收集⽤户特征</p><ul><li>⽤户注册信息：性别、年龄、地域</li><li>设备信息：定位、⼿机型号、app列表</li><li>社交信息、推⼴素材、安装来源<br><img src="recommend4.png" alt=""></li></ul></li><li><p>2 引导用户填写兴趣<br><img src="recommend5.png" alt=""></p></li><li><p>3 使用其它站点的行为数据, 例如腾讯视频&amp;QQ音乐 今日头条&amp;抖音</p></li><li><p>4 新老用户推荐策略的差异</p><ul><li>新⽤户在冷启动阶段更倾向于热门排⾏榜，⽼⽤户会更加需要长尾推荐</li><li>Explore Exploit⼒度</li><li>使⽤单独的特征和模型预估</li></ul></li><li><p>举例 性别与电视剧的关系<br><img src="firststart.png" alt=""><br><img src="firststart1.png" alt=""></p></li></ul></li><li><p>物品冷启动</p><ul><li>给物品打标签</li><li>利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。<br><img src="firststart2.png" alt=""></li></ul></li><li><p>系统冷启动</p><ul><li>基于内容的推荐 系统早期</li><li>基于内容的推荐逐渐过渡到协同过滤</li><li>基于内容的推荐和协同过滤的推荐结果都计算出来 加权求和得到最终推荐结果</li></ul></li></ul><h3 id="基于内容的推荐"><a href="#基于内容的推荐" class="headerlink" title="基于内容的推荐"></a>基于内容的推荐</h3><ul><li>给物品打标签<ul><li>系统自己提取从业务数据库中提取</li><li>用户填写</li><li>中文分词 利用算法计算词的权重<ul><li>TF-IDF</li><li>textrank</li></ul></li></ul></li><li>利用标签的文字 转换成词向量<ul><li>word2Vec</li><li>用向量表示语义</li><li>词向量相似度高则词义相近</li></ul></li><li>利用词向量 构建物品的向量<ul><li>一个物品有N个关键词 每个关键词对应一个词向量</li><li>求和（权重*词向量）/ N</li><li>利用N个关键词的词向量获取物品向量</li></ul></li><li>通过物品向量计算相似度<ul><li>皮尔逊 相关系数 </li></ul></li></ul><h3 id="基于内容推荐和基于物品协同过滤区别"><a href="#基于内容推荐和基于物品协同过滤区别" class="headerlink" title="基于内容推荐和基于物品协同过滤区别"></a>基于内容推荐和基于物品协同过滤区别</h3><ul><li>物品向量构建过程区别<ul><li>基于内容推荐：物品向量 文本（物品描述信息 系统填标签 用户填标签）</li><li>基于物品协同过滤：用户对物品的评分矩阵 用户的行为数据中来</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Search / Advertisement / Recommendation / Causal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Smart Search and Recommendation System Principles, Algorithm and Application</title>
      <link href="/2021/12/03/4-Smart-Search-and-Recommendation-System-Principles-Algorithm-and-Application/"/>
      <url>/2021/12/03/4-Smart-Search-and-Recommendation-System-Principles-Algorithm-and-Application/</url>
      
        <content type="html"><![CDATA[<p>《智能搜索和推荐系统原理、算法和应用》读书笔记，主要记录了搜索推荐中常用的算法，具体的算法流程需要单独记录笔记。书中代码<a href="https://github.com/michaelliu03/Search-Recommend-InAction">https://github.com/michaelliu03/Search-Recommend-InAction</a>。</p><h1 id="搜索和推荐系统的基础"><a href="#搜索和推荐系统的基础" class="headerlink" title="搜索和推荐系统的基础"></a>搜索和推荐系统的基础</h1><h2 id="概率论统计与应用数学基础知识"><a href="#概率论统计与应用数学基础知识" class="headerlink" title="概率论统计与应用数学基础知识"></a>概率论统计与应用数学基础知识</h2><h3 id="概率论基础"><a href="#概率论基础" class="headerlink" title="概率论基础"></a>概率论基础</h3><ol><li><p><strong>古典概率</strong>：可重复的实验次数N趋于无穷时，事件A发生的频率Q无限接近概率P。<script type="math/tex">lim_{N\rightarrow \infty}Q(A)=P(A)</script></p></li><li><p><strong>条件概率</strong>：已知事件B发生的情况下事件A发生的概率。<script type="math/tex">P(A|B)=\frac{P(AB)}{P(B)}</script></p></li><li><p><strong>全概率公式</strong>：将事件A分割成小事件，先求小事件的概率，相加求得事件A的概率<script type="math/tex">P(A)=P\left(A\bigcap(\bigcup^n_{i=1}B_i)\right)=\sum^n_{i=1}P(AB_i)=\sum^n_{i=1}P(B_i)P(A|B_i)</script></p></li><li><p><strong>贝叶斯公式</strong>：在大事件A发生的条件下求分割的小事件$B<em>i$发生的概率。$$P(B_i|A)=\frac{P(B_i)P(A|B_i)}{P(A)}=\frac{P(B_i)P(A|B_i)}{\sum^n</em>{i=1}P(B_i)P(A|B_i)}$$</p><script type="math/tex; mode=display">后验=\frac{先验·似然}{P(A)}</script></li><li><p><strong>基础的概率分布</strong>：</p><ul><li>0-1分布：$P(X=k)=p^k(1-p)^{1-k},k=0,1$</li><li>二项分布$B(n,p)$：$P(X=k)=C^k_np^k(1-p)^{n-k},k=0,1…n$</li><li>正态分布$N(\mu,\sigma^2)$：$\psi(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$</li><li>柏松分布</li><li>均匀分布</li><li>指数分布</li><li>几何分布</li><li>超几何分布</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binom_pmf_test</span>():</span></span><br><span class="line">  <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  离散分布</span></span><br><span class="line"><span class="string">  二项分布的例子：抛掷100次硬币，恰好两次正面朝上的概率是多少？</span></span><br><span class="line"><span class="string">  &#x27;&#x27;&#x27;</span></span><br><span class="line">  n = <span class="number">100</span>   <span class="comment"># 独立实验次数</span></span><br><span class="line">  p = <span class="number">0.5</span>   <span class="comment"># 每次正面朝上概率</span></span><br><span class="line">  k = np.arange(<span class="number">0</span>, <span class="number">100</span>)  <span class="comment"># 0-100次正面朝上概率</span></span><br><span class="line">  binomial = stats.binom.pmf(k, n, p)</span><br><span class="line">  <span class="built_in">print</span>(<span class="built_in">sum</span>(binomial))  <span class="comment"># 概率和为1</span></span><br><span class="line">  plt.plot(k, binomial, <span class="string">&#x27;o-&#x27;</span>)</span><br><span class="line">  plt.title(<span class="string">&#x27;Binomial: n=%i , p=%.2f&#x27;</span> % (n, p), fontsize=<span class="number">15</span>)</span><br><span class="line">  plt.xlabel(<span class="string">&#x27;Number of successes&#x27;</span>)</span><br><span class="line">  plt.ylabel(<span class="string">&#x27;Probability of success&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">  plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normal_distribution</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    正态分布是一种连续分布，其函数可以在实线上的任何地方取值。</span></span><br><span class="line"><span class="string">    正态分布由两个参数描述：分布的平均值μ和方差σ2 。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    mu = <span class="number">0</span>  <span class="comment"># mean</span></span><br><span class="line">    sigma = <span class="number">1</span>  <span class="comment"># standard deviation</span></span><br><span class="line">    x = np.arange(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">0.1</span>)</span><br><span class="line">    y = stats.norm.pdf(x, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.title(<span class="string">&#x27;Normal: $\mu$=%.1f, $\sigma^2$=%.1f&#x27;</span> % (mu, sigma))</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Probability density&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    binom_pmf_test()        <span class="comment"># 二项分布</span></span><br><span class="line">    normal_distribution()   <span class="comment"># 正态分布</span></span><br></pre></td></tr></table></figure><center>  <img align='center' src='binom.png' alt='二项分布'>  <div>二项分布</div>    <img align='center' src='normal.png' alt='正态分布'>  <div>正态分布</div></center><ul><li>期望$E(X)$</li><li>方差$D(X)$</li><li>标准差$\sqrt{D(X)}$</li><li>协方差$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]$</li></ul><h3 id="线性代数基础"><a href="#线性代数基础" class="headerlink" title="线性代数基础"></a>线性代数基础</h3><ol><li>矩阵</li><li>向量</li><li>张量</li><li><p><strong>特征向量和特征值</strong>：矩阵A的特征向量指与A相乘后相当于对该向量进行缩放的非0向量x，$\lambda$是相应的特征值。<script type="math/tex">Ax=\lambda x</script></p><script type="math/tex; mode=display">x^TA=\lambda x^T</script><p> 假设A有n个线性无关的特征向量${v^{(1)},…,v^{(n)}}$，V是每一列是一个特征向量的矩阵，将A特征值分解：<script type="math/tex">A=Vdiag(\lambda)V^{-1}</script></p><p> 不是每一个矩阵都能分解为特征值和特征向量，特征分解可能会涉及复数和非实数。每一个实对称矩阵都能分解为实特征向量和实特征值。<script type="math/tex">A=Q\Lambda Q^{-1}</script></p><p> 其中Q是A的特征向量组成的正交矩阵（若 $AA^T=E$，n阶实矩阵A是正交矩阵），$\Lambda$是对角矩阵。</p></li><li><p><strong>奇异值分解</strong>：可以将非方阵分解为奇异向量和奇异值。<script type="math/tex">A_{m\times n}=U_{m\times m}D_{m\times n}V^T_{n\times n}</script></p><p> U和V是正交阵，D是对角阵，对角阵上的元素称为矩阵A的奇异值，U的列向量为左奇异向量，V的列向量为右奇异向量。</p></li></ol><h3 id="机器学习基础"><a href="#机器学习基础" class="headerlink" title="机器学习基础"></a>机器学习基础</h3><ol><li>导数</li><li>梯度（矢量）</li><li><strong>最大似然估计</strong>：已知某个总体下的随机样本满足某种概率分布，概率分布的参数是未知的，经过反复试验，若某个参数使得样本出现概率最大，则这个参数值当作最大似然估计值。</li><li><p>随机过程与隐马尔可夫模型</p></li><li><p><strong>信息熵</strong>：熵是对不确定性和无序程度的预测。熵越大信息越混乱越不确定。</p><ul><li>熵：$H(X)=-\sum_{x\in R}p(x)log_2p(x)$，均匀概率分布时熵最大</li><li>联合熵：一对离散随机变量的不确定性$H(X,Y)=\sum<em>{x\in \Omega}\sum</em>{y\in \Psi}p(x,y)log_2p(x,y)$</li><li>条件熵：给定随机变量X条件下Y的条件熵$H(Y|x)=\sum_{y\in \Phi}p(y|x)log_2p(y|x)$</li><li>自信息：事件X发生的不确定性或事件包含的信息量$I(X)=-log_2P(x)$</li><li>互信息：$I(X;Y)=H(X)-H(X|Y)=log_2\frac{P(X,Y)}{P(X)P(Y)}$</li></ul></li></ol><h2 id="搜索系统和推荐系统常识"><a href="#搜索系统和推荐系统常识" class="headerlink" title="搜索系统和推荐系统常识"></a>搜索系统和推荐系统常识</h2><p><font color='bule'>ACM推荐系统大会</font></p><ol><li>搜索引擎分类：<ul><li>全文搜索引擎</li><li>元搜索引擎</li><li>垂直搜索引擎</li><li>目录搜索引擎</li></ul></li><li>推荐系统分类：<ul><li>基于内容的推荐</li><li>基于协同过滤的推荐</li><li>混合推荐方法</li></ul></li><li>推荐系统问题：<ul><li>冷启动</li><li>稀疏性</li><li>马太效应和长尾理论</li></ul></li></ol><h2 id="知识图谱相关理论"><a href="#知识图谱相关理论" class="headerlink" title="知识图谱相关理论"></a>知识图谱相关理论</h2><p>知识图谱：用图模型描述知识和建模世界万物之间关联关系的一种技术方法。组成三要素：实体、关系、属性</p><ol><li><strong>信息抽取</strong><ul><li>命名实体识别（Named Entity Recognition, NER）<ul><li>CRF</li><li>BiLSTM-CRF</li></ul></li><li>关系抽取<ul><li>基于RNN</li><li>基于CNN</li></ul></li></ul></li><li><strong>知识融合</strong><ul><li>实体对齐</li><li>实体消歧</li></ul></li><li><strong>知识加工</strong><ul><li>知识推理<ul><li>演绎推理<ul><li>基于规则的推理</li><li>马尔可夫逻辑网</li><li>概率软逻辑</li></ul></li><li>归纳推理<ul><li>归纳逻辑程序设计</li><li>关联规则挖掘</li><li>路径排序算法</li></ul></li><li>基于分布式的知识推理<ul><li>Trans模型</li><li>语义模型</li></ul></li></ul></li></ul></li><li><strong>质量评估</strong> </li></ol><h1 id="搜索系统的基本原理"><a href="#搜索系统的基本原理" class="headerlink" title="搜索系统的基本原理"></a>搜索系统的基本原理</h1><h2 id="搜索系统框架及原理"><a href="#搜索系统框架及原理" class="headerlink" title="搜索系统框架及原理"></a>搜索系统框架及原理</h2><ol><li><strong>数据收集及预处理</strong><ul><li>爬虫</li><li>数据清洗（去重算法<font color='blue'>SimHash</font>）</li><li>存储空间及分布式设计（<font color='blue'>Trie树</font>） </li></ul></li><li><strong>文本分析</strong><ul><li>查询处理<ul><li>分词方法：基于字符串、基于理解、基于统计的分词方法</li><li>查询建议 </li><li>查询更正（若样本类别不均衡，可采用上下采样）<ul><li>意图理解</li><li>其他方法</li></ul></li><li>层次聚类<ul><li>分类：凝聚式（自底向上）、分裂式（自顶向下）</li><li>求距离/相似度方法：闵可夫斯基距离（P范数）、马氏距离、相关系数、夹角余弦</li></ul></li><li>K均值聚类：采用欧式距离，初始聚类中心可考虑采用层次聚类</li><li>LDA主题模型<ul><li>LSA（Latent Senmantic Analysis）</li><li>PLSA（Probability LSA）</li><li>LDA（Latent Dirichlet Allocation）</li></ul></li></ul></li></ul></li><li>基于知识图谱的搜索系统</li></ol><h2 id="搜索系统中的主要算法"><a href="#搜索系统中的主要算法" class="headerlink" title="搜索系统中的主要算法"></a>搜索系统中的主要算法</h2><ol><li>信息检索基本模型<ul><li>布尔模型</li><li>向量空间模型（权重计算：TF-IDF）</li><li>概率检索模型（二元独立概率模型<font color='blue'>BIM</font>）</li><li>其他模型：基于集合论、基于代数论、基于概率统计的模型</li></ul></li><li>搜索和机器学习<ul><li>排序学习：单文档方法（CTR）、文档对方法（Boost、SVM、NN）、文档列表方法</li><li>示例：LR、AdaBoost、随机森林（海森矩阵：多元函数的二阶偏导构成的矩阵）</li></ul></li><li>搜索和深度学习<ul><li>DNN</li><li>DSSM（Deep Structured Semantic MOdels）</li><li>Transformer：编码、解码、Softmax与线性变换</li></ul></li></ol><h2 id="搜索系统评价"><a href="#搜索系统评价" class="headerlink" title="搜索系统评价"></a>搜索系统评价</h2><ol><li>效率评价：响应时间和开销、索引量</li><li>效果评价<ul><li>准确率和召回率</li><li>平均化和插值</li><li>排序靠前文档质量<ul><li>MRR（Mean Reciprocal Rank）</li><li>DCG（Normalized Discounted Cumulative Gain）</li></ul></li></ul></li></ol><h1 id="推荐系统的基本原理"><a href="#推荐系统的基本原理" class="headerlink" title="推荐系统的基本原理"></a>推荐系统的基本原理</h1><h2 id="推荐系统框架及原理"><a href="#推荐系统框架及原理" class="headerlink" title="推荐系统框架及原理"></a>推荐系统框架及原理</h2><p>预测+排序+可解释性</p><ol><li>基本框架：离线层、存储层、在线层</li><li>经典问题<ul><li>探索和利用（Exploration &amp; Exploitation, EE）<ul><li>贝叶斯方法</li><li>极小/极大方法</li><li>启发式赌博方案</li></ul></li><li>冷启动问题<ul><li>利用热门数据</li><li>利用用户注册信息</li><li>利用第三方数据</li><li>利用物品内容属性</li><li>利用专家标注数据</li></ul></li></ul></li><li>推荐系统的找回策略<ul><li>基于行为相似的召回<ul><li>相似度算法：Jacard相似度、余弦相似度、欧几里得相似度、皮尔逊相关系数</li></ul></li><li>基于内容相似的召回<ul><li>Hoffman编码及Hoffman Tree</li><li>CBow-Hierarchical Softmax</li><li>Skip-Gram-Hierarchical Softmax</li></ul></li></ul></li><li>推荐系统排序<ul><li>特征预处理：特征选择</li><li>排序模型<ul><li>线性模型 LR、FM、FFM</li><li>树模型 GDBT</li><li>深度学习模型</li><li>组合模型 GDBT+LR</li></ul></li></ul></li><li>基于知识图谱的推荐系统<ul><li>依次学习</li><li>联合学习</li><li>交替学习</li></ul></li></ol><h2 id="推荐系统的主要算法"><a href="#推荐系统的主要算法" class="headerlink" title="推荐系统的主要算法"></a>推荐系统的主要算法</h2><ol><li>矩阵分解<ul><li>奇异值分解 SVD</li><li>交替最小二乘 ACS，Alterating LeastSquares<ul><li>贝叶斯个性化排序</li></ul></li></ul></li><li>线性模型<ul><li>因子分解机 FM，Factorization Machine</li><li>FFM，Field-aware FM</li></ul></li><li>树模型<ul><li>决策树 ID3、CART、C4.5</li><li>集成算法 梯度提升决策树（Gradient Boosting Decision Tree,  GDBT）</li><li>GDBT+LR</li><li>eXtreme Gradient Boosting, XGBoost</li><li>LightGBM GOSS（Gradient-based One-side Sampling）+EFB（Exclusive Feature Bunding）</li></ul></li><li>深度学习模型<ul><li>Wide &amp; Deep model<ul><li>AdaGrad</li><li>FTRL（FOBOS+RDA）</li></ul></li><li>Deep FM model </li></ul></li></ol><h2 id="推荐系统的评价"><a href="#推荐系统的评价" class="headerlink" title="推荐系统的评价"></a>推荐系统的评价</h2><ol><li>推荐系统维度<ul><li>RMSE（Root Mean Squre Error）+R方</li><li>MAP（Mean Average Precision）+ MRR（Mean Reciprocal Rank）</li><li>AUC + ROC</li></ul></li><li>离线评估：准确率、覆盖率、多样性、实时性、Robost</li><li>在线评估：A/B实验、Interleaving</li></ol><h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><h2 id="搜索引擎工具"><a href="#搜索引擎工具" class="headerlink" title="搜索引擎工具"></a>搜索引擎工具</h2><ol><li>Lucene</li><li>Solr</li><li>Elasticsearch</li></ol><h2 id="搜索应用实战：基于电商的搜索开发"><a href="#搜索应用实战：基于电商的搜索开发" class="headerlink" title="搜索应用实战：基于电商的搜索开发"></a>搜索应用实战：基于电商的搜索开发</h2><h2 id="推荐应用实战：基于广告平台的推荐"><a href="#推荐应用实战：基于广告平台的推荐" class="headerlink" title="推荐应用实战：基于广告平台的推荐"></a>推荐应用实战：基于广告平台的推荐</h2>]]></content>
      
      
      <categories>
          
          <category> Search / Advertisement / Recommendation / Causal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> python </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tree</title>
      <link href="/2021/11/01/3-Tree/"/>
      <url>/2021/11/01/3-Tree/</url>
      
        <content type="html"><![CDATA[<p>树一般有两种解题方式：</p><ul><li>递归：确定递归条件和终止条件</li><li>迭代：利用队列或栈这两种数据结构实现，一般层次遍历用队列实现，前序遍历、中序遍历、后序遍历用栈实现</li></ul><p>稍微复杂的问题般都会结合<strong>DFS</strong>和<strong>回溯</strong></p><h1 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h1><ul><li>特殊二叉树包括：<ol><li>完全⼆叉树（Complete Binary Tree）：每⼀层都是紧凑靠左排列，计算节点数的时间复杂度是$O(logN*logN)$</li><li>满⼆叉树（Perfect Binary Tree）：每层都是是满的，节点数 = 2^树高 - 1，计算节点数的时间复杂度是$O(logN)$</li><li>Full Binary Tree：⼆叉树的所有节点要么没有孩⼦节点，要么有两个孩⼦节点</li></ol></li></ul><h2 id="二叉树的实现"><a href="#二叉树的实现" class="headerlink" title="二叉树的实现"></a>二叉树的实现</h2><p>以下代码实现了二叉树的初始化及增加节点函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;节点类&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val=-<span class="number">1</span>, left=<span class="literal">None</span>, right=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tree</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;树类&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.root = Node()</span><br><span class="line">        self.myQueue = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">self, val</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;为树添加节点&quot;&quot;&quot;</span></span><br><span class="line">        node = Node(val)</span><br><span class="line">        <span class="keyword">if</span> self.root.val == -<span class="number">1</span>:  <span class="comment"># 如果树是空的，则对根节点赋值</span></span><br><span class="line">            self.root = node</span><br><span class="line">            self.myQueue.append(self.root)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            treeNode = self.myQueue[<span class="number">0</span>]  <span class="comment"># 此结点的子树还没有齐</span></span><br><span class="line">            <span class="keyword">if</span> treeNode.left == <span class="literal">None</span>:</span><br><span class="line">                treeNode.left = node</span><br><span class="line">                self.myQueue.append(treeNode.left)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                treeNode.right = node</span><br><span class="line">                self.myQueue.append(treeNode.right)</span><br><span class="line">                self.myQueue.pop(<span class="number">0</span>)  <span class="comment"># 如果该结点存在右子树，将此结点丢弃</span></span><br></pre></td></tr></table></figure></p><h2 id="二叉树的遍历"><a href="#二叉树的遍历" class="headerlink" title="二叉树的遍历"></a>二叉树的遍历</h2><h3 id="递归法"><a href="#递归法" class="headerlink" title="递归法"></a>递归法</h3><p>以下代码实现了二叉树的前序（跟左右）、中序（左跟右）、后序（左右跟）遍历<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">front_recursive</span>(<span class="params">self, root</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;利用递归实现树的先序遍历&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="built_in">print</span>(root.val, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    self.front_recursive(root.left)</span><br><span class="line">    self.front_recursive(root.right)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">middle_recursive</span>(<span class="params">self, root</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;利用递归实现树的中序遍历&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    self.middle_recursive(root.left)</span><br><span class="line">    <span class="built_in">print</span>(root.val, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    self.middle_recursive(root.right)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">later_recursive</span>(<span class="params">self, root</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;利用递归实现树的后序遍历&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    self.later_recursive(root.left)</span><br><span class="line">    self.later_recursive(root.right)</span><br><span class="line">    <span class="built_in">print</span>(root.val, end=<span class="string">&#x27; &#x27;</span>)</span><br></pre></td></tr></table></figure></p><h3 id="迭代法"><a href="#迭代法" class="headerlink" title="迭代法"></a>迭代法</h3><p>以下代码实现了二叉树的前序、中序、后序、层次遍历<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">front_stack</span>(<span class="params">self, root</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;利用堆栈实现树的先序遍历&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    myStack = []</span><br><span class="line">    node = root</span><br><span class="line">    <span class="keyword">while</span> node <span class="keyword">or</span> myStack:</span><br><span class="line">        <span class="keyword">while</span> node:               <span class="comment"># 从根节点开始，一直找它的左子树</span></span><br><span class="line">            <span class="built_in">print</span>(node.val, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">            myStack.append(node)</span><br><span class="line">            node = node.left</span><br><span class="line">        node = myStack.pop()      <span class="comment"># while结束表示当前节点node为空，即前一个节点没有左子树了</span></span><br><span class="line">        node = node.right</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">middle_stack</span>(<span class="params">self, root</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;利用堆栈实现树的中序遍历&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    myStack = []</span><br><span class="line">    node = root</span><br><span class="line">    <span class="keyword">while</span> node <span class="keyword">or</span> myStack:</span><br><span class="line">        <span class="keyword">while</span> node:              <span class="comment"># 从根节点开始，一直找它的左子树</span></span><br><span class="line">            myStack.append(node)</span><br><span class="line">            node = node.left</span><br><span class="line">        node = myStack.pop()</span><br><span class="line">        <span class="built_in">print</span>(node.val, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        node = node.right</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">later_stack</span>(<span class="params">self, root</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;利用堆栈实现树的后序遍历&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    myStack1 = []</span><br><span class="line">    myStack2 = []</span><br><span class="line">    node = root</span><br><span class="line">    myStack1.append(node)</span><br><span class="line">    <span class="keyword">while</span> myStack1:                   <span class="comment"># 找出后序遍历的逆序存在myStack2里</span></span><br><span class="line">        node = myStack1.pop()</span><br><span class="line">        <span class="keyword">if</span> node.left:</span><br><span class="line">            myStack1.append(node.left)</span><br><span class="line">        <span class="keyword">if</span> node.right:</span><br><span class="line">            myStack1.append(node.right)</span><br><span class="line">        myStack2.append(node)</span><br><span class="line">    <span class="keyword">while</span> myStack2:                   <span class="comment"># 将myStack2中的元素出栈，即为后序遍历次序</span></span><br><span class="line">        <span class="built_in">print</span>(myStack2.pop().val, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">level_queue</span>(<span class="params">self, root</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;利用队列实现树的层次遍历&quot;&quot;&quot;</span></span><br><span class="line">    l2 = []</span><br><span class="line">    cur_layer = [root]</span><br><span class="line">    <span class="keyword">while</span> cur_layer <span class="keyword">and</span> root:</span><br><span class="line">        l1, next_layer = [], []</span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> cur_layer:</span><br><span class="line">            l1.append(node.val)</span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                next_layer.append(node.left)</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                next_layer.append(node.right)</span><br><span class="line">        cur_layer = next_layer</span><br><span class="line">        l2.append(l1)</span><br><span class="line">    <span class="keyword">return</span> l2</span><br></pre></td></tr></table></figure></p><h3 id="Morris遍历"><a href="#Morris遍历" class="headerlink" title="Morris遍历"></a>Morris遍历</h3><p>二叉树的递归和迭代遍历都需要借助栈，空间复杂度为$O(h)$，其中$h$指二叉树的最大高度。而Morris遍历的时间复杂度为$O(n)$，空间复杂度为$O(1)$。其遍历规则如下：</p><ul><li>设当前遍历的节点为cur，若cur无左子树，则<code>cur = cur.right</code></li><li>若cur有左子树，找到cur左子树的最右节点记为mostRight<ul><li>若mostRight的右子树为空，则令<code>mostRight.right = cur, cur = cur.left</code></li><li>若此时<code>mostRight.right = cur</code>，则令<code>mostRight.right = None, cur = cur.right</code></li></ul></li></ul><p><strong>代码实现</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">morris</span>(<span class="params">self, root, order</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;实现Morris遍历&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    cur = root</span><br><span class="line">    <span class="keyword">while</span> cur:</span><br><span class="line">        <span class="keyword">if</span> cur.left <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="built_in">print</span>(cur.val, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">            cur = cur.right</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mostRight = cur.left</span><br><span class="line">            <span class="keyword">while</span> mostRight.right <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> mostRight.right != cur:</span><br><span class="line">                mostRight = mostRight.right</span><br><span class="line">            <span class="keyword">if</span> mostRight.right <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                mostRight.right = cur</span><br><span class="line">                <span class="comment"># 先序遍历</span></span><br><span class="line">                <span class="keyword">if</span> order == <span class="string">&#x27;front&#x27;</span>:</span><br><span class="line">                    <span class="built_in">print</span>(cur.val, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">                cur = cur.left</span><br><span class="line">            <span class="keyword">elif</span> mostRight.right == cur:</span><br><span class="line">                <span class="comment"># 中序遍历</span></span><br><span class="line">                <span class="keyword">if</span> order == <span class="string">&#x27;middle&#x27;</span>:</span><br><span class="line">                    <span class="built_in">print</span>(cur.val, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">                mostRight.right = <span class="literal">None</span></span><br><span class="line">                cur = cur.right</span><br></pre></td></tr></table></figure><br>Morris遍历的后序遍历有点麻烦，具体可以看参考文献</p><h3 id="测试及结果"><a href="#测试及结果" class="headerlink" title="测试及结果"></a>测试及结果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;主函数&quot;&quot;&quot;</span></span><br><span class="line">    vals = <span class="built_in">range</span>(<span class="number">10</span>)           <span class="comment"># 生成十个数据作为树节点</span></span><br><span class="line">    tree = Tree()</span><br><span class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> vals:</span><br><span class="line">        tree.add(val)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;队列实现层次遍历:&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(tree.level_queue(tree.root))  <span class="comment"># [[0], [1, 2], [3, 4, 5, 6], [7, 8, 9]]</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n\n递归实现先序遍历:&#x27;</span>)</span><br><span class="line">    tree.front_recursive(tree.root)     <span class="comment"># 0 1 3 7 8 4 9 2 5 6</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n递归实现中序遍历:&#x27;</span>)</span><br><span class="line">    tree.middle_recursive(tree.root)    <span class="comment"># 7 3 8 1 9 4 0 5 2 6</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n递归实现后序遍历:&#x27;</span>)</span><br><span class="line">    tree.later_recursive(tree.root)     <span class="comment"># 7 8 3 9 4 1 5 6 2 0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n\n堆栈实现先序遍历:&#x27;</span>)</span><br><span class="line">    tree.front_stack(tree.root)         <span class="comment"># 0 1 3 7 8 4 9 2 5 6</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n堆栈实现中序遍历:&#x27;</span>)</span><br><span class="line">    tree.middle_stack(tree.root)        <span class="comment"># 7 3 8 1 9 4 0 5 2 6</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n堆栈实现后序遍历:&#x27;</span>)</span><br><span class="line">    tree.later_stack(tree.root)         <span class="comment"># 7 8 3 9 4 1 5 6 2 0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nMorris先序遍历：&#x27;</span>)</span><br><span class="line">    tree.morris(tree.root, <span class="string">&#x27;front&#x27;</span>)     <span class="comment"># 0 1 3 7 8 4 9 2 5 6</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nMorris中序遍历：&#x27;</span>)</span><br><span class="line">    tree.morris(tree.root, <span class="string">&#x27;middle&#x27;</span>)    <span class="comment"># 7 3 8 1 9 4 0 5 2 6</span></span><br></pre></td></tr></table></figure><h2 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h2><ul><li>简介：⼆叉搜索树（Binary Search Tree，BST）定义：⼀个⼆叉树中，任意节点的值要⼤于等于左⼦树所有节点的值，且要⼩于等于右边⼦树的所有节点的值。</li><li>性质：<ul><li>每个节点中的值必须大于或等于其左子树中的任何值</li><li>每个节点中的值必须小于或等于其右子树中的任何值</li><li>二叉搜索树<strong>中序遍历</strong>时，结果依此递增</li></ul></li></ul><h1 id="N叉树"><a href="#N叉树" class="headerlink" title="N叉树"></a>N叉树</h1><p>树的每个节点可以有两个以上的子节点，称为m阶的多叉树或m叉树</p><p><strong>节点实现</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val=<span class="literal">None</span>, children=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.children = children</span><br></pre></td></tr></table></figure></p><h2 id="前缀树（字典树）"><a href="#前缀树（字典树）" class="headerlink" title="前缀树（字典树）"></a>前缀树（字典树）</h2><p>Trie，前缀树或字典树，是一种树形数据结构，用于高效地存储和检索字符串数据集中的键。前缀树的节点可以是任意一个字符集中的字符，如对于都是小写字母的字符串，字符集就是’a’-‘z’；对于都是数字的字符串，字符集就是’0’-‘9’；对于二进制字符串，字符集就是0和1。前缀树有相当多的应用情景，例如自动补完和拼写检查。</p><p><strong>代码实现</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trie</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    实现一个字符集为小写英文字母的前缀树</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Initialize data structure.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.children = [<span class="literal">None</span>] * <span class="number">26</span></span><br><span class="line">        self.isEnd = <span class="literal">False</span>  <span class="comment"># 该节点是否是字符串的结尾</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">searchPrefix</span>(<span class="params">self, prefix</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        return None if prefix not in trie else the end of the prefix</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        node = self</span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> prefix:</span><br><span class="line">            ch = <span class="built_in">ord</span>(ch) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.children[ch]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">            node = node.children[ch]</span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span>(<span class="params">self, word: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Inserts a word into the trie.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        node = self</span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> word:</span><br><span class="line">            ch = <span class="built_in">ord</span>(ch) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.children[ch]:</span><br><span class="line">                <span class="comment"># 子节点不存在，创建一个新的子节点</span></span><br><span class="line">                node.children[ch] = Trie()</span><br><span class="line">            node = node.children[ch]</span><br><span class="line">        node.isEnd = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self, word: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Returns if the word is in the trie.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        node = self.searchPrefix(word)</span><br><span class="line">        <span class="keyword">return</span> node <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> node.isEnd</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">startsWith</span>(<span class="params">self, prefix: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Returns if there is any word in the trie that starts with the given prefix.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.searchPrefix(prefix) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    trie = Trie()</span><br><span class="line">    trie.insert(<span class="string">&quot;apple&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(trie.search(<span class="string">&quot;apple&quot;</span>))     <span class="comment"># True</span></span><br><span class="line">    <span class="built_in">print</span>(trie.search(<span class="string">&quot;app&quot;</span>))       <span class="comment"># False</span></span><br><span class="line">    <span class="built_in">print</span>(trie.startsWith(<span class="string">&quot;app&quot;</span>))   <span class="comment"># True</span></span><br><span class="line">    trie.insert(<span class="string">&quot;app&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(trie.search(<span class="string">&quot;app&quot;</span>))       <span class="comment"># True</span></span><br></pre></td></tr></table></figure><br><strong>复杂度分析：</strong></p><ul><li>时间复杂度：<br>初始化为$O(1)$，其余操作为$O(|S|)$，$|S|$是每次插入或查询的字符串长度</li><li>空间复杂度：<br>$O(|T|·\Sigma)$，其中$|T|$为所有插入字符串的长度之和，$\Sigma$为字符集的大小，代码中$\Sigma=26$</li></ul><h1 id="其他特殊结构"><a href="#其他特殊结构" class="headerlink" title="其他特殊结构"></a>其他特殊结构</h1><ul><li>线段树</li><li>霍夫曼树</li><li>B树</li><li>红黑树</li></ul><h1 id="力扣指南"><a href="#力扣指南" class="headerlink" title="力扣指南"></a>力扣指南</h1><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://blog.csdn.net/qq_30210107/article/details/88146252?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161182307616780274187603%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=161182307616780274187603&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-1-88146252.pc_search_result_hbase_insert&amp;utm_term=二叉树的遍历迭代法python&amp;spm=1018.2226.3001.4187">二叉树遍历和迭代方法</a></li><li><a href="https://blog.csdn.net/heshiliqiu/article/details/111540928?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161183582816780271554041%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=161183582816780271554041&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~hot_rank-2-111540928.first_rank_v2_pc_rank_v29_10&amp;utm_term=morris遍历&amp;spm=1018.2226.3001.4187">Morris遍历的图示理解以及代码实现</a></li><li><a href="https://blog.csdn.net/zearot/article/details/48299459?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522163833033716780271977440%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=163833033716780271977440&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-48299459.pc_search_all_es&amp;utm_term=线段树&amp;spm=1018.2226.3001.4187">线段树详解 （原理，实现与应用）</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Structures and Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structures and Algorithms </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ensemble  Learning</title>
      <link href="/2021/10/27/1-Ensemble-Learning/"/>
      <url>/2021/10/27/1-Ensemble-Learning/</url>
      
        <content type="html"><![CDATA[<h1 id="集成学习简介"><a href="#集成学习简介" class="headerlink" title="集成学习简介"></a>集成学习简介</h1><p><strong>集成学习</strong>（Ensemble Learning）通过构建并结合多个学习器来完成学习任务，也被称为多分类器系统（multi-classifier system）、基于委员会的学习（committee-based leLrning）等。</p><p>集成学习的原理可以简洁概括为综合对样本有不同鉴别力的分类器的优势，使错误率最小。通过产生一组个体学习器，再用某种策略将其结合起来。<font color='blue'>个体学习器</font>由一个现有学习算法从训练数据中产生，如决策树算法、BP神经网络算法等，集成中至包含同种类型的个体学习器称为<font color='blue'>基学习器</font>，相应算法为<font color='blue'>基学习算法</font>，基学习器也被称为<font color='blue'>弱学习器</font>。集成中包含不同类型的基学习器称为<font color='blue'>异质集成</font>，相应的称为<font color='blue'>组件学习器</font>。</p><p>通常要求基学习器相互独立且正确率大于50%，性能好切具有多样性的基分类器结合效果较优。根据个体学习器的生成方式，集成学习大致分为两类：</p><ul><li>个体学习器间存在强依赖关系、串行生成的序列化方法，如Boosting</li><li>个体学习器间不存在强依赖关系、可同时生成的并行化方法，如Bagging和随机森林（Random Forest）</li></ul><h1 id="集成学习方法"><a href="#集成学习方法" class="headerlink" title="集成学习方法"></a>集成学习方法</h1><h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>Boosting一族可将弱学习器提升为强学习器，最著名的代表为AdaBoost，这类算法流程如下：</p><ol><li>从初始训练集训练出一个基学习器</li><li>根据基学习器表现调整训练样本分布，加大对做错训练样本的关注，基于调整后的样本分布训练下一个基学习器</li><li>重复步骤2，直至基学习器数量达到指定期望$T$个基学习器加权结合</li></ol><center>  <img align='center' src='AdaBoost.jpg' alt='AdaBoost算法'>  <div>AdaBoost算法</div></center><p><strong>代码实现</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> imageio</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons, make_circles</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="keyword">import</span> plotly.graph_objs <span class="keyword">as</span> go</span><br><span class="line"><span class="keyword">from</span> plotly.offline <span class="keyword">import</span> download_plotlyjs, init_notebook_mode, plot, iplot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Adaboost_Demonstration</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, X, y, learning_rate=<span class="number">1.</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        输入的X为N*2矩阵, y为一维向量, y的值只能取1或-1</span></span><br><span class="line"><span class="string">        :param X: 数据点</span></span><br><span class="line"><span class="string">        :param y: 数据点标记</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.X = X</span><br><span class="line">        self.y = y</span><br><span class="line">        <span class="comment"># 给每个弱分类器一个衰减, 避免过拟合</span></span><br><span class="line">        self.learning_rate = learning_rate</span><br><span class="line">        <span class="comment"># 样本的个数</span></span><br><span class="line">        self.num_samples = <span class="built_in">len</span>(self.X)</span><br><span class="line">        <span class="comment"># 初始化数据样本的权重（设为等值）</span></span><br><span class="line">        self.sample_weight = np.full(self.num_samples, <span class="number">1</span> / self.num_samples)</span><br><span class="line">        <span class="comment"># 存储所有的弱分类器对象</span></span><br><span class="line">        self.classifiers = []</span><br><span class="line">        <span class="comment"># 储存在每一步的错误率</span></span><br><span class="line">        self.errors_list = []</span><br><span class="line">        <span class="comment"># 定义弱分类器, 直接调用sklearn的决策树, max_depth=1代表一层决策树, 即决策树桩</span></span><br><span class="line">        self.alphas = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, data=<span class="literal">None</span>, labels=<span class="literal">None</span>, reduction=<span class="string">&quot;sign&quot;</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        预测数据点的分类</span></span><br><span class="line"><span class="string">        :param reduction: &quot;sign&quot;对弱分类的线性加权组合取符号, &quot;mean&quot;取平均</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> data <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            data = self.X</span><br><span class="line">            labels = self.y</span><br><span class="line">        <span class="comment"># 计算弱分类器线性加权组合的结果</span></span><br><span class="line">        predictions = np.zeros([<span class="built_in">len</span>(data)]).astype(<span class="string">&quot;float&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> classifier, alpha <span class="keyword">in</span> <span class="built_in">zip</span>(self.classifiers, self.alphas):</span><br><span class="line">            predictions += alpha * classifier.predict(data)</span><br><span class="line">        <span class="comment"># 对结果取符号</span></span><br><span class="line">        <span class="keyword">if</span> reduction == <span class="string">&quot;sign&quot;</span>:</span><br><span class="line">            predictions = np.sign(predictions)</span><br><span class="line">        <span class="comment"># 对结果求均值</span></span><br><span class="line">        <span class="keyword">elif</span> reduction == <span class="string">&quot;mean&quot;</span>:</span><br><span class="line">            predictions /= <span class="built_in">len</span>(self.classifiers)</span><br><span class="line">        <span class="comment"># 如果可以的话获取f1 score</span></span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> reduction == <span class="string">&quot;sign&quot;</span>:</span><br><span class="line">            f1 = f1_score(predictions, labels)</span><br><span class="line">            <span class="keyword">return</span> predictions, f1</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">contour_plot</span>(<span class="params">self, data=<span class="literal">None</span>, labels=<span class="literal">None</span>, interval=<span class="number">0.2</span>, title=<span class="string">&quot;adaboost&quot;</span>, mode=<span class="string">&quot;3d&quot;</span>, epoch=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        等高线图可视化</span></span><br><span class="line"><span class="string">        :param interval: 等高线图网格的间隔</span></span><br><span class="line"><span class="string">        :param title: 等高线图的标题</span></span><br><span class="line"><span class="string">        :param mode: 可选3D或2D可视化</span></span><br><span class="line"><span class="string">        :param epoch: 迭代次数</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> data <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            data = self.X</span><br><span class="line">            labels = self.y</span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            labels = np.ones([<span class="built_in">len</span>(data)])</span><br><span class="line">        <span class="comment"># 获取网格</span></span><br><span class="line">        x_min, x_max = data[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">.5</span>, data[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">.5</span></span><br><span class="line">        y_min, y_max = data[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">.5</span>, data[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">.5</span></span><br><span class="line">        xx, yy = np.meshgrid(np.arange(x_min, x_max, interval), np.arange(y_min, y_max, interval))</span><br><span class="line">        <span class="comment"># 将网格的X, Y轴拼接用来进行等高线的计算</span></span><br><span class="line">        X_grid = np.concatenate([np.expand_dims(np.ravel(xx), axis=-<span class="number">1</span>),</span><br><span class="line">                                 np.expand_dims(np.ravel(yy), axis=-<span class="number">1</span>)], axis=-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># X_grid的形状[batch(数据点数量), 2]</span></span><br><span class="line">        <span class="comment"># 计算分类边界(等高线)</span></span><br><span class="line">        Z_grid = self.predict(data=X_grid, reduction=<span class="string">&quot;mean&quot;</span>)</span><br><span class="line">        Z_grid = Z_grid.reshape(xx.shape)</span><br><span class="line">        <span class="comment"># 可视化</span></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&quot;3d&quot;</span>:</span><br><span class="line">            <span class="comment"># 数据点画散点图</span></span><br><span class="line">            scatter = go.Scatter3d(x=data[:, <span class="number">0</span>], y=data[:, <span class="number">1</span>], z=self.predict(data=data, reduction=<span class="string">&quot;mean&quot;</span>),</span><br><span class="line">                                   mode=<span class="string">&#x27;markers&#x27;</span>,</span><br><span class="line">                                   marker=<span class="built_in">dict</span>(color=labels, size=<span class="number">5</span>, symbol=<span class="string">&#x27;circle&#x27;</span>,</span><br><span class="line">                                               line=<span class="built_in">dict</span>(color=<span class="string">&#x27;rgb(204, 204, 204)&#x27;</span>, width=<span class="number">1</span>),</span><br><span class="line">                                               opacity=<span class="number">0.9</span>))</span><br><span class="line">            <span class="comment"># 等高线3D轮廓图</span></span><br><span class="line">            surface = go.Surface(x=xx, y=yy, z=Z_grid, opacity=<span class="number">0.9</span>)</span><br><span class="line">            plot_data = [scatter, surface]</span><br><span class="line">            layout = go.Layout(title=title)</span><br><span class="line">            <span class="comment"># 设置视角</span></span><br><span class="line">            camera = <span class="built_in">dict</span>(up=<span class="built_in">dict</span>(x=<span class="number">0</span>, y=<span class="number">0</span>, z=<span class="number">1</span>),</span><br><span class="line">                          center=<span class="built_in">dict</span>(x=<span class="number">0</span>, y=<span class="number">0</span>, z=<span class="number">0</span>),</span><br><span class="line">                          eye=<span class="built_in">dict</span>(x=<span class="number">1</span>, y=<span class="number">1</span>, z=<span class="number">0.8</span>))</span><br><span class="line">            fig = go.Figure(data=plot_data, layout=layout)</span><br><span class="line">            fig[<span class="string">&#x27;layout&#x27;</span>].update(scene=<span class="built_in">dict</span>(camera=camera))</span><br><span class="line">            iplot(fig, image=<span class="string">&quot;png&quot;</span>, filename=title)</span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&quot;2d&quot;</span>:</span><br><span class="line">            <span class="comment"># 等高线</span></span><br><span class="line">            plt.contourf(xx, yy, Z_grid, cmap=plt.cm.RdBu, alpha=<span class="number">.8</span>)</span><br><span class="line">            <span class="comment"># 散点</span></span><br><span class="line">            plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>], c=labels,</span><br><span class="line">                        cmap=ListedColormap([<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>]), edgecolors=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">            plt.title(title)</span><br><span class="line">            <span class="comment"># plt.show()</span></span><br><span class="line">            plt.savefig(<span class="string">&#x27;imgs/&#x27;</span> + <span class="string">&#x27;res&#x27;</span> + <span class="built_in">str</span>(epoch))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span>(<span class="params">self, reduction=<span class="string">&quot;mean&quot;</span>, plot=<span class="literal">True</span>, plot_mode=<span class="string">&quot;2d&quot;</span>, epoch=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># 定义弱分类器(决策树桩)</span></span><br><span class="line">        <span class="comment">#         classifier = DecisionTreeClassifier(</span></span><br><span class="line">        <span class="comment">#                        max_depth=2,min_samples_split=20,</span></span><br><span class="line">        <span class="comment">#                        min_samples_leaf=5)</span></span><br><span class="line">        classifier = DecisionTreeClassifier(max_depth=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 用弱分类器拟合数据</span></span><br><span class="line">        classifier.fit(self.X, self.y, sample_weight=self.sample_weight)</span><br><span class="line">        <span class="comment"># 得到弱分类器对数据的推断, 也就是h(x)</span></span><br><span class="line">        predictions = classifier.predict(self.X)</span><br><span class="line">        <span class="comment"># 计算错误率</span></span><br><span class="line">        error_rate = np.mean(np.average((predictions != self.y), weights=self.sample_weight))</span><br><span class="line">        <span class="comment"># 计算alpha</span></span><br><span class="line">        alpha = self.learning_rate * (np.log((<span class="number">1</span> - error_rate) / error_rate)) / <span class="number">2</span></span><br><span class="line">        <span class="comment"># 计算t+1的权重</span></span><br><span class="line">        self.sample_weight *= np.exp(-alpha * self.y * predictions)</span><br><span class="line">        <span class="comment"># 归一化, 归一化因子为Z: sum(self.sample_weight)</span></span><br><span class="line">        self.sample_weight /= np.<span class="built_in">sum</span>(self.sample_weight)</span><br><span class="line">        <span class="comment"># 记录当前弱分类器对象</span></span><br><span class="line">        self.classifiers.append(classifier)</span><br><span class="line">        <span class="comment"># 记录当前弱分类器权重</span></span><br><span class="line">        self.alphas.append(alpha)</span><br><span class="line">        <span class="comment"># 计算f1 score</span></span><br><span class="line">        _, f1 = self.predict()</span><br><span class="line">        <span class="comment"># 画图</span></span><br><span class="line">        <span class="keyword">if</span> plot:</span><br><span class="line">            <span class="keyword">return</span> self.contour_plot(</span><br><span class="line">                title=<span class="string">&quot;adaboost step &quot;</span> + <span class="built_in">str</span>(<span class="built_in">len</span>(self.classifiers)) + <span class="string">&quot; f1 score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(f1), mode=plot_mode, epoch=epoch)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> f1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_gif</span>(<span class="params">epochs</span>):</span></span><br><span class="line">    outfile = <span class="string">&#x27;gifs/adaboost.gif&#x27;</span></span><br><span class="line">    filenames = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        filename = <span class="string">&#x27;imgs/res&#x27;</span> + <span class="built_in">str</span>(i) + <span class="string">&#x27;.png&#x27;</span></span><br><span class="line">        filenames.append(filename)</span><br><span class="line">    frames = []</span><br><span class="line">    <span class="keyword">for</span> image_name <span class="keyword">in</span> filenames:</span><br><span class="line">        img = imageio.imread(image_name)</span><br><span class="line">        frames.append(img)</span><br><span class="line">    imageio.mimsave(outfile, frames, <span class="string">&#x27;GIF&#x27;</span>, duration=<span class="string">&#x27;0.1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 测试</span></span><br><span class="line">    X, y = make_moons(n_samples=<span class="number">300</span>, noise=<span class="number">0.2</span>, random_state=<span class="number">3</span>)</span><br><span class="line">    y[np.where(y == <span class="number">0</span>)] = -<span class="number">1</span></span><br><span class="line">    model = Adaboost_Demonstration(X, y)</span><br><span class="line">    epochs = <span class="number">100</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        model.__next__(plot=<span class="literal">False</span>, epoch=i)</span><br><span class="line">    model.contour_plot(mode=<span class="string">&quot;2d&quot;</span>)</span><br><span class="line">    <span class="comment"># convert_gif(epochs)</span></span><br></pre></td></tr></table></figure><br><strong>运行结果</strong></p><center>  <img align='center' src='adaboost.gif'>  <div>AdaBoost算法运行结果</div></center><h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>Bagging是并行式集成学习方法最著名的代表，其算法流程如下：</p><ol><li>首先进行自助采样（bootstrap sampling），有放回的从给定包含$m$个训练样本的数据集中随机采样出$T$个含$m$个样本的采样集</li><li>基于每个采样集训练出一个基学习器</li><li>将基学习器按照某种策略结合，一般采用投票策略</li></ol><center>  <img align='center' src='Bagging.jpg' alt='Bagging算法'>  <div>Bagging算法</div></center><p>算法复杂度：基分类器复杂度 + 投票复杂度</p><p>由于每个基学习器只使用了部分训练集样本，剩余样本可用作验证集来对泛化性能进行“包外估计”。</p><h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p>随机森林是多决策树的Bagging，通常情况下 随机森林相较于Bagging会收敛到更低的泛化误差，且训练速度更快，其算法流程如下：</p><ol><li>随机自助采样出$T$个含有$m$个样本的采样集</li><li>每个采样集随机选择$k$个属性子集构建不剪枝的决策树，形成随机森林，推荐$k=log_2d$，$d$为属性总数</li><li>对于新样本经过随机森林进行决策，一般取得票最高的为分类结果</li></ol><h1 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h1><h2 id="平均法"><a href="#平均法" class="headerlink" title="平均法"></a>平均法</h2><ol><li>简单平均法：<script type="math/tex">H(x)=\frac{1}{T}\sum^T_{i=1}h_i(x)</script></li><li>加权平均法：<script type="math/tex">H(x)=\sum^T_{i=1}w_ih_i(x)</script><br>$w<em>i$是$h_i$的权重，通常$w_i\geq0,\sum^T</em>{i=1}w_i=1$</li></ol><h2 id="投票法"><a href="#投票法" class="headerlink" title="投票法"></a>投票法</h2><ol><li><p>绝对多数投票法：</p><!-- $$ H(x)=\left\{\begin{matrix}c_j & if \space \sum^T_{i=1} h^j_i(x)>0.5\sum^N_{k=1}\sum^T_{i=1}h_i^k(x)\\ reject & otherwise \end{matrix}\right. $$ --><script type="math/tex; mode=display">H(x)=c_j \space if \space \sum^T_{i=1} h^j_i(x)>0.5\sum^N_{k=1}\sum^T_{i=1}h_i^k(x) \space else \space reject</script></li><li><p>相对多数投票法：<script type="math/tex">H(x)=c_{\underset{j}{argmax}}\sum^T_{i=1}h^j_i(x)</script></p></li><li>加权投票法：<script type="math/tex">H(x)=c_{\underset{j}{argmax}}\sum^T_{i=1}w_ih^j_i(x)</script><br>其中$h_i^j(x)$是学习器$h_i$在类别标记$c_j$上的输出 </li></ol><h2 id="学习法"><a href="#学习法" class="headerlink" title="学习法"></a>学习法</h2><p>训练数据很多时，可以与另一个学习器进行结合。把个体学习器称为<font color='blue'>初级学习器</font>，用于结合的学习器称为<font color='blue'>次级学习器</font>或<font color='blue'>元学习器。</font>代表算法为<font color='blue'>Stacking</font>，Stacking本身就为一种集成学习方法，其算法流程如下：</p><ol><li>从初始训练集训练出初级学习器，生成一个新数据集</li><li>初级学习器的输出当作样例输入特征来训练次级学习器</li></ol><center>  <img align='center' src='Stacking.jpg' alt='Stacking算法'>  <div>Stacking算法</div></center><h1 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h1><table align='center'>    <tr>        <th></th>        <th>Bagging</th>        <th>Boosting</th>    </tr>    <tr>        <td></td>        <td>基学习器之间不存在强依赖关系，可并行生成</td>        <td>基学习器之间存在强相互依赖关系，必须串行生成</td>    </tr>    <tr>        <td>样本训练</td>        <td>有放回采样，各训练集相互独立</td>        <td>每一轮训练集不变，而训练集中的样例的权重变化</td>    </tr>    <tr>        <td>样本权重</td>        <td>均匀取样，各样例权重相等</td>        <td>根据学习误差率不断调整，错误率越大的权重越大</td>    </tr>    <tr>        <td>预测函数</td>        <td>所有预测函数权重相等</td>        <td>每个弱分类器都有相应的权重，对于分类误差小的分类器给予更大的权重</td>    </tr>    <tr>        <td></td>        <td>依靠降低方差提升预测的精准度</td>        <td>依靠降低偏差和方差提升预测精准度</td>    </tr></table><p>AdaBoost优缺点：</p><ul><li>具有较低的泛化误差且不容易出现过拟合</li><li>代码易实现</li><li>对异常点敏感，影响后续产生的弱分类器</li></ul><p>RF的优缺点：</p><ul><li>训练可以并行化，对于大规模样本的训练具有速度的优势</li><li>随机选择决策树划分特征列表使得在样本维度较高时仍具有比较高的训练性能</li><li>存在随机抽样，训练出来的模型方差小，泛化能力强</li><li>实现简单，且对于部分特征的缺失不敏感</li><li>在某些噪音比较大的特征上易陷入过拟合</li><li>取值比较多的划分特征对RF的决策会产生更大的影响，从而有可能影响模型的效果</li></ul><p>sklearn实现<strong>决策树</strong>、<strong>极度随机树</strong>、<strong>随机森林</strong>、<strong>AdaBoost</strong>及其在Iris数据集上的结果比较</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> (</span><br><span class="line">    RandomForestClassifier,</span><br><span class="line">    ExtraTreesClassifier,</span><br><span class="line">    AdaBoostClassifier,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameters</span></span><br><span class="line">n_classes = <span class="number">3</span></span><br><span class="line">n_estimators = <span class="number">30</span>   <span class="comment"># 森林中树的数量/终止提升的最大值</span></span><br><span class="line">cmap = plt.cm.RdYlBu</span><br><span class="line">plot_step = <span class="number">0.02</span>  <span class="comment"># fine step width for decision surface contours</span></span><br><span class="line">plot_step_coarser = <span class="number">0.5</span>  <span class="comment"># step widths for coarse classifier guesses</span></span><br><span class="line">RANDOM_SEED = <span class="number">13</span>  <span class="comment"># fix the seed on each iteration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load data</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line">plot_idx = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">models = [</span><br><span class="line">    DecisionTreeClassifier(max_depth=<span class="literal">None</span>),</span><br><span class="line">    RandomForestClassifier(n_estimators=n_estimators),</span><br><span class="line">    ExtraTreesClassifier(n_estimators=n_estimators),</span><br><span class="line">    AdaBoostClassifier(DecisionTreeClassifier(max_depth=<span class="number">3</span>), n_estimators=n_estimators),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pair <span class="keyword">in</span> ([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>]):   <span class="comment"># 选取不同特征分类</span></span><br><span class="line">    <span class="keyword">for</span> model <span class="keyword">in</span> models:</span><br><span class="line">        <span class="comment"># We only take the two corresponding features</span></span><br><span class="line">        X = iris.data[:, pair]</span><br><span class="line">        y = iris.target</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Shuffle</span></span><br><span class="line">        idx = np.arange(X.shape[<span class="number">0</span>])</span><br><span class="line">        np.random.seed(RANDOM_SEED)</span><br><span class="line">        np.random.shuffle(idx)</span><br><span class="line">        X = X[idx]</span><br><span class="line">        y = y[idx]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Standardize</span></span><br><span class="line">        mean = X.mean(axis=<span class="number">0</span>)</span><br><span class="line">        std = X.std(axis=<span class="number">0</span>)</span><br><span class="line">        X = (X - mean) / std</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Train</span></span><br><span class="line">        model.fit(X, y)</span><br><span class="line"></span><br><span class="line">        scores = model.score(X, y)</span><br><span class="line">        <span class="comment"># Create a title for each column and the console by using str() and</span></span><br><span class="line">        <span class="comment"># slicing away useless parts of the string</span></span><br><span class="line">        model_title = <span class="built_in">str</span>(<span class="built_in">type</span>(model)).split(<span class="string">&quot;.&quot;</span>)[-<span class="number">1</span>][:-<span class="number">2</span>][: -<span class="built_in">len</span>(<span class="string">&quot;Classifier&quot;</span>)]</span><br><span class="line"></span><br><span class="line">        model_details = model_title</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(model, <span class="string">&quot;estimators_&quot;</span>):</span><br><span class="line">            model_details += <span class="string">&quot; with &#123;&#125; estimators&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(model.estimators_))</span><br><span class="line">        <span class="built_in">print</span>(model_details + <span class="string">&quot; with features&quot;</span>, pair, <span class="string">&quot;has a score of&quot;</span>, scores)</span><br><span class="line"></span><br><span class="line">        plt.subplot(<span class="number">3</span>, <span class="number">4</span>, plot_idx)</span><br><span class="line">        <span class="keyword">if</span> plot_idx &lt;= <span class="built_in">len</span>(models):</span><br><span class="line">            <span class="comment"># Add a title at the top of each column</span></span><br><span class="line">            plt.title(model_title, fontsize=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Now plot the decision boundary using a fine mesh as input to a</span></span><br><span class="line">        <span class="comment"># filled contour plot</span></span><br><span class="line">        x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">        y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">        xx, yy = np.meshgrid(</span><br><span class="line">            np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Plot either a single DecisionTreeClassifier or alpha blend the</span></span><br><span class="line">        <span class="comment"># decision surfaces of the ensemble of classifiers</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(model, DecisionTreeClassifier):</span><br><span class="line">            Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">            Z = Z.reshape(xx.shape)</span><br><span class="line">            cs = plt.contourf(xx, yy, Z, cmap=cmap)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Choose alpha blend level with respect to the number</span></span><br><span class="line">            <span class="comment"># of estimators</span></span><br><span class="line">            <span class="comment"># that are in use (noting that AdaBoost can use fewer estimators</span></span><br><span class="line">            <span class="comment"># than its maximum if it achieves a good enough fit early on)</span></span><br><span class="line">            estimator_alpha = <span class="number">1.0</span> / <span class="built_in">len</span>(model.estimators_)</span><br><span class="line">            <span class="keyword">for</span> tree <span class="keyword">in</span> model.estimators_:</span><br><span class="line">                Z = tree.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">                Z = Z.reshape(xx.shape)</span><br><span class="line">                cs = plt.contourf(xx, yy, Z, alpha=estimator_alpha, cmap=cmap)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Build a coarser grid to plot a set of ensemble classifications</span></span><br><span class="line">        <span class="comment"># to show how these are different to what we see in the decision</span></span><br><span class="line">        <span class="comment"># surfaces. These points are regularly space and do not have a</span></span><br><span class="line">        <span class="comment"># black outline</span></span><br><span class="line">        xx_coarser, yy_coarser = np.meshgrid(</span><br><span class="line">            np.arange(x_min, x_max, plot_step_coarser),</span><br><span class="line">            np.arange(y_min, y_max, plot_step_coarser),</span><br><span class="line">        )</span><br><span class="line">        Z_points_coarser = model.predict(</span><br><span class="line">            np.c_[xx_coarser.ravel(), yy_coarser.ravel()]</span><br><span class="line">        ).reshape(xx_coarser.shape)</span><br><span class="line">        cs_points = plt.scatter(</span><br><span class="line">            xx_coarser,</span><br><span class="line">            yy_coarser,</span><br><span class="line">            s=<span class="number">15</span>,</span><br><span class="line">            c=Z_points_coarser,</span><br><span class="line">            cmap=cmap,</span><br><span class="line">            edgecolors=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Plot the training points, these are clustered together and have a</span></span><br><span class="line">        <span class="comment"># black outline</span></span><br><span class="line">        plt.scatter(</span><br><span class="line">            X[:, <span class="number">0</span>],</span><br><span class="line">            X[:, <span class="number">1</span>],</span><br><span class="line">            c=y,</span><br><span class="line">            cmap=ListedColormap([<span class="string">&quot;r&quot;</span>, <span class="string">&quot;y&quot;</span>, <span class="string">&quot;b&quot;</span>]),</span><br><span class="line">            edgecolor=<span class="string">&quot;k&quot;</span>,</span><br><span class="line">            s=<span class="number">20</span>,</span><br><span class="line">        )</span><br><span class="line">        plot_idx += <span class="number">1</span>  <span class="comment"># move on to the next plot in sequence</span></span><br><span class="line"></span><br><span class="line">plt.suptitle(<span class="string">&quot;Classifiers on feature subsets of the Iris dataset&quot;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;tight&quot;</span>)</span><br><span class="line">plt.tight_layout(h_pad=<span class="number">0.2</span>, w_pad=<span class="number">0.2</span>, pad=<span class="number">2.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>运行结果<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">DecisionTree with features [0, 1] has a score of 0.9266666666666666</span><br><span class="line">RandomForest with 30 estimators with features [0, 1] has a score of 0.9266666666666666</span><br><span class="line">ExtraTrees with 30 estimators with features [0, 1] has a score of 0.9266666666666666</span><br><span class="line">AdaBoost with 30 estimators with features [0, 1] has a score of 0.8533333333333334</span><br><span class="line">DecisionTree with features [0, 2] has a score of 0.9933333333333333</span><br><span class="line">RandomForest with 30 estimators with features [0, 2] has a score of 0.9933333333333333</span><br><span class="line">ExtraTrees with 30 estimators with features [0, 2] has a score of 0.9933333333333333</span><br><span class="line">AdaBoost with 30 estimators with features [0, 2] has a score of 0.9933333333333333</span><br><span class="line">DecisionTree with features [2, 3] has a score of 0.9933333333333333</span><br><span class="line">RandomForest with 30 estimators with features [2, 3] has a score of 0.9933333333333333</span><br><span class="line">ExtraTrees with 30 estimators with features [2, 3] has a score of 0.9933333333333333</span><br><span class="line">AdaBoost with 30 estimators with features [2, 3] has a score of 0.9933333333333333</span><br></pre></td></tr></table></figure></p><center>  <img align='center' src='4_classification.png'>  <div>四种分类器结果对比</div></center><h1 id="拓展学习"><a href="#拓展学习" class="headerlink" title="拓展学习"></a>拓展学习</h1><ol><li>TreeBoost</li><li>XGBoost</li><li>GBDT</li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble">官方文档sklearn.ensemble</a></li><li>机器学习，周志华，清华大学，2016.</li><li>统计学习方法，李航，清华大学，2012.</li><li><a href="https://cloud.tencent.com/developer/article/1486719">机器学习之自适应增强(Adaboost)</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MjA2NTQzMw==&amp;mid=2247483845&amp;idx=1&amp;sn=5484385408d694ba03a8bdc3a03c2263&amp;chksm=fcd7d233cba05b25b0f65289f8416466df9124b019b60704b4e3875d9864ff90e3388c666f66&amp;scene=21#wechat_redirect">机器学习之随机森林</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning and Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
