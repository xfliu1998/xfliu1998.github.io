<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Recommendation System Algorithm | 一直进步 做喜欢的</title><meta name="keywords" content="python"><meta name="author" content="贪钱算法还我头发"><meta name="copyright" content="贪钱算法还我头发"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="推荐系统学习笔记二——推荐算法">
<meta property="og:type" content="article">
<meta property="og:title" content="Recommendation System Algorithm">
<meta property="og:url" content="https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/index.html">
<meta property="og:site_name" content="一直进步 做喜欢的">
<meta property="og:description" content="推荐系统学习笔记二——推荐算法">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://img.shijue.me/d667362f0f6b42bcb21d4a4fc167e93a_d.jpg!dp6">
<meta property="article:published_time" content="2022-01-18T13:38:48.000Z">
<meta property="article:modified_time" content="2024-03-31T12:12:41.811Z">
<meta property="article:author" content="贪钱算法还我头发">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://img.shijue.me/d667362f0f6b42bcb21d4a4fc167e93a_d.jpg!dp6"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Recommendation System Algorithm',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-31 20:12:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/pool.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/iconfont.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/js/pool.min.js"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/mouse_snow.min.js"><link rel="stylesheet" href="/css/custom.css?v1"><link rel="stylesheet" href="//at.alicdn.com/t/font_2264842_b004iy0kk2b.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">57</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('http://img.shijue.me/d667362f0f6b42bcb21d4a4fc167e93a_d.jpg!dp6')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">一直进步 做喜欢的</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Recommendation System Algorithm</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-01-18T13:38:48.000Z" title="Created 2022-01-18 21:38:48">2022-01-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-03-31T12:12:41.811Z" title="Updated 2024-03-31 20:12:41">2024-03-31</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Search-Advertisement-Recommendation-Causal/">Search / Advertisement / Recommendation / Causal</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">18.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>77min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Recommendation System Algorithm"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">Comments:</span><a href="/2022/01/18/5.2-RS-Algorithm/#post-comment"><span class="gitalk-comment-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><strong>推荐系统学习笔记目录</strong></p>
<ol>
<li><a href="https://xfliu1998.github.io/2022/01/18/5.1-Recommendation-System-Introduction/">推荐系统介绍</a></li>
<li><a href="https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/">推荐算法</a></li>
<li><a href="https://xfliu1998.github.io/2022/01/18/5.3-Hadoop/">Hadoop</a></li>
<li><a href="https://xfliu1998.github.io/2022/01/18/5.4-Hive/">Hive &amp; HBase</a></li>
<li><a href="https://xfliu1998.github.io/2022/01/18/5.5-Spark-core/">Spark core</a></li>
<li><a href="https://xfliu1998.github.io/2022/01/18/5.6-Spark-SQL/">Spark SQL &amp; Spark streaming</a></li>
<li><a href="https://xfliu1998.github.io/2022/01/18/5.7-RS-case/">推荐系统案例</a></li>
</ol>
<h2 id="Model-Based-协同过滤算法"><a href="#Model-Based-协同过滤算法" class="headerlink" title="Model-Based 协同过滤算法"></a>Model-Based 协同过滤算法</h2><p>随着机器学习技术的逐渐发展与完善，推荐系统也逐渐运用机器学习的思想来进行推荐。将机器学习应用到推荐系统中的方案真是不胜枚举。以下对Model-Based CF算法做一个大致的分类：</p>
<ul>
<li>基于分类算法、回归算法、聚类算法</li>
<li>基于矩阵分解的推荐</li>
<li>基于神经网络算法</li>
<li>基于图模型算法</li>
</ul>
<p>接下来我们重点学习以下几种应用较多的方案：</p>
<ul>
<li><strong>基于K最近邻的协同过滤推荐</strong></li>
<li><strong>基于回归模型的协同过滤推荐</strong></li>
<li><strong>基于矩阵分解的协同过滤推荐</strong></li>
</ul>
<h2 id="基于K最近邻的协同过滤推荐"><a href="#基于K最近邻的协同过滤推荐" class="headerlink" title="基于K最近邻的协同过滤推荐"></a>基于K最近邻的协同过滤推荐</h2><p>基于K最近邻的协同过滤推荐其实本质上就是MemoryBased CF，只不过在选取近邻的时候，加上K最近邻的限制。</p>
<p>这里我们直接根据MemoryBased CF的代码实现 修改以下地方</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CollaborativeFiltering</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    based = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, k=<span class="number">40</span>, rules=<span class="literal">None</span>, use_cache=<span class="literal">False</span>, standard=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param k: 取K个最近邻来进行预测</span></span><br><span class="line"><span class="string">        :param rules: 过滤规则，四选一，否则将抛异常：&quot;unhot&quot;, &quot;rated&quot;, [&quot;unhot&quot;,&quot;rated&quot;], None</span></span><br><span class="line"><span class="string">        :param use_cache: 相似度计算结果是否开启缓存</span></span><br><span class="line"><span class="string">        :param standard: 评分标准化方法，None表示不使用、mean表示均值中心化、zscore表示Z-Score标准化</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.k = <span class="number">40</span></span><br><span class="line">        self.rules = rules</span><br><span class="line">        self.use_cache = use_cache</span><br><span class="line">        self.standard = standard</span><br></pre></td></tr></table></figure>
<p>修改所有的选取近邻的地方的代码，根据相似度来选取K个最近邻</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">similar_users = self.similar[uid].drop([uid]).dropna().sort_values(ascending=<span class="literal">False</span>)[:self.k]</span><br><span class="line">similar_items = self.similar[iid].drop([iid]).dropna().sort_values(ascending=<span class="literal">False</span>)[:self.k]</span><br></pre></td></tr></table></figure>
<p>但由于原始数据较少，这里我们的KNN方法的效果会比纯粹的MemoryBasedCF要差</p>
<h2 id="基于回归模型的协同过滤推荐"><a href="#基于回归模型的协同过滤推荐" class="headerlink" title="基于回归模型的协同过滤推荐"></a>基于回归模型的协同过滤推荐</h2><p>如果我们将评分看作是一个连续的值而不是离散的值，那么就可以借助线性回归思想来预测目标用户对某物品的评分。其中一种实现策略被称为Baseline（基准预测）。</p>
<h3 id="Baseline：基准预测"><a href="#Baseline：基准预测" class="headerlink" title="Baseline：基准预测"></a>Baseline：基准预测</h3><p>Baseline设计思想基于以下的假设：</p>
<ul>
<li>有些用户的评分普遍高于其他用户，有些用户的评分普遍低于其他用户。比如有些用户天生愿意给别人好评，心慈手软，比较好说话，而有的人就比较苛刻，总是评分不超过3分（5分满分）</li>
<li>一些物品的评分普遍高于其他物品，一些物品的评分普遍低于其他物品。比如一些物品一被生产便决定了它的地位，有的比较受人们欢迎，有的则被人嫌弃。</li>
</ul>
<p>这个用户或物品普遍高于或低于平均值的差值，我们称为偏置(bias)</p>
<p><strong>Baseline目标：</strong></p>
<ul>
<li>找出每个用户普遍高于或低于他人的偏置值$b_u$</li>
<li>找出每件物品普遍高于或低于其他物品的偏置值$b_i$</li>
<li>我们的目标也就转化为寻找最优的$b_u$和$b_i$</li>
</ul>
<p>使用Baseline的算法思想预测评分的步骤如下：</p>
<ul>
<li>计算所有电影的平均评分$\mu$（即全局平均评分）</li>
<li>计算每个用户评分与平均评分$\mu$的偏置值$b_u$</li>
<li>计算每部电影所接受的评分与平均评分$\mu$的偏置值$b_i$</li>
<li>预测用户对电影的评分：<script type="math/tex; mode=display">\hat r_{ui} = b_{ui} = \mu + b_u + b_i</script></li>
</ul>
<p>举例：<br>​比如我们想通过Baseline来预测用户A对电影“阿甘正传”的评分，那么首先计算出整个评分数据集的平均评分$\mu$是3.5分；而用户A是一个比较苛刻的用户，他的评分比较严格，普遍比平均评分低0.5分，即用户A的偏置值$b_i$是-0.5；而电影“阿甘正传”是一部比较热门而且备受好评的电影，它的评分普遍比平均评分要高1.2分，那么电影“阿甘正传”的偏置值$b_i$是+1.2，因此就可以预测出用户A对电影“阿甘正传”的评分为：$3.5+(-0.5)+1.2$，也就是4.2分。</p>
<p>对于所有电影的平均评分$\mu$是直接能计算出的，因此问题在于要测出每个用户的$b_u$值和每部电影的$b_i$的值。对于线性回归问题，我们可以利用平方差构建损失函数如下：</p>
<script type="math/tex; mode=display">
\begin{split}
Cost &= \sum_{u,i\in R}(r_{ui}-\hat r_{ui})^2
\\&=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2
\end{split}</script><p>加入L2正则化：</p>
<script type="math/tex; mode=display">
Cost=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)</script><p>公式解析：</p>
<ul>
<li>公式第一部分$ \sum<em>{u,i\in R}(r</em>{ui}-\mu-b_u-b_i)^2$是用来寻找与已知评分数据拟合最好的$b_u$和$b_i$</li>
<li>公式第二部分$\lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)​$是正则化项，用于避免过拟合现象</li>
</ul>
<p>对于最小过程的求解，我们一般采用<strong>随机梯度下降法</strong>或者<strong>交替最小二乘法</strong>来优化实现。</p>
<h3 id="方法一：随机梯度下降法优化"><a href="#方法一：随机梯度下降法优化" class="headerlink" title="方法一：随机梯度下降法优化"></a>方法一：随机梯度下降法优化</h3><p>使用随机梯度下降优化算法预测Baseline偏置值</p>
<h4 id="step-1：梯度下降法推导"><a href="#step-1：梯度下降法推导" class="headerlink" title="step 1：梯度下降法推导"></a>step 1：梯度下降法推导</h4><p>损失函数：</p>
<script type="math/tex; mode=display">
\begin{split}
&J(\theta)=Cost=f(b_u, b_i)\\
\\
&J(\theta)=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)
\end{split}</script><p>梯度下降参数更新原始公式：</p>
<script type="math/tex; mode=display">
\theta_j:=\theta_j-\alpha\cfrac{\partial }{\partial \theta_j}J(\theta)</script><p>梯度下降更新$b_u​$:</p>
<p>损失函数偏导推导：</p>
<script type="math/tex; mode=display">
\begin{split}
\cfrac{\partial}{\partial b_u} J(\theta)&=\cfrac{\partial}{\partial b_u} f(b_u, b_i)
\\&=2\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)(-1) + 2\lambda{b_u}
\\&=-2\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + 2\lambda*b_u
\end{split}</script><p>$b_u$更新(因为alpha可以人为控制，所以2可以省略掉)：</p>
<script type="math/tex; mode=display">
\begin{split}
b_u&:=b_u - \alpha*(-\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + \lambda * b_u)\\
&:=b_u + \alpha*(\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) - \lambda* b_u)
\end{split}</script><p>同理可得，梯度下降更新$b_i​$:</p>
<script type="math/tex; mode=display">
b_i:=b_i + \alpha*(\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) -\lambda*b_i)</script><h4 id="step-2：随机梯度下降"><a href="#step-2：随机梯度下降" class="headerlink" title="step 2：随机梯度下降"></a>step 2：随机梯度下降</h4><p>由于<strong>随机梯度下降法</strong>本质上利用<strong>每个样本的损失</strong>来更新参数，而不用每次求出全部的损失和，因此使用SGD时：</p>
<p>单样本损失值：</p>
<script type="math/tex; mode=display">error = r_{ui}-\hat r_{ui} = r_{ui}-(\mu + b_u + b_i) = r_{ui} - \mu - b_u - b_i</script><p>参数更新：</p>
<script type="math/tex; mode=display">b_u := b_u + \alpha *((r_{ui} - \mu - b_u - b_i) -\lambda * b_u)
:= b_u + \alpha *(error - \lambda * b_u) 
:= b_i + \alpha *((r_{ui}-\mu -b_u-b_i) -\lambda * b_i)
:= b_i + \alpha *(error -\lambda * b_i)</script><h4 id="step-3：算法实现"><a href="#step-3：算法实现" class="headerlink" title="step 3：算法实现"></a>step 3：算法实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFBySGD</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, alpha, reg, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># 学习率</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="comment"># 正则参数</span></span><br><span class="line">        self.reg = reg</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                error = real_rating - (self.global_mean + bu[uid] + bi[iid])</span><br><span class="line"></span><br><span class="line">                bu[uid] += self.alpha * (error - self.reg * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (error - self.reg * bi[iid])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">3</span>), dtype=<span class="built_in">dict</span>(dtype))</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFBySGD(<span class="number">20</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;uid: &quot;</span>))</span><br><span class="line">        iid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;iid: &quot;</span>))</span><br><span class="line">        <span class="built_in">print</span>(bcf.predict(uid, iid))</span><br></pre></td></tr></table></figure>
<h4 id="step-4-准确性指标评估"><a href="#step-4-准确性指标评估" class="headerlink" title="step 4: 准确性指标评估"></a>step 4: 准确性指标评估</h4><ul>
<li>添加test方法，然后使用之前实现accuary方法计算准确性指标</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span>(<span class="params">data_path, x=<span class="number">0.8</span>, random=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    切分数据集， 这里为了保证用户数量保持不变，将每个用户的评分数据按比例进行拆分</span></span><br><span class="line"><span class="string">    :param data_path: 数据集路径</span></span><br><span class="line"><span class="string">    :param x: 训练集的比例，如x=0.8，则0.2是测试集</span></span><br><span class="line"><span class="string">    :param random: 是否随机切分，默认False</span></span><br><span class="line"><span class="string">    :return: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始切分数据集...&quot;</span>)</span><br><span class="line">    <span class="comment"># 设置要加载的数据字段的类型</span></span><br><span class="line">    dtype = &#123;<span class="string">&quot;userId&quot;</span>: np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32, <span class="string">&quot;rating&quot;</span>: np.float32&#125;</span><br><span class="line">    <span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">    ratings = pd.read_csv(data_path, dtype=dtype, usecols=<span class="built_in">range</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    testset_index = []</span><br><span class="line">    <span class="comment"># 为了保证每个用户在测试集和训练集都有数据，因此按userId聚合</span></span><br><span class="line">    <span class="keyword">for</span> uid <span class="keyword">in</span> ratings.groupby(<span class="string">&quot;userId&quot;</span>).<span class="built_in">any</span>().index:</span><br><span class="line">        user_rating_data = ratings.where(ratings[<span class="string">&quot;userId&quot;</span>]==uid).dropna()</span><br><span class="line">        <span class="keyword">if</span> random:</span><br><span class="line">            <span class="comment"># 因为不可变类型不能被 shuffle方法作用，所以需要强行转换为列表</span></span><br><span class="line">            index = <span class="built_in">list</span>(user_rating_data.index)</span><br><span class="line">            np.random.shuffle(index)    <span class="comment"># 打乱列表</span></span><br><span class="line">            _index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x)</span><br><span class="line">            testset_index += <span class="built_in">list</span>(index[_index:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 将每个用户的x比例的数据作为训练集，剩余的作为测试集</span></span><br><span class="line">            index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x)</span><br><span class="line">            testset_index += <span class="built_in">list</span>(user_rating_data.index.values[index:])</span><br><span class="line"></span><br><span class="line">    testset = ratings.loc[testset_index]</span><br><span class="line">    trainset = ratings.drop(testset_index)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;完成数据集切分...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuray</span>(<span class="params">predict_results, method=<span class="string">&quot;all&quot;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    准确性指标计算方法</span></span><br><span class="line"><span class="string">    :param predict_results: 预测结果，类型为容器，每个元素是一个包含uid,iid,real_rating,pred_rating的序列</span></span><br><span class="line"><span class="string">    :param method: 指标方法，类型为字符串，rmse或mae，否则返回两者rmse和mae</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse_mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse和mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse, mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>), <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> method.lower() == <span class="string">&quot;rmse&quot;</span>:</span><br><span class="line">        rmse(predict_results)</span><br><span class="line">    <span class="keyword">elif</span> method.lower() == <span class="string">&quot;mae&quot;</span>:</span><br><span class="line">        mae(predict_results)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> rmse_mae(predict_results)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFBySGD</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, alpha, reg, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># 学习率</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="comment"># 正则参数</span></span><br><span class="line">        self.reg = reg</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                error = real_rating - (self.global_mean + bu[uid] + bi[iid])</span><br><span class="line"></span><br><span class="line">                bu[uid] += self.alpha * (error - self.reg * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (error - self.reg * bi[iid])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;评分预测&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;无法预测用户&lt;&#123;uid&#125;&gt;对电影&lt;&#123;iid&#125;&gt;的评分，因为训练集中缺失&lt;&#123;iid&#125;&gt;的数据&quot;</span>.<span class="built_in">format</span>(uid=uid, iid=iid))</span><br><span class="line"></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self,testset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;预测测试集数据&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> testset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                pred_rating = self.predict(uid, iid)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(e)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">yield</span> uid, iid, real_rating, pred_rating</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    trainset, testset = data_split(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, random=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFBySGD(<span class="number">20</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(trainset)</span><br><span class="line"></span><br><span class="line">    pred_results = bcf.test(testset)</span><br><span class="line"></span><br><span class="line">    rmse, mae = accuray(pred_results)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;rmse: &quot;</span>, rmse, <span class="string">&quot;mae: &quot;</span>, mae)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="方法二：交替最小二乘法优化"><a href="#方法二：交替最小二乘法优化" class="headerlink" title="方法二：交替最小二乘法优化"></a>方法二：交替最小二乘法优化</h3><p>使用交替最小二乘法优化算法预测Baseline偏置值</p>
<h4 id="step-1-交替最小二乘法推导"><a href="#step-1-交替最小二乘法推导" class="headerlink" title="step 1: 交替最小二乘法推导"></a>step 1: 交替最小二乘法推导</h4><p>最小二乘法和梯度下降法一样，可以用于求极值。</p>
<p><strong>最小二乘法思想：对损失函数求偏导，然后再使偏导为0</strong></p>
<p>同样，损失函数：</p>
<script type="math/tex; mode=display">
J(\theta)=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)</script><p>对损失函数求偏导：</p>
<script type="math/tex; mode=display">
\cfrac{\partial}{\partial b_u} f(b_u, b_i) =-2 \sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + 2\lambda * b_u</script><p>令偏导为0，则可得：</p>
<script type="math/tex; mode=display">
\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) = \lambda* b_u
\\\sum_{u,i\in R}(r_{ui}-\mu-b_i) = \sum_{u,i\in R} b_u+\lambda * b_u</script><p>为了简化公式，这里令$\sum_{u,i\in R} b_u \approx |R(u)|*b_u$，即直接假设每一项的偏置都相等，可得：</p>
<script type="math/tex; mode=display">
b_u := \cfrac {\sum_{u,i\in R}(r_{ui}-\mu-b_i)}{\lambda_1 + |R(u)|}</script><p>其中$|R(u)|$表示用户$u​$的有过评分数量</p>
<p>同理可得：</p>
<script type="math/tex; mode=display">
b_i := \cfrac {\sum_{u,i\in R}(r_{ui}-\mu-b_u)}{\lambda_2 + |R(i)|}</script><p>其中$|R(i)|$表示物品$i​$收到的评分数量</p>
<p>$b_u$和$b_i​$分别属于用户和物品的偏置，因此他们的正则参数可以分别设置两个独立的参数</p>
<h4 id="step-2-交替最小二乘法应用"><a href="#step-2-交替最小二乘法应用" class="headerlink" title="step 2: 交替最小二乘法应用"></a>step 2: 交替最小二乘法应用</h4><p>通过最小二乘推导，我们最终分别得到了$b_u$和$b_i$的表达式，但他们的表达式中却又各自包含对方，因此这里我们将利用一种叫交替最小二乘的方法来计算他们的值：    </p>
<ul>
<li>计算其中一项，先固定其他未知参数，即看作其他未知参数为已知</li>
<li>如求$b_u$时，将$b_i$看作是已知；求$b_i$时，将$b_u$看作是已知；如此反复交替，不断更新二者的值，求得最终的结果。这就是<strong>交替最小二乘法（ALS）</strong></li>
</ul>
<h4 id="step-3-算法实现"><a href="#step-3-算法实现" class="headerlink" title="step 3: 算法实现"></a>step 3: 算法实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFByALS</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, reg_bu, reg_bi, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># bu的正则参数</span></span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        <span class="comment"># bi的正则参数</span></span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.als()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">als</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> iid, uids, ratings <span class="keyword">in</span> self.items_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _<span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> uid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(uids, ratings):</span><br><span class="line">                    _<span class="built_in">sum</span> += rating - self.global_mean - bu[uid]</span><br><span class="line">                bi[iid] = _<span class="built_in">sum</span> / (self.reg_bi + <span class="built_in">len</span>(uids))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> uid, iids, ratings <span class="keyword">in</span> self.users_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _<span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> iid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(iids, ratings):</span><br><span class="line">                    _<span class="built_in">sum</span> += rating - self.global_mean - bi[iid]</span><br><span class="line">                bu[uid] = _<span class="built_in">sum</span> / (self.reg_bu + <span class="built_in">len</span>(iids))</span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">3</span>), dtype=<span class="built_in">dict</span>(dtype))</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFByALS(<span class="number">20</span>, <span class="number">25</span>, <span class="number">15</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;uid: &quot;</span>))</span><br><span class="line">        iid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;iid: &quot;</span>))</span><br><span class="line">        <span class="built_in">print</span>(bcf.predict(uid, iid))</span><br></pre></td></tr></table></figure>
<h4 id="step-4-准确性指标评估-1"><a href="#step-4-准确性指标评估-1" class="headerlink" title="step 4: 准确性指标评估"></a>step 4: 准确性指标评估</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span>(<span class="params">data_path, x=<span class="number">0.8</span>, random=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    切分数据集， 这里为了保证用户数量保持不变，将每个用户的评分数据按比例进行拆分</span></span><br><span class="line"><span class="string">    :param data_path: 数据集路径</span></span><br><span class="line"><span class="string">    :param x: 训练集的比例，如x=0.8，则0.2是测试集</span></span><br><span class="line"><span class="string">    :param random: 是否随机切分，默认False</span></span><br><span class="line"><span class="string">    :return: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始切分数据集...&quot;</span>)</span><br><span class="line">    <span class="comment"># 设置要加载的数据字段的类型</span></span><br><span class="line">    dtype = &#123;<span class="string">&quot;userId&quot;</span>: np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32, <span class="string">&quot;rating&quot;</span>: np.float32&#125;</span><br><span class="line">    <span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">    ratings = pd.read_csv(data_path, dtype=dtype, usecols=<span class="built_in">range</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    testset_index = []</span><br><span class="line">    <span class="comment"># 为了保证每个用户在测试集和训练集都有数据，因此按userId聚合</span></span><br><span class="line">    <span class="keyword">for</span> uid <span class="keyword">in</span> ratings.groupby(<span class="string">&quot;userId&quot;</span>).<span class="built_in">any</span>().index:</span><br><span class="line">        user_rating_data = ratings.where(ratings[<span class="string">&quot;userId&quot;</span>]==uid).dropna()</span><br><span class="line">        <span class="keyword">if</span> random:</span><br><span class="line">            <span class="comment"># 因为不可变类型不能被 shuffle方法作用，所以需要强行转换为列表</span></span><br><span class="line">            index = <span class="built_in">list</span>(user_rating_data.index)</span><br><span class="line">            np.random.shuffle(index)    <span class="comment"># 打乱列表</span></span><br><span class="line">            _index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x)</span><br><span class="line">            testset_index += <span class="built_in">list</span>(index[_index:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 将每个用户的x比例的数据作为训练集，剩余的作为测试集</span></span><br><span class="line">            index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x)</span><br><span class="line">            testset_index += <span class="built_in">list</span>(user_rating_data.index.values[index:])</span><br><span class="line"></span><br><span class="line">    testset = ratings.loc[testset_index]</span><br><span class="line">    trainset = ratings.drop(testset_index)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;完成数据集切分...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuray</span>(<span class="params">predict_results, method=<span class="string">&quot;all&quot;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    准确性指标计算方法</span></span><br><span class="line"><span class="string">    :param predict_results: 预测结果，类型为容器，每个元素是一个包含uid,iid,real_rating,pred_rating的序列</span></span><br><span class="line"><span class="string">    :param method: 指标方法，类型为字符串，rmse或mae，否则返回两者rmse和mae</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse_mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse和mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse, mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>), <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> method.lower() == <span class="string">&quot;rmse&quot;</span>:</span><br><span class="line">        rmse(predict_results)</span><br><span class="line">    <span class="keyword">elif</span> method.lower() == <span class="string">&quot;mae&quot;</span>:</span><br><span class="line">        mae(predict_results)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> rmse_mae(predict_results)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFByALS</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, reg_bu, reg_bi, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># bu的正则参数</span></span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        <span class="comment"># bi的正则参数</span></span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.als()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">als</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> iid, uids, ratings <span class="keyword">in</span> self.items_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _<span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> uid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(uids, ratings):</span><br><span class="line">                    _<span class="built_in">sum</span> += rating - self.global_mean - bu[uid]</span><br><span class="line">                bi[iid] = _<span class="built_in">sum</span> / (self.reg_bi + <span class="built_in">len</span>(uids))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> uid, iids, ratings <span class="keyword">in</span> self.users_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _<span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> iid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(iids, ratings):</span><br><span class="line">                    _<span class="built_in">sum</span> += rating - self.global_mean - bi[iid]</span><br><span class="line">                bu[uid] = _<span class="built_in">sum</span> / (self.reg_bu + <span class="built_in">len</span>(iids))</span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;评分预测&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;无法预测用户&lt;&#123;uid&#125;&gt;对电影&lt;&#123;iid&#125;&gt;的评分，因为训练集中缺失&lt;&#123;iid&#125;&gt;的数据&quot;</span>.<span class="built_in">format</span>(uid=uid, iid=iid))</span><br><span class="line"></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self,testset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;预测测试集数据&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> testset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                pred_rating = self.predict(uid, iid)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(e)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">yield</span> uid, iid, real_rating, pred_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    trainset, testset = data_split(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, random=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFByALS(<span class="number">20</span>, <span class="number">25</span>, <span class="number">15</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(trainset)</span><br><span class="line"></span><br><span class="line">    pred_results = bcf.test(testset)</span><br><span class="line"></span><br><span class="line">    rmse, mae = accuray(pred_results)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;rmse: &quot;</span>, rmse, <span class="string">&quot;mae: &quot;</span>, mae)</span><br></pre></td></tr></table></figure>
<h2 id="基于矩阵分解的CF算法"><a href="#基于矩阵分解的CF算法" class="headerlink" title="基于矩阵分解的CF算法"></a>基于矩阵分解的CF算法</h2><h3 id="矩阵分解发展史"><a href="#矩阵分解发展史" class="headerlink" title="矩阵分解发展史"></a>矩阵分解发展史</h3><p><strong>Traditional SVD:</strong></p>
<p>通常SVD矩阵分解指的是SVD（奇异值）分解技术，在这我们姑且将其命名为Traditional SVD（传统并经典）其公式如下：</p>
<p><img src="矩阵分解1.jpg" alt="img"></p>
<p>Traditional SVD分解的形式为3个矩阵相乘，中间矩阵为奇异值矩阵。如果想运用SVD分解的话，有一个前提是要求矩阵是稠密的，即矩阵里的元素要非空，否则就不能运用SVD分解。</p>
<p>很显然我们的数据其实绝大多数情况下都是稀疏的，因此如果要使用Traditional SVD，一般的做法是先用均值或者其他统计学方法来填充矩阵，然后再运用Traditional SVD分解降维，但这样做明显对数据的原始性造成一定影响。</p>
<p><strong>FunkSVD（LFM）</strong></p>
<p>刚才提到的Traditional SVD首先需要填充矩阵，然后再进行分解降维，同时存在计算复杂度高的问题，因为要分解成3个矩阵，所以后来提出了Funk SVD的方法，它不在将矩阵分解为3个矩阵，而是分解为2个用户-隐含特征，项目-隐含特征的矩阵，Funk SVD也被称为最原始的LFM模型</p>
<p><img src="矩阵分解2.jpg" alt="img"></p>
<p>借鉴线性回归的思想，通过最小化观察数据的平方来寻求最优的用户和项目的隐含向量表示。同时为了避免过度拟合（Overfitting）观测数据，又提出了带有L2正则项的FunkSVD，上公式：</p>
<p><img src="矩阵分解3.jpg" alt="img"></p>
<p>以上两种最优化函数都可以通过梯度下降或者随机梯度下降法来寻求最优解。</p>
<p><strong>BiasSVD:</strong></p>
<p>在FunkSVD提出来之后，出现了很多变形版本，其中一个相对成功的方法是BiasSVD，顾名思义，即带有偏置项的SVD分解：</p>
<p><img src="矩阵分解4.jpg" alt="img"></p>
<p>它基于的假设和Baseline基准预测是一样的，但这里将Baseline的偏置引入到了矩阵分解中</p>
<p><strong>SVD++:</strong></p>
<p>人们后来又提出了改进的BiasSVD，被称为SVD++，该算法是在BiasSVD的基础上添加了用户的隐式反馈信息：</p>
<p><img src="矩阵分解5.jpg" alt="img"></p>
<p>显示反馈指的用户的评分这样的行为，隐式反馈指用户的浏览记录、购买记录、收听记录等。</p>
<p>SVD++是基于这样的假设：在BiasSVD基础上，认为用户对于项目的历史浏览记录、购买记录、收听记录等可以从侧面反映用户的偏好。</p>
<h2 id="基于矩阵分解的CF算法实现（二）：BiasSvd"><a href="#基于矩阵分解的CF算法实现（二）：BiasSvd" class="headerlink" title="基于矩阵分解的CF算法实现（二）：BiasSvd"></a>基于矩阵分解的CF算法实现（二）：BiasSvd</h2><p>BiasSvd其实就是前面提到的Funk SVD矩阵分解基础上加上了偏置项。</p>
<h3 id="BiasSvd"><a href="#BiasSvd" class="headerlink" title="BiasSvd"></a>BiasSvd</h3><p>利用BiasSvd预测用户对物品的评分，$k$表示隐含特征数量：</p>
<script type="math/tex; mode=display">\hat r_{ui} = \mu + b_u + b_i + \vec {p_{uk}} \cdot \vec {q_{ki}}
= \mu + b_u + b_i + \sum_{k=1}^k p_{uk} q_{ik}</script><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>同样对于评分预测我们利用平方差来构建损失函数：</p>
<script type="math/tex; mode=display">Cost = \sum_{u,i \in R} (r_{ui}-\hat r_{ui})^2
= \sum_{u,i \in R} (r_{ui}- \mu - b_u - b_i - \sum_{k=1}^k p_{uk} q_{ik})^2</script><p>加入L2正则化：</p>
<script type="math/tex; mode=display">
Cost = \sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)</script><p>对损失函数求偏导：</p>
<script type="math/tex; mode=display">
\begin{split}
\cfrac {\partial}{\partial p_{uk}}Cost &= \cfrac {\partial}{\partial p_{uk}}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]
\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}
\\\\
\cfrac {\partial}{\partial q_{ik}}Cost &= \cfrac {\partial}{\partial q_{ik}}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]
\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-p_{uk}) + 2\lambda q_{ik}
\end{split}</script><script type="math/tex; mode=display">
\begin{split}
\cfrac {\partial}{\partial b_u}Cost &= \cfrac {\partial}{\partial b_u}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]
\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-1) + 2\lambda b_u
\\\\
\cfrac {\partial}{\partial b_i}Cost &= \cfrac {\partial}{\partial b_i}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]
\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-1) + 2\lambda b_i
\end{split}</script><h3 id="随机梯度下降法优化"><a href="#随机梯度下降法优化" class="headerlink" title="随机梯度下降法优化"></a>随机梯度下降法优化</h3><p>梯度下降更新参数$p_{uk}$：</p>
<script type="math/tex; mode=display">
\begin{split}
p_{uk}&:=p_{uk} - \alpha\cfrac {\partial}{\partial p_{uk}}Cost
\\&:=p_{uk}-\alpha [2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}]
\\&:=p_{uk}+\alpha [\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda p_{uk}]
\end{split}</script><p> 同理：</p>
<script type="math/tex; mode=display">
\begin{split}
q_{ik}&:=q_{ik} + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda q_{ik}]
\end{split}</script><script type="math/tex; mode=display">
b_u:=b_u + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda b_u]</script><script type="math/tex; mode=display">
b_i:=b_i + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda b_i]</script><p><strong>随机梯度下降：</strong></p>
<script type="math/tex; mode=display">
\begin{split}
&p_{uk}:=p_{uk}+\alpha [(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda_1 p_{uk}]
\\&q_{ik}:=q_{ik} + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda_2 q_{ik}]
\end{split}</script><script type="math/tex; mode=display">
b_u:=b_u + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda_3 b_u]</script><script type="math/tex; mode=display">
b_i:=b_i + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda_4 b_i]</script><p>由于P矩阵和Q矩阵是两个不同的矩阵，通常分别采取不同的正则参数，如$\lambda_1$和$\lambda_2$</p>
<p><strong>算法实现</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">BiasSvd Model</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BiasSvd</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, alpha, reg_p, reg_q, reg_bu, reg_bi, number_LatentFactors=<span class="number">10</span>, number_epochs=<span class="number">10</span>, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        self.alpha = alpha <span class="comment"># 学习率</span></span><br><span class="line">        self.reg_p = reg_p</span><br><span class="line">        self.reg_q = reg_q</span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        self.number_LatentFactors = number_LatentFactors  <span class="comment"># 隐式类别数量</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        fit dataset</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        self.dataset = pd.DataFrame(dataset)</span><br><span class="line"></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        self.globalMean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line"></span><br><span class="line">        self.P, self.Q, self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_matrix</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        初始化P和Q矩阵，同时为设置0，1之间的随机值作为初始值</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># User-LF</span></span><br><span class="line">        P = <span class="built_in">dict</span>(<span class="built_in">zip</span>(</span><br><span class="line">            self.users_ratings.index,</span><br><span class="line">            np.random.rand(<span class="built_in">len</span>(self.users_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="comment"># Item-LF</span></span><br><span class="line">        Q = <span class="built_in">dict</span>(<span class="built_in">zip</span>(</span><br><span class="line">            self.items_ratings.index,</span><br><span class="line">            np.random.rand(<span class="built_in">len</span>(self.items_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="keyword">return</span> P, Q</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        使用随机梯度下降，优化结果</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        P, Q = self._init_matrix()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;iter%d&quot;</span>%i)</span><br><span class="line">            error_list = []</span><br><span class="line">            <span class="keyword">for</span> uid, iid, r_ui <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                v_pu = P[uid]</span><br><span class="line">                v_qi = Q[iid]</span><br><span class="line">                err = np.float32(r_ui - self.globalMean - bu[uid] - bi[iid] - np.dot(v_pu, v_qi))</span><br><span class="line"></span><br><span class="line">                v_pu += self.alpha * (err * v_qi - self.reg_p * v_pu)</span><br><span class="line">                v_qi += self.alpha * (err * v_pu - self.reg_q * v_qi)</span><br><span class="line">                </span><br><span class="line">                P[uid] = v_pu </span><br><span class="line">                Q[iid] = v_qi</span><br><span class="line">                </span><br><span class="line">                bu[uid] += self.alpha * (err - self.reg_bu * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (err - self.reg_bi * bi[iid])</span><br><span class="line"></span><br><span class="line">                error_list.append(err ** <span class="number">2</span>)</span><br><span class="line">            <span class="built_in">print</span>(np.sqrt(np.mean(error_list)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> P, Q, bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> uid <span class="keyword">not</span> <span class="keyword">in</span> self.users_ratings.index <span class="keyword">or</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">return</span> self.globalMean</span><br><span class="line"></span><br><span class="line">        p_u = self.P[uid]</span><br><span class="line">        q_i = self.Q[iid]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.globalMean + self.bu[uid] + self.bi[iid] + np.dot(p_u, q_i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">3</span>), dtype=<span class="built_in">dict</span>(dtype))</span><br><span class="line"></span><br><span class="line">    bsvd = BiasSvd(<span class="number">0.02</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">    bsvd.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = <span class="built_in">input</span>(<span class="string">&quot;uid: &quot;</span>)</span><br><span class="line">        iid = <span class="built_in">input</span>(<span class="string">&quot;iid: &quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(bsvd.predict(<span class="built_in">int</span>(uid), <span class="built_in">int</span>(iid)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="基于内容的推荐算法（Content-Based）"><a href="#基于内容的推荐算法（Content-Based）" class="headerlink" title="基于内容的推荐算法（Content-Based）"></a>基于内容的推荐算法（Content-Based）</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>基于内容的推荐方法是非常直接的，它以物品的内容描述信息为依据来做出的推荐，本质上是基于对物品和用户自身的特征或属性的直接分析和计算。</p>
<p>例如，假设已知电影A是一部喜剧，而恰巧我们得知某个用户喜欢看喜剧电影，那么我们基于这样的已知信息，就可以将电影A推荐给该用户。</p>
<h3 id="基于内容的推荐实现步骤"><a href="#基于内容的推荐实现步骤" class="headerlink" title="基于内容的推荐实现步骤"></a>基于内容的推荐实现步骤</h3><ul>
<li><p><strong>画像构建</strong>。顾名思义，画像就是刻画物品或用户的特征。本质上就是给用户或物品贴标签。</p>
<ul>
<li><p><strong>物品画像</strong>：例如给电影《战狼2》贴标签，可以有哪些？</p>
<p><img src="基于内容推荐1.png" alt=""></p>
<p>“动作”、”吴京”、”吴刚”、”张翰”、”大陆电影”、”国产”、”爱国”、”军事”等等一系列标签是不是都可以贴上</p>
</li>
<li><p><strong>用户画像</strong>：例如已知用户的观影历史是：”《战狼1》”、”《战狼2》”、”《建党伟业》”、”《建军大业》”、”《建国大业》”、”《红海行动》”、”《速度与激情1-8》”等，我们是不是就可以分析出该用户的一些兴趣特征如：”爱国”、”战争”、”赛车”、”动作”、”军事”、”吴京”、”韩三平”等标签。</p>
</li>
</ul>
</li>
</ul>
<h4 id="问题：物品的标签来自哪儿？"><a href="#问题：物品的标签来自哪儿？" class="headerlink" title="问题：物品的标签来自哪儿？"></a>问题：物品的标签来自哪儿？</h4><ol>
<li>PGC    物品画像—冷启动<ul>
<li>物品自带的属性（物品一产生就具备的）：如电影的标题、导演、演员、类型等等</li>
<li>服务提供方设定的属性（服务提供方为物品附加的属性）：如短视频话题、微博话题（平台拟定）</li>
<li>其他渠道：如爬虫</li>
</ul>
</li>
<li>UGC    冷启动问题<ul>
<li>用户在享受服务过程中提供的物品的属性：如用户评论内容，微博话题（用户拟定）</li>
</ul>
</li>
</ol>
<p>根据PGC内容构建的物品画像的可以解决物品的冷启动问题</p>
<h4 id="基于内容推荐的算法流程："><a href="#基于内容推荐的算法流程：" class="headerlink" title="基于内容推荐的算法流程："></a>基于内容推荐的算法流程：</h4><ul>
<li>根据PGC/UGC内容构建物品画像</li>
<li>根据用户行为记录生成用户画像</li>
<li>根据用户画像从物品中寻找最匹配的TOP-N物品进行推荐</li>
</ul>
<h4 id="物品冷启动处理："><a href="#物品冷启动处理：" class="headerlink" title="物品冷启动处理："></a>物品冷启动处理：</h4><ul>
<li>根据PGC内容构建物品画像</li>
<li>利用物品画像计算物品间两两相似情况</li>
<li>为每个物品产生TOP-N最相似的物品进行相关推荐：如与该商品相似的商品有哪些？与该文章相似文章有哪些？</li>
</ul>
<h2 id="基于内容的电影推荐：物品画像"><a href="#基于内容的电影推荐：物品画像" class="headerlink" title="基于内容的电影推荐：物品画像"></a>基于内容的电影推荐：物品画像</h2><p>物品画像构建步骤：</p>
<ul>
<li>利用tags.csv中每部电影的标签作为电影的候选关键词</li>
<li>利用TF·IDF计算每部电影的标签的tfidf值，选取TOP-N个关键词作为电影画像标签</li>
<li>将电影的分类词直接作为每部电影的画像标签</li>
</ul>
<h2 id="基于TF-IDF的特征提取技术"><a href="#基于TF-IDF的特征提取技术" class="headerlink" title="基于TF-IDF的特征提取技术"></a>基于TF-IDF的特征提取技术</h2><p>前面提到，物品画像的特征标签主要都是指的如电影的导演、演员、图书的作者、出版社等结构话的数据，也就是他们的特征提取，尤其是体征向量的计算是比较简单的，如直接给作品的分类定义0或者1的状态。</p>
<p>但另外一些特征，比如电影的内容简介、电影的影评、图书的摘要等文本数据，这些被称为非结构化数据，首先他们本应该也属于物品的一个特征标签，但是这样的特征标签进行量化时，也就是计算它的特征向量时是很难去定义的。</p>
<p>因此这时就需要借助一些自然语言处理、信息检索等技术，将如用户的文本评论或其他文本内容信息的非结构化数据进行量化处理，从而实现更加完善的物品画像/用户画像。</p>
<p>TF-IDF算法便是其中一种在自然语言处理领域中应用比较广泛的一种算法。可用来提取目标文档中，并得到关键词用于计算对于目标文档的权重，并将这些权重组合到一起得到特征向量。</p>
<h3 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h3><p>TF-IDF自然语言处理领域中计算文档中词或短语的权值的方法，是<strong>词频</strong>（Term Frequency，TF）和逆转文档频率（Inverse Document Frequency，IDF）的乘积。TF指的是某一个给定的词语在该文件中出现的次数。这个数字通常会被正规化，以防止它偏向长的文件（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否）。IDF是一个词语普遍重要性的度量，某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。</p>
<p>TF-IDF算法基于一个这样的假设：若一个词语在目标文档中出现的频率高而在其他文档中出现的频率低，那么这个词语就可以用来区分出目标文档。这个假设需要掌握的有两点：</p>
<ul>
<li>在本文档出现的频率高；</li>
<li>在其他文档出现的频率低。</li>
</ul>
<p>因此，TF-IDF算法的计算可以分为词频（Term Frequency，TF）和逆转文档频率（Inverse Document Frequency，IDF）两部分，由TF和IDF的乘积来设置文档词语的权重。</p>
<p>TF指的是一个词语在文档中的出现频率。假设文档集包含的文档数为$N​$，文档集中包含关键词$k<em>i​$的文档数为$n_i​$，$f</em>{ij}​$表示关键词$k<em>i​$在文档$d_j​$中出现的次数，$f</em>{dj}​$表示文档$d<em>j​$中出现的词语总数，$k_i​$在文档dj中的词频$TF</em>{ij}​$定义为：<script type="math/tex">TF_{ij}=\frac {f_{ij}}{f_{dj}}​</script><br>这个数字通常会被正规化，以防止它偏向长的文件（指同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否）。</p>
<p>IDF是一个词语普遍重要性的度量。表示某一词语在整个文档集中出现的频率，由它计算的结果取对数得到关键词$k_i​$的逆文档频率$IDF_i​$：<script type="math/tex">IDF_i=log\frac {N}{n_i}​</script></p>
<p>由TF和IDF计算词语的权重为：<script type="math/tex">w_{ij}=TF_{ij}</script></p>
<script type="math/tex; mode=display">IDF_{i}=\frac {f_{ij}}{f_{dj}}</script><script type="math/tex; mode=display">log\frac {N}{n_i}</script><p><strong>结论：TF-IDF与词语在文档中的出现次数成正比，与该词在整个文档集中的出现次数成反比。</strong></p>
<p><strong>用途：在目标文档中，提取关键词(特征标签)的方法就是将该文档所有词语的TF-IDF计算出来并进行对比，取其中TF-IDF值最大的k个数组成目标文档的特征向量用以表示文档。</strong></p>
<p>注意：文档中存在的停用词（Stop Words），如“是”、“的”之类的，对于文档的中心思想表达没有意义的词，在分词时需要先过滤掉再计算其他词语的TF-IDF值。</p>
<h3 id="算法举例"><a href="#算法举例" class="headerlink" title="算法举例"></a>算法举例</h3><p>对于计算影评的TF-IDF，以电影“加勒比海盗：黑珍珠号的诅咒”为例，假设它总共有1000篇影评，其中一篇影评的总词语数为200，其中出现最频繁的词语为“海盗”、“船长”、“自由”，分别是20、15、10次，并且这3个词在所有影评中被提及的次数分别为1000、500、100，就这3个词语作为关键词的顺序计算如下。</p>
<ol>
<li><p>将影评中出现的停用词过滤掉，计算其他词语的词频。以出现最多的三个词为例进行计算如下：</p>
<ul>
<li>“海盗”出现的词频为20/200＝0.1</li>
<li>“船长”出现的词频为15/200=0.075</li>
<li>“自由”出现的词频为10/200=0.05；</li>
</ul>
</li>
<li><p>计算词语的逆文档频率如下：</p>
<ul>
<li>“海盗”的IDF为：log(1000/1000)=0</li>
<li>“船长”的IDF为：log(1000/500)=0.3<br>“自由”的IDF为：log(1000/100)=1</li>
</ul>
</li>
<li>由1和2计算的结果求出词语的TF-IDF结果，“海盗”为0，“船长”为0.0225，“自由”为0.05。</li>
</ol>
<p>通过对比可得，该篇影评的关键词排序应为：“自由”、“船长”、“海盗”。把这些词语的TF-IDF值作为它们的权重按照对应的顺序依次排列，就得到这篇影评的特征向量，我们就用这个向量来代表这篇影评，向量中每一个维度的分量大小对应这个属性的重要性。</p>
<p>将总的影评集中所有的影评向量与特定的系数相乘求和，得到这部电影的综合影评向量，与电影的基本属性结合构建视频的物品画像，同理构建用户画像，可采用多种方法计算物品画像和用户画像之间的相似度，为用户做出推荐。</p>
<h3 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">- 利用tags.csv中每部电影的标签作为电影的候选关键词</span></span><br><span class="line"><span class="string">- 利用TF·IDF计算每部电影的标签的tfidf值，选取TOP-N个关键词作为电影画像标签</span></span><br><span class="line"><span class="string">- 并将电影的分类词直接作为每部电影的画像标签</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie_dataset</span>():</span></span><br><span class="line">    <span class="comment"># 加载基于所有电影的标签</span></span><br><span class="line">    <span class="comment"># all-tags.csv来自ml-latest数据集中</span></span><br><span class="line">    <span class="comment"># 由于ml-latest-small中标签数据太多，因此借助其来扩充</span></span><br><span class="line">    _tags = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/all-tags.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>)).dropna()</span><br><span class="line">    tags = _tags.groupby(<span class="string">&quot;movieId&quot;</span>).agg(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载电影列表数据集</span></span><br><span class="line">    movies = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/movies.csv&quot;</span>, index_col=<span class="string">&quot;movieId&quot;</span>)</span><br><span class="line">    <span class="comment"># 将类别词分开</span></span><br><span class="line">    movies[<span class="string">&quot;genres&quot;</span>] = movies[<span class="string">&quot;genres&quot;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment"># 为每部电影匹配对应的标签数据，如果没有将会是NAN</span></span><br><span class="line">    movies_index = <span class="built_in">set</span>(movies.index) &amp; <span class="built_in">set</span>(tags.index)</span><br><span class="line">    new_tags = tags.loc[<span class="built_in">list</span>(movies_index)]</span><br><span class="line">    ret = movies.join(new_tags)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建电影数据集，包含电影Id、电影名称、类别、标签四个字段</span></span><br><span class="line">    <span class="comment"># 如果电影没有标签数据，那么就替换为空列表</span></span><br><span class="line">    <span class="comment"># map(fun,可迭代对象)</span></span><br><span class="line">    movie_dataset = pd.DataFrame(</span><br><span class="line">        <span class="built_in">map</span>(</span><br><span class="line">            <span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], x[<span class="number">2</span>]+x[<span class="number">3</span>]) <span class="keyword">if</span> x[<span class="number">3</span>] <span class="keyword">is</span> <span class="keyword">not</span> np.nan <span class="keyword">else</span> (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], []), ret.itertuples())</span><br><span class="line">        , columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;genres&quot;</span>,<span class="string">&quot;tags&quot;</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    movie_dataset.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_dataset</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line"><span class="built_in">print</span>(movie_dataset)</span><br></pre></td></tr></table></figure>
<h3 id="基于TF·IDF提取TOP-N关键词，构建电影画像"><a href="#基于TF·IDF提取TOP-N关键词，构建电影画像" class="headerlink" title="基于TF·IDF提取TOP-N关键词，构建电影画像"></a>基于TF·IDF提取TOP-N关键词，构建电影画像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset: </span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    <span class="comment"># 根据数据集建立词袋，并统计词频，将所有词放入一个词典，使用索引进行获取</span></span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    <span class="comment"># 根据将每条数据，返回对应的词索引和词频</span></span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line">    <span class="comment"># 训练TF-IDF模型，即计算TF-IDF值</span></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    movie_profile = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i, mid <span class="keyword">in</span> <span class="built_in">enumerate</span>(movie_dataset.index):</span><br><span class="line">        <span class="comment"># 根据每条数据返回，向量</span></span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        <span class="comment"># 按照TF-IDF值得到top-n的关键词</span></span><br><span class="line">        movie_tags = <span class="built_in">sorted</span>(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        <span class="comment"># 根据关键词提取对应的名称</span></span><br><span class="line">        movie_profile[mid] = <span class="built_in">dict</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">pprint(create_movie_profile(movie_dataset))</span><br></pre></td></tr></table></figure>
<h3 id="完善画像关键词"><a href="#完善画像关键词" class="headerlink" title="完善画像关键词"></a>完善画像关键词</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    <span class="comment"># 根据数据集建立词袋，并统计词频，将所有词放入一个词典，使用索引进行获取</span></span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    <span class="comment"># 根据将每条数据，返回对应的词索引和词频</span></span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line">    <span class="comment"># 训练TF-IDF模型，即计算TF-IDF值</span></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    _movie_profile = []</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(movie_dataset.itertuples()):</span><br><span class="line">        mid = data[<span class="number">0</span>]</span><br><span class="line">        title = data[<span class="number">1</span>]</span><br><span class="line">        genres = data[<span class="number">2</span>]</span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        movie_tags = <span class="built_in">sorted</span>(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        topN_tags_weights = <span class="built_in">dict</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line">        <span class="comment"># 将类别词的添加进去，并设置权重值为1.0</span></span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> genres:</span><br><span class="line">            topN_tags_weights[g] = <span class="number">1.0</span></span><br><span class="line">        topN_tags = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> topN_tags_weights.items()]</span><br><span class="line">        _movie_profile.append((mid, title, topN_tags, topN_tags_weights))</span><br><span class="line"></span><br><span class="line">    movie_profile = pd.DataFrame(_movie_profile, columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;profile&quot;</span>, <span class="string">&quot;weights&quot;</span>])</span><br><span class="line">    movie_profile.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">pprint(create_movie_profile(movie_dataset))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>为了根据指定关键词迅速匹配到对应的电影，因此需要对物品画像的标签词，建立<strong>倒排索引</strong></p>
<p><strong>倒排索引介绍</strong></p>
<p>通常数据存储数据，都是以物品的ID作为索引，去提取物品的其他信息数据<br>而倒排索引就是用物品的其他数据作为索引，去提取它们对应的物品的ID列表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">建立tag-物品的倒排索引</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_inverted_table</span>(<span class="params">movie_profile</span>):</span></span><br><span class="line">    inverted_table = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> mid, weights <span class="keyword">in</span> movie_profile[<span class="string">&quot;weights&quot;</span>].iteritems():</span><br><span class="line">        <span class="keyword">for</span> tag, weight <span class="keyword">in</span> weights.items():</span><br><span class="line">            <span class="comment">#到inverted_table dict 用tag作为Key去取值 如果取不到就返回[]</span></span><br><span class="line">            _ = inverted_table.get(tag, [])</span><br><span class="line">            _.append((mid, weight))</span><br><span class="line">            inverted_table.setdefault(tag, _)</span><br><span class="line">    <span class="keyword">return</span> inverted_table</span><br><span class="line"></span><br><span class="line">inverted_table = create_inverted_table(movie_profile)</span><br><span class="line">pprint(inverted_table)</span><br></pre></td></tr></table></figure>
<h2 id="基于内容的电影推荐：用户画像"><a href="#基于内容的电影推荐：用户画像" class="headerlink" title="基于内容的电影推荐：用户画像"></a>基于内容的电影推荐：用户画像</h2><p>用户画像构建步骤：</p>
<ul>
<li>根据用户的评分历史，结合物品画像，将有观影记录的电影的画像标签作为初始标签反打到用户身上</li>
<li>通过对用户观影标签的次数进行统计，计算用户的每个初始标签的权重值，排序后选取TOP-N作为用户最终的画像标签</li>
</ul>
<h3 id="用户画像建立"><a href="#用户画像建立" class="headerlink" title="用户画像建立"></a>用户画像建立</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">user profile画像建立：</span></span><br><span class="line"><span class="string">1. 提取用户观看列表</span></span><br><span class="line"><span class="string">2. 根据观看列表和物品画像为用户匹配关键词，并统计词频</span></span><br><span class="line"><span class="string">3. 根据词频排序，最多保留TOP-k个词，这里K设为100，作为用户的标签</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_user_profile</span>():</span></span><br><span class="line">    watch_record = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">2</span>), dtype=&#123;<span class="string">&quot;userId&quot;</span>:np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32&#125;)</span><br><span class="line"></span><br><span class="line">    watch_record = watch_record.groupby(<span class="string">&quot;userId&quot;</span>).agg(<span class="built_in">list</span>)</span><br><span class="line">    <span class="comment"># print(watch_record)</span></span><br><span class="line"></span><br><span class="line">    movie_dataset = get_movie_dataset()</span><br><span class="line">    movie_profile = create_movie_profile(movie_dataset)</span><br><span class="line"></span><br><span class="line">    user_profile = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> uid, mids <span class="keyword">in</span> watch_record.itertuples():</span><br><span class="line">        record_movie_prifole = movie_profile.loc[<span class="built_in">list</span>(mids)]</span><br><span class="line">        counter = collections.Counter(reduce(<span class="keyword">lambda</span> x, y: <span class="built_in">list</span>(x)+<span class="built_in">list</span>(y), record_movie_prifole[<span class="string">&quot;profile&quot;</span>].values))</span><br><span class="line">        <span class="comment"># 兴趣词</span></span><br><span class="line">        interest_words = counter.most_common(<span class="number">50</span>)</span><br><span class="line">        maxcount = interest_words[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">        interest_words = [(w,<span class="built_in">round</span>(c/maxcount, <span class="number">4</span>)) <span class="keyword">for</span> w,c <span class="keyword">in</span> interest_words]</span><br><span class="line">        user_profile[uid] = interest_words</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> user_profile</span><br><span class="line"></span><br><span class="line">user_profile = create_user_profile()</span><br><span class="line">pprint(user_profile)</span><br></pre></td></tr></table></figure>
<h2 id="基于内容的电影推荐：为用户产生TOP-N推荐结果"><a href="#基于内容的电影推荐：为用户产生TOP-N推荐结果" class="headerlink" title="基于内容的电影推荐：为用户产生TOP-N推荐结果"></a>基于内容的电影推荐：为用户产生TOP-N推荐结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">user_profile = create_user_profile()</span><br><span class="line"></span><br><span class="line">watch_record = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">2</span>),dtype=&#123;<span class="string">&quot;userId&quot;</span>: np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32&#125;)</span><br><span class="line"></span><br><span class="line">watch_record = watch_record.groupby(<span class="string">&quot;userId&quot;</span>).agg(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> uid, interest_words <span class="keyword">in</span> user_profile.items():</span><br><span class="line">    result_table = &#123;&#125; <span class="comment"># 电影id:[0.2,0.5,0.7]</span></span><br><span class="line">    <span class="keyword">for</span> interest_word, interest_weight <span class="keyword">in</span> interest_words:</span><br><span class="line">        related_movies = inverted_table[interest_word]</span><br><span class="line">        <span class="keyword">for</span> mid, related_weight <span class="keyword">in</span> related_movies:</span><br><span class="line">            _ = result_table.get(mid, [])</span><br><span class="line">            _.append(interest_weight)    <span class="comment"># 只考虑用户的兴趣程度</span></span><br><span class="line">            <span class="comment"># _.append(related_weight)    # 只考虑兴趣词与电影的关联程度</span></span><br><span class="line">            <span class="comment"># _.append(interest_weight*related_weight)    # 二者都考虑</span></span><br><span class="line">            result_table.setdefault(mid, _)</span><br><span class="line"></span><br><span class="line">    rs_result = <span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x[<span class="number">0</span>], <span class="built_in">sum</span>(x[<span class="number">1</span>])), result_table.items())</span><br><span class="line">    rs_result = <span class="built_in">sorted</span>(rs_result, key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">100</span>]</span><br><span class="line">    <span class="built_in">print</span>(uid)</span><br><span class="line">    pprint(rs_result)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 历史数据  ==&gt;  历史兴趣程度 ==&gt;  历史推荐结果       离线推荐    离线计算</span></span><br><span class="line">    <span class="comment"># 在线推荐 ===&gt;    娱乐(王思聪)   ===&gt;   我 ==&gt;  王思聪 100%  </span></span><br><span class="line">    <span class="comment"># 近线：最近1天、3天、7天           实时计算</span></span><br></pre></td></tr></table></figure>
<h2 id="基于内容的电影推荐：物品冷启动处理"><a href="#基于内容的电影推荐：物品冷启动处理" class="headerlink" title="基于内容的电影推荐：物品冷启动处理"></a>基于内容的电影推荐：物品冷启动处理</h2><p>利用Word2Vec可以计算电影所有标签词之间的关系程度，可用于计算电影之间的相似度</p>
<h3 id="word2vec原理简介"><a href="#word2vec原理简介" class="headerlink" title="word2vec原理简介"></a>word2vec原理简介</h3><ul>
<li><p>word2vec是google在2013年开源的一个NLP(Natural Language Processing自然语言处理) 工具，它的特点是将所有的词向量化，这样词与词之间就可以定量的去度量他们之间的关系，挖掘词之间的联系。</p>
</li>
<li><p>one-hot vector VS. word vector</p>
<ul>
<li>用向量来表示词并不是word2vec的首创</li>
<li>最早的词向量是很冗长的，它使用是词向量维度大小为整个词汇表的大小，对于每个具体的词汇表中的词，将对应的位置置为1。</li>
<li>比如下面5个词组成词汇表，词”Queen”的序号为2， 那么它的词向量就是(0,1,0,0,0)同样的道理，词”Woman”的词向量就是(0,0,0,1,0)。</li>
</ul>
<p><img src="word2vec1.png" alt=""></p>
</li>
<li><p>one hot vector的问题</p>
<ul>
<li>如果词汇表非常大，如达到万级别，这样每个词都用万维的向量来表示浪费内存。这样的向量除了一个位置是1，其余位置全部为0，表达效率低(稀疏)，需要降低词向量的维度</li>
<li>难以发现词之间的关系，以及难以捕捉句法（结构）和语义（意思）之间的关系</li>
<li>Dristributed representation可以解决One hot representation的问题，它的思路是通过训练，将每个词都映射到一个较短的词向量上来。所有的这些词向量就构成了向量空间，进而可以用普通的统计学的方法来研究词与词之间的关系。这个较短的词向量维度一般需要我们在训练时指定。</li>
<li>比如下图我们将词汇表里的词用”Royalty(王位)”,”Masculinity(男性气质)”, “Femininity(女性气质)”和”Age”4个维度来表示，King这个词对应的词向量可能是(0.99,0.99,0.05,0.7)。当然在实际情况中，我们并不一定能对词向量的每个维度做一个很好的解释。</li>
</ul>
<p><img src="word2vec2.png" alt=""></p>
</li>
<li><p>有了用Dristributed representation表示的较短的词向量，就可以较容易的分析词之间的关系，比如将词的维度降维到2维，用下图的词向量表示我们的词时，发现：$\vec{King} - \vec{Man} + \vec{Woman} = \vec{Queen}​$ </p>
<p><img src="word2vec3.png" alt=""></p>
</li>
<li><p>什么是word vector（词向量）</p>
<ul>
<li>每个单词被表征为多维的浮点数，每一维的浮点数的数值大小表示了它与另一个单词之间的“距离”，表征的结果就是语义相近的词被映射到相近的集合空间上，好处是这样单词之间就是可以计算的：</li>
</ul>
<table>
    <th>
    <td> animal </td>
    <td> pet </td>
    </th>
<tr>
 <td> dog </td>
 <td> -0.4 </td>
 <td> 0.02 </td>
</tr>
<tr>
 <td> lion </td>
 <td> 0.2 </td>
 <td> 0.35 </td>
</tr>
</table>

<p>animal那一列表示的就是左边的词与animal这个概念的”距离“</p>
</li>
</ul>
<h3 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h3><h4 id="两个重要模型：CBOW和Skip-Gram"><a href="#两个重要模型：CBOW和Skip-Gram" class="headerlink" title="两个重要模型：CBOW和Skip-Gram"></a>两个重要模型：CBOW和Skip-Gram</h4><ul>
<li><p>介绍：CBOW把一个词从词窗剔除。在CBOW下给定<em>n</em>词围绕着词<em>w</em>，word2vec预测一个句子中其中一个缺漏的词<em>c</em>，即以概率$p(c|w)$来表示。相反地，Skip-gram给定词窗中的文本，预测当前的词$p(w|c)​$。</p>
</li>
<li><p>原理：拥有差不多上下文的两个单词的意思往往是相近的</p>
</li>
<li><p><strong>Continuous Bag-of-Words(CBOW)</strong> 连续词袋向量</p>
<ul>
<li><p>功能：通过上下文预测当前词出现的概率</p>
</li>
<li><p>原理分析</p>
<p>假设文本如下：“the florid <u>prose of</u> <strong>the</strong> <u>nineteenth century.</u>”</p>
<p>想象有个滑动窗口，中间的词是关键词，两边为相等长度的文本来帮助分析。文本的长度为7，就得到了7个one-hot向量，作为神经网络的输入向量，训练目标是：最大化在给定前后文本情况下输出正确关键词的概率，比如给定(“prose”,”of”,”nineteenth”,”century”)的情况下，要最大化输出”the”的概率，用公式表示就是：<br>P(“the”|(“prose”,”of”,”nineteenth”,”century”))</p>
</li>
<li><p>特性</p>
<ul>
<li>hidden layer只是将权重求和，传递到下一层，是线性的</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Continuous Skip-gram</strong></p>
<ul>
<li>功能：根据当前词预测上下文</li>
<li>原理分析<ul>
<li>和CBOW相反，则我们要求的概率就变为P(Context(w)|w)</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><strong>总结：</strong>word2vec算法可以计算出每个词语的一个词向量，我们可以用它来表示该词的语义层面的含义</li>
</ul>
<h3 id="Word2Vec使用"><a href="#Word2Vec使用" class="headerlink" title="Word2Vec使用"></a>Word2Vec使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie_dataset</span>():</span></span><br><span class="line">    <span class="comment"># 加载基于所有电影的标签</span></span><br><span class="line">    <span class="comment"># all-tags.csv来自ml-latest数据集中</span></span><br><span class="line">    <span class="comment"># 由于ml-latest-small中标签数据太多，因此借助其来扩充</span></span><br><span class="line">    _tags = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/all-tags.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>)).dropna()</span><br><span class="line">    tags = _tags.groupby(<span class="string">&quot;movieId&quot;</span>).agg(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载电影列表数据集</span></span><br><span class="line">    movies = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/movies.csv&quot;</span>, index_col=<span class="string">&quot;movieId&quot;</span>)</span><br><span class="line">    <span class="comment"># 将类别词分开</span></span><br><span class="line">    movies[<span class="string">&quot;genres&quot;</span>] = movies[<span class="string">&quot;genres&quot;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment"># 为每部电影匹配对应的标签数据，如果没有将会是NAN</span></span><br><span class="line">    movies_index = <span class="built_in">set</span>(movies.index) &amp; <span class="built_in">set</span>(tags.index)</span><br><span class="line">    new_tags = tags.loc[<span class="built_in">list</span>(movies_index)]</span><br><span class="line">    ret = movies.join(new_tags)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建电影数据集，包含电影Id、电影名称、类别、标签四个字段</span></span><br><span class="line">    <span class="comment"># 如果电影没有标签数据，那么就替换为空列表</span></span><br><span class="line">    movie_dataset = pd.DataFrame(</span><br><span class="line">        <span class="built_in">map</span>(</span><br><span class="line">            <span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], x[<span class="number">2</span>]+x[<span class="number">3</span>]) <span class="keyword">if</span> x[<span class="number">3</span>] <span class="keyword">is</span> <span class="keyword">not</span> np.nan <span class="keyword">else</span> (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], []), ret.itertuples())</span><br><span class="line">        , columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;genres&quot;</span>,<span class="string">&quot;tags&quot;</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    movie_dataset.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line"></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    _movie_profile = []</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(movie_dataset.itertuples()):</span><br><span class="line">        mid = data[<span class="number">0</span>]</span><br><span class="line">        title = data[<span class="number">1</span>]</span><br><span class="line">        genres = data[<span class="number">2</span>]</span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        movie_tags = <span class="built_in">sorted</span>(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        topN_tags_weights = <span class="built_in">dict</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line">        <span class="comment"># 将类别词的添加进去，并设置权重值为1.0</span></span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> genres:</span><br><span class="line">            topN_tags_weights[g] = <span class="number">1.0</span></span><br><span class="line">        topN_tags = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> topN_tags_weights.items()]</span><br><span class="line">        _movie_profile.append((mid, title, topN_tags, topN_tags_weights))</span><br><span class="line"></span><br><span class="line">    movie_profile = pd.DataFrame(_movie_profile, columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;profile&quot;</span>, <span class="string">&quot;weights&quot;</span>])</span><br><span class="line">    movie_profile.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">movie_profile = create_movie_profile(movie_dataset)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> gensim, logging</span><br><span class="line"></span><br><span class="line">logging.basicConfig(<span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s : %(levelname)s : %(message)s&#x27;</span>, level=logging.INFO)</span><br><span class="line"></span><br><span class="line">sentences = <span class="built_in">list</span>(movie_profile[<span class="string">&quot;profile&quot;</span>].values)</span><br><span class="line"></span><br><span class="line">model = gensim.models.Word2Vec(sentences, window=<span class="number">3</span>, min_count=<span class="number">1</span>, <span class="built_in">iter</span>=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    words = <span class="built_in">input</span>(<span class="string">&quot;words: &quot;</span>)  <span class="comment"># action</span></span><br><span class="line">    ret = model.wv.most_similar(positive=[words], topn=<span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(ret)</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<p>Doc2Vec是建立在Word2Vec上的，用于直接计算以文档为单位的文档向量，这里我们将一部电影的所有标签词，作为整个文档，这样可以计算出每部电影的向量，通过计算向量之间的距离，来判断用于计算电影之间的相似程度。</p>
<p>这样可以解决物品冷启动问题</p>
<h3 id="Doc2Vec使用"><a href="#Doc2Vec使用" class="headerlink" title="Doc2Vec使用"></a>Doc2Vec使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie_dataset</span>():</span></span><br><span class="line">    <span class="comment"># 加载基于所有电影的标签</span></span><br><span class="line">    <span class="comment"># all-tags.csv来自ml-latest数据集中</span></span><br><span class="line">    <span class="comment"># 由于ml-latest-small中标签数据太多，因此借助其来扩充</span></span><br><span class="line">    _tags = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/all-tags.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>)).dropna()</span><br><span class="line">    tags = _tags.groupby(<span class="string">&quot;movieId&quot;</span>).agg(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载电影列表数据集</span></span><br><span class="line">    movies = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/movies.csv&quot;</span>, index_col=<span class="string">&quot;movieId&quot;</span>)</span><br><span class="line">    <span class="comment"># 将类别词分开</span></span><br><span class="line">    movies[<span class="string">&quot;genres&quot;</span>] = movies[<span class="string">&quot;genres&quot;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment"># 为每部电影匹配对应的标签数据，如果没有将会是NAN</span></span><br><span class="line">    movies_index = <span class="built_in">set</span>(movies.index) &amp; <span class="built_in">set</span>(tags.index)</span><br><span class="line">    new_tags = tags.loc[<span class="built_in">list</span>(movies_index)]</span><br><span class="line">    ret = movies.join(new_tags)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建电影数据集，包含电影Id、电影名称、类别、标签四个字段</span></span><br><span class="line">    <span class="comment"># 如果电影没有标签数据，那么就替换为空列表</span></span><br><span class="line">    movie_dataset = pd.DataFrame(</span><br><span class="line">        <span class="built_in">map</span>(</span><br><span class="line">            <span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], x[<span class="number">2</span>]+x[<span class="number">3</span>]) <span class="keyword">if</span> x[<span class="number">3</span>] <span class="keyword">is</span> <span class="keyword">not</span> np.nan <span class="keyword">else</span> (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], []), ret.itertuples())</span><br><span class="line">        , columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;genres&quot;</span>,<span class="string">&quot;tags&quot;</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    movie_dataset.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line"></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    _movie_profile = []</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(movie_dataset.itertuples()):</span><br><span class="line">        mid = data[<span class="number">0</span>]</span><br><span class="line">        title = data[<span class="number">1</span>]</span><br><span class="line">        genres = data[<span class="number">2</span>]</span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        movie_tags = <span class="built_in">sorted</span>(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        topN_tags_weights = <span class="built_in">dict</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line">        <span class="comment"># 将类别词的添加进去，并设置权重值为1.0</span></span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> genres:</span><br><span class="line">            topN_tags_weights[g] = <span class="number">1.0</span></span><br><span class="line">        topN_tags = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> topN_tags_weights.items()]</span><br><span class="line">        _movie_profile.append((mid, title, topN_tags, topN_tags_weights))</span><br><span class="line"></span><br><span class="line">    movie_profile = pd.DataFrame(_movie_profile, columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;profile&quot;</span>, <span class="string">&quot;weights&quot;</span>])</span><br><span class="line">    movie_profile.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">movie_profile = create_movie_profile(movie_dataset)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> gensim, logging</span><br><span class="line"><span class="keyword">from</span> gensim.models.doc2vec <span class="keyword">import</span> Doc2Vec, TaggedDocument</span><br><span class="line"></span><br><span class="line">logging.basicConfig(<span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s : %(levelname)s : %(message)s&#x27;</span>, level=logging.INFO)</span><br><span class="line"></span><br><span class="line">documents = [TaggedDocument(words, [movie_id]) <span class="keyword">for</span> movie_id, words <span class="keyword">in</span> movie_profile[<span class="string">&quot;profile&quot;</span>].iteritems()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型并保存</span></span><br><span class="line">model = Doc2Vec(documents, vector_size=<span class="number">100</span>, window=<span class="number">3</span>, min_count=<span class="number">1</span>, workers=<span class="number">4</span>, epochs=<span class="number">20</span>)</span><br><span class="line"><span class="keyword">from</span> gensim.test.utils <span class="keyword">import</span> get_tmpfile</span><br><span class="line">fname = get_tmpfile(<span class="string">&quot;my_doc2vec_model&quot;</span>)</span><br><span class="line">model.save(fname)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">words = movie_profile[<span class="string">&quot;profile&quot;</span>].loc[<span class="number">6</span>]</span><br><span class="line"><span class="built_in">print</span>(words)</span><br><span class="line">inferred_vector = model.infer_vector(words)</span><br><span class="line">sims = model.docvecs.most_similar([inferred_vector], topn=<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(sims)</span><br></pre></td></tr></table></figure>
<h2 id="基于关联规则的推荐"><a href="#基于关联规则的推荐" class="headerlink" title="基于关联规则的推荐"></a>基于关联规则的推荐</h2><p>基于关联规则的推荐思想类似基于物品的协同过滤推荐</p>
<p><strong>“啤酒与尿布”</strong></p>
<p>关联分析中最有名的例子就是“啤酒与尿布”。</p>
<p>据报道，在美国沃尔玛超市会发现一个很有趣的现象：货架上啤酒与尿布竟然放在一起售卖，这看似两者毫不相关的东西，为什么会放在一起售卖呢？</p>
<p>原来，在美国，妇女们经常会嘱咐她们的丈夫下班以后给孩子买一点尿布回来，而丈夫在买完尿布后，大都会顺手买回一瓶自己爱喝的啤酒（由此看出美国人爱喝酒）。商家通过对一年多的原始交易记录进行详细的分析，发现了这对神奇的组合。于是就毫不犹豫地将尿布与啤酒摆放在一起售卖，通过它们的关联性，互相促进销售。“啤酒与尿布”的故事一度是营销界的神话。</p>
<p>那么问题来了，<strong>商家是如何发现啤酒与尿布两者之间的关联性呢？</strong></p>
<p>这里我们可以使用数据挖掘中的关联规则挖掘技术，目的就是为了找出两个对象（如X,Y）之间的关联性。一旦找出二者关联性，那么就可以根据它来进行推荐。</p>
<p><strong>基于关联规则的推荐</strong></p>
<p>一般我们可以找出用户购买的所有物品数据里频繁出现的项集活序列，来做频繁集挖掘，找到满足支持度阈值的关联物品的频繁N项集或者序列。如果用户购买了频繁N项集或者序列里的部分物品，那么我们可以将频繁项集或序列里的其他物品按一定的评分准则推荐给用户，这个评分准则可以包括支持度，置信度和提升度等。</p>
<p>常用的关联推荐算法有Apriori，FP-Growth</p>
<h3 id="关联分析"><a href="#关联分析" class="headerlink" title="关联分析"></a>关联分析</h3><p>关联分析是一种在大规模数据集中寻找有趣关系的任务。 这些关系可以有两种形式:</p>
<ul>
<li>频繁项集（frequent item sets）是指经常出现在一块的物品的集合。</li>
<li>关联规则（associational rules）是暗示两种物品之间可能存在很强的关系。</li>
</ul>
<p>从大规模数据集中寻找物品间的隐含关系被称作关联分析(association analysis)或者关联规则学习（association rule learning）</p>
<h3 id="关联性衡量指标"><a href="#关联性衡量指标" class="headerlink" title="关联性衡量指标"></a>关联性衡量指标</h3><p>假设我们下图所示的一份数据集</p>
<p><img src="关联规则数据示例.png" alt=""></p>
<p>确定X， Y的关联性，需要用两个指标来衡量：</p>
<ul>
<li><p><strong>支持度（support）</strong></p>
<p>支持度是针对项集而言的</p>
<p>项集的支持度被定义为数据集中包含该项集的记录所占的比例</p>
<p>那么项集<code>&#123;豆奶&#125;</code>的支持度就是4/5，那么项集<code>&#123;豆奶, 莴苣&#125;</code>的支持度就是3/5</p>
</li>
<li><p><strong>置信度（confidence）</strong></p>
<p>置信度也成为可信度，是针对一个关联规则而言的，如<code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>，表示<code>&#123;豆奶&#125;</code>之于<code>&#123;莴苣&#125;</code>的关联程度（注意：<code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>不等价于<code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>）</p>
<p><code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>的置信度 = 支持度(<code>&#123;豆奶, 莴苣&#125;</code>)/支持度(<code>&#123;豆奶&#125;</code>)，即3/4</p>
<p><code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>的置信度 = 支持度(<code>&#123;豆奶, 莴苣&#125;</code>)/支持度(<code>&#123;莴苣&#125;</code>)，即3/4</p>
<p>注意：这里他们俩的置信度相等纯属巧合</p>
</li>
</ul>
<p>如果不考虑关联规则的支持度和置信度，那么在数据库中会存在着无穷多的关联规则。因此我们为了提取出真正的频繁项集和关联规则，必须指定一个最小支持度阈值和最小置信度阈值，因为对于支持度和置信度太低的关联规则基本没有什么使用价值。</p>
<ul>
<li><p><strong>最小支持度</strong>：</p>
<p>它表示了一组物品集在统计意义上需要满足的最低程度</p>
</li>
<li><p><strong>最小可信度</strong></p>
<p>它反映了关联规则的最低可靠程度</p>
</li>
</ul>
<p><strong>同时满足最小可信度阈值和最小支持度阈值的关联规则被称为强关联规则。</strong>比如啤酒与尿布。</p>
<p>比如这里，如果我们假设最小支持度阈值为50%，最小可信度阈值为70%，那么这里<code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>和<code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>都属于符合条件的两条关联规则，分别表示：</p>
<ul>
<li>同时购买豆奶和莴苣的顾客占全部顾客的60%</li>
<li><code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>：在购买豆奶的用户中，有75%的顾客会购买莴苣</li>
<li><code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>：在购买莴苣的用户中，有75%的顾客会购买豆奶</li>
</ul>
<h2 id="关键规则挖掘算法（一）Apriori算法"><a href="#关键规则挖掘算法（一）Apriori算法" class="headerlink" title="关键规则挖掘算法（一）Apriori算法"></a>关键规则挖掘算法（一）Apriori算法</h2><h3 id="Apriori算法原理"><a href="#Apriori算法原理" class="headerlink" title="Apriori算法原理"></a>Apriori算法原理</h3><p>Apriori算法是著名的关联规则挖掘算法。</p>
<p>假如我们在经营一家商品种类并不多的杂货店，我们对哪些经常在一起被购买的商品非常感兴趣。我们只有四种商品：商品0、商品1、商品2、商品3。那么所有可能被一起购买的商品组合都有哪些？这些商品组合可能著有一种商品，比如商品0，也可能包括两种、三种或所有四种商品。但我们不关心某人买了两件商品0以及四件商品2的情况，只关心他购买了一种或多种商品。</p>
<p>下图显示了物品之间所有可能的组合：</p>
<ul>
<li>图中使用物品的编号0来表示物品0本身。</li>
<li>图中从上往下的第一个集合是$\phi$，表示空集或不包含任何物品的集合。</li>
<li>物品集合之间的连线表明两个或者更多集合可以组合形成一个更大的集合。</li>
</ul>
<p><img src="apriori1.png" alt=""></p>
<p><strong>目标：</strong>我们的目标是找到经常在一起购买的物品集合。我们使用集合的支持度来度量其出现的频率。</p>
<blockquote>
<p>一个集合的支持度是指有多少比例的交易记录包含该集合。</p>
</blockquote>
<p><strong>问题：</strong> 如何对一个给定的集合，比如<code>&#123;0，3&#125;</code>，来计算其支持度？</p>
<ul>
<li>我们可以遍历毎条记录并检查该记录包含0和3，如果记录确实同时包含这两项，那么就增加总计数值。在扫描完所有数据之后，使用统计得到的总数除以总的交易记录数，就可以得到支持度。</li>
</ul>
<p><strong>注意：</strong>上述过程和结果只是针对单个集合{0,3}。要获得每种可能集合的支持度就需要多次重复上述过程。我们可以数一下图中的集合数目，会发现即使对于仅有4种物品的集合，也需要遍历数据15次。而随着物品数目的增加遍历次数会急剧增长。对于包含N种物品的数据集共有$2^{N-1}$种项集组合。而且实际上出售10 000或更多种物品的商店并不少见。即使只出售100种商品的商店也会有$1.26 * 10^{30}$种可能的项集组合。这样的运算量，其实即使是对于现在的很多计算机而言，也需要很长的时间才能完成运算。</p>
<p><strong>Apriori算法的原理可以帮我们减少可能感兴趣的项集，降低所需的计算时间。</strong></p>
<p>Apriori算法原理：</p>
<ul>
<li><p>如果某个项集是频繁的，那么它的所有子集都是频繁的，例如，假设<code>&#123;1,2&#125;</code>是频繁的，那么<code>&#123;1&#125;</code>和<code>&#123;2&#125;</code>也一定是频繁的。</p>
</li>
<li><p>将这个原理取反会发现：如果一个项集是非频繁的，那么它的所有超集也是非频繁的</p>
<p>如下图中，已知项集<code>&#123;2,3&#125;</code>是非频繁的，那么可立即判断出项集<code>&#123;0,2,3&#125;</code>、<code>&#123;1,2,3&#125;</code>、<code>&#123;0,1,2,3&#125;</code>都是非频繁的，因此这些项集的支持度也就不需要再计算</p>
<p><img src="apriori2.png" alt=""></p>
</li>
</ul>
<p><strong>Apriori算法的一般过程：</strong></p>
<ol>
<li>收集数据：使用任意方法。</li>
<li>准备数据：任何数据类型都可以，因为我们只保存集合。</li>
<li>分析数据：使用任意方法。</li>
<li>训练算法：使用Apriori算法来找到频繁项集。</li>
<li>测试算法：不需要测试过程。</li>
<li>使用算法：用于发现频繁项集以及物品之间的关联规则。</li>
</ol>
<h3 id="Apriori算法实现"><a href="#Apriori算法实现" class="headerlink" title="Apriori算法实现"></a>Apriori算法实现</h3><p><img src="挖掘频繁项集.png" alt=""></p>
<p>实现数据集扫描方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    加载数据集</span></span><br><span class="line"><span class="string">    :return: dataset</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> [[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">2</span>, <span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createC1</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    创建C1候选项集，C1是所有大小为1的候选项集的列表</span></span><br><span class="line"><span class="string">    :param dataSet:</span></span><br><span class="line"><span class="string">    :return: C1</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># C1是所有大小为1的候选项集的列表</span></span><br><span class="line">    C1 = []</span><br><span class="line">    <span class="comment"># 遍历数据集，逐个添加到C1中</span></span><br><span class="line">    <span class="keyword">for</span> record <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> record:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> [item] <span class="keyword">in</span> C1:</span><br><span class="line">                C1.append([item])</span><br><span class="line">    C1.sort()</span><br><span class="line">    <span class="comment"># 使用不变集合存储C1内部的每个候选项集，那么就可以将其作为字典的Key，如果是list类型不能直接作为字典的Key</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">frozenset</span>, C1))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanDataset</span>(<span class="params">dataset, ck, minSupport</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    扫描数据集，判断频繁项集</span></span><br><span class="line"><span class="string">    :param dataset:</span></span><br><span class="line"><span class="string">    :param ck: ck是所有大小为k的候选项集的列表</span></span><br><span class="line"><span class="string">    :param minSupport: 设置的最小支持度阈值</span></span><br><span class="line"><span class="string">    :return: 符合条件的项集、每个项集的支持度</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 存储项集的出现次数</span></span><br><span class="line">    selectedSetCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> record <span class="keyword">in</span> dataset:    <span class="comment"># 遍历每一条记录</span></span><br><span class="line">        <span class="keyword">for</span> candidateSet <span class="keyword">in</span> ck:</span><br><span class="line">            <span class="comment"># 判断当前候选项集是不是当前记录的子集</span></span><br><span class="line">            <span class="keyword">if</span> candidateSet.issubset(record):    </span><br><span class="line">                <span class="keyword">if</span> candidateSet <span class="keyword">not</span> <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">                    selectedSetCount[candidateSet] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    selectedSetCount[candidateSet] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 计算总条目数</span></span><br><span class="line">    numItems = <span class="built_in">float</span>(<span class="built_in">len</span>(dataset))</span><br><span class="line">    <span class="comment"># 存储符合条件的项集</span></span><br><span class="line">    retList = []</span><br><span class="line">    <span class="comment"># 存储项集的支持度</span></span><br><span class="line">    supportData = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">        <span class="comment"># 计算支持度</span></span><br><span class="line">        support = selectedSetCount[key] / numItems</span><br><span class="line">        <span class="keyword">if</span> support &gt;= minSupport:</span><br><span class="line">            retList.insert(<span class="number">0</span>, key)</span><br><span class="line">        supportData[key] = support</span><br><span class="line">    <span class="keyword">return</span> retList, supportData</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    c1 = createC1(dataset)</span><br><span class="line">    pprint(scanDataset(dataset, c1, <span class="number">0.5</span>))</span><br></pre></td></tr></table></figure>
<p>实现频繁项集挖掘：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createCk</span>(<span class="params">lastFrequentItems, k</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    根据k-1项的频繁项集列表生成k项的候选项集</span></span><br><span class="line"><span class="string">    :param lastFrequentItems: k-1项的频繁项集</span></span><br><span class="line"><span class="string">    :param k: 第k个项集</span></span><br><span class="line"><span class="string">    :return: ck项集</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    retList = []</span><br><span class="line">    lenLk = <span class="built_in">len</span>(lastFrequentItems)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lenLk):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, lenLk):</span><br><span class="line">            <span class="comment"># 因为新构建的ck项集，特征是任意一个k项集其中k-1项都必须存在于lastCk中</span></span><br><span class="line">            <span class="comment"># 通过以下判断，能筛选出那些符合要求的k-1项</span></span><br><span class="line">            L1 = <span class="built_in">list</span>(lastFrequentItems[i])[:k-<span class="number">2</span>]; L2 = <span class="built_in">list</span>(lastFrequentItems[j])[:k-<span class="number">2</span>]</span><br><span class="line">            L1.sort(); L2.sort()</span><br><span class="line">            <span class="keyword">if</span> L1==L2:</span><br><span class="line">                retList.append(lastFrequentItems[i] | lastFrequentItems[j])</span><br><span class="line">    <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apriori</span>(<span class="params">dataSet, minSupport=<span class="number">0.5</span></span>):</span></span><br><span class="line">    C1 = createC1(dataSet)</span><br><span class="line">    k1FrequentItems, supportData = scanDataset(dataSet, C1, minSupport)</span><br><span class="line">    frequentItemsList = [k1FrequentItems]</span><br><span class="line">    <span class="comment"># 应为k=1的频繁项集已经找到，因此从k=2继续</span></span><br><span class="line">    k = <span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 根据k-1的频繁项集，创建k候选集，</span></span><br><span class="line">        <span class="comment"># k-1-1是因为列表下表从0开始</span></span><br><span class="line">        ck = createCk(frequentItemsList[k-<span class="number">1</span>-<span class="number">1</span>], k)</span><br><span class="line">        <span class="comment"># 再次扫描数据集，找出新的k项频繁项集</span></span><br><span class="line">        newFrequentItems, supK = scanDataset(dataSet, ck, minSupport)</span><br><span class="line">        <span class="comment"># 更新项集的支持度</span></span><br><span class="line">        supportData.update(supK)</span><br><span class="line">        <span class="comment"># 如果无法生成新的频繁项集，那么推出循环</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(newFrequentItems) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 存储所有的频繁项集</span></span><br><span class="line">        frequentItemsList.append(newFrequentItems)</span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> frequentItemsList, supportData</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    c1 = createC1(dataset)</span><br><span class="line"></span><br><span class="line">    pprint(apriori(dataset, <span class="number">0.3</span>))</span><br></pre></td></tr></table></figure>
<p>实现关联规则挖掘：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateRules</span>(<span class="params">frequentItemsList, supportData, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    <span class="comment"># 存储关联规则</span></span><br><span class="line">    ruleList = []</span><br><span class="line">    <span class="comment"># 从含有2项item的频繁项集开始遍历，计算两两的置信度</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(frequentItemsList)):</span><br><span class="line">        <span class="comment"># 遍历每一阶段的频繁项集</span></span><br><span class="line">        <span class="keyword">for</span> frequentItem <span class="keyword">in</span> frequentItemsList[i]:</span><br><span class="line">            <span class="built_in">print</span>(frequentItem)</span><br><span class="line">            subItems = [<span class="built_in">frozenset</span>([item]) <span class="keyword">for</span> item <span class="keyword">in</span> frequentItem]</span><br><span class="line">            <span class="built_in">print</span>(subItems)</span><br><span class="line">            <span class="keyword">if</span> (i == <span class="number">1</span>):</span><br><span class="line">                <span class="comment"># 先计算2项item的频繁项集的置信度，并将关联规则存储到ruleList</span></span><br><span class="line">                calculateConfidence(frequentItem, subItems, supportData, ruleList, minConf)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 然后使用递归依次计算3到k项item频繁项集之间两两的置信度，并提取关联规则</span></span><br><span class="line">                rulesFromRecursive(frequentItem, subItems, supportData, ruleList, minConf)</span><br><span class="line">    <span class="keyword">return</span> ruleList</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculateConfidence</span>(<span class="params">frequentItem, subItems, supportData, ruleList, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    <span class="comment"># 存储符合最小置信度阈值的item</span></span><br><span class="line">    retList = []</span><br><span class="line">    <span class="keyword">for</span> subItem <span class="keyword">in</span> subItems:</span><br><span class="line">        <span class="comment">#支持度(&#123;豆奶, 莴苣&#125;)/支持度(&#123;豆奶&#125;)</span></span><br><span class="line">        <span class="comment"># 计算置信度[frozenset(&#123;2, 3&#125;), frozenset(&#123;3, 5&#125;), frozenset(&#123;2, 5&#125;), frozenset(&#123;1, 3&#125;)],</span></span><br><span class="line">        conf = supportData[frequentItem]/supportData[frequentItem-subItem]</span><br><span class="line">        <span class="keyword">if</span> conf &gt;= minConf:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Rule：&quot;</span>, frequentItem-subItem, <span class="string">&#x27;--&gt;&#x27;</span>, subItem, <span class="string">&#x27;confidence:&#x27;</span>, conf)</span><br><span class="line">            ruleList.append((frequentItem-subItem, subItem, conf))</span><br><span class="line">            retList.append(subItem)</span><br><span class="line">    <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rulesFromRecursive</span>(<span class="params">frequentItem, subItems, supportData, ruleList, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    m = <span class="built_in">len</span>(subItems[<span class="number">0</span>])    <span class="comment"># 判断当前子项集的长度</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(frequentItem) &gt; (m + <span class="number">1</span>)): <span class="comment">#frozenset(&#123;2, 3, 5&#125;)</span></span><br><span class="line">        <span class="comment"># 根据子项集得出CK候选集</span></span><br><span class="line">        ck = createCk(subItems, m+<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 根据候选集再筛选出符合最小置信度的item集合</span></span><br><span class="line">        newItems = calculateConfidence(frequentItem, ck, supportData, ruleList, minConf)</span><br><span class="line">        <span class="comment"># 如果符合要求的item至少有2个，那么继续递归</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">len</span>(newItems) &gt; <span class="number">1</span>):</span><br><span class="line">            rulesFromRecursive(frequentItem, newItems, supportData, ruleList, minConf)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    c1 = createC1(dataset)</span><br><span class="line">    <span class="comment"># pprint(scanDataset(dataset, c1, 0.5))</span></span><br><span class="line"></span><br><span class="line">    pprint(generateRules(*apriori(dataset, <span class="number">0.3</span>)))</span><br></pre></td></tr></table></figure>
<p>面向对象封装</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    加载数据集</span></span><br><span class="line"><span class="string">    :return: dataset</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> [[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">2</span>, <span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AssociationRule</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, minSupport=<span class="number">0.5</span>, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">        self.minSupport = minSupport</span><br><span class="line">        self.minConf = minConf</span><br><span class="line">        self.dataset = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        self.frequentItemsList, self.supportData = self.apriori(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_createC1</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        创建C1候选项集，C1是所有大小为1的候选项集的列表</span></span><br><span class="line"><span class="string">        :return: C1</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># C1是所有大小为1的候选项集的列表</span></span><br><span class="line">        C1 = []</span><br><span class="line">        <span class="comment"># 遍历数据集，逐个添加到C1中</span></span><br><span class="line">        <span class="keyword">for</span> record <span class="keyword">in</span> dataset:</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> record:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> [item] <span class="keyword">in</span> C1:</span><br><span class="line">                    C1.append([item])</span><br><span class="line">        C1.sort()</span><br><span class="line">        <span class="comment"># 使用不变集合存储C1内部的每个候选项集，那么就可以将其作为字典的Key，如果是list类型不能直接作为字典的Key</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">frozenset</span>, C1))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_scanDataset</span>(<span class="params">self, ck</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        扫描数据集，判断频繁项集</span></span><br><span class="line"><span class="string">        :param ck: ck是所有大小为k的候选项集的列表</span></span><br><span class="line"><span class="string">        :return: 符合条件的项集、每个项集的支持度</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 存储项集的出现次数</span></span><br><span class="line">        selectedSetCount = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> record <span class="keyword">in</span> self.dataset:  <span class="comment"># 遍历每一条记录</span></span><br><span class="line">            <span class="keyword">for</span> candidateSet <span class="keyword">in</span> ck:</span><br><span class="line">                <span class="comment"># 判断当前候选项集是不是当前记录的子集</span></span><br><span class="line">                <span class="keyword">if</span> candidateSet.issubset(record):</span><br><span class="line">                    <span class="keyword">if</span> candidateSet <span class="keyword">not</span> <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">                        selectedSetCount[candidateSet] = <span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        selectedSetCount[candidateSet] += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 计算总条目数</span></span><br><span class="line">        numItems = <span class="built_in">float</span>(<span class="built_in">len</span>(self.dataset))</span><br><span class="line">        <span class="comment"># 存储符合条件的项集</span></span><br><span class="line">        retList = []</span><br><span class="line">        <span class="comment"># 存储项集的支持度</span></span><br><span class="line">        supportData = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">            <span class="comment"># 计算支持度</span></span><br><span class="line">            support = selectedSetCount[key] / numItems</span><br><span class="line">            <span class="keyword">if</span> support &gt;= self.minSupport:</span><br><span class="line">                retList.insert(<span class="number">0</span>, key)</span><br><span class="line">            supportData[key] = support</span><br><span class="line">        <span class="keyword">return</span> retList, supportData</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_createCk</span>(<span class="params">self, lastFrequentItems, k</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        根据k-1项的频繁项集列表生成k项的候选项集</span></span><br><span class="line"><span class="string">        :param lastFrequentItems: k-1项的频繁项集</span></span><br><span class="line"><span class="string">        :param k: 第k个项集</span></span><br><span class="line"><span class="string">        :return: ck项集</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        retList = []</span><br><span class="line">        lenLk = <span class="built_in">len</span>(lastFrequentItems)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lenLk):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, lenLk):</span><br><span class="line">                <span class="comment"># 因为新构建的ck项集，特征是任意一个k项集其中k-1项都必须存在于lastCk中</span></span><br><span class="line">                <span class="comment"># 通过以下判断，能筛选出那些符合要求的k-1项</span></span><br><span class="line">                L1 = <span class="built_in">list</span>(lastFrequentItems[i])[:k - <span class="number">2</span>]</span><br><span class="line">                L2 = <span class="built_in">list</span>(lastFrequentItems[j])[:k - <span class="number">2</span>]</span><br><span class="line">                L1.sort()</span><br><span class="line">                L2.sort()</span><br><span class="line">                <span class="keyword">if</span> L1 == L2:</span><br><span class="line">                    retList.append(lastFrequentItems[i] | lastFrequentItems[j])</span><br><span class="line">        <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">apriori</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        C1 = self._createC1(dataset)</span><br><span class="line">        k1FrequentItems, supportData = self._scanDataset(C1)</span><br><span class="line">        frequentItemsList = [k1FrequentItems]</span><br><span class="line">        <span class="comment"># 应为k=1的频繁项集已经找到，因此从k=2继续</span></span><br><span class="line">        k = <span class="number">2</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="comment"># 根据k-1的频繁项集，创建k候选集，</span></span><br><span class="line">            <span class="comment"># k-1-1是因为列表下表从0开始</span></span><br><span class="line">            ck = self._createCk(frequentItemsList[k - <span class="number">1</span> - <span class="number">1</span>], k)</span><br><span class="line">            <span class="comment"># 再次扫描数据集，找出新的k项频繁项集</span></span><br><span class="line">            newFrequentItems, supK = self._scanDataset(ck)</span><br><span class="line">            <span class="comment"># 更新项集的支持度</span></span><br><span class="line">            supportData.update(supK)</span><br><span class="line">            <span class="comment"># 如果无法生成新的频繁项集，那么推出循环</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(newFrequentItems) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="comment"># 存储所有的频繁项集</span></span><br><span class="line">            frequentItemsList.append(newFrequentItems)</span><br><span class="line">            k += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> frequentItemsList, supportData</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generateRules</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 存储关联规则</span></span><br><span class="line">        ruleList = []</span><br><span class="line">        <span class="comment"># 从含有2项item的频繁项集开始遍历，计算两两的置信度</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(self.frequentItemsList)):</span><br><span class="line">            <span class="comment"># 遍历每一阶段的频繁项集</span></span><br><span class="line">            <span class="keyword">for</span> frequentItem <span class="keyword">in</span> self.frequentItemsList[i]:</span><br><span class="line">                subItems = [<span class="built_in">frozenset</span>([item]) <span class="keyword">for</span> item <span class="keyword">in</span> frequentItem]</span><br><span class="line">                <span class="keyword">if</span> (i == <span class="number">1</span>):</span><br><span class="line">                    <span class="comment"># 先计算2项item的频繁项集的置信度，并将关联规则存储到ruleList</span></span><br><span class="line">                    self._calculateConfidence(frequentItem, subItems, self.supportData, ruleList)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 然后使用递归依次计算3到k项item频繁项集之间两两的置信度，并提取关联规则</span></span><br><span class="line">                    self._rulesFromRecursive(frequentItem, subItems, self.supportData, ruleList)</span><br><span class="line">        <span class="keyword">return</span> ruleList</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_calculateConfidence</span>(<span class="params">self, frequentItem, subItems, supportData, ruleList</span>):</span></span><br><span class="line">        <span class="comment"># 存储符合最小置信度阈值的item</span></span><br><span class="line">        retList = []</span><br><span class="line">        <span class="keyword">for</span> subItem <span class="keyword">in</span> subItems:</span><br><span class="line">            <span class="comment"># 计算置信度</span></span><br><span class="line">            conf = supportData[frequentItem] / supportData[frequentItem - subItem]</span><br><span class="line">            <span class="keyword">if</span> conf &gt;= self.minConf:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Rule：&quot;</span>, frequentItem - subItem, <span class="string">&#x27;--&gt;&#x27;</span>, subItem, <span class="string">&#x27;confidence:&#x27;</span>, conf)</span><br><span class="line">                ruleList.append((frequentItem - subItem, subItem, conf))</span><br><span class="line">                retList.append(subItem)</span><br><span class="line">        <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_rulesFromRecursive</span>(<span class="params">self, frequentItem, subItems, supportData, ruleList</span>):</span></span><br><span class="line">        m = <span class="built_in">len</span>(subItems[<span class="number">0</span>])  <span class="comment"># 判断当前子项集的长度</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">len</span>(frequentItem) &gt; (m + <span class="number">1</span>)):</span><br><span class="line">            <span class="comment"># 根据子项集得出CK候选集</span></span><br><span class="line">            ck = self._createCk(subItems, m + <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 根据候选集再筛选出符合最小置信度的item集合</span></span><br><span class="line">            newItems = self._calculateConfidence(frequentItem, ck, supportData, ruleList)</span><br><span class="line">            <span class="comment"># 如果符合要求的item至少有2个，那么继续递归</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">len</span>(newItems) &gt; <span class="number">1</span>):</span><br><span class="line">                self._rulesFromRecursive(frequentItem, newItems, supportData, ruleList)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    ar = AssociationRule()</span><br><span class="line">    <span class="comment"># pprint(scanDataset(dataset, c1, 0.5))</span></span><br><span class="line">    ar.fit(dataset)</span><br><span class="line">    pprint(ar.generateRules())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pprint(ar.generateRules(*ar.apriori(dataset, 0.3)))</span></span><br></pre></td></tr></table></figure>
<h2 id="频繁项集挖掘（二）FP-Growth算法"><a href="#频繁项集挖掘（二）FP-Growth算法" class="headerlink" title="频繁项集挖掘（二）FP-Growth算法"></a>频繁项集挖掘（二）FP-Growth算法</h2><p>FP-Growth（Frequent Patterns）相比于Apriori是一种更加有效的频繁项集挖掘算法，FP-Growth算法只需要对数据库进行两次扫描，而Apriori算法对于每次产生的候选项集都会扫描一次数据集来判断是否频繁，因此当数据量特别巨大，且扫描数据库的成本比较高时，FP-Growth的速度要比Apriori快。</p>
<p>但是FP-Growth只能用于发现频繁项集，不能用于发现关联规则。</p>
<h3 id="FP-Growth原理分析"><a href="#FP-Growth原理分析" class="headerlink" title="FP-Growth原理分析"></a>FP-Growth原理分析</h3><p>FP-Growth算法实现步骤</p>
<ul>
<li>构建FP树</li>
<li>从FP树中挖掘频繁项集</li>
</ul>
<p>FP-Growth算法将数据存储在一种被称为FP树的紧凑数据结构中。</p>
<p><img src="fp-growth2.png" alt=""></p>
<p>下图就是利用上面的数据构建的一棵FP树（最小支持度为3）：</p>
<p><img src="fp-growth1.png" alt=""></p>
<ul>
<li>FP树中最小支持度指项集总共出现的次数</li>
<li>一个元素项可以在一棵FP树中出现多次</li>
<li>FP树存储项集的出现频率，且每个项集会以路径的方式存储在树中</li>
<li>存在相似元素的集合会共享树的一部分</li>
<li>只有当集合之间完全不同时，树才会分叉</li>
<li>树节点上给出集合中的单个元素及其在序列中的出现次数，路径会给出该序列的出现次数</li>
</ul>
<p>FP-Growth算法工作流程：</p>
<ul>
<li>扫描数据集两遍</li>
<li>第一遍对所有元素项的出现次数进行计数</li>
<li>根据前面的结论，如果某元素是不频繁的，那么包含该元素的超集也是不频繁的</li>
<li>第二遍扫描，只考虑那些频繁元素，并且第二遍扫描开始构建FP树</li>
</ul>
<h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">treeNode</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, nameValue, numOccur, parentNode</span>):</span></span><br><span class="line">        <span class="comment"># 节点名称</span></span><br><span class="line">        self.name = nameValue</span><br><span class="line">        <span class="comment"># 节点计数</span></span><br><span class="line">        self.count = numOccur</span><br><span class="line">        <span class="comment"># 记录相似的元素项</span></span><br><span class="line">        self.nodeLink = <span class="literal">None</span></span><br><span class="line">        <span class="comment"># 父节点对象</span></span><br><span class="line">        self.parent = parentNode</span><br><span class="line">        <span class="comment"># 子节点</span></span><br><span class="line">        self.children = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inc</span>(<span class="params">self, numOccur</span>):</span></span><br><span class="line">        self.count += numOccur</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">disp</span>(<span class="params">self, ind=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;--&#x27;</span>*ind, self.name, <span class="string">&#x27; &#x27;</span>, self.count)</span><br><span class="line">        <span class="keyword">for</span> child <span class="keyword">in</span> self.children.values():</span><br><span class="line">            child.disp(ind+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span>(<span class="params">dataSet, minSup=<span class="number">1</span></span>):</span>  <span class="comment"># create FP-tree from dataset but don&#x27;t mine</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;遍历数据集两遍&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 第一遍对元素计数</span></span><br><span class="line">    originHeaderTable = &#123;&#125;    <span class="comment"># headerTable用于记录树的结构情况</span></span><br><span class="line">    <span class="keyword">for</span> trans <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> trans:</span><br><span class="line">            originHeaderTable[item] = originHeaderTable.get(item, <span class="number">0</span>) + dataSet[trans]</span><br><span class="line"></span><br><span class="line">    popKeys = []</span><br><span class="line">    <span class="comment"># 过滤掉非频繁项集</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> originHeaderTable.keys():</span><br><span class="line">        <span class="comment"># 记录非频繁项</span></span><br><span class="line">        <span class="keyword">if</span> originHeaderTable[k] &lt; minSup:</span><br><span class="line">            popKeys.append(k)</span><br><span class="line"></span><br><span class="line">    freqItemSet = <span class="built_in">set</span>(originHeaderTable.keys()) - <span class="built_in">set</span>(popKeys)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># headerTable用于记录树的结构情况</span></span><br><span class="line">    headerTable = &#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(freqItemSet) == <span class="number">0</span>:   <span class="comment"># 如果初选没有频繁项集，那么直接退出</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 重新构建headerTable</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> freqItemSet:</span><br><span class="line">        headerTable[k] = [originHeaderTable[k], <span class="literal">None</span>]  <span class="comment"># reformat headerTable to use Node link</span></span><br><span class="line">    <span class="keyword">del</span> originHeaderTable</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建空树，根节点为空集</span></span><br><span class="line">    root_node = treeNode(<span class="string">&#x27;Null Set&#x27;</span>, <span class="number">1</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># 第二遍扫描，开始构建FP树</span></span><br><span class="line">    <span class="keyword">for</span> tranSet, count <span class="keyword">in</span> dataSet.items():  <span class="comment"># go through dataset 2nd time</span></span><br><span class="line">        localD = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> tranSet:  <span class="comment"># put transaction items in order</span></span><br><span class="line">            <span class="keyword">if</span> item <span class="keyword">in</span> freqItemSet:</span><br><span class="line">                localD[item] = headerTable[item][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(localD) &gt; <span class="number">0</span>:</span><br><span class="line">            orderedItems = [v[<span class="number">0</span>] <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">sorted</span>(localD.items(), key=<span class="keyword">lambda</span> p: p[<span class="number">1</span>], reverse=<span class="literal">True</span>)]</span><br><span class="line">            updateTree(orderedItems, root_node, headerTable, count)  <span class="comment"># populate tree with ordered freq itemset</span></span><br><span class="line">    <span class="keyword">return</span> root_node, headerTable  <span class="comment"># return tree and header table</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateTree</span>(<span class="params">items, parentNode, headerTable, count</span>):</span></span><br><span class="line">    <span class="comment"># 判断第一个项集是已经是当前节点的子节点</span></span><br><span class="line">    <span class="keyword">if</span> items[<span class="number">0</span>] <span class="keyword">in</span> parentNode.children:  <span class="comment"># check if orderedItems[0] in retTree.children</span></span><br><span class="line">        <span class="comment"># 如果是，那么直接count + 1</span></span><br><span class="line">        parentNode.children[items[<span class="number">0</span>]].inc(count)  <span class="comment"># incrament count</span></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># add items[0] to inTree.children</span></span><br><span class="line">        <span class="comment"># 如果不是，那么新建节点，并存储为当前节点的子节点</span></span><br><span class="line">        parentNode.children[items[<span class="number">0</span>]] = treeNode(items[<span class="number">0</span>], count, parentNode)</span><br><span class="line">        <span class="comment"># 更新headerTable</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 判断当前item是否是第一次记录</span></span><br><span class="line">        <span class="keyword">if</span> headerTable[items[<span class="number">0</span>]][<span class="number">1</span>] == <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 如果是第一次，那么把新建的节点直接记录到头表中</span></span><br><span class="line">            headerTable[items[<span class="number">0</span>]][<span class="number">1</span>] = parentNode.children[items[<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 如果不是第一次，那么说明新节点是当前item的节点的子节点，因此将它记录到当前分支的末位去，即设置为当前分支的叶子节点</span></span><br><span class="line">            updateHeader(headerTable[items[<span class="number">0</span>]][<span class="number">1</span>], parentNode.children[items[<span class="number">0</span>]])</span><br><span class="line">    <span class="comment"># 如果还有第二个元素，那么递归执行以上操作</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(items) &gt; <span class="number">1</span>:</span><br><span class="line">        updateTree(items[<span class="number">1</span>::], parentNode.children[items[<span class="number">0</span>]], headerTable, count)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateHeader</span>(<span class="params">lastNode, newLeafNode</span>):</span></span><br><span class="line">    <span class="comment"># 判断上一节点是否有连接节点，如果没有，那么说明上一节点就是叶子节点，那么直接将新节点设为叶子节点</span></span><br><span class="line">    <span class="keyword">while</span> (lastNode.nodeLink != <span class="literal">None</span>):</span><br><span class="line">        <span class="comment"># 如果上一节点已经有连接节点，那么循环知道遍历到叶子节点，再设置新叶子节点</span></span><br><span class="line">        lastNode = lastNode.nodeLink</span><br><span class="line">    <span class="comment"># 将新的叶子节点设置为旧叶子节点的连接节点</span></span><br><span class="line">    lastNode.nodeLink = newLeafNode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadTestDataset</span>():</span></span><br><span class="line">    dataset = [[<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;j&#x27;</span>, <span class="string">&#x27;p&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, <span class="string">&#x27;v&#x27;</span>, <span class="string">&#x27;u&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;s&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;z&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;s&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;q&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;p&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;q&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;m&#x27;</span>]]</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createInitDataset</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    dictDataset = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> trans <span class="keyword">in</span> dataSet:</span><br><span class="line">        dictDataset[<span class="built_in">frozenset</span>(trans)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> dictDataset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildCombinedItems</span>(<span class="params">leafNode, combinedItems</span>):</span></span><br><span class="line">    <span class="keyword">if</span> leafNode.parent != <span class="literal">None</span>:</span><br><span class="line">        combinedItems.append(leafNode.name)</span><br><span class="line">        buildCombinedItems(leafNode.parent, combinedItems)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildCombinedDataset</span>(<span class="params">nodeObject</span>):</span></span><br><span class="line">    <span class="comment"># 根据节点名称，组合出新的项集节点</span></span><br><span class="line">    combinedDataset = &#123;&#125;</span><br><span class="line">    <span class="keyword">while</span> nodeObject != <span class="literal">None</span>:</span><br><span class="line">        combinedItems = []</span><br><span class="line">        buildCombinedItems(nodeObject, combinedItems)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(combinedItems) &gt; <span class="number">1</span>:</span><br><span class="line">            combinedDataset[<span class="built_in">frozenset</span>(combinedItems[<span class="number">1</span>:])] = nodeObject.count</span><br><span class="line">        nodeObject = nodeObject.nodeLink</span><br><span class="line">    <span class="keyword">return</span> combinedDataset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanFPTree</span>(<span class="params">headerTable, minSup, parentNodeNames, freqItemList</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历排序后的headerTable，(节点名称，节点信息）</span></span><br><span class="line">    <span class="keyword">for</span> baseNode, nodeInfo <span class="keyword">in</span> headerTable.items():</span><br><span class="line">        <span class="comment"># 根据prefix</span></span><br><span class="line">        newFreqSet = parentNodeNames.copy()</span><br><span class="line">        newFreqSet.add(baseNode)</span><br><span class="line">        <span class="comment"># 节点计数值</span></span><br><span class="line">        nodeCount = nodeInfo[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 节点对象</span></span><br><span class="line">        nodeObject = nodeInfo[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 记录下频繁项集以及计数</span></span><br><span class="line">        freqItemList.append((newFreqSet, nodeCount))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据当前节点的子节点，构建出新的项集组合</span></span><br><span class="line">        combinedDataset = buildCombinedDataset(nodeObject)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据新的项集组合，重合构建子FP树</span></span><br><span class="line">        subFPTree, subFPTreeHeaderTable = createTree(combinedDataset, minSup)</span><br><span class="line">        <span class="comment"># 如果头表不为空，那么递归新树的头表</span></span><br><span class="line">        <span class="keyword">if</span> subFPTreeHeaderTable != <span class="literal">None</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;conditional tree for: &#x27;</span>, newFreqSet)</span><br><span class="line">            subFPTree.disp(<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 根据新的头表 扫描FP-Tree</span></span><br><span class="line">            scanFPTree(subFPTreeHeaderTable, minSup, newFreqSet, freqItemList)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    simpDat = loadTestDataset()</span><br><span class="line">    initSet = createInitDataset(simpDat)</span><br><span class="line">    <span class="comment"># 构建初始的FP-Tree</span></span><br><span class="line">    initFPtree, initFPtreeHeaderTable = createTree(initSet, <span class="number">3</span>)</span><br><span class="line">    initFPtree.disp(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    freqItems = []    <span class="comment"># 存储频繁项集</span></span><br><span class="line">    <span class="comment"># 扫描FP树，找出所有符合条件的频繁项集</span></span><br><span class="line"></span><br><span class="line">    root_node_names = <span class="built_in">set</span>([])    <span class="comment"># 从根路径空集开始扫描</span></span><br><span class="line">    scanFPTree(initFPtreeHeaderTable, <span class="number">3</span>, root_node_names, freqItems)</span><br><span class="line">    pprint(freqItems)</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">贪钱算法还我头发</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/">https://xfliu1998.github.io/2022/01/18/5.2-RS-Algorithm/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a></div><div class="post_share"><div class="social-share" data-image="http://img.shijue.me/d667362f0f6b42bcb21d4a4fc167e93a_d.jpg!dp6" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/01/18/5.3-Hadoop/"><img class="prev-cover" src="http://img.shijue.me/d667362f0f6b42bcb21d4a4fc167e93a_d.jpg!dp6" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Hadoop</div></div></a></div><div class="next-post pull-right"><a href="/2022/01/18/5.1-Recommendation-System-Introduction/"><img class="next-cover" src="http://img.shijue.me/d667362f0f6b42bcb21d4a4fc167e93a_d.jpg!dp6" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Recommendation System Introduction</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2024/07/09/Technical-Summary-Deep-Learning/" title="Technical Summary —— Pytorch & Numpy"><img class="cover" src="http://img.shijue.me/21cdab996c944862bac3947c8c7197f1_d.jpg!dp6" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-09</div><div class="title">Technical Summary —— Pytorch & Numpy</div></div></a></div><div><a href="/2024/07/02/Technical-Summary-Necessary/" title="Technical Summary —— Common Command"><img class="cover" src="http://img.shijue.me/82cad50b40214d388d246ae4847e8bec_d.jpeg!dp6" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-02</div><div class="title">Technical Summary —— Common Command</div></div></a></div><div><a href="/2024/04/15/Technical-Summary-BigData/" title="Technical Summary —— Big Data Processing"><img class="cover" src="http://img.shijue.me/886e06c4e9b04b8a836a1b6ec00a0b17_d.jpeg!dp6" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-15</div><div class="title">Technical Summary —— Big Data Processing</div></div></a></div><div><a href="/2024/04/07/Technical-Summary-Database/" title="Technical Summary —— Database Usage"><img class="cover" src="http://img.shijue.me/078729117f75472bae4bbc684d2b714c_d.jpg!dp6" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-07</div><div class="title">Technical Summary —— Database Usage</div></div></a></div><div><a href="/2023/05/19/Summary-NG/" title="Summary NG"><img class="cover" src="http://img.shijue.me/0a336cc060e74ca29f9cf862eb2ee8cf_d.png!dp6" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-19</div><div class="title">Summary NG</div></div></a></div><div><a href="/2023/05/19/Experimental-Technique/" title="Experimental Technique"><img class="cover" src="http://img.shijue.me/c94bd493552d441ab4c647296a6913b5_d.jpg!dp6" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-19</div><div class="title">Experimental Technique</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">贪钱算法还我头发</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">57</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xfliu1998"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xfliu1998" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:liuxiaofei_7@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://blog.csdn.net/keiven_" target="_blank" title="CSDN"><i class="fa fa-address-card"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">欢迎来这里掉头发</div></div><div class="card-widget" id="newYear"><div class="item-headline"><i></i><span></span></div><div class="item-content"><div id="newYear-main"><div class="mask"></div> <p class="title"></p> <div class="newYear-time"></div> <p class="today" style="text-align: right;"></p> </div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Model-Based-%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95"><span class="toc-number">1.</span> <span class="toc-text">Model-Based 协同过滤算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8EK%E6%9C%80%E8%BF%91%E9%82%BB%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90"><span class="toc-number">2.</span> <span class="toc-text">基于K最近邻的协同过滤推荐</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90"><span class="toc-number">3.</span> <span class="toc-text">基于回归模型的协同过滤推荐</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Baseline%EF%BC%9A%E5%9F%BA%E5%87%86%E9%A2%84%E6%B5%8B"><span class="toc-number">3.1.</span> <span class="toc-text">Baseline：基准预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E4%B8%80%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E4%BC%98%E5%8C%96"><span class="toc-number">3.2.</span> <span class="toc-text">方法一：随机梯度下降法优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#step-1%EF%BC%9A%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E6%8E%A8%E5%AF%BC"><span class="toc-number">3.2.1.</span> <span class="toc-text">step 1：梯度下降法推导</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#step-2%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-number">3.2.2.</span> <span class="toc-text">step 2：随机梯度下降</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#step-3%EF%BC%9A%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.2.3.</span> <span class="toc-text">step 3：算法实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#step-4-%E5%87%86%E7%A1%AE%E6%80%A7%E6%8C%87%E6%A0%87%E8%AF%84%E4%BC%B0"><span class="toc-number">3.2.4.</span> <span class="toc-text">step 4: 准确性指标评估</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E4%BA%8C%EF%BC%9A%E4%BA%A4%E6%9B%BF%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E4%BC%98%E5%8C%96"><span class="toc-number">3.3.</span> <span class="toc-text">方法二：交替最小二乘法优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#step-1-%E4%BA%A4%E6%9B%BF%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E6%8E%A8%E5%AF%BC"><span class="toc-number">3.3.1.</span> <span class="toc-text">step 1: 交替最小二乘法推导</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#step-2-%E4%BA%A4%E6%9B%BF%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E5%BA%94%E7%94%A8"><span class="toc-number">3.3.2.</span> <span class="toc-text">step 2: 交替最小二乘法应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#step-3-%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.3.3.</span> <span class="toc-text">step 3: 算法实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#step-4-%E5%87%86%E7%A1%AE%E6%80%A7%E6%8C%87%E6%A0%87%E8%AF%84%E4%BC%B0-1"><span class="toc-number">3.3.4.</span> <span class="toc-text">step 4: 准确性指标评估</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%9A%84CF%E7%AE%97%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">基于矩阵分解的CF算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E5%8F%91%E5%B1%95%E5%8F%B2"><span class="toc-number">4.1.</span> <span class="toc-text">矩阵分解发展史</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%9A%84CF%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ABiasSvd"><span class="toc-number">5.</span> <span class="toc-text">基于矩阵分解的CF算法实现（二）：BiasSvd</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BiasSvd"><span class="toc-number">5.1.</span> <span class="toc-text">BiasSvd</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">5.2.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E4%BC%98%E5%8C%96"><span class="toc-number">5.3.</span> <span class="toc-text">随机梯度下降法优化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%EF%BC%88Content-Based%EF%BC%89"><span class="toc-number">6.</span> <span class="toc-text">基于内容的推荐算法（Content-Based）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">6.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E6%8E%A8%E8%8D%90%E5%AE%9E%E7%8E%B0%E6%AD%A5%E9%AA%A4"><span class="toc-number">6.2.</span> <span class="toc-text">基于内容的推荐实现步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%EF%BC%9A%E7%89%A9%E5%93%81%E7%9A%84%E6%A0%87%E7%AD%BE%E6%9D%A5%E8%87%AA%E5%93%AA%E5%84%BF%EF%BC%9F"><span class="toc-number">6.2.1.</span> <span class="toc-text">问题：物品的标签来自哪儿？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90%E7%9A%84%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%EF%BC%9A"><span class="toc-number">6.2.2.</span> <span class="toc-text">基于内容推荐的算法流程：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A8%E5%A4%84%E7%90%86%EF%BC%9A"><span class="toc-number">6.2.3.</span> <span class="toc-text">物品冷启动处理：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%EF%BC%9A%E7%89%A9%E5%93%81%E7%94%BB%E5%83%8F"><span class="toc-number">7.</span> <span class="toc-text">基于内容的电影推荐：物品画像</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8ETF-IDF%E7%9A%84%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E6%8A%80%E6%9C%AF"><span class="toc-number">8.</span> <span class="toc-text">基于TF-IDF的特征提取技术</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">8.1.</span> <span class="toc-text">算法原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E4%B8%BE%E4%BE%8B"><span class="toc-number">8.2.</span> <span class="toc-text">算法举例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">8.3.</span> <span class="toc-text">加载数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8ETF%C2%B7IDF%E6%8F%90%E5%8F%96TOP-N%E5%85%B3%E9%94%AE%E8%AF%8D%EF%BC%8C%E6%9E%84%E5%BB%BA%E7%94%B5%E5%BD%B1%E7%94%BB%E5%83%8F"><span class="toc-number">8.4.</span> <span class="toc-text">基于TF·IDF提取TOP-N关键词，构建电影画像</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%8C%E5%96%84%E7%94%BB%E5%83%8F%E5%85%B3%E9%94%AE%E8%AF%8D"><span class="toc-number">8.5.</span> <span class="toc-text">完善画像关键词</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%EF%BC%9A%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F"><span class="toc-number">9.</span> <span class="toc-text">基于内容的电影推荐：用户画像</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F%E5%BB%BA%E7%AB%8B"><span class="toc-number">9.1.</span> <span class="toc-text">用户画像建立</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%EF%BC%9A%E4%B8%BA%E7%94%A8%E6%88%B7%E4%BA%A7%E7%94%9FTOP-N%E6%8E%A8%E8%8D%90%E7%BB%93%E6%9E%9C"><span class="toc-number">10.</span> <span class="toc-text">基于内容的电影推荐：为用户产生TOP-N推荐结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A8%E5%A4%84%E7%90%86"><span class="toc-number">11.</span> <span class="toc-text">基于内容的电影推荐：物品冷启动处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#word2vec%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B"><span class="toc-number">11.1.</span> <span class="toc-text">word2vec原理简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Word2Vec"><span class="toc-number">11.2.</span> <span class="toc-text">Word2Vec</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%A4%E4%B8%AA%E9%87%8D%E8%A6%81%E6%A8%A1%E5%9E%8B%EF%BC%9ACBOW%E5%92%8CSkip-Gram"><span class="toc-number">11.2.1.</span> <span class="toc-text">两个重要模型：CBOW和Skip-Gram</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Word2Vec%E4%BD%BF%E7%94%A8"><span class="toc-number">11.3.</span> <span class="toc-text">Word2Vec使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Doc2Vec%E4%BD%BF%E7%94%A8"><span class="toc-number">11.4.</span> <span class="toc-text">Doc2Vec使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E7%9A%84%E6%8E%A8%E8%8D%90"><span class="toc-number">12.</span> <span class="toc-text">基于关联规则的推荐</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90"><span class="toc-number">12.1.</span> <span class="toc-text">关联分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E8%81%94%E6%80%A7%E8%A1%A1%E9%87%8F%E6%8C%87%E6%A0%87"><span class="toc-number">12.2.</span> <span class="toc-text">关联性衡量指标</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%80%EF%BC%89Apriori%E7%AE%97%E6%B3%95"><span class="toc-number">13.</span> <span class="toc-text">关键规则挖掘算法（一）Apriori算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Apriori%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">13.1.</span> <span class="toc-text">Apriori算法原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Apriori%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-number">13.2.</span> <span class="toc-text">Apriori算法实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86%E6%8C%96%E6%8E%98%EF%BC%88%E4%BA%8C%EF%BC%89FP-Growth%E7%AE%97%E6%B3%95"><span class="toc-number">14.</span> <span class="toc-text">频繁项集挖掘（二）FP-Growth算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#FP-Growth%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90"><span class="toc-number">14.1.</span> <span class="toc-text">FP-Growth原理分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-number">14.2.</span> <span class="toc-text">算法实现</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('http://img.shijue.me/d667362f0f6b42bcb21d4a4fc167e93a_d.jpg!dp6')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025  <i id="heartbeat" class="fa fas fa-heartbeat"></i> 贪钱算法还我头发</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div><head><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/HCLonely/images@master/others/heartbeat.min.css"></head></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '1b0c10ce649501ea4a72',
      clientSecret: '741b5e861137e3d5a482bba272c8201b78da6cb0',
      repo: 'xfliu1998.github.io',
      owner: 'xfliu1998',
      admin: ['xfliu1998'],
      id: '16a1a731c8b27014964bacc48f5a79c7',
      language: 'en',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: true,
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script src="/js/script.js?v1"></script><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async data-pjax src="https://cdn.wpon.cn/2022-sucai/Gold-ingot.js"></script><script async data-pjax src="/js/newYear.js"></script><script async src="//at.alicdn.com/t/font_2264842_b004iy0kk2b.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='all'|| 'all' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Machine-Learning-and-Deep-Learning/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 机器学习与深度学习 (12)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Data-Structures-and-Algorithms/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">😼 数据结构与算法 (16)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Search-Advertisement-Recommendation-Causal/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🗂️ 搜索/广告/推荐/因果 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Data-Analysis-and-Processing/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 数据分析与处理 (7)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Reading-Notes/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 阅读笔记 (8)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Daily/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 日常随想 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://xfliu1998.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/09/17/Papers-Reading-about-NLP/" alt=""><img width="48" height="48" src="https://tse1-mm.cn.bing.net/th/id/OIP-C.KNjcp6IetyzFaIaSc8-eKAHaE8?w=303&amp;h=201&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.88&amp;pid=1.7" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-09-17</span><a class="blog-slider__title" href="2022/09/17/Papers-Reading-about-NLP/" alt="">Papers Reading about NLP</a><div class="blog-slider__text">自然语言处理论文阅读笔记</div><a class="blog-slider__button" href="2022/09/17/Papers-Reading-about-NLP/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/10/01/9-3D-Construction/" alt=""><img width="48" height="48" src="http://img.shijue.me/2354043620ae4b5896f833d80bb312c4_d.jpg!dp6" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-10-01</span><a class="blog-slider__title" href="2022/10/01/9-3D-Construction/" alt="">3D Construction</a><div class="blog-slider__text">三维重建基础</div><a class="blog-slider__button" href="2022/10/01/9-3D-Construction/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/01/11/SfM-SLAM/" alt=""><img width="48" height="48" src="https://tse2-mm.cn.bing.net/th/id/OIP-C.V5uTTQ6LTBHc42xoBPG8hAHaEm?pid=ImgDet&amp;rs=1" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-11</span><a class="blog-slider__title" href="2023/01/11/SfM-SLAM/" alt="">SfM &amp; SLAM</a><div class="blog-slider__text">SfM和SLAM系统</div><a class="blog-slider__button" href="2023/01/11/SfM-SLAM/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/03/25/Papers-Ideas/" alt=""><img width="48" height="48" src="https://tse2-mm.cn.bing.net/th/id/OIP-C.Mmv8iGEVFxSQII6QH0BG9QHaEJ?w=302&amp;h=180&amp;c=7&amp;r=0&amp;o=5&amp;dpr=2&amp;pid=1.7" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-03-25</span><a class="blog-slider__title" href="2023/03/25/Papers-Ideas/" alt="">Papers Ideas</a><div class="blog-slider__text">大模型时代下的科研思路</div><a class="blog-slider__button" href="2023/03/25/Papers-Ideas/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/09/17/Papers-Summary/" alt=""><img width="48" height="48" src="https://tse1-mm.cn.bing.net/th/id/OIP-C.KNjcp6IetyzFaIaSc8-eKAHaE8?w=303&amp;h=201&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.88&amp;pid=1.7" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-09-17</span><a class="blog-slider__title" href="2022/09/17/Papers-Summary/" alt="">Papers Summary</a><div class="blog-slider__text">论文总结笔记</div><a class="blog-slider__button" href="2022/09/17/Papers-Summary/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/09/17/Papers-Reading-about-CV/" alt=""><img width="48" height="48" src="https://tse1-mm.cn.bing.net/th/id/OIP-C.KNjcp6IetyzFaIaSc8-eKAHaE8?w=303&amp;h=201&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.88&amp;pid=1.7" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-09-17</span><a class="blog-slider__title" href="2022/09/17/Papers-Reading-about-CV/" alt="">Papers Reading about CV</a><div class="blog-slider__text">计算机视觉论文阅读笔记</div><a class="blog-slider__button" href="2022/09/17/Papers-Reading-about-CV/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/06/05/Interview-Experience/" alt=""><img width="48" height="48" src="http://img.shijue.me/00964c481ad34d78acbf148d2b391c9e_d.jpg!dp6" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-06-05</span><a class="blog-slider__title" href="2023/06/05/Interview-Experience/" alt="">Interview Experience</a><div class="blog-slider__text">面经八股</div><a class="blog-slider__button" href="2023/06/05/Interview-Experience/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/08/16/Papers-Reading-about-LLM/" alt=""><img width="48" height="48" src="http://img.shijue.me/9ce88483789847cebe8d38fd7a77f7c7_d.jpg!dp6" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-08-16</span><a class="blog-slider__title" href="2024/08/16/Papers-Reading-about-LLM/" alt="">Papers Reading about LLM</a><div class="blog-slider__text">LLM论文阅读笔记</div><a class="blog-slider__button" href="2024/08/16/Papers-Reading-about-LLM/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/01/21/Learning-Framework/" alt=""><img width="48" height="48" src="http://img.shijue.me/78ae8b05a73444cd9643a8312abc0d43.jpg!dp6" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-01-21</span><a class="blog-slider__title" href="2022/01/21/Learning-Framework/" alt="">Learning Framework</a><div class="blog-slider__text">学习大纲</div><a class="blog-slider__button" href="2022/01/21/Learning-Framework/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<container><style>#git_container{min-height: 280px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></container>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("https://gitcalendar.fomal.cc/api?xfliu1998",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'xfliu1998')
    }
  </script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>