<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>LLM —— GRs | 一直进步 做喜欢的</title><meta name="keywords" content="LLM,Search, Ads &amp; Reco"><meta name="author" content="贪钱算法还我头发"><meta name="copyright" content="贪钱算法还我头发"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="生成式在推荐广告领域的落地">
<meta property="og:type" content="article">
<meta property="og:title" content="LLM —— GRs">
<meta property="og:url" content="https://xfliu1998.github.io/2025/11/16/LLM-GRs/index.html">
<meta property="og:site_name" content="一直进步 做喜欢的">
<meta property="og:description" content="生成式在推荐广告领域的落地">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://xfliu1998.github.io/2025/11/16/LLM-GRs/cover.jpg">
<meta property="article:published_time" content="2025-11-16T11:50:59.000Z">
<meta property="article:modified_time" content="2025-11-16T10:26:14.983Z">
<meta property="article:author" content="贪钱算法还我头发">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="Search, Ads &amp; Reco">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://xfliu1998.github.io/2025/11/16/LLM-GRs/cover.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://xfliu1998.github.io/2025/11/16/LLM-GRs/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LLM —— GRs',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-11-16 18:26:14'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/pool.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/iconfont.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/js/pool.min.js"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/mouse_snow.min.js"><link rel="stylesheet" href="/css/custom.css?v1"><link rel="stylesheet" href="//at.alicdn.com/t/font_2264842_b004iy0kk2b.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">63</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">16</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/2025/11/16/LLM-GRs/cover.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">一直进步 做喜欢的</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">LLM —— GRs</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-11-16T11:50:59.000Z" title="Created 2025-11-16 19:50:59">2025-11-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-11-16T10:26:14.983Z" title="Updated 2025-11-16 18:26:14">2025-11-16</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Search-Ads-Reco/">Search, Ads &amp; Reco</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>18min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="LLM —— GRs"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">Comments:</span><a href="/2025/11/16/LLM-GRs/#post-comment"><span class="gitalk-comment-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="从传统推荐到生成式推荐"><a href="#从传统推荐到生成式推荐" class="headerlink" title="从传统推荐到生成式推荐"></a>从传统推荐到生成式推荐</h2><p><strong>传统推荐/广告系统是如何工作的？</strong><br>在生成式范式兴起之前，工业界的推荐/广告系统普遍采用 <strong>“多阶段、模块化”</strong> 的Pipeline架构。这个过程通常是“检索-粗排-精排-重排”的漏斗模型。</p>
<ul>
<li><strong>召回/检索</strong>从百万乃至数十亿的候选物品池中，快速、初步地筛选出数百或数千个可能与用户相关的物品。核心要求是快和全。经典方法比如协同过滤是基于“物以类聚，人以群分”的思想，包括User-CF和Item-CF；向量化召回通过双塔模型（如DSSM）将用户和物品分别映射为向量，通过近似最近邻搜索（ANN）寻找最相近的物品向量，这是深度学习时代的主流；基于规则的召回如热门召回、地域召回、新物品召回等作为补充。</li>
<li><strong>排序</strong>是对召回阶段得到的数百个候选物品进行精准打分，通常使用判别式模型预估的点击率、转化率等。早期经典模型使用逻辑回归，依赖大量人工特征工程。梯度提升决策树如XGBoost、LightGBM在表格数据上表现优异。深度学习模型如Wide &amp; Deep, DeepFM, DCN等能够自动学习特征的高阶交叉，在此基础上出现了DIN、SIM等经典的迭代工作。</li>
<li><strong>重排</strong>在精排打分的基础上，引入业务规则、多样性、新颖性、公平性等非精度指标，生成最终的用户可见列表。经典方法如MMR、DPP等，或者简单的规则调整。</li>
</ul>
<p><strong>传统范式的问题</strong></p>
<ul>
<li>模块割裂：召回、排序、重排各阶段目标不一致、模型独立，存在误差累积和信息损失。召回模型看不到最终目标，可能将潜在的高价值物品过早过滤。</li>
<li>曝光偏差：模型严重依赖于用户历史已曝光的数据进行训练，对于“用户可能喜欢但从未接触过”的长尾、新颖物品发掘能力有限。</li>
<li>目标局限：传统模型大多进行“点估计”，即预测单个物品的反馈概率，从封闭的候选集中集中排序，难以对整个列表的全局最优进行建模。</li>
</ul>
<p><strong>什么是生成式推荐/召回？</strong><br>生成式推荐是一种端到端的范式，它将推荐问题重新定义为 <strong>“序列生成”</strong> 问题。给定用户的上下文信息（如用户画像、历史行为序列），生成式直接生成用户下一个可能感兴趣的物品ID序列。类似于自然语言处理中的任务。</p>
<ul>
<li>在NLP中，给定上文，模型生成下一个词。<code>&quot;今天天气很好，我们一起去__&quot; -&gt; 生成 “公园”</code></li>
<li>在推荐中，给定用户历史行为，模型生成下一个物品。<code>User历史点击 [item_A, item_B, item_C] -&gt; 生成 [item_D, item_E, ...]</code></li>
</ul>
<p>生成式将物品ID/语义ID视为“单词”，整个物品库构成一个庞大的“词表”。将用户行为序列视为“句子”：<code>[item_1, item_2, ..., item_n]</code> 就是一个句子，除了物品id也可以是行为相关的各类特征。使用生成式模型（如Transformer）而非判别式模型学习用户行为序列内部的模式和规律，从而预测下一个或多个物品。模型不仅可以生成一个物品，还可以一步到位地生成一个有序的推荐列表，这相当于将召回和排序/重排多个阶段融合到了一个统一的生成过程中。</p>
<h2 id="生成式推荐的优劣与挑战"><a href="#生成式推荐的优劣与挑战" class="headerlink" title="生成式推荐的优劣与挑战"></a>生成式推荐的优劣与挑战</h2><p><strong>生成式推荐的优势/收益来源</strong></p>
<ol>
<li><strong>端到端代替级联式架构</strong>：级联式的架构迭代越来越复杂，收益进入瓶颈期，各级之间通信缓存代价越来越高。生成式模型直接以最终推荐列表的质量为优化目标，避免了多阶段 pipeline 的误差传递和信息损失，模型可以学到从海量候选池直接到最优列表的映射。Meta的HSTU工作在工业级数据上验证了scaling law，得以让端到端生成式模型的规模扩大。</li>
<li><strong>融合多模态信息与统一序列建模</strong>：用户的历史行为可以包含点击、购买、点赞、搜索等多种类型。生成式模型可以将这些异构行为视为一个统一的序列进行建模，从而构建更全面的用户兴趣表示。基于Transformer的架构能够捕捉用户行为序列中复杂的、长期的依赖关系。用户的兴趣可能是动态变化的，生成式模型能更好地理解这种演变，例如从“浏览手机”到“购买手机壳”的跨域兴趣迁移。对长尾和冷启动物品更友好，只要一个物品在训练序列中出现过，模型就有可能根据其上下文模式将其生成出来，而不是像双塔模型那样严重依赖物品侧特征的完善度。</li>
<li><strong>全局最优列表生成</strong>：传统的列表生成是“贪心”的，即选取top-k打分最高的物品。而生成式模型在生成每一个位置的物品时，可以考虑已经生成的物品，而不仅仅是对单个物品的点击，从而在<strong>列表级别</strong>上优化多样性、互补性等指标，实现全局最优。</li>
</ol>
<p><strong>生成式落地面临的挑战</strong></p>
<ol>
<li><strong>样本构造及特征工程问题</strong>：NLP中的词表通常在几万到几十万，而推荐系统的物品库动辄数百万甚至数亿，这导致模型的输出层计算（Softmax）成为巨大的性能瓶颈，同时召粗精各个环节样本的构造方式也都不同，如何高效处理超大词表构建样本是首要挑战。工业系统中的特征数及特征类型也很多样，特征处理方式更加复杂，包括DeepFM特征交叉、DIN的target attention、序列间的cross attention、SENet自适应特征选择、MMoE多任务建模，如何做特征工程才能让生成式打败这些累计多年的DLRM行业经验也是一个挑战。</li>
<li><strong>生成过程的不可控性与“幻觉”</strong>：生成式模型可能会生成不存在的物品ID或重复物品。如何保证生成物品的有效性、多样性和准确性，并融入业务规则，比如不允许出现已购物品，是一个难题。</li>
<li><strong>训练与推理的一致性</strong>：在训练时，模型使用真实的用户行为序列作为上文（Teacher Forcing）。但在推理时，模型使用自己生成的结果作为上文，这可能导致曝光偏差的累积，即一步错，步步错。</li>
<li><strong>评估困难</strong>：传统的基于点击率的评估指标可能不足以衡量生成列表的整体质量。如何评估列表的多样性、新颖性和用户长期满意度，需要新的评估体系。</li>
<li><strong>系统部署与性能压力</strong>：模型参数的scaling后，如何在保证效果的同时，降低在线推理时的计算开销和延迟，适用于广告推荐系统高吞吐、低延迟的场景。</li>
</ol>
<h2 id="生成式经典工作演进"><a href="#生成式经典工作演进" class="headerlink" title="生成式经典工作演进"></a>生成式经典工作演进</h2><h3 id="GRU4Rec-Session-based-Recommendations-with-Recurrent-Neural-Networks"><a href="#GRU4Rec-Session-based-Recommendations-with-Recurrent-Neural-Networks" class="headerlink" title="GRU4Rec: Session-based Recommendations with Recurrent Neural Networks"></a>GRU4Rec: Session-based Recommendations with Recurrent Neural Networks</h3><p>在GRU4Rec之前，推荐系统大多基于协同过滤或矩阵分解，这些方法主要有2个缺点：静态建模忽略了用户行为内在的时序动态性；缺失序列信息无法捕捉用户兴趣的演变过程。GRU4Rec是发表在ICLR2016的工作，GRU4Rec将用户在一个会话内的交互序列（如点击、购买）视为一个时间序列，使用RNN（GRU）来建模这个序列，从而预测用户下一个可能感兴趣的项目。GRU4Rec为序列推荐奠定了基础。它本质上是在做“下一个物品预测”，可视为生成式召回的雏形。</p>
<div align="center">
  <img src="GRU4Rec1.png" height=90% width=90%>
</div>

<p>GRU4Rec的几个主要贡献：</p>
<ul>
<li>Session并行miniBatch处理：用户会话长度不一，如何高效地进行批处理训练？GRU4Rec将多个会话组合成一个矩阵进行并行计算。如果一个会话结束，就用下一个会话的初始状态“填充”到同一批次中。极大提高了GPU的利用率。</li>
<li>基于排名的损失函数： 传统的交叉熵损失函数在物品库极大（百万甚至上亿）的情况下，计算Softmax非常昂贵，且它平等地看待所有负样本（未交互的物品）。GRU4Rec提出几种基于排名的损失函数，包括1）<strong>BPR Loss（Bayesian Personalized Ranking）</strong>：最大化正样本和负样本得分之差的对数似然。2）<strong>TOP1 Loss</strong>：一个更简单的正则化排名损失，鼓励正样本得分高于负样本，同时鼓励负样本得分接近于0。3）loss负采样：不需要对所有未交互的物品进行计算，而是随机采样少量（如100-500个）负样本，与一个正样本组成样本对，这解决了超大规模物品库的计算瓶颈。</li>
</ul>
<div align="center">
  <img src="GRU4Rec2.png" height=70% width=70%>
</div>

<p>从GRU4Rec出发，后续发展出很多对其工作的拓展：<strong>模型架构</strong>（RNN -&gt; CNN -&gt; Transformer/GNN）、<strong>信息利用</strong>（仅物品ID -&gt; 丰富Side Information）、<strong>训练目标</strong>（排名损失 -&gt; 对比学习 -&gt; 生成式目标）。</p>
<h3 id="SASRec-Self-Attentive-Sequential-Recommendation"><a href="#SASRec-Self-Attentive-Sequential-Recommendation" class="headerlink" title="SASRec: Self-Attentive Sequential Recommendation"></a>SASRec: Self-Attentive Sequential Recommendation</h3><p>SASRec之前，序列推荐的主流模型是GRU4Rec等基于RNN的模型。RNN存在的问题：1是由于梯度问题难以学习非常长的序列依赖；2是递归计算无法并行处理序列导致训练速度慢；3是RNN的隐藏状态机制对序列中不同物品的“重要性”是隐式且固定的，难以明确捕捉哪些历史行为对预测下一个物品最关键。SASRec于2018年发表在ICDM，将Transformer架构引入序列推荐（仅含解码器的GPT风格），应用在召回场景，利用自注意力机制捕捉长期依赖，直接、显式地捕捉用户行为序列中任意两个物品之间的依赖关系。SASRec明确地将推荐定义为自回归生成任务。</p>
<div align="center">
  <img src="SASRec.png" height=70% width=70%>
</div>

<h3 id="TDM-Learning-Tree-based-Deep-Model-for-Recommender-Systems"><a href="#TDM-Learning-Tree-based-Deep-Model-for-Recommender-Systems" class="headerlink" title="TDM: Learning Tree-based Deep Model for Recommender Systems"></a>TDM: Learning Tree-based Deep Model for Recommender Systems</h3><p>TDM是阿里2018年发表在KDD的工作，是生成式召回的标志。虽然不是严格的NLP式生成，但TDM开创了“使用复杂模型进行端到端检索”的思路。在TDM提出之前，工业界解决大规模推荐尤其是召回阶段的主流方法是：</p>
<ul>
<li>双塔模型：分别学习用户和物品的emedding，通过近似最近邻搜索快速召回。但用户和物品的深度交互仅在最后的内积运算中发生，限制了模型的表达能力。</li>
<li>基于物品的协同过滤：简单有效，但难以融入丰富的特征，且泛化能力有限。</li>
</ul>
<p>我们既希望召回模型能像精排模型一样复杂、强大，能进行深度特征交叉，又需要它能在毫秒内从亿级物品池中完成检索。传统的“内积检索”范式无法容纳复杂的深度模型。TDM将大规模推荐问题转化为一系列在树结构上的层次化分类问题。通过一棵树来组织所有物品，使用一个复杂的深度模型从根节点到叶子节点逐层决策，最终检索出叶子节点物品。召回包括索引构建和排序两部分，TDM中索引构建使用图中右侧树结构，检索算法是beam search。评分部分是图中左侧的DNN网络，用于输出用户对树节点的偏好程度。</p>
<div align="center">
  <img src="TDM.png" height=100% width=100%>
</div>

<p>TDM构建了一棵<strong>最大堆树</strong>。每个叶子节点对应一个具体的物品。拥有 <code>N</code> 个物品，就有 <code>N</code> 个叶子节点。非叶子节点都是虚拟节点，不代表具体物品，而是代表其子树下所有叶子节点物品的集合。最大堆树具有的最大堆性质即对于任意一个非叶子节点 <code>n</code>，其被用户 <code>u</code> 喜欢的概率，应该大于或等于其任意一个子节点被 <code>u</code> 喜欢的概率。直观理解就是如果你对“电子产品”这个大类别感兴趣（父节点概率高），那么你更可能对其下的某个子类如“手机”或具体商品如“iPhone”感兴趣。反之则不一定成立。TDM树采用随机初始化，简单随机地将物品分配到叶子节点。再基于内容聚类，利用物品的内容特征如标题嵌入、类别等进行层次化聚类，将相似的物品放在同一个子树下。</p>
<p>传统遍历复杂度是<code>O(N)</code>。双塔ANN检索复杂度是<code>O(d log N)</code>，其中 <code>d</code> 是向量维度。TDM树检索复杂度是<code>O(beam_size * D * log N)</code>，其中 <code>D</code> 是树的最大度（每个节点的子节点数）。由于 <code>beam_size</code> 和 <code>D</code> 都是常数，因此复杂度是<code>O(log N)</code>。这使得从亿级物品池中检索在毫秒级完成成为可能。</p>
<p>TDM可以看作是生成式推荐的先驱。路径生成即物品生成：在TDM的检索过程中，从根节点到叶子节点的一条路径唯一确定了一个物品。这个“路径”可以被视为物品的一种离散的、层次化的标识符。因此TDM的检索过程，本质上是在<strong>自回归地生成一条路径</strong>，在每一层，模型选择一个子节点，直到生成完整的路径（即物品）。同时TDM与语义ID的完美对应：生成式推荐中的语义ID为物品分配一个层次化的代码（如 <code>[c1, c2, c3]</code>），TDM中的树路径 <code>[根 -&gt; n1 -&gt; n2 -&gt; 叶子]</code> 就是一个天然的、可学习的语义ID。基于TDM的检索，就变成了<strong>基于语义ID的生成式召回</strong>。后续从TDM出发的技术发展线：TDM（树+判别模型） -&gt; JTM（联合优化树和模型）-&gt; 语义ID（物品的层次化表示）-&gt; 生成式推荐（自回归生成语义ID路径）。</p>
<h3 id="M6-Rec-Generative-Pretrained-Language-Models-are-Open-Ended-Recommender-Systems"><a href="#M6-Rec-Generative-Pretrained-Language-Models-are-Open-Ended-Recommender-Systems" class="headerlink" title="M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender Systems"></a>M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender Systems</h3><p>M6-Rec阿里达摩院发表在2022KDD上的工作。在M6-Rec之前，推荐系统面临的几个问题：</p>
<ol>
<li>任务割裂：召回、排序、重排各阶段模型独立，目标不一致。用户画像、行为序列、物品内容等异构信息难以统一建模。</li>
<li>封闭世界假设：传统模型只能在训练时见过的、固定物品库中进行推荐，无法处理新物品或开放域请求。模型基于统计相关性进行推荐，无法像人类一样进行常识推理和因果推断。</li>
</ol>
<p>M6是阿里研发的10B中文多模态预训练模型Multi-Modality to Multi-Modality Mega-Transformer。M6-Rec是将用户行为数据表示为纯文本，将任务转换为语言理解或生成任务，利用M6的预训练能力实现的在推荐任务上的下游适配。推荐基础大模型面临的两个挑战是1下游任务的集合可能是无限的；2计算效率问题。对于问题1，M6-Rec将推荐系统重构为一个统一的基于大语言模型的开放域文本生成任务。它不再将推荐视为对固定物品ID的打分或排序，而是视为根据用户上下文生成推荐理由或物品描述的文本生成问题。不仅将物品ID作为token，还将用户属性、用户历史行为序列、物品标题、上下文、任务指令等全部统一成自然语言序列。如输入序列是：<code>“用户：年轻男性。行为：点击了‘Nike篮球鞋’，搜索了‘Java编程书’。推荐：”</code>，模型基于其在大规模语料上预训练得到的语言知识和推理能力生成推荐结果，如 <code>“《Java核心技术卷Ⅰ》， Adidas运动T恤”</code>。对于问题2，M6-Rec通过改进版prompt tuning -&gt; option tuning、late interaction、early exiting、参数共享、剪枝等技术减少推理时间和模型大小。</p>
<div align="center">
  <img src="M6-Rec1.png" height=100% width=100%>
</div>

<div align="center">
  <img src="M6-Rec2.png" height=100% width=100%>
</div>

<h3 id="Tiger-Recommender-Systems-with-Generative-Retrieval"><a href="#Tiger-Recommender-Systems-with-Generative-Retrieval" class="headerlink" title="Tiger: Recommender Systems with Generative Retrieval"></a>Tiger: Recommender Systems with Generative Retrieval</h3><p>现代推荐系统通过先将查询和候选项目嵌入到同一个统一空间中，然后进行近似最近邻搜索，根据查询嵌入选择排名靠前的候选项目，从而执行大规模检索。Tiger: Transformer Index for GEnerative Recommenders是谷歌DeepMind发表在NeurIPS2023的工作，首个用于推荐任务的基于语义ID的生成式模型，给定用户会话中项目的语义ID，检索模型自回归地解码目标候选项目的标识符，预测用户接下来将交互的item的语义ID。</p>
<div align="center">
  <img src="Tiger1.png" height=100% width=100%>
</div>

<p>Tiger利用物品的内容特征（如标题、价格、品牌和类别）构建句子，然后将其输入预训练的Sentence-T5模型，得到768维的物品语义embedding，再使用RQ-VAE量化形成一组有序的codeword，即该物品的语义ID。将语义ID embedding序列拼接到用户embedding后，使用双向Transformer encoder实现特征间的充分交叉，一定程度上缓解双塔ui特征交叉太晚的问题。</p>
<div align="center">
  <img src="Tiger2.png" height=100% width=100%>
</div>

<p>论文中提到的关于语义ID一些其他点：</p>
<ul>
<li>生成语义ID的其他量化方法对比：局部敏感哈希LSH、分层k-means聚类（会丢失不同簇之间的语义含义）、VQ-VAE（检索时生成候选的性能与RQ-VAE相似，但它没有ID的层次结构），这三个都不如RQ-VAE效果好。</li>
<li>语义ID碰撞处理：语义碰撞即多个item映射到同一个语义ID，通常会维护一个将语义ID映射到对应item的查找表来检测碰撞。为解决语义碰撞，在有序语义编码的末尾附加一个额外token确保唯一性，这个过程仅在RQ-VAE模型训练完成后执行一次。</li>
<li>生成无效的语义ID：论文中说这种情况很少，由于语义ID的层次结构，可以在模型生成无效token时进行前缀匹配，检索和模型生成token具有相似语义的item。</li>
</ul>
<p>语义ID的优势：</p>
<ul>
<li>codebook缩短了候选Token的个数，从千万级到256，语义ID是整数元组，相比高维embedding查找表（负采样+ANN）的存储效率更高。</li>
<li>语义ID中的语义信息可用于冷启动推荐。</li>
<li>因为语义ID的层次化特性，在解码过程中基于温度的采样可以控制模型预测的多样性。比如对语义ID的第一个token采样可以检索粗粒度类别的物品，对第二/三个token采样则可以在类别内采样物品。</li>
</ul>
<p>在实际应用中语义ID是存在一些问题的，后续的一些工作都在尝试通过混合建模、层次化结构等方法来弥补这些不足。</p>
<ul>
<li>区分能力问题：语义ID基于内容特征生成，相似的物品会有相似的ID前缀。这可能导致模型难以区分高度相似但用户偏好不同的物品。</li>
<li>迁移能力局限：虽然语义ID理论上能改善冷启动，但实际效果受限。新物品的语义ID可能无法准确反映用户的潜在兴趣。模型需要足够的训练数据来学习语义ID与用户行为之间的复杂映射关系。</li>
</ul>
<h3 id="Actions-Speak-Louder-than-Words-Trillion-Parameter-Sequential-Transducers-for-Generative-Recommendations"><a href="#Actions-Speak-Louder-than-Words-Trillion-Parameter-Sequential-Transducers-for-Generative-Recommendations" class="headerlink" title="Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations"></a>Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations</h3><p>HSTU是Mata AI发表在ICML2024的工作，该工作摒弃了近10年工业级主流的深度学习推荐系统架构DLRMs，首次基于LLM构建工业级生成式推荐系统，并首次验证了LLM的Scaling Law同样适用于推荐系统。GRs对DLRM中的异构特征空间进行统一，将推荐系统的召回排序重新表达为GR中的纯时间序列顺序推导问题。这样模型就可以用生成式的方式在相同计算量下训练更多数据。</p>
<div align="center">
  <img src="HSTU1.png" height=100% width=100%>
</div>

<p>GRs的层次推导架构HSTU针对性修改了注意力机制，包括：</p>
<ul>
<li>类似DIN的思想，sigmoid取代softmax，sigmoid可以保留数值本身的强度；</li>
<li>QKV-&gt;QKVU，类似ResNet，U表示原始向量表征，最终和attention后的表征相乘，同时保留深度交互后和原始的特征表征，增强泛化性；</li>
<li>MLP中使用<code>silu(silu=x*sigmoid(x))</code>作为激活函数，同时保留了线性和非线性激活函数，结合了relu和sigmoid的信息，且不会产生神经元死亡的现象，提升了模型的表现和稳定性。</li>
<li>GRs还做了很多工程优化，比如结合FlashAttention2和提出新的M-FALCON推理方法加速。</li>
</ul>
<div align="center">
  <img src="HSTU2.png" height=60% width=60%>
</div>

<h3 id="其他业界经典工作"><a href="#其他业界经典工作" class="headerlink" title="其他业界经典工作"></a>其他业界经典工作</h3><p><strong>阿里妈妈URM《Large Language Model as Universal Retriever in Industrial-Scale Recommender System》：多目标生成式召回。</strong>URM将多种检索目标统一至协调的输入-输出框架，利用LLM作为特征生成器。最终URM能根据输入指令动态调整检索输出，在数十毫秒延迟内返回商品集。在淘宝广告平台上在线A/B关键指标提升超3%。</p>
<div align="center">
  <img src="URM.png" height=100% width=100%>
</div>

<p><strong>美团《MTGR: Industrial-Scale Generative Recommendation Framework in Meituan》：基于HSTU架构升级生成式精排模型。</strong>相对HSTU增加了user和item的交叉特征，提出组层归一化GLN对异质token分别归一化来提升不同语义空间内的编码性能，采用动态掩码策略来避免信息泄露。</p>
<div align="center">
  <img src="MTGR.png" height=100% width=100%>
</div>

<p><strong>快手《OneRec: Unifying Retrieve and Rank with GenerativeRecommender and Preference Alignment》：统一召粗精的端到端架构。</strong>1）使用encoder-decoder结构对用户的历史行为序列编码，并逐步解码出用户可能感兴趣的视频（V2使用decoder-only架构）。用稀疏混合专家模型MoE扩展模型容量数。2）与传统的下一item预测不同，提出会话级生成（实际技术报告中采用的point-wise）。3）结合直接偏好优化DPO（技术报告中使用Early Clipped GRPO, ECPO，V2使用GBPO）提升生成结果的质量，设计一个奖励模型来模拟用户生成，并定制了采样策略。最终在快手主场景实现了1.6%的观看时长增长。</p>
<div align="center">
  <img src="ONERec1.png" height=100% width=100%>
</div>

<div align="center">
  <img src="ONERec2.png" height=80% width=80%>
</div>


<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/1916207872066430537/answer/1931712161224320583">生成式推荐会成为下一代推荐系统的范式吗？</a> 王喆老师的回答非常好</li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/1906473225224953962/answer/1956667989328888901">生成式推荐是不是一个伪范式？</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/21751563983">现在，我们最好的召回模型来</a> 召回的架构为索引+排序，字节的Streaming VQ</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/1955356511661458958">聊聊生成式召回的本质</a> 本质上是Streaming VQ</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/1927420378491389862">万字长文——生成式推荐有几种写法</a> 生成式精排：GRs、HSTU、MTGR；生成式召回：Tiger、COBRA、端到端OneRec，模型架构及原理介绍</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1511.06939">Session-based Recommendations with Recurrent Neural Networks</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1808.09781">Self-Attentive Sequential Recommendation</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1801.02294">Learning Tree-based Deep Model for Recommender Systems</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.08084">M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender Systems</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.05065">Recommender Systems with Generative Retrieval</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.17152">Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.03041">Large Language Model as Universal Retriever in Industrial-Scale Recommender System</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.18654">MTGR: Industrial-Scale Generative Recommendation Framework in Meituan</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.18965">OneRec: Unifying Retrieve and Rank with Generative Recommender and Preference Alignment</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.13695">OneRec Technical Report</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.20900">OneRec-V2 Technical Report</a></li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">贪钱算法还我头发</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://xfliu1998.github.io/2025/11/16/LLM-GRs/">https://xfliu1998.github.io/2025/11/16/LLM-GRs/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a><a class="post-meta__tags" href="/tags/Search-Ads-Reco/">Search, Ads &amp; Reco</a></div><div class="post_share"><div class="social-share" data-image="/2025/11/16/LLM-GRs/cover.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2025/10/24/LLM-RL4LLM/"><img class="next-cover" src="/2025/10/24/LLM-RL4LLM/cover.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">LLM —— RL4LLM</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2025/10/24/LLM-RL4LLM/" title="LLM —— RL4LLM"><img class="cover" src="/2025/10/24/LLM-RL4LLM/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-24</div><div class="title">LLM —— RL4LLM</div></div></a></div><div><a href="/2025/09/18/LLM-SFT/" title="LLM —— SFT"><img class="cover" src="/2025/09/18/LLM-SFT/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-18</div><div class="title">LLM —— SFT</div></div></a></div><div><a href="/2025/08/03/LLM-Tokenize/" title="LLM —— Tokenize"><img class="cover" src="/2025/08/03/LLM-Tokenize/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-03</div><div class="title">LLM —— Tokenize</div></div></a></div><div><a href="/2025/07/26/LLM-Position-Embedding/" title="LLM —— Position Embedding"><img class="cover" src="/2025/07/26/LLM-Position-Embedding/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-26</div><div class="title">LLM —— Position Embedding</div></div></a></div><div><a href="/2025/06/21/LLM-Parameter-Calculation/" title="LLM —— Parameter Calculation"><img class="cover" src="/2025/06/21/LLM-Parameter-Calculation/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-21</div><div class="title">LLM —— Parameter Calculation</div></div></a></div><div><a href="/2025/05/05/LLM-MoE/" title="LLM —— MoE"><img class="cover" src="/2025/05/05/LLM-MoE/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-05</div><div class="title">LLM —— MoE</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">贪钱算法还我头发</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">63</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">16</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xfliu1998"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xfliu1998" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:liuxiaofei_7@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://www.zhihu.com/people/fan-xu-15-35/posts" target="_blank" title="Zhihu"><i class="fa fa-address-card"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">👋你好呀，欢迎围观～搭建这个小站源于一个朴素的愿望：对抗遗忘，沉淀思考。期待在代码与逻辑的世界里探索技术的深度与广度，永远保持热情与好奇。</div></div><div class="card-widget" id="newYear"><div class="item-headline"><i></i><span></span></div><div class="item-content"><div id="newYear-main"><div class="mask"></div> <p class="title"></p> <div class="newYear-time"></div> <p class="today" style="text-align: right;"></p> </div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8E%E4%BC%A0%E7%BB%9F%E6%8E%A8%E8%8D%90%E5%88%B0%E7%94%9F%E6%88%90%E5%BC%8F%E6%8E%A8%E8%8D%90"><span class="toc-number">1.</span> <span class="toc-text">从传统推荐到生成式推荐</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E5%BC%8F%E6%8E%A8%E8%8D%90%E7%9A%84%E4%BC%98%E5%8A%A3%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-number">2.</span> <span class="toc-text">生成式推荐的优劣与挑战</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E5%BC%8F%E7%BB%8F%E5%85%B8%E5%B7%A5%E4%BD%9C%E6%BC%94%E8%BF%9B"><span class="toc-number">3.</span> <span class="toc-text">生成式经典工作演进</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#GRU4Rec-Session-based-Recommendations-with-Recurrent-Neural-Networks"><span class="toc-number">3.1.</span> <span class="toc-text">GRU4Rec: Session-based Recommendations with Recurrent Neural Networks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SASRec-Self-Attentive-Sequential-Recommendation"><span class="toc-number">3.2.</span> <span class="toc-text">SASRec: Self-Attentive Sequential Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TDM-Learning-Tree-based-Deep-Model-for-Recommender-Systems"><span class="toc-number">3.3.</span> <span class="toc-text">TDM: Learning Tree-based Deep Model for Recommender Systems</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#M6-Rec-Generative-Pretrained-Language-Models-are-Open-Ended-Recommender-Systems"><span class="toc-number">3.4.</span> <span class="toc-text">M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender Systems</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tiger-Recommender-Systems-with-Generative-Retrieval"><span class="toc-number">3.5.</span> <span class="toc-text">Tiger: Recommender Systems with Generative Retrieval</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Actions-Speak-Louder-than-Words-Trillion-Parameter-Sequential-Transducers-for-Generative-Recommendations"><span class="toc-number">3.6.</span> <span class="toc-text">Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E4%B8%9A%E7%95%8C%E7%BB%8F%E5%85%B8%E5%B7%A5%E4%BD%9C"><span class="toc-number">3.7.</span> <span class="toc-text">其他业界经典工作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">4.</span> <span class="toc-text">参考</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('/2025/11/16/LLM-GRs/cover.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025  <i id="heartbeat" class="fa fas fa-heartbeat"></i> 贪钱算法还我头发</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div><head><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/HCLonely/images@master/others/heartbeat.min.css"></head></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '1b0c10ce649501ea4a72',
      clientSecret: '741b5e861137e3d5a482bba272c8201b78da6cb0',
      repo: 'xfliu1998.github.io',
      owner: 'xfliu1998',
      admin: ['xfliu1998'],
      id: '4d79ad815f69ad37b7fec4515707ecb5',
      language: 'en',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: true,
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script src="/js/script.js?v1"></script><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async data-pjax src="https://cdn.wpon.cn/2022-sucai/Gold-ingot.js"></script><script async data-pjax src="/js/newYear.js"></script><script async src="//at.alicdn.com/t/font_2264842_b004iy0kk2b.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='all'|| 'all' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Machine-Learning-and-Deep-Learning/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 机器学习与深度学习 (18)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Data-Structures-and-Algorithms/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">😼 数据结构与算法 (16)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Search-Advertisement-Recommendation-Causal/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🗂️ 搜索/广告/推荐/因果 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Data-Analysis-and-Processing/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 数据分析与处理 (7)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Reading-Notes/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 阅读笔记 (7)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Daily/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 日常随笔 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://xfliu1998.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/09/17/Papers-Reading-about-NLP/" alt=""><img width="48" height="48" src="2022/09/17/Papers-Reading-about-NLP/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-09-17</span><a class="blog-slider__title" href="2022/09/17/Papers-Reading-about-NLP/" alt="">Papers Reading about NLP</a><div class="blog-slider__text">自然语言处理论文阅读笔记</div><a class="blog-slider__button" href="2022/09/17/Papers-Reading-about-NLP/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/01/11/SfM-SLAM/" alt=""><img width="48" height="48" src="2023/01/11/SfM-SLAM/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-11</span><a class="blog-slider__title" href="2023/01/11/SfM-SLAM/" alt="">SfM &amp; SLAM</a><div class="blog-slider__text">SfM和SLAM系统</div><a class="blog-slider__button" href="2023/01/11/SfM-SLAM/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/03/25/Papers-Ideas/" alt=""><img width="48" height="48" src="2023/03/25/Papers-Ideas/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-03-25</span><a class="blog-slider__title" href="2023/03/25/Papers-Ideas/" alt="">Papers Ideas</a><div class="blog-slider__text">大模型时代下的科研思路</div><a class="blog-slider__button" href="2023/03/25/Papers-Ideas/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/09/17/Papers-Summary/" alt=""><img width="48" height="48" src="2022/09/17/Papers-Summary/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-09-17</span><a class="blog-slider__title" href="2022/09/17/Papers-Summary/" alt="">Papers Summary</a><div class="blog-slider__text">论文总结笔记</div><a class="blog-slider__button" href="2022/09/17/Papers-Summary/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/09/17/Papers-Reading-about-CV/" alt=""><img width="48" height="48" src="2022/09/17/Papers-Reading-about-CV/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-09-17</span><a class="blog-slider__title" href="2022/09/17/Papers-Reading-about-CV/" alt="">Papers Reading about CV</a><div class="blog-slider__text">计算机视觉论文阅读笔记</div><a class="blog-slider__button" href="2022/09/17/Papers-Reading-about-CV/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/06/05/Interview-Experience/" alt=""><img width="48" height="48" src="2023/06/05/Interview-Experience/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-06-05</span><a class="blog-slider__title" href="2023/06/05/Interview-Experience/" alt="">Interview Experience</a><div class="blog-slider__text">面经八股</div><a class="blog-slider__button" href="2023/06/05/Interview-Experience/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/08/16/Papers-Reading-about-LLM/" alt=""><img width="48" height="48" src="2024/08/16/Papers-Reading-about-LLM/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-08-16</span><a class="blog-slider__title" href="2024/08/16/Papers-Reading-about-LLM/" alt="">Papers Reading about LLM</a><div class="blog-slider__text">LLM论文阅读笔记</div><a class="blog-slider__button" href="2024/08/16/Papers-Reading-about-LLM/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/11/16/LLM-GRs/" alt=""><img width="48" height="48" src="2025/11/16/LLM-GRs/cover.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-11-16</span><a class="blog-slider__title" href="2025/11/16/LLM-GRs/" alt="">LLM —— GRs</a><div class="blog-slider__text">生成式在推荐广告领域的落地</div><a class="blog-slider__button" href="2025/11/16/LLM-GRs/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/01/21/Learning-Framework/" alt=""><img width="48" height="48" src="2022/01/21/Learning-Framework/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-01-21</span><a class="blog-slider__title" href="2022/01/21/Learning-Framework/" alt="">学习大纲</a><div class="blog-slider__text">目录</div><a class="blog-slider__button" href="2022/01/21/Learning-Framework/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<container><style>#git_container{min-height: 280px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></container>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("https://gitcalendar.fomal.cc/api?xfliu1998",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'xfliu1998')
    }
  </script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>