<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Rank Model | 一直进步 做喜欢的</title><meta name="keywords" content="Deep Learning,Search, Ads &amp; Reco"><meta name="author" content="贪钱算法还我头发"><meta name="copyright" content="贪钱算法还我头发"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="精排模型——从特征交叉建模到深度兴趣序列建模">
<meta property="og:type" content="article">
<meta property="og:title" content="Rank Model">
<meta property="og:url" content="https://xfliu1998.github.io/2025/12/07/Rank-Model/index.html">
<meta property="og:site_name" content="一直进步 做喜欢的">
<meta property="og:description" content="精排模型——从特征交叉建模到深度兴趣序列建模">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://xfliu1998.github.io/2025/12/07/Rank-Model/cover.jpeg">
<meta property="article:published_time" content="2025-12-07T12:00:59.000Z">
<meta property="article:modified_time" content="2025-12-07T14:07:13.732Z">
<meta property="article:author" content="贪钱算法还我头发">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Search, Ads &amp; Reco">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://xfliu1998.github.io/2025/12/07/Rank-Model/cover.jpeg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://xfliu1998.github.io/2025/12/07/Rank-Model/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Rank Model',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-12-07 22:07:13'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/pool.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/iconfont.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/js/pool.min.js"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/mouse_snow.min.js"><link rel="stylesheet" href="/css/custom.css?v1"><link rel="stylesheet" href="//at.alicdn.com/t/font_2264842_b004iy0kk2b.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">66</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">14</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/2025/12/07/Rank-Model/cover.jpeg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">一直进步 做喜欢的</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Rank Model</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-12-07T12:00:59.000Z" title="Created 2025-12-07 20:00:59">2025-12-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-12-07T14:07:13.732Z" title="Updated 2025-12-07 22:07:13">2025-12-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Search-Ads-Reco/">Search, Ads &amp; Reco</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">9.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>34min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Rank Model"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">Comments:</span><a href="/2025/12/07/Rank-Model/#post-comment"><span class="gitalk-comment-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="推荐系统技术演进——从特征交叉建模到深度兴趣序列建模"><a href="#推荐系统技术演进——从特征交叉建模到深度兴趣序列建模" class="headerlink" title="推荐系统技术演进——从特征交叉建模到深度兴趣序列建模"></a>推荐系统技术演进——从特征交叉建模到深度兴趣序列建模</h1><p>推荐系统的起点是基于群体行为的记忆的协同过滤模型，本质是“物以类聚，人以群分”。利用用户-物品交互矩阵如评分、点击，不依赖任何额外特征。经典的包括 <strong>User-CF</strong>（找到与你相似的用户，把他们喜欢的推荐给你）和 <strong>Item-CF</strong>（找到与你喜欢物品相似的物品，推荐给你）。但是这种方法的局限性是交互矩阵稀疏，无法处理冷启动问题，泛化能力差。为了引入丰富的上下文信息比如用户画像、物品属性等模型必须<strong>从“记忆”走向“泛化”</strong>。由此推荐系统经历了特征交叉模型和深度兴趣序列模型。特征交叉模型利用神经网络的学习能力挖掘特征信息的低阶、高阶融合。深度兴趣序列模型基于用户兴趣和行为进行显式语义特征交互来去捕捉用户和目标商品的相关性。在深度兴趣序列模型之后，推荐模型继续沿着更强大的序列建模如基于LLM的模型、多任务学习（同时优化点击、时长、购买等）、跨域信息融合、生成式推荐等快速发展。</p>
<h2 id="特征交叉模型"><a href="#特征交叉模型" class="headerlink" title="特征交叉模型"></a>特征交叉模型</h2><p>特征交叉模型的技术演进，经历了以下三个阶段：</p>
<ul>
<li><strong>线性与手工时代</strong>：基础线性模型LR依赖特征工程，POLY2尝试自动化二阶交叉但维度爆炸。</li>
<li><strong>特征自动工程</strong>：FM用隐向量解决稀疏交互，FFM引入Field概念细化交互粒度，GBDT+LR用树模型自动发现特征组合。</li>
<li><strong>深度学习融合</strong>：Wide&amp;Deep首次提出记忆与泛化结合架构，DeepFM用FM替代Wide部分实现全自动，DCN利用交叉网络高效学习显式交叉，DCN V2工业优化版平衡了效果与效率，CAN通过微网络结构在表达能力和计算效率之间取得了良好平衡。</li>
</ul>
<h3 id="LR-Logistic-Regression"><a href="#LR-Logistic-Regression" class="headerlink" title="LR (Logistic Regression)"></a>LR (Logistic Regression)</h3><p>广告数据具有高维稀疏性，特征维度可达数十亿，每个样本仅有少量特征非零，数据也是不平衡的，CTR通常很低（0.1%-5%）。用户特征、广告特征、上下文特征的交叉组合具有强预测性。</p>
<p>传统线性模型如LR只能学习线性关系：$P(y=1|\mathbf{x}) = \sigma(\mathbf{w}^T\mathbf{x} + b)$，无法自动学习特征交互，依赖人工特征工程，但是人工交叉特征会导致维度爆炸和泛化能力差。我们简单回顾下LR建模。</p>
<ul>
<li>LR模型形式化：给定特征向量 $\mathbf{x} = (x_1, x_2, …, x_n)^T$，LR模型如下，其中 $\mathbf{w} \in \mathbb{R}^n$ 为权重向量，$b \in \mathbb{R}$ 为偏置项。<script type="math/tex; mode=display">P(y=1|\mathbf{x}) = \frac{1}{1 + \exp(-(\mathbf{w}^T\mathbf{x} + b))}</script></li>
<li><p>参数估计与损失函数：使用最大似然估计，对数似然函数如下，其中 $p_i = \sigma(\mathbf{w}^T\mathbf{x}_i + b), \sigma(z) = 1/(1+e^{-z})$</p>
<script type="math/tex; mode=display">\mathcal{L}(\mathbf{w}) = \sum_{i=1}^N \left[ y_i \log p_i + (1-y_i) \log(1-p_i) \right]</script></li>
</ul>
<p>在广告推荐场景中，特征交叉非常重要。例如，用户的性别和商品类别的交叉特征（如女性用户和化妆品）可能对点击率有显著影响。包括一阶特征 $x_i$（原始特征）；二阶交叉特征 $x_i x_j$（特征乘积）；高阶交叉特征 $x_i x_j x_k$（三阶及以上）。为了解决特征交叉问题，早期做法是进行人工特征工程，将交叉特征作为新特征加入模型。但是这样做会导致维度灾难，n个特征的k阶组合数为 $C_n^k$，特征维度指数增长，在数据稀疏的情况下，很多交叉特征出现次数极少，难以有效学习其权重。泛化能力也很差，无法学习未见过的特征组合。</p>
<h3 id="POLY2-Polynomial-2"><a href="#POLY2-Polynomial-2" class="headerlink" title="POLY2 (Polynomial-2)"></a>POLY2 (Polynomial-2)</h3><p>为了自动化特征交叉，二阶多项式POLY2模型直接对所有的二阶交叉特征进行建模，并为每个交叉特征赋予一个权重。模型形式为：</p>
<script type="math/tex; mode=display">
\phi_{\text{POLY2}}(\mathbf{x}) = b + \sum_{i=1}^n w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} w_{ij} x_i x_j</script><p>POLY2的问题是总参数量为$O(n^2)$，训练复杂度高。对于交叉特征 $x<em>i x_j$，其参数 $w</em>{ij}$ 的梯度如下，在数据稀疏时，交叉特征权重难以训练，因为需要同时满足 $x_i$ 和 $x_j$ 都非零，这在稀疏数据中很难。</p>
<script type="math/tex; mode=display">
\frac{\partial \mathcal{L}}{\partial w_{ij}} = (y - \hat{y}) x_i x_j</script><h3 id="FM-Factorization-Machines"><a href="#FM-Factorization-Machines" class="headerlink" title="FM (Factorization Machines)"></a>FM (Factorization Machines)</h3><p>FM模型发表在SIGIR2011上。FM模型通过引入隐向量的思想，将交叉特征的权重矩阵进行矩阵分解，从而解决稀疏数据下的特征交叉学习问题。FM模型不仅考虑一阶特征，还考虑二阶特征交叉，但使用两个隐向量的内积来建模交叉特征的权重。模型公式如下，其中 $\mathbf{v}_i \in \mathbb{R}^k$ 是特征i的隐向量，$\langle \cdot, \cdot \rangle$ 表示向量内积：</p>
<script type="math/tex; mode=display">\phi_{\text{FM}}(\mathbf{x}) = b + \sum_{i=1}^n w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j</script><script type="math/tex; mode=display">\langle v_i, v_j \rangle = \sum_{f=1}^k v_{i, f} v_{j, f}</script><p>对于每一个特征 $i$，我们学习一个一阶权重 $w_i$ 和一个隐向量 $\mathbf{v}_i$（维度为 $k$）。因此总参数量为 $O(nk)$，其中 $k \ll n$，远小于POLY2的 $O(n^2)$。</p>
<p><strong>为什么FM能解决稀疏数据问题？</strong> 在POLY2中，交叉特征 $x<em>i x_j$ 的权重 $w</em>{ij}$ 只由这两个特征同时出现的数据学习。但在FM中，$w_{ij}$ 被分解为 $\langle \mathbf{v}_i, \mathbf{v}j \rangle$，也就是说，学习 $w{ij}$ 变成了学习特征 $i$ 和 $j$ 的隐向量。这样，对于特征 $i$，我们可以从所有包含 $i$ 的交叉特征中学习它的隐向量。例如，对于交叉特征 $x_i x_j$ 和 $x_i x_l$，它们都会更新特征 $i$ 的隐向量 $\mathbf{v}_i$。因此，即使某个交叉特征 $x_i x_j$ 在训练数据中很少出现，但只要特征 $i$ 和其他特征交叉出现过多次，那么 $\mathbf{v}_i$ 就能学习到较好的表示，从而可以泛化到未见过的交叉特征。</p>
<h3 id="GBDT-LR"><a href="#GBDT-LR" class="headerlink" title="GBDT+LR"></a>GBDT+LR</h3><p>GBDT+LR是Facebook在ADKDD2014提出的模型，利用GBDT（Gradient Boosting Decision Tree）强大的非线性特征组合能力进行自动特征组合，GBDT对原始特征进行训练，得到一系列决策树。每棵决策树将输入样本映射到某个叶子节点，将该叶子节点视为一个离散特征one-hot编码。然后GBDT的输出作为特征输入到LR模型中的方法。</p>
<div align="center">
  <img src="GBDT+LR.png" height=70% width=70%>
</div>

<ul>
<li><strong>GBDT模型</strong>：GBDT是一种加法模型，由多棵决策树组成，每棵树拟合的是之前所有树的残差，也就是梯度方向。对于输入特征向量x，GBDT的输出如下，其中，$h_t(x)$是第t棵决策树的输出，$γ_t$是学习率。在GBDT+LR中，我们并不直接使用F(x)的数值，而是使用每棵树的叶子节点编号作为新的特征。<script type="math/tex; mode=display">F(x) = Σ_{t=1}^{T} γ_t * h_t(x)</script></li>
<li><strong>特征转换</strong>：假设我们有 $T$ 棵树，每棵树有 $J<em>t$ 个叶子节点。对于第 $t$ 棵树，定义函数 $q_t(x)$为：输入x，输出该样本落在第t棵树的哪个叶子节点上，即 $q_t(x) ∈ {1, 2, …, J_t}$。然后，我们构造一个新的向量：$φ(x) = [I(q_1(x)=1), …, I(q_1(x)=J_1), …, I(q_T(x)=1), …, I(q_T(x)=J_T)]$。其中，$I(·)$ 是指示函数，当条件成立时取1，否则取0。这个向量 $φ(x)$ 就是GBDT提取出的新特征，它是一个one-hot向量，维度为 $Σ</em>{t=1}^{T} J_t$。</li>
<li><strong>LR模型</strong>：将 $φ(x)$ 作为输入，LR模型为 $p(y=1|x) = 1 / (1 + exp(-w^T φ(x) - b))$.</li>
</ul>
<p>使用GBDR+LR模型可以实现自动化特征组合，GBDT还能同时处理连续值和离散值并分析特征重要性但是，这种两阶段训练，不易进行端到端优化。而且GBDT模型训练时间长，且生成的特征维度高，可能过亿维，需要仔细处理稀疏性。</p>
<h3 id="FFM-Field-aware-FM"><a href="#FFM-Field-aware-FM" class="headerlink" title="FFM (Field-aware FM)"></a>FFM (Field-aware FM)</h3><p>FFM发表在RecSys2016上，在FM基础上引入了Field的概念。在广告推荐系统中，特征通常可以按照不同的领域进行分组。例如，我们可以将特征分为用户相关特征（如用户ID、年龄、性别）、广告相关特征（如广告ID、广告类别）和上下文特征（如时间、位置）等。在FM中，每个特征只有一个隐向量，用来与其他特征交互。但实际上，一个特征在与不同Field的特征交互时，其重要性或影响可能是不同的。例如，用户特征“性别”在与广告特征“类别”交互时和在与上下文特征“时间”交互时，其隐向量应该有所不同。在FFM中，每个特征针对其他每一个Field都会学习一个隐向量。这样，当两个特征交互时，会根据对方所属的Field选择对应的隐向量。</p>
<p><strong>FFM建模</strong>：给定一个样本，假设有n个特征，这些特征属于f个不同的Field。那么，FFM模型的公式如下，其中$\mathbf{v}_{i, F(j)}$ 是第i个特征针对第j个特征所属的Field（即$F(j)$）所学习的隐向量。</p>
<script type="math/tex; mode=display">
\phi_{\text{FFM}}(x) = w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} \langle v_{i,F(j)}, v_{j,F(i)} \rangle x_i x_j</script><p><strong>参数分析</strong>：FM每个特征有1个隐向量，参数量 $O(nk)$；FFM每个特征针对每个field有1个隐向量，每个隐向量是k维，参数量 $O(n \cdot f \cdot k)$，其中f是field数，由于f通常远小于n，所以FFM的参数量比FM大很多。</p>
<h3 id="WDL-Wide-amp-Deep-Learning"><a href="#WDL-Wide-amp-Deep-Learning" class="headerlink" title="WDL (Wide &amp; Deep Learning)"></a>WDL (Wide &amp; Deep Learning)</h3><p>Google在2016年提出Wide &amp; Deep Learning模型，WDL将传统特征工程结合深度学习模型，落地在Google Play推荐场景。Wide部分学习特征间的交互，尤其是稀疏特征的组合，便于记忆历史数据中的模式。Deep部分学习特征的深层表示，可以泛化到未见过的特征组合。</p>
<div align="center">
  <img src="WDL1.png" height=100% width=100%>
</div>

<div align="center">
  <img src="WDL2.png" height=80% width=80%>
</div>

<ul>
<li><strong>Wide部分</strong>：一个线性模型LR，输入包括原始特征和交叉特征。</li>
<li><strong>Deep部分</strong>：一个前馈神经网络，输入是稠密特征，可以是连续特征，也可以是embedding后的稀疏特征。</li>
</ul>
<p>将Wide部分和Deep部分的输出相加，然后通过一个sigmoid函数得到最终的预测概率。$P(Y=1|x) = σ( W<em>{wide}^T [x, φ(x)] + W</em>{deep}^T a^{(l<em>f)} + b )$。其中，$φ(x)$ 是特征交叉变换，$a^{(l_f)}$ 是Deep部分最后一层激活值。训练时同时训练Wide和Deep部分，使用联合损失函数logistic损失$\text{Loss} = -\frac{1}{N} \sum</em>{i=1}^N \left[ y_i \log(P(y_i|x_i)) + (1-y_i) \log(1 - P(y_i|x_i)) \right]$进行梯度下降。</p>
<p>训练时Wide与Deep联合训练。Wide部分使用FTRL（Follow-the-Regularized-Leader）优化器，适合稀疏特征，具有更好的收敛性。Deep部分使用自适应学习率的AdaGrad优化器，适合稠密特征。</p>
<p>Wide&amp;Deep 的“Wide” 部分仍依赖人工设计或搜索交叉特征，效率低且难以扩展。DNN的特征交叉能自动学习特征交互，但交互是<strong>隐式、高度非线性</strong>的，不易解释，可能无法高效学习某些有界阶数的特征交叉。后续出现了很多分别关于Wide和Deep部分改进的迭代。</p>
<h3 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h3><p>DeepFM于2017年由哈尔滨工业大学和华为诺亚方舟实验室联合提出，用FM组件替代Wide &amp; Deep中的Wide部分，不用人工特征工程，FM自动学习所有特征间的二阶交互，Deep网络自动学习高阶非线性交互。FM和DNN共享输入特征embedding，联合训练，端到端优化。</p>
<div align="center">
  <img src="DeepFM1.png" height=100% width=100%>
</div>

<div align="center">
  <img src="DeepFM2.png" height=100% width=100%>
</div>

<div align="center">
  <img src="DeepFM3.png" height=70% width=70%>
</div>


<h3 id="DCN-Deep-amp-Cross-Network"><a href="#DCN-Deep-amp-Cross-Network" class="headerlink" title="DCN (Deep &amp; Cross Network)"></a>DCN (Deep &amp; Cross Network)</h3><p>DCN是Google发表在AdKDD2017的文章。DCN 通过引入交叉网络，在 Wide&amp;Deep 的基础上实现了<strong>自动、高效、显式的特征交叉学习</strong>。DCN无需人工设计，通过可控的网络深度，可以自动学习显式生成从低阶到高阶的交叉特征。相比 DNN，DCN 以更少的参数量达到更好或相当的性能，适用于大规模稀疏输入和稠密特征。</p>
<div align="center">
  <img src="DCN.png" height=100% width=100%>
</div>

<ul>
<li>Embedding &amp; Stacking Layer：稀疏特征通过embedding层转换为稠密向量，将所有embedding向量与归一化的稠密特征拼接后得到 $\mathbf{x}_0$。</li>
<li>Cross Network：$\mathbf{x}_{l+1} = \mathbf{x}_0 \mathbf{x}_l^T \mathbf{w}_l + \mathbf{b}_l + \mathbf{x}_l$，这样第 $l$ 层输出的最高交叉阶数为 $l+1$。比如1 层 → 2 阶交叉 $x_i x_j$，2 层 → 3 阶交叉 $x_i x_j x_k$。时间复杂度为 $O(d)$，$d$ 为输入维度，远低于显式计算所有交叉 $O(d^2)$。</li>
<li>Deep Network：标准全连接网络，$\mathbf{h}_{l+1} = \text{ReLU}(W_l \mathbf{h}_l + \mathbf{b}_l)$ 用于学习高度非线性、隐式的特征交互。</li>
<li>Combination Layer：拼接交叉网络与深度网络的输出，通过逻辑回归层输出预测概率 $p = \sigma(\mathbf{z}^T \mathbf{w}_{\text{logits}})$</li>
</ul>
<p>DCN的缺点也很明显，交叉阶数受深度限制，最高阶数为 $L_c + 1$，可能无法学习极高阶交叉。而且交叉网络仅为乘法交互，可能无法捕获复杂非线性模式（需依赖 DNN 补充）或是存在冗余交叉特征。论文中指出DCN训练不稳定，交叉层数过多可能导致性能波动。</p>
<h3 id="DCN-V2"><a href="#DCN-V2" class="headerlink" title="DCN V2"></a>DCN V2</h3><p>DCN V2是Google发表在WWW2021的文章。DCN V2 的提出，源于将原始 DCN 模型应用于谷歌等公司超大规模工业级排序系统时遇到的实际挑战：</p>
<ul>
<li>原始 DCN 的表达能力有限：交叉网络的参数复杂度仅为 $O(d)$，限制了它建模复杂交叉模式的能力。在大规模生产数据中，DCN 的交叉网络未能学习到足够多有效的特征交互。</li>
<li>参数分配不平衡：在原始 DCN 中，绝大多数参数被分配给了深度网络用于学习隐式交互，而负责显式交互的交叉网络参数量过少，导致两者能力不匹配。</li>
<li>效率与性能平衡：工业级系统对模型的服务延迟和计算资源有极其严格的限制。需要在有限的预算内，设计一个既高效又能学习有效显式交叉的模型。</li>
<li>DNN 的低效性被再次确认：尽管 DNN 是通用函数逼近器，但大量研究和实践表明，标准的基于 ReLU 的全连接网络在学习乘法关系特征交叉（即使是 2 阶或 3 阶）时是低效的，往往需要过于庞大和复杂的网络。</li>
</ul>
<p>因此，DCN V2 的目标是在继承 DCN 自动、高效学习有界阶数显式交叉基础上，大幅提升其表达能力，并引入低秩混合等工程优化技术，使其能真正落地于十亿/百亿级样本的工业推荐与排序系统。</p>
<div align="center">
  <img src="DCNV2.png" height=80% width=80%>
</div>

<p>DCN V2 保留了原始 DCN 的并行双路结构，改进了交叉网络，支持 stacked 和 parallel 两种结构，</p>
<ul>
<li><p>原始 DCN 交叉层公式 ：$\mathbf{x}_{l+1} = \mathbf{x}_0 \mathbf{x}_l^T \mathbf{w}_l + \mathbf{b}_l + \mathbf{x}_l$，其中 $\mathbf{w}_l \in \mathbb{R}^d$ 是一个向量。这本质上是将 $\mathbf{x}_0$ 和 $\mathbf{x}_l$ 的所有 $d^2$ 个成对交互，通过一个<strong>秩为1</strong>的矩阵（$\mathbf{x}_0 \mathbf{x}_l^T$）进行隐式构建，再用一个向量 $\mathbf{w}_l$ 投影回 $d$ 维。</p>
</li>
<li><p>DCN V2 交叉层公式：$\mathbf{x}_{l+1} = \mathbf{x}_0 \odot (W_l \mathbf{x}_l + \mathbf{b}_l) + \mathbf{x}_l$，其中 $W_l \in \mathbb{R}^{d \times d}$ 是一个<strong>完整的矩阵</strong>，$\odot$ 表示逐元素乘法（Hadamard积）。将投影权重从一个向量 $\mathbf{w}_l$ 升级为一个矩阵 $W_l$。这使得模型能够为<strong>每一对特征交互</strong>学习一个独立的、更复杂的权重模式，而不是像原始 DCN 那样共享一个简单的投影向量。</p>
</li>
</ul>
<p>尽管效果很好，但包含 $d \times d$ 矩阵的交叉层在输入维度 $d$ 很大时，计算和存储成本依然较高，是线上服务的潜在瓶颈。为了解决全矩阵 $W$ 可能带来的计算和存储开销，论文观察到学习到的 $W$ 矩阵通常具有<strong>低秩特性</strong>。</p>
<ul>
<li><p><strong>低秩交叉层</strong>：将 $W<em>l$ 分解为两个“高瘦”矩阵 $U_l, V_l \in \mathbb{R}^{d \times r}, (r \ll d)$：$\mathbf{x}</em>{l+1} = \mathbf{x}_0 \odot (U_l (V_l^\top \mathbf{x}_l) + \mathbf{b}_l) + \mathbf{x}_l$，参数量从 $d^2$ 降至 $2dr$。</p>
</li>
<li><p><strong>混合专家低秩交叉层</strong>：受 MoE 启发，使用多个低秩“专家”，每个专家在不同子空间学习特征交互，并通过一个门控网络根据输入动态聚合。</p>
</li>
</ul>
<h3 id="CAN-Co-Action-Network"><a href="#CAN-Co-Action-Network" class="headerlink" title="CAN (Co-Action Network)"></a>CAN (Co-Action Network)</h3><p>传统方法<strong>笛卡尔积（Cartesian Product）</strong> 直接将特征组合视为新特征来增强特征交互，虽然表达能力强，但会导致参数量爆炸（$O(N^2 \times D)$），难以在大规模工业场景中部署。另一方面，基于深度神经网络的隐式交互方法如FM、DeepFM等虽能自动学习特征组合，但其表达能力有限，无法完全保留显式特征交互的信息。CAN是阿里发表在WSDM2022的工作，CAN的提出正是为了在<strong>保持笛卡尔积强大表达能力的同时，大幅降低参数量和计算开销</strong>，使其适用于工业级推荐与广告系统。</p>
<div align="center">
  <img src="CAN.png" height=100% width=100%>
</div>

<p>CAN通过<strong>Co-Action Unit</strong>模块显式建模特征对之间的交互，原理是对于一对特征（$P<em>{induction}$, $P</em>{feed}$），使用 $P<em>{feed}$ 的不同阶次 $P</em>{feed}, P<em>{feed}^2, P</em>{feed}^3$ embedding向量构建一个<strong>微网络（Micro-MLP）</strong>，将 $P_{induction}$ 的embedding向量作为该网络的输入，输出即为两特征的交互表示。Co-Action Unit 前向过程如下：</p>
<ol>
<li>从 $P_{induction}$ 重构MLP参数。</li>
<li>逐层计算：$h<em>0 = P</em>{feed}, h<em>i = \sigma(w</em>{i-1} \otimes h<em>{i-1} + b</em>{i-1}), \quad i=1,\dots,L$。其中使用了多阶增强 $H<em>{\text{Multi-order}}(P</em>{induction}, P<em>{feed}) = \sum</em>{c=1}^{C} H(P<em>{induction}, (P</em>{feed})^c)$</li>
<li>输出为各层输出的拼接：$F(u, m) = \big|_{i=1}^{L} h_i$</li>
</ol>
<p>CAN拥有近似笛卡尔积的表达能力，但是参数量大幅减少从 $O(N^2 \times D)$ 降至 $O(N \times (D’ + D))$。通过MLP和多阶增强捕捉复杂模式，效果显著优于FM、DeepFM等隐式方法，已成功应用于阿里巴巴广告系统，带来CTR +12%，RPM +8%的提升。但是整体计算复杂度较高，相比纯embedding模型，增加了MLP前向计算开销，且多层MLP需要充足数据才能有效训练。</p>
<h2 id="兴趣-序列模型"><a href="#兴趣-序列模型" class="headerlink" title="兴趣/序列模型"></a>兴趣/序列模型</h2><h3 id="DIN-Deep-Interest-Network"><a href="#DIN-Deep-Interest-Network" class="headerlink" title="DIN (Deep Interest Network)"></a>DIN (Deep Interest Network)</h3><p>在工业级 CTR 预测任务中，常见的深度学习模型如 Wide&amp;Deep、DeepFM、PNN 等遵循 Embedding&amp;MLP 范式，将大规模稀疏特征映射为低维embedding向量，通过 sum/average pooling 将变长行为序列转为固定长度向量，拼接所有特征向量后输入 MLP 进行预测。然而，用户兴趣是多样化的，比如同时关注服装、电子产品、母婴用品，用户对某个广告的点击往往只与其部分历史行为相关，传统方法将用户所有历史行为压缩为同一个固定长度向量，无论候选广告是什么，这导致模型表达能力受限，难以捕捉局部激活的兴趣。</p>
<div align="center">
  <img src="DIN.png" height=100% width=100%>
</div>

<p>阿里在KDD2018上提出了DIN算法，给阿里广告系统带来+10.0%CTR和+3.8%RPM提升。DIN 在基础 Embedding&amp;MLP 模型上引入<strong>局部激活单元</strong>，公式如下：</p>
<script type="math/tex; mode=display">v_U(A) = \sum_{j=1}^{H} a(e_j, v_A) \cdot e_j</script><p>其中 $e_j$ 是用户第 $ j $ 个行为的embedding向量；$ v_A $ 是候选广告的embedding向量；$ a(\cdot) $ 是前馈网络，输入为 $ e_j $ 和 $ v_A $，输出为激活权重 $ w_j $。和传统注意力机制不同的是，传统注意力机制使用softmax约束权重和为 1，DIN 不做归一化，保留权重的绝对值，以反映兴趣强度。</p>
<p>另外，论文中提到了个训练技术：</p>
<ul>
<li>Mini-Batch Aware 正则化：传统 L2 正则化需计算所有参数的 L2 范数，计算量大，DIN 提出仅对<strong>当前 mini-batch 中出现的特征</strong>计算正则化项，显著降低计算量，适用于亿级参数稀疏网络</li>
<li>数据自适应激活函数 Dice：PReLU 的 rectified point 固定为 0，不适合输入分布变化大的场景，Dice 根据输入分布的均值和方差自适应调整 rectified point。</li>
</ul>
<h3 id="DIEN-Deep-Interest-Evolution-Network"><a href="#DIEN-Deep-Interest-Evolution-Network" class="headerlink" title="DIEN (Deep Interest Evolution Network)"></a>DIEN (Deep Interest Evolution Network)</h3><p>DIN 通过注意力机制实现了用户兴趣的<strong>局部激活</strong>，但 DIN 将用户行为embedding直接加权求和作为兴趣表示，未建模兴趣的<strong>时序演变过程</strong>，用户兴趣可能随时间变化，DIN 未显式建模这种演化趋势。另外行为 ≠ 兴趣，用户行为是兴趣的载体，但二者并非严格对应。DIN 直接将行为作为兴趣，未挖掘其背后的<strong>隐含兴趣状态</strong>。传统 RNN/LSTM 可建模序列依赖，但隐藏状态缺乏对“兴趣表示”的显式监督，无法针对不同候选商品建模差异化的兴趣演化路径。</p>
<p>DIEN是阿里继DIN后发表在AAAI2019的工作，DIEN提出兴趣提取层（GRU + 辅助损失） + 兴趣演化层（AUGRU）的双层结构，显式建模兴趣的时序演化。DIEN在淘宝广告系统中CTR 提升 20.7%，eCPM 提升 17.1%。DIEN 为后续更复杂的序列模型如 DSIN、MIMN奠定了基础，是 CTR 建模从“静态兴趣”走向“动态演化”的关键里程碑。</p>
<div align="center">
  <img src="DIEN.png" height=100% width=100%>
</div>

<p><strong>兴趣提取层</strong>：使用 <strong>GRU</strong> 对用户行为序列建模，其中 $ i_t = e_b[t] $ 是第 $ t $ 个行为的embedding向量，$ h_t $ 是隐状态。</p>
<script type="math/tex; mode=display">u_t = \sigma(W^u i_t + U^u h_{t-1} + b^u)</script><script type="math/tex; mode=display">r_t = \sigma(W^r i_t + U^r h_{t-1} + b^r)</script><script type="math/tex; mode=display">\mathbf{h_t} = tanh(W^h i_t + r_t \odot U^h h_{t-1} + b^h)</script><script type="math/tex; mode=display">h_t = (1 - u_t) \odot h_{t-1} + u_t \odot \mathbf{h_t}</script><p><strong>辅助损失</strong>：引入监督信号，用下一时刻的真实行为 $ e_b[t+1] $ 作为正样本，随机采样的负样本 $ \hat{e}_b[t+1] $ 作为负样本，目标是使隐状态 $ h_t $ 能预测下一行为，从而提升兴趣表示的语义质量。</p>
<script type="math/tex; mode=display">
  L_{aux} = -\frac{1}{N} \sum_{i=1}^N \sum_t \left[ \log \sigma(h_t^i \cdot e_b^i[t+1]) + \log(1 - \sigma(h_t^i \cdot \hat{e}_b^i[t+1])) \right]</script><p><strong>兴趣演化层</strong>： 输入兴趣序列 $ [h<em>1, h_2, …, h_T] $，使用 AUGRU（GRU with attention update gate） 建模兴趣演化，并融入注意力机制，注意力分数 $a_t = \frac{\exp(h_t W e_a)}{\sum</em>{j=1}^T \exp(h_j W e_a)}$，其中 $ e_a $ 是候选商品的embedding向量。将注意力分数作用于更新门 $ u’_t $：$\tilde{u}’_t = a_t \cdot u’_t$。然后更新隐状态。AUGRU 使用向量形式的更新门，而非标量注意力分数，保留各维度的重要性差异，提升演化建模的灵活性。论文中还尝试了其他形式的GRU：</p>
<ul>
<li><strong>AIGRU</strong>：$ i’_t = h_t * a_t $，仅缩放输入，效果有限。</li>
<li><strong>AGRU</strong>：用标量 $ a_t $ 替换更新门，丢失维度信息。</li>
</ul>
<p><strong>预测层</strong>：最终兴趣状态 $ h’_T $ 与候选商品、用户画像等特征拼接，输入 MLP 进行 CTR 预测。</p>
<h3 id="BST-Behavior-Sequence-Transformer"><a href="#BST-Behavior-Sequence-Transformer" class="headerlink" title="BST (Behavior Sequence Transformer)"></a>BST (Behavior Sequence Transformer)</h3><p>BST是阿里2019发表的工作，BST 是<strong>首次将 Transformer 应用于推荐系统精排阶段</strong>的工业级模型。通过自注意力机制显式建模用户行为序列的时序依赖，学习上下文感知的商品表示。在淘宝推荐场景中在线 CTR 提升 7.57\%，并成功部署服务于亿万用户。为后续基于 Transformer 的推荐模型比如 BERT4Rec、SASRec 等奠定了基础。</p>
<div align="center">
  <img src="BST.png" height=100% width=100%>
</div>

<p>行为序列特征处理时每个商品使用 <code>item_id</code> 和 <code>category_id</code> 表示，并添加<strong>位置特征</strong> $pos(v_i) = t(v_t) - t(v_i)$，其中 $ t(v_t) $ 为推荐时间，$ t(v_i) $ 为用户点击商品 $ v_i $ 的时间戳，使用时间差而非正弦/余弦函数，在实践中效果更好。但是这种时间差位置编码可能无法完全捕捉绝对顺序或长期依赖。整体模型架构就是标准的Transformer，自注意力复杂度为 $O(n^2)$，当序列长度较长时计算开销大。</p>
<h3 id="DSIN-Deep-Session-Interest-Network"><a href="#DSIN-Deep-Session-Interest-Network" class="headerlink" title="DSIN (Deep Session Interest Network)"></a>DSIN (Deep Session Interest Network)</h3><p>DSIN是阿里发表在IJCAI2019的工作。DSIN首次将会话结构引入 CTR 预测，推动了 CTR 预测从“序列建模”到“会话感知建模”的演进。用户行为序列通常具有内在的会话结构，一个会话是指在特定时间窗口内发生的连续用户行为。 同一会话内的行为高度同质，而不同会话间的行为高度异质。比如用户可能在会话1浏览裤子，会话2浏览戒指，会话3浏览外套，兴趣在不同会话间发生明显转移。</p>
<p>DIN使用注意力机制激活与目标商品相关的行为，但未显式建模会话结构，忽略了行为序列的局部同质性。DIEN使用 GRU 建模兴趣演化，但未利用会话划分，可能因兴趣快速跳跃导致噪声。传统 RNN 方法直接对长序列建模可能因兴趣漂移而导致信息损失。DSIN利用会话内同质、会话间异质的特性，整体模型架构为：用户行为序列 → 会话划分层 → 会话兴趣提取层（自注意力 + Bias Encoding）→ 会话兴趣交互层（Bi-LSTM）→ 会话兴趣激活层（局部注意力）→ 拼接其他特征 → MLP → CTR预测</p>
<div align="center">
  <img src="DSIN.png" height=100% width=100%>
</div>

<p><strong>会话划分层（Session Division Layer）</strong>：将用户行为序列按<strong>时间间隔 &gt; 30分钟</strong>划分为多个会话（遵循常见实践）。设共有 $K$ 个会话，每个会话保留 $T$ 个行为，不足补零，过长截断。每个行为用 $d<em>{model}$ 维embedding向量表示，会话 $k$ 表示为矩阵：$Q_k \in \mathbb{R}^{T \times d</em>{model}}$。</p>
<p><strong>会话兴趣提取层（Session Interest Extractor Layer）</strong>：使用多头自注意力提取每个会话的兴趣表示，并引入Bias Encoding编码会话、位置、embedding维度偏置。Bias Encoding 公式 $BE<em>{(k,t,c)} = w_k^K + w_t^T + w_c^C$。其中$ \mathbf{w}^K \in \mathbb{R}^K $ 为会话偏置向量，$ \mathbf{w}^T \in \mathbb{R}^T $ 为行为在会话中的位置偏置向量，$ \mathbf{w}^C \in \mathbb{R}^{d</em>{model}} $ 为embedding维度的偏置向量。更新会话表示 $Q = Q + \mathbf{BE}$。$\mathbf{Q}$经多头自注意力计算后通过FFN得到 $\mathbf{I}_k^Q$，最后平均池化得到会话兴趣：$\mathbf{I}_k = \text{Avg}(\mathbf{I}_k^Q)$。</p>
<p><strong>会话兴趣交互层（Session Interest Interacting Layer）</strong>：使用 <strong>Bi-LSTM</strong> 建模会话兴趣序列的交互与演化 $H<em>t = \overrightarrow{h</em>{ft}} \oplus \overleftarrow{h_{bt}}$，输出隐藏状态序列 $H = [H_1, \dots, H_K]$，融入上下文信息。</p>
<p><strong>会话兴趣激活层（Session Interest Activating Layer）</strong>：使用DIN局部注意力机制计算各会话兴趣与目标商品的相关性权重。最后会将 $\mathbf{U}^I$、$\mathbf{U}^H$ 与user/item特征concat输入mlp。</p>
<h3 id="MIMN-Multi-channel-user-Interest-Memory-Network"><a href="#MIMN-Multi-channel-user-Interest-Memory-Network" class="headerlink" title="MIMN (Multi-channel user Interest Memory Network)"></a>MIMN (Multi-channel user Interest Memory Network)</h3><p>传统模型DIN、DIEN、DSIN通常处理较短序列（≤ 150），而真实场景中用户行为序列长度会更长。长序列建模面临的两个挑战是存储压力和计算延迟。阿里在KDD2019提出MIMN支持1000+ 长度行为序列，是一个算法-系统协同设计方案：</p>
<ul>
<li><strong>系统侧</strong>：设计<strong>用户兴趣中心UIC</strong>，将用户兴趣计算解耦为独立模块，离线更新，实时预测时直接读取兴趣状态，实现零延迟。</li>
<li><strong>算法侧</strong>：基于 NTM 改进设计 MIMN，引入<strong>记忆利用率正则化</strong>与<strong>记忆归纳单元</strong>，在固定大小记忆中高效存储长序列兴趣，并支持增量更新。</li>
</ul>
<div align="center">
  <img src="MIMN1.png" height=100% width=100%>
</div>

<p>左侧网络用于用户兴趣建模：用户行为序列 → NTM（记忆读写） → MIU（记忆归纳） → 兴趣表示。<br>右侧网络是传统CTR预测：兴趣表示 + 其他特征（用户/广告/上下文） → Embedding → MLP → CTR预测。</p>
<div align="center">
  <img src="MIMN2.png" height=100% width=100%>
</div>

<p><strong>神经图灵机NTM基础</strong>：维护外部记忆矩阵 $\mathbf{M}_t \in \mathbb{R}^{m \times d}$，$m$ 为记忆槽数，$d$ 为槽维度。每步接收行为embedding $\mathbf{e}_t$，通过控制器（全连接网络）生成读写键、添加向量、擦除向量。</p>
<p>记忆读取：</p>
<script type="math/tex; mode=display">w_t^r(i) = \frac{\exp(K(k_t, M_t(i)))}{\sum_{j=1}^{m} \exp(K(k_t, M_t(j)))}</script><script type="math/tex; mode=display">K(k_t, M_t(i)) = \frac{\mathbf{k}_t^T M_t(i)}{\|k_t\| \|\mathbf{M}_t(i)\|}</script><script type="math/tex; mode=display">r_t = \sum_{i=1}^{m} \mathbf{w}_t^r(i) M_t(i)</script><p>记忆写入：<script type="math/tex">M_t = (1 - E_t) \odot M_{t-1} + \mathbf{A}_t</script></p>
<script type="math/tex; mode=display">\mathbf{E}_t = \mathbf{w}_t^w \otimes \mathbf{e}_t</script><script type="math/tex; mode=display">\mathbf{A}_t = \mathbf{w}_t^w \otimes \mathbf{a}_t</script><p>其中$ \mathbf{M}_t $ 为擦除矩阵，$\mathbf{E}_t$ 为添加矩阵，$\otimes$ 为外积，$\odot$ 为逐元素乘。</p>
<p><strong>记忆利用率正则化</strong>：热门商品频繁出现会导致某些记忆槽过度使用，而其他槽闲置。记忆利用率正则化对写入权重进行重新平衡，鼓励均匀使用。其中 $g<em>t = \sum</em>{c=1}^{t} \mathbf{w}_c^{s}$ 为累积写入权重。</p>
<script type="math/tex; mode=display">P_t = \text{softmax}(W_g \mathbf{g}_t)</script><script type="math/tex; mode=display">\mathbf{w}_t^{s} = \mathbf{w}_t^w P_t</script><p>正则化损失为：</p>
<script type="math/tex; mode=display">L_{reg} = \lambda \sum_{i=1}^{m} \left( \mathbf{w}^{s}(i) - \frac{1}{m} \sum_{j=1}^{m} \mathbf{w}^{s}(j) \right)^2</script><script type="math/tex; mode=display">\mathbf{w}^{s} = \sum_{t=1}^{T} \mathbf{w}_t^{s}</script><p><strong>记忆归纳单元MIU</strong>：从 NTM 记忆中提取高阶兴趣演化信息。维护另一记忆矩阵 $\mathbf{S}_t \in \mathbb{R}^{m \times d}$，每个槽视为一个兴趣通道。每步选择 NTM 读取权重 $\mathbf{w}_t^r$ 的 top-k 个通道，使用 GRU 更新。</p>
<p><strong>用户兴趣中心UIC</strong>：离线时，当用户有新行为时，UIC 读取当前记忆状态 $(\mathbf{M}_t, \mathbf{S}_t)$，运行 NTM+MIU 更新，写回存储（如 TAIR）。实时预测时 RTP 服务器直接从存储读取用户当前记忆状态，拼接其他特征，输入右侧网络进行预测。实时预测仅需读取固定大小记忆张量，计算复杂度与序列长度无关。</p>
<p>可以看到MIMN的模型复杂度很高，包括NTM + MIU + 正则化，训练与调试难度大。记忆槽数 $m$ 影响模型容量，需根据数据分布调整。UIC 服务也需要独立维护，增加运维与同步成本。适用于行为丰富、用户活跃的场景，对低频用户效果有限。</p>
<h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><div class="table-container">
<table>
<thead>
<tr>
<th>维度</th>
<th><strong>DIN</strong></th>
<th><strong>DIEN</strong></th>
<th><strong>BST</strong></th>
<th><strong>DSIN</strong></th>
<th><strong>MIMN</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>思路</strong></td>
<td>兴趣局部激活</td>
<td>兴趣演化建模</td>
<td>Transformer序列建模</td>
<td>会话感知兴趣建模</td>
<td>记忆网络 + 系统解耦</td>
</tr>
<tr>
<td><strong>序列建模方式</strong></td>
<td>注意力加权池化</td>
<td>GRU + 注意力 + 辅助损失</td>
<td>自注意力（Transformer）</td>
<td>会话内自注意力 + 会话间Bi-LSTM</td>
<td>NTM + 记忆归纳单元（MIU）</td>
</tr>
<tr>
<td><strong>序列长度处理</strong></td>
<td>短（≈150）</td>
<td>短（≈150）</td>
<td>中（≈20-50）</td>
<td>中（≈200）</td>
<td><strong>超长（≈1000+）</strong></td>
</tr>
<tr>
<td><strong>是否建模时序</strong></td>
<td>否</td>
<td>是（GRU）</td>
<td>是（自注意力）</td>
<td>是（Bi-LSTM）</td>
<td>是（MIU-GRU）</td>
</tr>
<tr>
<td><strong>是否显式会话建模</strong></td>
<td>否</td>
<td>否</td>
<td>否</td>
<td><strong>是</strong></td>
<td>否</td>
</tr>
<tr>
<td><strong>是否支持增量更新</strong></td>
<td>否</td>
<td>否</td>
<td>否</td>
<td>否</td>
<td><strong>是（UIC）</strong></td>
</tr>
<tr>
<td><strong>存储开销</strong></td>
<td>高（存原始序列）</td>
<td>高（存原始序列）</td>
<td>高（存原始序列）</td>
<td>高（存原始序列）</td>
<td><strong>低（存记忆张量）</strong></td>
</tr>
<tr>
<td><strong>线上延迟</strong></td>
<td>中</td>
<td>高</td>
<td>中</td>
<td>高</td>
<td><strong>低（UIC解耦）</strong></td>
</tr>
<tr>
<td><strong>主要优势</strong></td>
<td>兴趣多样性建模</td>
<td>兴趣演化建模</td>
<td>强序列依赖捕捉</td>
<td>会话结构利用</td>
<td>超长序列支持 + 低延迟</td>
</tr>
<tr>
<td><strong>主要挑战</strong></td>
<td>未建模时序依赖</td>
<td>训练复杂，延迟高</td>
<td>位置编码敏感，计算复杂</td>
<td>会话划分依赖阈值</td>
<td>系统架构复杂，同步风险</td>
</tr>
</tbody>
</table>
</div>
<h2 id="长序列模型"><a href="#长序列模型" class="headerlink" title="长序列模型"></a>长序列模型</h2><h3 id="SIM-Search-based-User-Interest-Modeling"><a href="#SIM-Search-based-User-Interest-Modeling" class="headerlink" title="SIM (Search-based User Interest Modeling)"></a>SIM (Search-based User Interest Modeling)</h3><p>DIN、DIEN能处理数百长度的用户行为序列，但无法处理数千甚至数万长度的“终身行为序列”。阿里之前提出的MIMN模型虽能处理最多1000长度的序列，但当序列长度进一步增加比如1万以上时，模型性能下降，因为固定大小的记忆矩阵中引入了过多噪声。SIM发表于2020年，将用户行为序列扩展至54000，是MIMN的54倍，解决了超长序列建模难题。SIM 采用<strong>两阶段搜索机制</strong>，先粗筛再精搜，从海量行为数据中提取相关兴趣。在阿里巴巴展示广告系统中，CTR 提升 7.1%，RPM 提升 4.4%。</p>
<div align="center">
  <img src="SIM.png" height=100% width=100%>
</div>

<ol>
<li><strong>General Search Unit（通用搜索单元，GSU）</strong>  从原始长序列中快速筛选出与候选物品相关的子序列，将序列长度从数万降至数百。Hard-search仅保留与候选物品同类别的行为，是非参数化的，效率高，适合线上系统。Soft-search使用embedding向量计算相似度，借助<strong>最大内积搜索（MIPS）</strong> 如 ALSH 加速 Top-K 检索。</li>
<li><strong>Exact Search Unit（精确搜索单元，ESU）</strong>  在筛选后的子序列上使用注意力机制DIEN进行精细建模，捕捉用户对候选物品的具体兴趣。</li>
</ol>
<p>通过两阶段搜索将计算复杂度从线性降至子线性，可以高效处理超长序列。但软搜索计算成本高，需维护embedding索引，存储与检索开销大。</p>
<h3 id="ETA-End-to-end-Target-Attention"><a href="#ETA-End-to-end-Target-Attention" class="headerlink" title="ETA (End-to-end Target Attention)"></a>ETA (End-to-end Target Attention)</h3><p>SIM通过辅助任务从长序列中检索Top-K相似物品，再与候选物品进行注意力计算。但检索阶段使用的信息（如类别属性或预训练embedding）与主CTR任务的目标不一致，导致性能提升受限。ETA是阿里2021年继SIM的工作，实现检索与CTR任务的端到端训练，消除两阶段中检索目标与CTR目标不一致问题，ETA将相似度计算从高维内积降为低维汉明距离计算，支持在线学习，避免使用离线的预训练embedding或倒排索引，实现embedding的实时更新与同步。线上A/B测试带来3.1%的GMV提升。</p>
<div align="center">
  <img src="ETA.png" height=100% width=100%>
</div>

<p>ETA 使用局部敏感哈希SimHash将高维embedding向量压缩为二进制fingerprint，通过汉明距离快速检索Top-K相似行为物品，再进行目标注意力计算。检索部分不参与梯度更新，仅依赖固定的随机投影矩阵。embedding更新后，SimHash fingerprint同步更新，保证检索与CTR目标的一致性。直接使用Target Attention的计算复杂度为 $O(L×B×d)$，ETA的计算复杂度为 $O(L×B)$，其中 $L$ 是序列长度，$B$ 是候选物品数量，$d$ 是embedding维度，虽然ETA支持上千长度序列，但若序列过长（如数万），汉明距离计算仍会成为瓶颈。</p>
<h3 id="SDIM-Sampling-based-Deep-Interest-Modeling"><a href="#SDIM-Sampling-based-Deep-Interest-Modeling" class="headerlink" title="SDIM (Sampling-based Deep Interest Modeling)"></a>SDIM (Sampling-based Deep Interest Modeling)</h3><p>SDIM是美团发表在CIKM2022的工作，是一种基于哈希采样的端到端长序列用户兴趣建模方法。SDIM 避免从长序列中检索Top-K相似物品带来的信息损失和偏差，将计算复杂度从 $O(BLd)$ 降低至与序列长度 $L$ 无关的水平。</p>
<div align="center">
  <img src="SDIM.png" height=100% width=100%>
</div>

<p>SDIM 通过多轮SimHash将用户行为物品与候选物品映射到哈希signature，直接聚合与候选物品signature相同的行为物品作为用户兴趣表示。</p>
<p><strong>1. 哈希signature生成</strong>：使用 SimHash 对行为序列物品 $\mathbf{s}_j$ 和候选物品 $\mathbf{q}$ 进行哈希：$h(\mathbf{x}, \mathbf{r}) = \text{sign}(\mathbf{r}^\top \mathbf{x})$，其中 $\mathbf{r} \sim \mathcal{N}(0,1)$ 为随机投影向量。</p>
<p><strong>2. 多轮哈希聚合</strong>：为降低噪声，采用 $(m, \tau)$-参数化 SimHash，采样 $m$ 个哈希函数，每 $\tau$ 个哈希码合并为一个signature。行为物品 $\mathbf{s}_j$ 与候选物品 $\mathbf{q}$ 碰撞的条件是它们在同一个signature桶中 $\tilde{p}^{(\mathbf{R}_i)}$</p>
<p><strong>3. 兴趣聚合</strong>：直接聚合与候选物品signature相同的行为物品：$\text{Attn}(\mathbf{q},\mathbf{S}) = \frac{1}{m/\tau} \sum<em>{i=1}^{m/\tau} \ell_2\left( \sum</em>{j=1}^L \tilde{p}^{(\mathbf{R}_i)}_j \mathbf{s}_j \right)$，其中 $\ell_2$ 为 L2 归一化，使注意力权重和为 1。</p>
<p><strong>4. 理论近似性</strong>：期望碰撞概率与向量夹角相关：$\mathbb{E}[\tilde{p}_j] = \left(1 - \frac{\arccos(\mathbf{q}^\top \mathbf{s}_j)}{\pi}\right)^\tau$，当 $m/\tau$ 足够大时，SDIM 的注意力分布与 softmax 目标注意力高度一致。</p>
<h3 id="对比-1"><a href="#对比-1" class="headerlink" title="对比"></a>对比</h3><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th><strong>SIM</strong></th>
<th><strong>ETA</strong></th>
<th><strong>SDIM</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>思路</strong></td>
<td>两阶段检索（类目/预训练embedding） + 目标注意力</td>
<td>端到端哈希检索（SimHash + 汉明距离） + 目标注意力</td>
<td>端到端哈希采样（SimHash 签名聚合） + 直接兴趣聚合</td>
</tr>
<tr>
<td><strong>检索/选择方式</strong></td>
<td>基于属性（如类目）或预训练embedding检索 Top-K</td>
<td>基于 SimHash 指纹的汉明距离检索 Top-K</td>
<td>基于多轮 SimHash 签名直接聚合相同签名的行为物品</td>
</tr>
<tr>
<td><strong>主要优点</strong></td>
<td>1. 实现简单<br>2. 检索速度快<br>3. 可处理长序列</td>
<td>1. 端到端训练，目标一致<br>2. 哈希检索效率高<br>3. 优于SIM/UBR4CTR</td>
<td>1. 无需显式检索，避免偏差<br>2. 计算效率最高<br>3. 支持极长序列（如2000）<br>4. 在线效果显著</td>
</tr>
<tr>
<td><strong>主要缺点</strong></td>
<td>1. 检索目标与CTR不一致<br>2. 依赖离线索引<br>3. 检索可能丢失信息</td>
<td>1. 仍需Top-K检索<br>2. 哈希冲突可能引入噪声<br>3. 复杂度与L相关</td>
<td>1. 哈希冲突可能引入噪声<br>2. 参数敏感（需调优m, τ）<br>3. 需额外传输开销</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>1. 类目信息强相关<br>2. 可接受离线索引延迟<br>3. 长序列</td>
<td>1. 需要端到端训练<br>2. 实时性要求高<br>3. 序列较长（~1000）</td>
<td>1. 极长序列建模（&gt;2000）<br>2. 对延迟要求极高<br>3. 希望避免检索偏差</td>
</tr>
</tbody>
</table>
</div>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.ismll.uni-hildesheim.de/pub/pdfs/Rendle_et_al2011-Context_Aware.pdf">Fast Context-aware Recommendations with Factorization Machines</a></li>
<li><a target="_blank" rel="noopener" href="https://scontent-hkg1-1.xx.fbcdn.net/v/t39.8562-6/240842589_204052295113548_74168590424110542_n.pdf?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=7XnLUYJMKswQ7kNvwF-KOPA&amp;_nc_oc=AdmcSNMLf6PFnnmyy0-IdyRkvtsul24ZfU1pC3aScB_fiM8bAndL7sFBcVbJIPqSzQs&amp;_nc_zt=14&amp;_nc_ht=scontent-hkg1-1.xx&amp;_nc_gid=GgjAOmYtCd45yabbDULluA&amp;oh=00_AfkIgb1zxBfUf3ZhmgAX5N_1_N0_gaAQLC8gUhsBrMdFbA&amp;oe=6936DD8A">Practical Lessons from Predicting Clicks on Ads at Facebook</a></li>
<li><a target="_blank" rel="noopener" href="https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf">Field-aware Factorization Machines for CTR Prediction</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.07792">Wide &amp; Deep Learning for Recommender Systems</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.04247">DeepFM: A Factorization-Machine based Neural Network for CTR Prediction</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1708.05123">Deep &amp; Cross Network for Ad Click Predictions</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2008.13535">DCN V2: Improved Deep &amp; Cross Network and Practical Lessons for Web-scale Learning to Rank Systems</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2011.05625">CAN: Feature Co-Action for Click-Through Rate Prediction</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.06978">Deep Interest Network for Click-Through Rate Prediction</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1809.03672">Deep Interest Evolution Network for Click-Through Rate Prediction</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.06874">Behavior Sequence Transformer for E-commerce Recommendation in Alibaba</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.06482">Deep Session Interest Network for Click-Through Rate Prediction</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.09248">Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.05639">Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2108.04468">End-to-End User Behavior Retrieval in Click-Through RatePrediction Model</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.10249">Sampling Is All You Need on Modeling Long-Term User Behaviors for CTR Prediction</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/462090167">如何在工业界优化点击率预估</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/432817787">【总结】推荐系统——精排篇【1】FM/FFM/GBDT+LR/MLR</a></li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">贪钱算法还我头发</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://xfliu1998.github.io/2025/12/07/Rank-Model/">https://xfliu1998.github.io/2025/12/07/Rank-Model/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><a class="post-meta__tags" href="/tags/Search-Ads-Reco/">Search, Ads &amp; Reco</a></div><div class="post_share"><div class="social-share" data-image="/2025/12/07/Rank-Model/cover.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2026/01/18/Bidding/"><img class="prev-cover" src="/2026/01/18/Bidding/cover.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Ad Bidding</div></div></a></div><div class="next-post pull-right"><a href="/2025/11/26/LLM-Ad&amp;Rec/"><img class="next-cover" src="/2025/11/26/LLM-Ad&amp;Rec/cover.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">LLM —— LLM4Ad&amp;Rec</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2024/03/31/Causal-Inference/" title="Causal Inference"><img class="cover" src="/2024/03/31/Causal-Inference/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-31</div><div class="title">Causal Inference</div></div></a></div><div><a href="/2021/12/03/4-Smart-Search-and-Recommendation-System-Principles-Algorithm-and-Application/" title="Smart Search and Recommendation System Principles, Algorithm and Application"><img class="cover" src="/2021/12/03/4-Smart-Search-and-Recommendation-System-Principles-Algorithm-and-Application/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-03</div><div class="title">Smart Search and Recommendation System Principles, Algorithm and Application</div></div></a></div><div><a href="/2025/10/24/LLM-RL4LLM/" title="LLM —— RL4LLM"><img class="cover" src="/2025/10/24/LLM-RL4LLM/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-24</div><div class="title">LLM —— RL4LLM</div></div></a></div><div><a href="/2025/09/18/LLM-SFT/" title="LLM —— SFT"><img class="cover" src="/2025/09/18/LLM-SFT/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-18</div><div class="title">LLM —— SFT</div></div></a></div><div><a href="/2025/08/03/LLM-Tokenize/" title="LLM —— Tokenize"><img class="cover" src="/2025/08/03/LLM-Tokenize/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-03</div><div class="title">LLM —— Tokenize</div></div></a></div><div><a href="/2025/07/26/LLM-Position-Embedding/" title="LLM —— Position Embedding"><img class="cover" src="/2025/07/26/LLM-Position-Embedding/cover.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-26</div><div class="title">LLM —— Position Embedding</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">贪钱算法还我头发</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">66</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">14</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xfliu1998"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xfliu1998" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:liuxiaofei_7@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://www.zhihu.com/people/fan-xu-15-35/posts" target="_blank" title="Zhihu"><i class="fa fa-address-card"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">👋你好呀，欢迎围观～搭建这个小站源于一个朴素的愿望：对抗遗忘，沉淀思考。期待在代码与逻辑的世界里探索技术的深度与广度，永远保持热情与好奇。</div></div><div class="card-widget" id="newYear"><div class="item-headline"><i></i><span></span></div><div class="item-content"><div id="newYear-main"><div class="mask"></div> <p class="title"></p> <div class="newYear-time"></div> <p class="today" style="text-align: right;"></p> </div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E2%80%94%E2%80%94%E4%BB%8E%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%E5%BB%BA%E6%A8%A1%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%85%B4%E8%B6%A3%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1"><span class="toc-number">1.</span> <span class="toc-text">推荐系统技术演进——从特征交叉建模到深度兴趣序列建模</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.</span> <span class="toc-text">特征交叉模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#LR-Logistic-Regression"><span class="toc-number">1.1.1.</span> <span class="toc-text">LR (Logistic Regression)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#POLY2-Polynomial-2"><span class="toc-number">1.1.2.</span> <span class="toc-text">POLY2 (Polynomial-2)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FM-Factorization-Machines"><span class="toc-number">1.1.3.</span> <span class="toc-text">FM (Factorization Machines)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GBDT-LR"><span class="toc-number">1.1.4.</span> <span class="toc-text">GBDT+LR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FFM-Field-aware-FM"><span class="toc-number">1.1.5.</span> <span class="toc-text">FFM (Field-aware FM)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WDL-Wide-amp-Deep-Learning"><span class="toc-number">1.1.6.</span> <span class="toc-text">WDL (Wide &amp; Deep Learning)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DeepFM"><span class="toc-number">1.1.7.</span> <span class="toc-text">DeepFM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DCN-Deep-amp-Cross-Network"><span class="toc-number">1.1.8.</span> <span class="toc-text">DCN (Deep &amp; Cross Network)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DCN-V2"><span class="toc-number">1.1.9.</span> <span class="toc-text">DCN V2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CAN-Co-Action-Network"><span class="toc-number">1.1.10.</span> <span class="toc-text">CAN (Co-Action Network)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B4%E8%B6%A3-%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.2.</span> <span class="toc-text">兴趣&#x2F;序列模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DIN-Deep-Interest-Network"><span class="toc-number">1.2.1.</span> <span class="toc-text">DIN (Deep Interest Network)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DIEN-Deep-Interest-Evolution-Network"><span class="toc-number">1.2.2.</span> <span class="toc-text">DIEN (Deep Interest Evolution Network)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BST-Behavior-Sequence-Transformer"><span class="toc-number">1.2.3.</span> <span class="toc-text">BST (Behavior Sequence Transformer)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DSIN-Deep-Session-Interest-Network"><span class="toc-number">1.2.4.</span> <span class="toc-text">DSIN (Deep Session Interest Network)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MIMN-Multi-channel-user-Interest-Memory-Network"><span class="toc-number">1.2.5.</span> <span class="toc-text">MIMN (Multi-channel user Interest Memory Network)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94"><span class="toc-number">1.2.6.</span> <span class="toc-text">对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%95%BF%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.</span> <span class="toc-text">长序列模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SIM-Search-based-User-Interest-Modeling"><span class="toc-number">1.3.1.</span> <span class="toc-text">SIM (Search-based User Interest Modeling)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ETA-End-to-end-Target-Attention"><span class="toc-number">1.3.2.</span> <span class="toc-text">ETA (End-to-end Target Attention)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SDIM-Sampling-based-Deep-Interest-Modeling"><span class="toc-number">1.3.3.</span> <span class="toc-text">SDIM (Sampling-based Deep Interest Modeling)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94-1"><span class="toc-number">1.3.4.</span> <span class="toc-text">对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">1.4.</span> <span class="toc-text">参考</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('/2025/12/07/Rank-Model/cover.jpeg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2026  <i id="heartbeat" class="fa fas fa-heartbeat"></i> 贪钱算法还我头发</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div><head><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/HCLonely/images@master/others/heartbeat.min.css"></head></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '1b0c10ce649501ea4a72',
      clientSecret: '741b5e861137e3d5a482bba272c8201b78da6cb0',
      repo: 'xfliu1998.github.io',
      owner: 'xfliu1998',
      admin: ['xfliu1998'],
      id: '5ee6d283fe9ddca5c5d585c7b90911f0',
      language: 'en',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: true,
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script src="/js/script.js?v1"></script><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async data-pjax src="https://cdn.wpon.cn/2022-sucai/Gold-ingot.js"></script><script async data-pjax src="/js/newYear.js"></script><script async src="//at.alicdn.com/t/font_2264842_b004iy0kk2b.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='all'|| 'all' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Machine-Learning-and-Deep-Learning/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 机器学习与深度学习 (18)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Data-Structures-and-Algorithms/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">😼 数据结构与算法 (16)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Data-Analysis-and-Processing/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 数据分析与处理 (7)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Reading-Notes/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 阅读笔记 (7)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://xfliu1998.github.io/categories/Daily/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 日常随笔 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="https://xfliu1998.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/03/25/Papers-Ideas/" alt=""><img width="48" height="48" src="2023/03/25/Papers-Ideas/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-03-25</span><a class="blog-slider__title" href="2023/03/25/Papers-Ideas/" alt="">Papers Ideas</a><div class="blog-slider__text">大模型时代下的科研思路</div><a class="blog-slider__button" href="2023/03/25/Papers-Ideas/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/09/17/Papers-Summary/" alt=""><img width="48" height="48" src="2022/09/17/Papers-Summary/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-09-17</span><a class="blog-slider__title" href="2022/09/17/Papers-Summary/" alt="">Papers Summary</a><div class="blog-slider__text">论文总结笔记</div><a class="blog-slider__button" href="2022/09/17/Papers-Summary/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/11/16/LLM-GRs/" alt=""><img width="48" height="48" src="2025/11/16/LLM-GRs/cover.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-11-16</span><a class="blog-slider__title" href="2025/11/16/LLM-GRs/" alt="">LLM —— GRs</a><div class="blog-slider__text">生成式在推荐广告领域的落地</div><a class="blog-slider__button" href="2025/11/16/LLM-GRs/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/11/26/LLM-Ad&amp;Rec/" alt=""><img width="48" height="48" src="2025/11/26/LLM-Ad&amp;Rec/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-11-26</span><a class="blog-slider__title" href="2025/11/26/LLM-Ad&amp;Rec/" alt="">LLM —— LLM4Ad&amp;Rec</a><div class="blog-slider__text">LLM在广告推荐领域的应用范式</div><a class="blog-slider__button" href="2025/11/26/LLM-Ad&amp;Rec/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/12/07/Rank-Model/" alt=""><img width="48" height="48" src="2025/12/07/Rank-Model/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-12-07</span><a class="blog-slider__title" href="2025/12/07/Rank-Model/" alt="">Rank Model</a><div class="blog-slider__text">精排模型——从特征交叉建模到深度兴趣序列建模</div><a class="blog-slider__button" href="2025/12/07/Rank-Model/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/01/18/Bidding/" alt=""><img width="48" height="48" src="2026/01/18/Bidding/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-01-18</span><a class="blog-slider__title" href="2026/01/18/Bidding/" alt="">Ad Bidding</a><div class="blog-slider__text">广告出价算法：从传统式到生成式</div><a class="blog-slider__button" href="2026/01/18/Bidding/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/01/21/Learning-Framework/" alt=""><img width="48" height="48" src="2022/01/21/Learning-Framework/cover.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-01-21</span><a class="blog-slider__title" href="2022/01/21/Learning-Framework/" alt="">学习大纲</a><div class="blog-slider__text">目录</div><a class="blog-slider__button" href="2022/01/21/Learning-Framework/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<container><style>#git_container{min-height: 280px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></container>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("https://gitcalendar.fomal.cc/api?xfliu1998",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'xfliu1998')
    }
  </script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>